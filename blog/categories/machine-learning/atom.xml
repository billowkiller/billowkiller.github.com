<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Machine Learning | Billowkiller's Blog]]></title>
  <link href="http://billowkiller.github.io/blog/categories/machine-learning/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2016-03-17T00:12:43+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Practice in Recommend System]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/16/rs-note/"/>
    <updated>2016-03-16T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/16/rs-note</id>
    <content type="html"><![CDATA[<p>本文作为推荐系统实践笔记。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/11336234.jpg" width="350px" /></p>

<p>推荐系统是为了解决信息过载问题，一般说来这个问题还可以用搜索引擎解决，但是搜索引擎需要需要用户主动提供准确的关键词来寻找信息；推荐系统不需要用户提供明确的需求,而是通过分析用户的历史行为给用户的兴趣建模,从而主动给用户推荐能够满足他们兴趣和需求的信息。</p>

<p>总的来说，<strong>搜索引擎满足了用户有明确目的时的主动查找需求,而推荐系统能够在用户没有明确目的的时候帮助他们发现感兴趣的新内容</strong>。</p>

<!--more-->

<p>推荐系统可以更好地发掘物品的长尾，推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。个性化推荐系统应用包括：</p>

<ul>
  <li>电子商务</li>
  <li>电影和视频网站</li>
  <li>个性化音乐网站电台</li>
  <li>社交网络</li>
  <li>个性化阅读</li>
  <li>基于位置的服务</li>
  <li>个性化邮件</li>
  <li>个性化广告</li>
</ul>

<p>一般来说,一个新的推荐算法最终上线，需要完成3个实验：</p>

<ul>
  <li>首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。</li>
  <li>然后，需要通过用户调查确定它的用户满意度不低于现有算法。</li>
  <li>最后，通过在线的AB测试确定它在我们关系的指标上由于现有的算法。</li>
</ul>

<p>指标包括以下：</p>

<ol>
  <li>
    <p>用户满意度，反馈按钮，点击率，用户停留时间，转化率</p>
  </li>
  <li>
    <p>预测准确度，可以通过离线实验计算</p>

    <ul>
      <li>
        <p>评分预测的预测准确度一般通过均方根误差(RMSE)和平均绝对误差(MAE)计算。</p>

        <script type="math/tex; mode=display"> RMSE = \frac{\sqrt{\sum_{u,i \in T}(r_{ui}-\hat{r}_{ui})^2}}{\vert T \vert}，MAE = \frac{\sum_{u,i \in T} \vert r_{ui}-\hat{r}_{ui} \vert}{\vert T \vert} </script>

        <ul>
          <li>用户u和物品i，$r_{ui}$ 是用户u对物品i的实际评分，$\hat{r}_{ui}$ 是推荐算法给出的预测评分</li>
          <li>RMSE加大了对预测不准的用户物品评分的惩罚，因而对系统的评测更加苛刻；如果评分系统是基于整数建立的，那么对预测结果取整会降低MAE的误差。</li>
        </ul>
      </li>
      <li>
        <p>TopN推荐的预测准确率一般通过准确率(precision)/召回率(recall)度量</p>

        <script type="math/tex; mode=display"> Recall = \frac{\sum_{u \in U} \vert R(u) \cap T(u) \vert }{\sum_{u \in U} \vert  T(u) \vert}，Precision = \frac{\sum_{u \in U} \vert R(u) \cap T(u) \vert }{\sum_{u \in U} \vert  R(u) \vert} </script>

        <ul>
          <li>$R(u)$ 是根据用户在训练集上的行为给用户作出的推荐列表，而 $T(u)$ 是用户在测试集上的行为列表。</li>
          <li>
            <u>召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中,而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录</u>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>覆盖率</p>

    <ul>
      <li>描述一个推荐系统对物品长尾的发掘能力。表示推荐系统能够推荐出来的物品占总物品集合的比例。</li>
      <li>系统的用户集合为 $U$，推荐系统给每个用户推荐一个长度为N的物品列表 $R(u)$。</li>
      <li>物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力，可以用信息熵和基尼系数定义覆盖率。分配不均匀，基尼系数大，表示覆盖率低。</li>
    </ul>
  </li>
  <li>
    <p>多样性</p>

    <ul>
      <li>为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性，描述推荐列表物品两两之间的不相似性。</li>
    </ul>
  </li>
  <li>
    <p>新颖性</p>
  </li>
  <li>
    <p>惊喜度</p>
  </li>
  <li>
    <p>信任度</p>

    <ul>
      <li>需要增加推荐系统的透明度</li>
      <li>虑用户的社交网络信息,利用用户的好友信息给用户做推荐,并且用好友进行推荐解释</li>
    </ul>
  </li>
  <li>
    <p>实时性</p>

    <ul>
      <li>实时地更新推荐列表来满足用户新的行为变化</li>
      <li>能够将新加入系统的物品推荐给用户</li>
    </ul>
  </li>
  <li>
    <p>健壮性</p>
  </li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-14/24652935.jpg" width="500px" /></p>

<h2 id="section">一 利用用户行为数据</h2>

<p>存储的日志种类：</p>

<ul>
  <li>raw log：网站在运行过程中都产生大量原始日志</li>
  <li>session log：原始日志按照用户行为汇总成会话日志，其中每个会话表示一次用户行为和对应的服务</li>
  <li>impression log：展示日志，session log的一种，在搜索引擎和搜索广告系统中,服务会为每次查询生成一个展示日志，记录了查询和返回结。</li>
  <li>click log：点击了某个结果,这个点击信息会被服务器截获并存储在点击日志</li>
</ul>

<p>一个并行程序会周期性地归并展示日志和点击日志,得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。会话日志通常存储在分布式数据仓库中,如支持离线分析的Hadoop Hive和支持在线分析的Google Dremel。</p>

<p>用户行为在个性化推荐系统中一般分两种</p>

<ul>
  <li>显性反馈行为(explicit feedback)</li>
  <li>隐性反馈 行为(implicit feedback)</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-14/78274688.jpg" width="500px" /></p>

<p>仅仅基于用户行为数据设计的推荐算法一般称为<strong>协同过滤算法</strong>，包括但不限于：</p>

<ul>
  <li>基于邻域的方法(neighborhood-based)
    <ul>
      <li>基于用户的协同过滤算法</li>
      <li>基于物品的协同过滤算法</li>
    </ul>
  </li>
  <li>隐语义模型 (latent factor model)</li>
  <li>基于图的随机游走算法(random walk on graph)</li>
</ul>

<h3 id="section-1">1.1 基于用户的协同过滤算法</h3>

<p>基于用户的协同过滤算法主要包括两个步骤。</p>

<ol>
  <li>找到和目标用户兴趣相似的用户集合。</li>
  <li>找到这个集合中的用户喜欢的,且目标用户没有听说过的物品推荐给目标用户.</li>
</ol>

<p>步骤1的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要利用行为的相似度计算兴趣的相似度。给定用户u和用户v，$N(u)$ 表示用户u曾经有过正反馈的物品集合，$N(v)$ 为用户v曾经有过正反馈的物品集合。</p>

<p>可以通过如下的Jaccard公式简单地计算u和v的兴趣相似度:</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\vert N(u) \cup N(v) \vert} </script>

<p>或者通过余弦相似度计算:</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\sqrt{\vert N(u) \vert  \vert N(v) \vert}} </script>

<p>事实上,很多用户相互之间并没有对同样的物品产生过行为,即很多时候 $\vert N(u) \cap N(v) \vert = 0$。我们可以首先计算出$\vert N(u) \cap N(v) \vert \neq 0$ 的用户对 $(u,v)$，然后再对这种情况除以分母。</p>

<p>为此,可以首先建立物品到用户的倒排表,对于每个物品都保存对该物品产生过行为的用户列表。令稀疏矩阵 $C[u][v] = \vert N(u) \cap N(v) \vert$。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/4819139.jpg" width="300px" /></p>

<p>得到用户之间的兴趣相似度后,UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度:</p>

<script type="math/tex; mode=display"> p(u,i) = \sum_{v \in S(u,K) \cap N(i)} w_{uv} r_{vi} </script>

<p>其中, $S(u, K)$ 包含和用户u兴趣最接近的K个用户, $N(i)$ 是对物品i有过行为的用户集合, $w_{uv}$ 是用户u和用户v的兴趣相似度, $r_{vi}$ 代表用户v对物品i的兴趣。</p>

<p>可以使用改进的余弦相似度公式来提高UserCF的推荐性能：</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\sum_{i \in  N(u) \cap N(v)}\frac{1}{log(1+N(i))}}{\sqrt{\vert N(u) \vert  \vert N(v) \vert}} </script>

<p>该公式惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响。</p>

<h3 id="section-2">1.2 基于物品的协同过滤算法</h3>

<p>基于物品的协同过滤算法(简称ItemCF)给用户推荐那些和他们之前喜欢的物品相似的物品。ItemCF算法并不利用物品的内容属性计算物品之间的相似度,它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为,物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。</p>

<p>基于物品的协同过滤算法主要分为两步。</p>

<ol>
  <li>计算物品之间的相似度。</li>
  <li>根据物品的相似度和用户的历史行为给用户生成推荐列表。</li>
</ol>

<p>可以用下面的公式定义物品的相似度, $\vert N(i) \vert$ 是喜欢物品i的用户数:</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\vert N(i) \cap N(j) \vert}{\sqrt{\vert N(i) \vert \vert N(j) \vert}} </script>

<p>上述公式惩罚了物品j的权重,因此减轻了热门物品会和很多物品相似的可能性。和UserCF算法类似,用ItemCF算法计算物品相似度时也可以首先建立用户—物品倒排表,然后对于每个用户,将他物品列表中的物品两两在共现矩阵C中加1。</p>

<p>如果j非常热门,那么上面公式的分子 就会越来越接近 $N(i)$。尽管上面的公式分母已经考虑到了j的流行度,但在实际应用中,热门的j仍然会获得比较大的相似度。可以采用下面的公式加大惩罚：</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\vert N(i) \cap N(j) \vert}{\vert N(i) \vert^{1-\alpha} \vert N(j) \vert ^{\alpha}} </script>

<p>其中 $\alpha \in [0.5 ,1]$。通过提高$\alpha$, 就可以惩罚热门的j。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/51979298.jpg" width="400px" /></p>

<p>在得到物品之间的相似度后,ItemCF通过如下公式计算用户u对一个物品j的兴趣:</p>

<script type="math/tex; mode=display"> p(u,j) = \sum_{i \in S(j,K) \cap N(u)} w_{ji} r_{ui} </script>

<p>这里 $N(u)$ 是用户喜欢的物品的集合, $S(j,K)$ 是和物品j最相似的K个物品的集合, $w_{ji}$ 是物品j和i的相似度, $r_{ui}$是用户u对物品i的兴趣。该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。</p>

<p>类似UserCF中的惩罚公式，ItemCF中认为不活跃的用户的贡献程度要比活跃用户更大，所以应该加上Inverse User Frequence修正物品相似度的计算公式：</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\sum_{u \in  N(i) \cap N(j)}\frac{1}{log(1+N(u))}}{\sqrt{\vert N(i) \vert  \vert N(j) \vert}} </script>

<p>另外如果将ItemCF的相似度矩阵按最大值归一化,可以提高推荐的准确率。如果已经得到了物品相似度矩阵 $w$, 那么可以用如下公式得到归一化之后的相似度 矩阵 $w’$：</p>

<script type="math/tex; mode=display"> w'_{ij} = \frac{w_{ij}}{max_j w_{ij}} </script>

<p>归一化的好处不仅仅在于增加推荐的准确度,它还可以提高推荐的覆盖率和多样性。一般来说,热门的类其类内物品相似度一般比较大。如果不进行归一化,就会推荐 比较热门的类里面的物品,而这些物品也是比较热门的。因此,推荐的覆盖率就比较低。相反, 如果进行相似度的归一化,则可以提高推荐系统的覆盖率。</p>

<h3 id="usercfitemcf">1.3 UserCF和ItemCF的综合比较</h3>

<p>UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品,而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算法的原理可以看到,UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点,而ItemCF的推荐结果着重于维系用户的历史兴趣。</p>

<p>UserCF适合用于新闻推荐</p>

<ul>
  <li>可以给用户推荐有相似爱好的其他用户看的新闻，这样在抓住热点和时效性的同时，保证了一定程度的个性化。</li>
  <li>技术角度考量，物品的更新速度远远快于新用户的加入速度。</li>
</ul>

<p>ItemCF适合于图书、电子商务和电影网站等的推荐：</p>

<ul>
  <li>在这些网站中，用户的兴趣是比较固定和持久的</li>
  <li>用户不需要流行物品，而是通过自己熟悉领域的知识自己判断物品的质量</li>
  <li>从技术上考虑，用户数目往往非常庞大，物品的数目则是比较少的</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/2625074.jpg" width="700px" /></p>

<h3 id="section-3">1.4 隐语义模型</h3>

<p>除了使用UserCF、ItemCF外，还可以对书和物品的兴趣进行分类做推荐。要解决自动地找到那些类,然后进行个性化推荐，可以使用隐含语义分析技术(latent variable analysis)，采取基于用户行为统计的自动聚类。</p>

<p>隐含语义分析技术从诞生到今天产生了很多著名的模型和方法,其中和该技术相关且耳熟能详的名词有pLSA、LDA、隐含类别模型(latent class model)、隐含主题模型(latent topic model)、 矩阵分解(matrix factorization)。</p>

<h3 id="section-4">1.5 基于图的模型</h3>

<p>如果 将个性化推荐算法放到二分图模型上,那么给用户u推荐物品的任务就可以转化为度量用户顶点 $v_u$ 和与 $v_u$ 没有边直接相连的物品节点在图上的相关性,相关性越高的物品在推荐列表中的权重就越高。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/23922601.jpg" width="400px" /></p>

<p>相关性高的一对顶点一般具有如下特征:</p>

<ul>
  <li>两个顶点之间有很多路径相连</li>
  <li>连接两个顶点之间的路径长度都比较短;</li>
  <li>连接两个顶点之间的路径不会经过出度比较大的顶点。</li>
</ul>

<p>基于这三个要素，可以使用一种基于随机游走的PersonRank算法：</p>

<p>假设要给用户u进行个性化推荐，可以从用户u对应的节点 $v_u$ 开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率 $\alpha$ 决定是继续游走，还是停止这次游走并从 $v_u$ 节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/56306116.jpg" width="500px" /></p>

<h2 id="section-5">二 推荐系统冷启动问题</h2>

<p>冷启动问题(cold start)主要分3类。</p>

<ul>
  <li><strong>用户冷启动</strong>  用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐 </li>
  <li><strong>物品冷启动</strong>  物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。 </li>
  <li><strong>系统冷启动</strong>  系统冷启动主要解决如何在一个新开发的网站上设计个性化推荐系统,从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。</li>
</ul>

<p>对于这3种不同的冷启动问题,有不同的解决方案。一般来说,可以参考如下解决方案</p>

<ul>
  <li><strong>提供非个性化的推荐</strong>   非个性化推荐的最简单例子就是热门排行榜,我们可以给用户推荐热门排行榜,然后等到用户数据收集到一定的时候,再切换为个性化推荐。</li>
  <li>利用用户注册时提供的年龄、性别等数据做粗粒度的个性化推荐。</li>
  <li>利用用户的社交网络获取好友信息，然后给用户推荐好友喜欢的物品。</li>
  <li>要求用户登录时对一些物品进行反馈，收集用户对这些物*品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。</li>
  <li>对于新加入的物品,可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。</li>
  <li>在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。</li>
</ul>

<p>可以用一个决策树解决启动用户兴趣的物品问题：</p>

<p>首先,给定一群用户用这群用户对物品评分的方差度量这群用户兴趣的一 致程度。如果方差很大,说明这一群用户的兴趣不太一致,反之则说明这群用户的兴趣比较一致。</p>

<script type="math/tex; mode=display">D(i) = \sigma_{u \in N^+(i)} + \sigma_{u \in N^-(i)} + \sigma_{u \in N^*(i)}</script>

<p>其中，$N^+(i)$ 是喜欢物品i的用户集合，$N^-(i)$ 是不喜欢物品i的用户集合，$N^*(i)$ 是没有对物品
i评分的用户集合。</p>

<p>接着会从所有用户中找到具有最高区分度的物品i，然后将用户分成3 类。接着在每类用户中再找到最具区分度的物品，如此迭代到叶子节点。</p>

<h3 id="section-6">2.1 利用物品的内容信息</h3>

<p>UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。那么需要解决的是第一个用户从哪儿发现新的物品。可以考虑利用物品的 内容信息,将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</p>

<p>对于ItemCF算法来说,物品冷启动就是一个严重的问题。新物品的加入需要更新物品相似度表，但这个操作非常耗时。为此,我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表(比如半小时计算一次)。</p>

<p>物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个关键词向量。每个关键词都有权重，可以用TF-IDF表示。得到向量后，就可以用余弦相似度等计算物品的相似度。这里同样可以建立关键词—物品的倒排表加速文档集合相似度的计算过程。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/58154911.jpg" width="400px" /></p>

<p>另外，如果两篇文章的关键词虽然不同，但关键词所属的话题是相同的时，可以使用话题模型，代表算法是LDA。</p>

<blockquote>
  <p>任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。</p>
</blockquote>

<h2 id="section-7">三 利用用户标签数据</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/51079519.jpg" width="500px" /></p>

<p>上图中的第三种方式是通过一些特征(feature)联系用户和物品，给用户推荐那些具有用户喜欢的特征的物品。特征有不同的表现方式</p>

<ul>
  <li>物品的属性集合</li>
  <li>隐语义向量(latent factor vector)</li>
  <li>物品的标签，包括作者或者专家给物品打标签;另一种是UGC标签</li>
</ul>

<p>UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的 语义，从而将用户和物品联系了起来。</p>

<p>一个简单的算法如下：</p>

<ul>
  <li>统计每个用户最常用的标签。</li>
  <li>对于每个标签，统计被打过这个标签次数最多的物品。</li>
  <li>对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。</li>
</ul>

<p>用户u对物品i的兴趣公式为：$p(u,i)=\sum_b n_{u,b} n_{b,i}$</p>

<p>$B(u)$ 是用户u打过的标签集合, $B(i)$ 是物品i被打过的标签集合, $n_{u,b}$ 是用户u打过标签b的次数, $n_{b,i}$是物品i被打过标签b的次数。</p>

<p>可以进行如下改进：</p>

<ul>
  <li>TF-IDF： 上式给热门标签和物品过大的权重,从而不能反应用户个性化的兴趣。改进公式如下，$n_b^{(u)}$ 记录了标签b被多少个不同的用户使用过，$n_i^{(u)}$记录了物品i被多少个不同的用户打过标签：</li>
</ul>

<script type="math/tex; mode=display"> p(u,i)=\underset{b}{sum} \frac{n_{u,b}}{log(1+n_b^{(u)})} \frac{n_{b,i}}{log(1+n_i^{(u)})}</script>

<ul>
  <li>
    <p>数据稀疏性：通过标签扩展解决，方法包括话题模型，基于邻域的方法（从数据中统计出标签的相似度）</p>
  </li>
  <li>
    <p>标签清理：只保留正向推荐的标签词；另外可以将标签作为推荐解释。</p>
  </li>
</ul>

<h2 id="section-8">四 利用上下文信息</h2>

<p>用户所处的上下文(context)包括用户访问推荐系统的时间、地点、心情等。时间信息对于用户兴趣的影响表现在以下几个方面：</p>

<ul>
  <li>用户兴趣是变化的</li>
  <li>物品是有生命周期和时效性
    <ul>
      <li>物品平均在线天数</li>
      <li>相隔T天系统物品流行度向量的平均相似度</li>
    </ul>
  </li>
  <li>季节效应</li>
</ul>

<p>实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，推荐算法实时性意味着：</p>

<ul>
  <li>要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计推荐列表。</li>
  <li>需要平衡考虑用户的近期行为和长期行为。</li>
</ul>

<p>推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。首先，需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。</p>

<p>如果用户没有行为，可以：</p>

<ul>
  <li>在生成推荐结果时加入一定的随机性。</li>
  <li>记录用户每天看到的推荐结果，对之前的推荐结果进行降权。</li>
  <li>每天给用户使用不同的推荐算法。</li>
</ul>

<h3 id="section-9">4.1 时间上下文推荐算法</h3>

<ol>
  <li>
    <p>最近最热门</p>

    <p>给定时间T, 物品i最近的流行度 $n_i(T)$ 可以定义为</p>

    <script type="math/tex; mode=display">% &lt;![CDATA[
n_i(T)=\underset{(u,i,t) \in Train, t<T}{\Sigma} \frac{1}{1+\alpha (T-t)} %]]&gt;</script>
  </li>
  <li>
    <p>时间上下文相关的ItemCF算法</p>

    <ul>
      <li>用户在相隔很短的时间内喜欢的物品具有更高相似度</li>
      <li>用户近期行为相比用户很久之前的行为,更能体现用户现在的兴趣。</li>
    </ul>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/45373851.jpg" width="600px" /></p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/9416103.jpg" width="350px" /></p>

    <p>其中, $t_0$ 是当前时间。</p>
  </li>
  <li>
    <p>时间上下文相关的UserCF算法</p>
    <ul>
      <li>类似于ItemCF算法，在权重和预测部分增加时间衰减因子</li>
      <li>对于用户u和用户v共同喜欢的物品i增加了一个时间衰减因子。</li>
      <li>考虑和用户u兴趣相似用户的最近兴趣</li>
    </ul>
  </li>
</ol>

<h2 id="section-10">五 利用社交网络数据</h2>

<p>社会化推荐之所以受到很多网站的重视，是缘于如下优点：</p>

<ul>
  <li>好友推荐可以增加推荐的信任度</li>
  <li>社交网络可以解决冷启动问题</li>
</ul>

<ol>
  <li>
    <p>基于邻域的社会化推荐算法</p>

    <p>也就是给用户推荐好友喜欢的物品集合。$p_{ui} = \underset{v \in out(u)}{\Sigma} w_{uv} r_{vi}$</p>

    <p>其中 $out(u)$ 是用户u的好友集合，如果用户v喜欢物品i，则 $r_{vi}=1$，否则 $r_{vi}=0$。$w_{uv}$ 由两部分相似度构成，一部分是用户u和用户v的熟悉程度，另一部分是用户u和用户v的兴趣相似度。</p>

    <script type="math/tex; mode=display"> familiarity(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\vert out(u) \cup out(v) \vert}</script>

    <script type="math/tex; mode=display"> similiarity(u,v) = \frac{\vert N(u) \cap N(v) \vert}{\vert N(u) \cup N(v) \vert}</script>

    <p>其中 $N(u)$ 是用户u喜欢的物品集合。</p>
  </li>
  <li>
    <p>基于图的社会化推荐算法</p>

    <p>在社交网站中存在两种关系，一种是用户对物品的兴趣关系，一种是用户之间的社交网络关系。需要将这两种关系建立到图模型中。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/68899610.jpg" width="300px" /></p>

    <p>该图上有用户顶点（圆圈）和物品顶点（方块）两种顶点。在定义完图中的顶点和边后,需要定义边的权重。其中用户和用户之间边的权重可以定义为用户之间相似度的 $\alpha$ 倍（包括熟悉程度和兴趣相似度）,而用户和物品之间的权重可以定义为用户对物品喜欢程度的 $\beta$ 倍。$\alpha,\beta$ 根据应用的需求确定。</p>
  </li>
</ol>

<p>大型网站中用户数目、历史行为记录非常庞大，所以不太可能将用户的所有行为都缓存在内存中，只能在数据库前做一个热数据的缓存。如果我们需要比较实时的数据，这个缓存中的数据就要比较频繁地更新，因而避免不了数据库的查询。数据库查询一般是很慢的，所以在实际做推荐时获取用户历史行为数据比较困难。</p>

<p>可以从几个方面改进基于邻域的社会化推荐算法,让它能够具有比较快的响应时间:</p>

<ul>
  <li>只拿出和用户相似度最高的N个好友；只返回用户最近1个月的行为。</li>
  <li>重新设计数据库
    <ul>
      <li>首先，为每个用户维护一个消息队列，用于存储他的推荐列表;</li>
      <li>当一个用户喜欢一个物品时，就将(物品ID、用户ID和时间)这条记录写入关注该用户的推荐列表消息队列中;</li>
      <li>当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，重新计算该物品的权重。</li>
    </ul>
  </li>
</ul>

<u>对比于协同过滤推荐，社会化推荐的优势不在于增加预测准确度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐 结果。</u>

<p>信息流推荐可以参考Facebook的EdgeRank算法。</p>

<p>另外好友推荐算法在社交网络上被称为链接预测(link prediction)，可以基于以下方法做推荐：</p>

<ul>
  <li>基于内容的匹配</li>
  <li>基于共同兴趣的好友推荐</li>
  <li>基于社交网络图的好友推荐</li>
</ul>

<h2 id="section-11">六 推荐系统实例</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/94386004.jpg" width="400px" /></p>

<p>从实时存取的角度上看，购买、收藏、评论、评分、分享等行为都是需要实时存取的，因为只要用户有了这些行为，界面上就需要体现出来，比如用户购买了商品后，用户的个人购买列表中就应立即显示用户购买的商品。而有些行为，比如浏览网页的行为和搜索行为并不需要实时存取。</p>

<p>数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，给用户进行实时推荐。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/79737632.jpg" width="600px" /></p>

<p>推荐系统由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。多个推荐引擎还可以：</p>

<ul>
  <li>可以方便地增加/删除引擎,控制不同引擎对推荐结果的影响。</li>
  <li>可以实现推荐引擎级别的用户反馈。</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/32415777.jpg" width="500px" /></p>

<p>如上图所示推荐引擎架构主要包括3部分：</p>

<ul>
  <li>该部分负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。</li>
  <li>该部分负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。</li>
  <li>该部分负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。</li>
</ul>

<p>具体对不同部分解释下。</p>

<ol>
  <li>
    <p><strong>用户特征向量</strong>包括两种：</p>

    <ul>
      <li>用户的注册信息中可以提取出来的,主要包括用户 的人口统计学特征。</li>
      <li>
        <p>从用户的行为中计算出来的，需要考虑：</p>

        <ul>
          <li>用户行为的种类（按行为的成本划分）</li>
          <li>用户行为产生的时间，近期行为比较重要</li>
          <li>用户行为的次数</li>
          <li>物品的热门程度</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>特征—物品相关推荐</p>

    <p>在得到用户的特征向量后,我们可以根据离线的相关表得到初始的物品推荐列表。在线使用的特征物品相关表一般都不止一张，推荐引擎可以在配置文件中配置很多相关表以及它们的权重。</p>

    <p>特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。</p>
  </li>
  <li>
    <p>过滤模块</p>

    <ul>
      <li>用户已经产生过行为物品</li>
      <li>候选物品以外的物品</li>
      <li>某些质量很差的物品</li>
    </ul>
  </li>
  <li>
    <p>排名模块</p>

    <ul>
      <li>新颖性排名，对推荐结果中热门的物品进行降权。</li>
      <li>多样性，推荐结果分类；控制不同推荐结果的推荐理由出现的次数。</li>
      <li>时间多样性</li>
      <li>用户反馈，通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。
        <ul>
          <li>CTR预测</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="section-12">七 评分预测问题</h2>

<p>前面主要介绍TopN推荐，因为它非常接近于满足实际系统的需求。评分预测问题却是推荐系统研究的核心。</p>

<ol>
  <li>
    <p>基于邻域的方法</p>

    <p>基于用户的邻域算法和基于物品的邻域算法都可以应用到评分预测中。基于用户的邻域算法：</p>

    <script type="math/tex; mode=display">\hat{r}_{ui} = \overline{r}_u + \frac{\sum_{v \in S(u,K) \cap N(i)} w_{uv}(r_{vi} -\overline{r}_v)}{\sum_{v \in S(u,K) \cap N(i)} \vert w_{uv} \vert}</script>

    <p>这里, $S(u, K)$ 是和用户u兴趣最相似的K个用户的集合, $N(i)$ 是对物品i评过分的用户集合, $r_{vi}$ 是用户v对物品i的评分, $\overline{r}_v$ 是用户v对他评过分的所有物品评分的平均值。$w_{uv}$ 是相似度，有以下几种：</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/86649362.jpg" width="420px" /></p>

    <p>基于物品的领域算法类似。</p>
  </li>
  <li>
    <p>隐语义模型与矩阵分解模型</p>

    <p>传统的SVD分解有一下几个缺点：</p>

    <ul>
      <li>该方法首先需要用一个简单的方法补全稀疏评分矩阵。</li>
      <li>该方法依赖的SVD分解方法的计算复杂度很高</li>
    </ul>

    <p>基于此，Simon Funk提出的基于新的矩阵分解方法Latent Factor Model (LFM)。</p>

    <p>将评分矩阵R分解为两个低维矩阵相乘 $\hat{R} = P^TQ$，其中 $P_{f \times m}$ 和 $Q_{f \times n}$ 是两个降维后的矩阵。那么，对于用户u对物品i的评分的预测值 $\hat{R}(u,i)=\hat{r}_{ui}$，可以表示为 $\hat{r}_{ui} = \sum_f p_{uf} q_{if}$。</p>

    <p>Simon Funk的思想很简单:可以直接通过训练集中的观察值利用最小化RMSE学习P、Q矩阵。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/90816576.jpg" width="620px" /></p>

    <p>要最小化上面的损失函数，可以利用随机梯度下降法。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/9179243.jpg" width="620px" /></p>
  </li>
  <li>
    <p>加入偏置项后的LFM</p>

    <p>LFM预测公式通过隐类将用户和物品联系在了一起。但是，实际情况下，一个评分系统有些固有属性和用户物品无关，而用户也有些属性和物品无关，物品也有些属性和用户无关。所以提出加入偏置项后的LFM：</p>

    <script type="math/tex; mode=display">\hat{r}_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i</script>

    <p>$\mu$ 是训练集中所有记录的评分的全局平均数。$b_u$ 是用户偏置(user bias)项，表示了用户的评分习惯中和物品没有关系的因素。$b_i$ 是物品偏置(item bias)项，表示了物品接受的评分中和用户没有什么关系的因素。</p>

    <p>$b_u,b_i$ 通过机器学习训练出来的。同样可以求导，然后用梯度下降法求解这两个参数。</p>
  </li>
  <li>
    <p>考虑邻域影响的LFM</p>

    <p>前面的LFM模型中并没有显式地考虑用户的历史行为对用户评分预测的影响。新的算法成为SVD++。可以将ItemCF的预测算法改成如下方式:</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/88102444.jpg" width="620px" /></p>
  </li>
</ol>

<p>另外还可以增加时间因素进行考虑。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apriori and FP-Growth]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/06/apriori/"/>
    <updated>2016-03-06T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/06/apriori</id>
    <content type="html"><![CDATA[<p>如果说监督学习的形式化表达是 $Pr(Y \vert X)$, 找到最佳的参数最小化每个 $x$ 的epxected error： $argmin_{\theta}\ E_{Y \vert X} L(Y, \theta)$。那么非监督学习的形式化表达就是 $Pr(X)$，目标是在没有 $Y$ 引导的情况下，推测出 $Pr(X)$ 的潜在属性。本文要提到的apriori算法也是一种非监督学习算法，wiki的定义为</p>

<blockquote>
  <p>The Apriori Algorithm is an influential algorithm for mining frequent itemsets for boolean association rules.</p>
</blockquote>

<p>著名的啤酒和尿布例子就是指这个算法。它是属于关联分析中的一种，也就是从大规模数据集中寻找物品间的隐含关系。</p>

<!--more-->

<p>在apriori的定义中出现两个词，frequent itemsets 和 association rules，也就是频繁项集和关联规则，这里解释下频繁项集是经常出现在一块的物品的集合，关联规暗示两种物品之间可能存在很强的关系。下面给个简单的例子：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/5038926.jpg" width="300px" /></p>

<p>集合{葡萄酒，尿布, 豆奶} 就是频繁项集的一个例子，尿布➞葡萄酒 则是关联规则，意味着如果有人买了尿布，那么他很可能也会买葡萄酒。</p>

<h2 id="definition">Definition</h2>

<p>频繁是如何定义的呢？有许多的概念可以表示，主要有</p>

<ul>
  <li><strong>Support</strong>，这个表示数据集包含该项集的记录比例， $S(A) = T(A) / total\ transactions$</li>
  <li><strong>Confidence</strong>，$C(A \to B) = T(A \to B) / T(A)$</li>
  <li><strong>Lift</strong>, $L(A \to B) = C(A \to B)/ T(B)$</li>
</ul>

<p>如果有，Computer ➞ antivirus_software , 其中 support=2%, confidence=60%。
表示的意思是所有的商品交易中有2%的顾客同时买了电脑和杀毒软件，并且购买电脑的顾客中有60%也购买了杀毒软件。</p>

<p>下面我们给出关联规则形式化的定义：</p>

<p>假设 $I = \lbrace i_1, i_2…i_n \rbrace $ 表示items，$i_n$ 是binary attribute，表示商品买或不买。$T = \lbrace t_1, t_2…t_n \rbrace $ 是交易的集合，成为 database。每个交易都有唯一的标示，并且为 $I$ 的一个子集。规则就是 $X \to Y,\ where\ X,Y \subseteq I, X \cap Y = \varnothing$，这里 $X$ 称为 antecedent， $Y$ 称为 consequent.</p>

<h2 id="apriori-algorithm">Apriori Algorithm</h2>

<p>关联规则的生成过程可以分为两步：</p>

<ol>
  <li>首先根据最小support在database中找出所有的频繁项集</li>
  <li>根据所得的频繁项集和最小confidence约束生成规则</li>
</ol>

<p>在database中找到所有的频繁项集是比较困难的，因为需要找到所有可能的 $2^n-1$ 项集（排除空集）。虽然项集的个数是根据 $I$ 的大小呈指数增长，但是可以通过support的downward-closure特性进行有效的搜索。downward-closure表示对于一个频繁项，它的子集也必须是频繁的；对于一个非频繁的集合，它的超集必定也是非频繁的。下面给出伪代码：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/1439703.jpg" width="600px" /></p>

<p>迭代过程可以看成两个步骤：</p>

<ul>
  <li>Join Step: $C_k$ is generated by joining $L_{k-1}$ width itself</li>
  <li>Prune Step: Any (k-1)-itemset that is not frequent cnanot be a subset of a frequent k-itemset</li>
</ul>

<p>下面给出一个示例可以参考：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/4948435.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/92538392.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/62108557.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/26861819.jpg" width="500px" /></p>

<p>这里解释下3-itemset的生成，对于 $\lbrace I1,I2,I3 \rbrace$ 这儿例子，因为是属于L2的笛卡尔积，所以在L2中需要包含有 $\lbrace I1,I2 \rbrace, \lbrace I2, I3 \rbrace, \lbrace I1, I3 \rbrace$。所有不满足的都不能构成 $C_3$。</p>

<p>对于下一步 Generating 4-itemset Frequent Pattern，我们得到是一个空集，所以被剪枝了。最后一步是根据频繁项集生成关联规则。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/33075969.jpg" width="500px" /></p>

<p>对于大的数据量来说，生成频繁项集比较耗时，可以采用下面的方法提高效率。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/23943688.jpg" width="500px" /></p>

<h2 id="fp-growth">FP-Growth</h2>

<p>Apriori通过不断的构造候选集、筛选候选集挖掘出频繁项集，需要多次扫描原始数据，当原始数据较大时，磁盘I/O次数太多，效率比较低下。FP-Growth算法则只需扫描原始数据两遍，通过FP-tree数据结构对原始数据进行压缩，效率较高。</p>

<p>搜索引擎中的提示词项就可以用FP-Growth得到，通过输入项找到它的频繁项集。</p>

<p>FP-Growth算法主要分为两个步骤：FP-tree构建、递归挖掘FP-tree。FP-tree构建通过两次数据扫描，将原始数据中的事务压缩到一个FP-tree树，该FP-tree类似于前缀树，相同前缀的路径可以共用，从而达到压缩数据，减少数据库扫描的目的。接着通过FP-tree找出每个item的条件模式基、条件FP-tree，递归的挖掘条件FP-tree得到所有的频繁项集。递归挖掘FP-tree利用分治的思想将任务分解为更小的任务，并且可以避免频繁项集Candidate的生成。</p>

<p>还是以上面的数据库为示例，我们看下产生频繁项集的过程。剩下的挖掘关联规则则和Apriori一样。</p>

<ul>
  <li>
    <p>第一次扫描和Apriori一样，得到1-itemsets和它们的support counts。频繁集是按照support的带下倒序排列。结果为 $L = \lbrace I2:7,I1:6,I3:6,I4:2,I5:2 \rbrace$。</p>
  </li>
  <li>
    <p>第二次扫描的时候构建FP-tree。</p>

    <ul>
      <li>对每个transaction，过滤不频繁集合，剩下的频繁项集按 $L$ 顺序排序</li>
      <li>把每个transaction的1-itemsets插入到FP-tree中，相同前缀的路径可以共用</li>
      <li>同时增加一个header table，把FP-tree中相同item连接起来，也是降序排序</li>
    </ul>
  </li>
</ul>

<p>结果如图所示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/45883923.jpg" width="500px" /></p>

<p>接下来进行频繁项的挖掘。</p>

<p>步骤为：</p>

<ol>
  <li>从header table的最下面的item开始，构造每个item的条件模式基（conditional pattern base）
    <ul>
      <li>顺着header table中item的链表，找出所有包含该item的前缀路径，这些前缀路径就是该item的条件模式基（CPB）</li>
      <li>所有这些CPB的频繁度（计数）为该路径上item的频繁度（计数）</li>
    </ul>
  </li>
  <li>构造条件FP-tree（conditional FP-tree）
    <ul>
      <li>累加每个CPB上的item的频繁度（计数），过滤低于阈值的item，构建FP-tree</li>
    </ul>
  </li>
  <li>FP-Growh：递归的挖掘每个条件FP-tree，累加后缀频繁项集，直到找到FP-tree为空或者FP-tree只有一条路径（只有一条路径情况下，所有路径上item的组合都是频繁项集）</li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/57749816.jpg" width="500px" /></p>

<p>接着上面的例子：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/37306135.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/29869117.jpg" width="500px" /></p>

<p>FP-Growth算法计算频繁项集的效率要高于Apriori，原因有以下几点：</p>

<ul>
  <li>无需Candidate的生成和检查</li>
  <li>使用压缩的数据结构</li>
  <li>减少重复的数据库扫描，事实上只需要两次</li>
  <li>基本的操作就是计数和构建FP-Tree</li>
</ul>

<h2 id="reference">Reference</h2>

<p><a href="http://120.52.72.49/software.ucv.ro/c3pr90ntcsf0/~cmihaescu/ro/teaching/AIR/docs/Lab8-Apriori.pdf">http://120.52.72.49/software.ucv.ro/c3pr90ntcsf0/~cmihaescu/ro/teaching/AIR/docs/Lab8-Apriori.pdf</a>
<a href="http://120.52.72.51/www3.cs.stonybrook.edu/c3pr90ntcsf0/~cse634/lecture_notes/07apriori.pdf">http://120.52.72.51/www3.cs.stonybrook.edu/c3pr90ntcsf0/~cse634/lecture_notes/07apriori.pdf</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Expectation Maximization]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/05/em/"/>
    <updated>2016-03-05T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/05/em</id>
    <content type="html"><![CDATA[<p>Expectation Maximization, EM算法在参数估计里面有极大的用处，它用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率（MAP）估计。隐变量的概率模型参数的极大似然估计可以理解为，使用的方法还是的极大似然估计，但是要处理隐变量。极大后验概率是一种Beyesian Inference，其实就是把极大似然估计中的参数赋予权值，这个权值是预先定义好的先验概率。可以来看下下表中Frequentist-Bayesian对峙的部分，来感受下EM算法的应用范围：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/88568881.jpg" width="500px" /></p>

<!--more-->

<p>下面我们先从一个Two-Component Gaussian Mixture Model为例，介绍EM算法。</p>

<h2 id="two-component-gaussian-mixture-model">Two-Component Gaussian Mixture Model</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/45836233.jpg" width="600px" /></p>

<p>上图是一个mixture example，左边是我们观察到数据的直方图，右边红线是最大似然拟合的高斯密度函数，绿色的点是用来做两个模型的分类用。</p>

<p>这里其实我们得到的是一些数据点，对于这些点的分布完全一无所知。先做出如下假设，这是两个高斯模型混合后的sample data。</p>

<script type="math/tex; mode=display"> Y_1 \sim N(\mu_1, \theta_1^2) </script>

<script type="math/tex; mode=display"> Y_2 \sim N(\mu_2, \theta_2^2) </script>

<script type="math/tex; mode=display"> Y = (1 - \Delta)\cdot Y_1 + \Delta \cdot Y_2,\  \Delta \in \{0,1\}, Pr(\Delta =1) = \pi</script>

<p>那么需要我们估计的参数就为 $(\pi, \theta_1, \theta_2) = (\pi, \mu_1, \sigma_1, \mu_2, \sigma_2)$，一共五个参数。使用似然估计，我们可以得到如下过程：</p>

<script type="math/tex; mode=display"> g_Y(y) = (1-\pi)\phi_{\theta_1}(y) + \pi \phi_{\theta_2}(y) </script>

<script type="math/tex; mode=display">log\ likelihood \to l(\theta; Z) = \sum_{i=1}^N log[(1-\pi)\phi_{\theta_1}(y_i) + \pi \phi_{\theta_2}(y_i)] </script>

<p>最大化 $l(\theta; Z)$ 无疑是困难的，因为对数中含有加号。如果我们知道隐变量 $\Delta$ 的取值，那么参数估计就会变得容易，$\phi$ 的估计也就是 $\Delta_i=1$ 的比例，另外 $\theta_1,\theta_2$ 也就变成 $\Delta_i=0，\Delta_i=1$ 的似然估计。</p>

<p>所以问题的关键是 $\Delta$ 的取值，解决问题的思路是采用迭代的方式，每次都用 $\Delta_i$ 的估计值替换：</p>

<script type="math/tex; mode=display">\gamma_i(\theta) = E(\Delta_i \vert \theta,Z) = Pr(\Delta_i=1 \vert \theta,Z)</script>

<p>如此 $\theta_1,\theta_2$ 自然也就可以由最大似然估计求出。在下一次过程中，$\gamma_i(\theta)$ 又可以由上一步估计的 $\theta_1,\theta_2$ 求出。所以我们首先需要给出参数的初始值，就可以由上述过程得到结果。算法入下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/24344888.jpg" width="550px" /></p>

<p>这里需要注意的是，如果我们在某个点取 $\hat{\mu}_1 = y_i, \hat{\sigma}_1=0$ 那么我们可以去到最大的似然值，无限大，但这并不是有用的解。所以我们其实是求解 <u>a good local maximum of the likelihood</u>，因此我们可以设多个初值，最后选择似然值最大的解。</p>

<h2 id="em-in-general">EM in General</h2>

<p>EM算法被用于data augmentation，关于data augmentation的解释如下：</p>

<blockquote>
  <p>maximization of the likelihodd is difficult, but made easier by enlarging the sample with latent data</p>
</blockquote>

<p>上面的例子中我们设的latent data为 $\Delta$，是出于我们对模型的假设；其他的latent data还可以为丢失的观察值。接下来我们介绍EM的通用形式，先给出算法：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/67870944.jpg" width="550px" /></p>

<p>上面的算法中，$Z$ 为观察值，log likelihood是 $l(\theta, Z)$。latent or missing data 为 $Z^m$， 完整的数据为 $T=(Z, Z^m$)，对比于上面的例子 $(Z, Z^m) = (y, \Delta)$。</p>

<ul>
  <li>E step就是完全数据 $T$ 的对数似然函数 $l_0(\theta’; T)$ 关于在给定观察数据 $Z$ 和当前参数 $\theta^{(j)}$ 下对未观察数据 $Z^m$ 的条件概率分布 $Pr(Z^m \vert Z, \theta^{(j)})$ 的期望，得到的是 $Z^m$ 的估计。</li>
  <li>M step就是通过似然估计方法，求未观察数据 $Z^m$ 的条件概率分布的期望的最大值，得到参数 $\theta$ 的重新估计 $\theta’$，在下一个E中变为 $\theta^{(j+1)}$。</li>
</ul>

<p>上面叙述了EM的算法，那么为什么EM算法能有效，也就是近似实现对观测数据的极大似然估计呢？我们看到</p>

<script type="math/tex; mode=display"> Pr(Z^m \vert Z, \theta') = \frac{Pr(Z^m,Z  \vert \theta')}{Pr(Z \vert  \theta')} </script>

<script type="math/tex; mode=display"> \to Pr(Z \vert  \theta') = \frac{Pr(T  \vert  \theta')}{ Pr(Z^m \vert Z, \theta')} </script>

<script type="math/tex; mode=display"> \to l(\theta'; Z) = l_0(\theta'; T) - l_1(\theta'; Z^m \vert Z) </script>

<p>对由 $\theta$ 控制的分布 $T \vert Z$ 数据求期望可以得到：</p>

<script type="math/tex; mode=display"> l(\theta'; Z) = E[l_0(\theta'; T) \vert Z,\theta] - E[l_1(\theta'; Z^m \vert Z) \vert Z,\theta] = Q(\theta', \theta) - R(\theta', \theta) </script>

<p>在 $M\ step$ 中，EM算法求出可以使 $Q(\theta’, \theta)$ 最大化的 $\theta’$，而不是真正的目标函数 $l(\theta’; Z)$。为什么最大化 $Q(\theta’, \theta)$ 最终可以最大化 $l(\theta’; Z)$呢？</p>

<p>可以看到 $R(\theta^*, \theta)$ 是由 $\theta^*$ 决定的条件分布的log-likelihood的期望，这个分布和由 $\theta$ 决定的条件分布是相同的。因此由 Jensen’s inequality 可以得到，$R(\theta’, \theta) \le R(\theta, \theta)$。具体的推导可以参考《统计学习方法》。所以如果 $\theta’$ 最大化 $Q(\theta’, \theta)$ 则</p>

<script type="math/tex; mode=display"> l(\theta'; Z) - l(\theta; Z) = [Q(\theta', \theta) - Q(\theta, \theta)] - [R(\theta', \theta) - R(\theta, \theta)] \ge 0 </script>

<p>所以说EM迭代中，$l(\theta’; Z)$ 一直都会在增大。</p>

<blockquote>
  <p>Jensen’s inequality, $E[\phi(X)] \ge \phi[E(X)]$, for Random variable $X$ and convex function $\phi(x)$</p>
</blockquote>

<p>也就是说在 $M step$ 中完全的最大化是没有必要的，我们只需要找到一个 $\theta^{(j+1)}$ 使得 $Q(\theta^{(j+1)}, \theta^{(j)}) - Q(\theta^{(j)}, \theta^{(j)})$。所以我们得到的EM收敛条件也就是 </p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 \theta^{(j+1)} - \theta^{(j)} < \epsilon\ or\ Q(\theta^{(j+1)}, \theta^{(j)}) - Q(\theta^{(j)}, \theta^{(j)}) < \epsilon  %]]&gt;</script>

<h2 id="em-as-max-max-procedure">EM as max-max Procedure</h2>

<p>EM算法还可以看成是F 函数的极大极大算法， F函数定义如下</p>

<script type="math/tex; mode=display"> F(\theta',  \tilde{P}) = E_{\tilde{P}}[l_0(\theta'; T)] - E_{\tilde{P}}[log \tilde{P}(Z^m)] </script>

<p>$\tilde{P}(Z^m)$也就是隐变量 $Z^m$ 的分布, $- E_{\tilde{P}}[log \tilde{P}(Z^m)]$ 也就是 $\tilde{P}(Z^m)$ 的熵。于是EM算法可以由下图表示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/44573110.jpg" width="500px" /></p>

<p>也就是，设 $\theta^{(i)}$ 为第 $i$ 次迭代参数 $\theta$ 的估计，$\tilde{P}^{(i)}$ 为第 $i$ 次迭代参数 $\tilde{P}$ 的估计。在第 $i+1$ 次迭代的两步为：</p>

<ul>
  <li>对固定的 $\theta^{(i)}$，求 $\tilde{P}^{(i+1)}$ 使得 $F(\theta^{(i)},  \tilde{P})$ 极大化</li>
  <li>对固定的 $\tilde{P}^{(i+1)}$，求 $\theta^{(i+1)}$ 使得 $F(\theta,  \tilde{P}^{(i+1)})$ 极大化</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kernel Logistic Regression versus SVM]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/29/klr-svr/"/>
    <updated>2016-02-29T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/29/klr-svr</id>
    <content type="html"><![CDATA[<p>Logistic Regression和SVM都是分类方法，它们定义线性决策边界（linear decision boundaries）作为划分的依据。但二者在motivation方便完全不同，区别如下</p>

<ul>
  <li>LR初衷是为了让linear regression能够输出二元分类，估计一个实例属于某一类的概率；线性决策边界也只是回归函数的结果，在回归函数中使用阈值作为分类的标准，一般是0.5。决策边界在SVM中来的更为重要，整个模型的目标就是为了获得最优的决策边界。</li>
  <li>每个训练样本都对LR的过程有一定的影响，但SVM只依赖于在决策边界附近的某些点。</li>
  <li>LR适应于低维空间，并且由于使用最大似然估计，所以对噪声不敏感；SVM更适应于高维空间</li>
  <li>没有正规化的LR无法保证获得最好的分离超平面，只能获得margin附近的较高的置信度; SVM则能获得最优的分离超平面。</li>
</ul>

<p>那么二者会有什么联系呢，SVM的kernel function又是如何应用到LR模型的呢？</p>

<!--more-->

<h2 id="loss-function">Loss Function</h2>

<p>我们先来看下Loss Function，它是用来衡量学习函数与数据拟合的程度的。回顾对于机器学习来说有一下几个过程：</p>

<ol>
  <li>假设空间：函数的参数形式，包括lr，svm等</li>
  <li>拟合的衡量：Loss function，likelihood</li>
  <li>bias和variance的trade-off：regularization，bayesian estimator (MAP)</li>
  <li>在假设空间中寻找好的假设：optimization. convex - global. non-convex - multiple starts</li>
  <li>假设的验证：测试数据的预测，cross validation</li>
</ol>

<p>在线性学习方法中，通常我们是要找到一个假设 $y=f(\theta^T x)$，选决定f的参数形式，再通过最大化似然函数或者最小化损失函数找到对应的 $\theta$，常见的几个Loss Function：</p>

<p>For classfication $correct \to y \cdot f &gt; 0;\ incorrect \to y \cdot f &lt; 0$</p>

<ol>
  <li>0/1 loss： $min_\theta \sum_i L_{0/1}(\theta^T x)$. 定义 $L_{0/1}(\theta^T x)=1\ if\ y \cdot f &lt; 0$，其他情况等于0，非凸函数，难以优化。</li>
  <li>Hinge loss: $min_\theta \sum_i H(\theta^T x)$。接近 0/1 损失函数，定义 $H(\theta^T x) = max (0,1-y \cdot f)$</li>
  <li>Logistic loss: $min_\theta \sum_i log(1 + exp(-y \cdot \theta^T x))$. </li>
</ol>

<p>关于3，在逻辑回归中我们最大化似然函数其实就是最小化Logistic loss：</p>

<script type="math/tex; mode=display">\sum_i log \frac{1}{1+exp(-y^{(i)}\cdot \theta^T x^{(i)})} = \sum_i -log (1+exp(-y^{(i)}\cdot \theta^T x^{(i)}))</script>

<script type="math/tex; mode=display">\to min_\theta \sum_i log(1 + exp(-y \cdot \theta^T x))</script>

<p>For regression:</p>

<ol>
  <li>Square loss: $min_\theta \sum_i | y^{(i)} - \theta^T x^{(i)} |^2$</li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-22/70940842.jpg" width="400px" /></p>

<p>如上图所示，SVM使用Hinge Loss；Binomial Deviance就是Logistic Loss，因为output是binomial的；Exponential Loss 可以在Gradient Boost中应用到。</p>

<h2 id="connection-between-svm-and-logistic-regression">Connection between SVM and Logistic Regression</h2>

<p>回顾下soft-margin SVM的原始问题：</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi}{min} \frac{1}{2}w^T w  + C\sum_{n=1}\xi_n</script>

<script type="math/tex; mode=display">s.t.\ y_i(w^T z_n + b) \ge 1-\xi_n,\ \xi_n \ge 0\ for\ all\ n</script>

<p>这里的 $\xi_n$ 实际上就是违反 margin 的距离，称为 margin violation。如果 $(x_n, y_n)$ 不违反 margin，那么 $\xi_n=0$，否则为 $\xi_n=1-y_n(w^T z_n + b)$，从这里我们看到实际上 $\xi_n = max(1-y_n(w^T z_n + b), 0)$，所以原来问题可以写成：</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi}{min} \frac{1}{2}w^T w  + C\sum_{n=1}max(1-y_n(w^T z_n + b), 0)</script>

<p>上式写成 $min\ \frac{1}{2} w^Tw + C \sum \hat{err}$ 就比较熟悉了，这个就是L2 regularization: $min\ \lambda w^Tw + C \sum err$ 嘛。对应关系如下：</p>

<ul>
  <li>soft-margin $\to special\ \hat{err}$</li>
  <li>large margin $\to$ fewer hyperplanes $\to$ L2 regularization for small $w$</li>
  <li>larger C or C $\to$ smaller $\lambda\ to$ less regularization</li>
</ul>

<p>对比于SVM的原始问题，我们发现新的形式并不是凸二次规划问题；不能利用kernel trick；并且max函数不能微分，所以难以解决。那么为什么要变化成这种形式呢？如果设置 linear score: $s=w^T z_n + b$。我们观察下它的损失函数 $\hat{err}_{svm}(s,y) = max(1-ys, 0)$，另外再看下logistic loss: $err_{ll}(ys) = log(1 + exp(-ys))$.</p>

<p>可以对比下上图的损失函数曲线，二者比较接近，并且都是 0/1 损失函数的上限。所以可以把 SVM 当成 L2-regularized logistic regression。以下是几个二分类线性模型的对比：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/76344341.jpg" width="600px" /></p>

<h2 id="kernel-logistic-regression">Kernel Logistic Regression</h2>

<p>现在我们知道 SVM 和 Logistic Regression存在联系，那么是否可以综合二者的有点呢：</p>

<ul>
  <li>SVM flavor: 利用kernel function 得到 $w_{svm}，b_{svm}$ 得到超平面 </li>
  <li>LR flavor: 通过 scalling(A) 和 shifting(B) 匹配最大似然函数的方法细粒度地调优超平面
    <ul>
      <li>often $A &gt; 0$ if $w_{svm}$ reasonably good</li>
      <li>often $B \approx 0$ if $b_{svm}$ reasonably good</li>
    </ul>
  </li>
</ul>

<p>所以新的LR问题可以看成 two-level learning 问题：LR on SVM-transformed data</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/6560678.jpg" width="450px" /></p>

<p>于是我们得到Probabilistic SVM for Soft Binary Classification 的算法，因为 LR 是根据概率分类的，过程如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/75482355.jpg" width="450px" /></p>

<ul>
  <li>这个 Soft Binary Classifier 得到 bounary 与 SVM 的不同，因为有平移 B。</li>
  <li>只需要解两个变量，可以使用GD或者SGD等。</li>
  <li>Kernel SVM 相当于在 $Z$ 空间中进行 LR</li>
</ul>

<p>Kernel SVM 中有 $w_{svm}^T \phi(x) + b_{svm} = \sum_{SV} \alpha_n y_n K(x_n, x) + b_{svm}$，则最后 Probabilistic SVM 的结果为</p>

<script type="math/tex; mode=display"> g(x) = \theta(\sum_{SV} A\alpha_n y_n K(x_n, x) + Ab_{svm} + B)</script>

<p>但这个方法其实并不是在 $Z$ 空间里的最好的解，只是通过两次 scaling 和 shifting 接近最好的解，那么如何得到最好的解呢。这就是我们要介绍的Kernel Logistic Regression。</p>

<p>先来介绍下 Representer Theorem，它的定义如下：</p>

<blockquote>
  <p>the solution of regularization and interpolation problems with Hillbertian penalties can be expressed as a linear combination of the data.</p>
</blockquote>

<p>也就是最优的 $w_* = \sum_{n=1}^N \beta_n z_n$，我们可以把原来在 Hillbertian Space
 的计算放到低维空间中进行。</p>

<script type="math/tex; mode=display"> w_*z = \sum_{n=1}^N \beta_n z_n^Tz = \sum_{n=1}^N \beta_n K(x_n, x)</script>

<p>证明Representer Theorem如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/22880811.jpg" width="500px" /></p>

<p>这其实就表明所有的 L2-regularized linear model 都可以被 kernalized。把损失函数替换成 logistic loss，我们就得到 Kernel Logistic Regression 的优化函数。</p>

<script type="math/tex; mode=display"> \underset{w}{min}\ \frac{\lambda}{N}w^Tw + \frac{1}{N} \sum_{n=1}^N log(1+ exp(-y_n w^T z_n)) </script>

<p>利用 Representer Theorem，将原来对 $w$ 的求解转化为对 $\beta$ 求解：</p>

<script type="math/tex; mode=display"> \underset{\beta}{min}\ \frac{\lambda}{N} \sum_{n=1}^N \sum_{m=1}^N \beta_n \beta_m K(x_n, x_m) +  \frac{1}{N} \sum_{n=1}^N log(1+ exp(-y_n \sum_{m=1}^N \beta_m K(x_m, x_n)))</script>

<p>可以用 GD/SGD 等做最优化求解，<strong>解出来的 $\beta$ 并不同于 SVM 的 $\alpha$，基本上是非零的</strong>。综合上述，总结得到 KLR 其实就是</p>

<blockquote>
  <p>use representer theorem for kernel trick on L2-regularized logistic regression</p>
</blockquote>

<p>对 KLR 还有另外另外的解释</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/45320882.jpg" width="450px" /></p>

<h2 id="support-vector-regression">Support Vector Regression</h2>

<p>最后说下SVR，上面提到 regression 的损失函数 squared error $err(y, w^Tz) = (y- w^Tz)^2$，替换下KLR的损失函数我们可以得到</p>

<script type="math/tex; mode=display"> \underset{w}{min}\ \frac{\lambda}{N}w^Tw + \frac{1}{N} \sum_{n=1}^N (y- w^Tz)^2 </script>

<p>这个就是 <strong>kernel ridge regression</strong>，也可以通过解 $\beta$ 得到答案</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/56123028.jpg" width="500px" /></p>

<p>对 $\beta$ 求导得到</p>

<script type="math/tex; mode=display">\nabla E_{aug}(\beta) = \frac{2}{N}(\lambda K^TI\beta + K^TK\beta - K^Ty) = \frac{2}{N}K^T((\lambda I + K)\beta - y)</script>

<script type="math/tex; mode=display">\nabla E_{aug}(\beta) =0 \to \beta=(\lambda I + K)^{-1}y</script>

<p>因为 Merer’s condition，所以 $K$ 是半正定矩阵，继而上式有解。但是稠密矩阵求反需要 $O(N^3)$ 时间复杂度。可以对比下 linear ridge regression:</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/7052157.jpg" width="450px" /></p>

<p>根据前面所述的SVM和LR之间的关系，我们这里可以吧 kernel ridge regression 看成 least-squares SVM(LLSVM)。它有什么特点呢：</p>

<ul>
  <li>对比soft-margin SVM，有这相似的boundary，但是更多的支持向量。导致预测慢，因为 $\beta$ 比较稠密</li>
</ul>

<p>现在想让 $\beta$ 变得和 soft-margin SVM 的 $\alpha$ 一样稀疏。可以看到 tube regression 的特点，使用 $\epsilon$-insensitive error：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/74768649.jpg" width="450px" /></p>

<p>整理下是 L2-regularized tube regression</p>

<script type="math/tex; mode=display"> \underset{w}{min}\ \frac{\lambda}{N}w^Tw + \frac{1}{N} \sum_{n=1}^N\ max(0, \vert w^Tz_n - y \vert - \epsilon)</script>

<p>这个函数没有限制条件，但是max难以微分，并且不能很明显的看出有 sparse $\beta$。发现这个表达式和最开始 soft-SVM 的表示有点像，那么我们可以反向的把它模拟成 standard SVM 形式:</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi^ \vee, \xi ^ \land}{min}\ \frac{1}{2} w^Tw + C \sum_{n=1}^N (\xi_n^ \vee + \xi_n ^ \land)</script>

<script type="math/tex; mode=display">s.t.\ -\epsilon-\xi_n^ \vee \le y_n - w^Tz_n-b \le \epsilon-\xi_n^ \land,\ \xi_n^ \vee \ge 0,\ \xi_n^ \land \ge 0</script>

<p>这就构成 SVR 的原始问题: minimize regularizer + (upper tube violations $\xi_n^ \land$ and lower violations $\xi_n^ \vee$)。这里参数 $C$ 就是 trade-off of regularization and tube violation. 现在要求 SVR 的对偶问题。</p>

<ul>
  <li>Lagrange multiplier $\alpha_n^ \vee\ for\ -\epsilon-\xi_n^ \vee \le y_n - w^Tz_n-b$</li>
  <li>Lagrange multiplier $\alpha_n^ \land\ for\ y_n - w^Tz_n-b \le \epsilon-\xi_n^ \land$</li>
</ul>

<p>一些KTT条件如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-1/97895297.jpg" width="450px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-1/34361452.jpg" width="500px" /></p>

<p>在 tube 中我们可以得到 </p>

<p>$\vert w^Tz_n + b- y_n \vert &lt; \epsilon$</p>

<p>$\to \xi_n^ \vee=0,\ \xi_n^ \land=0$</p>

<p>$\to (\epsilon + \xi_n^ \land - y_n + w^Tz_n +b) \neq 0,\ (\epsilon + \xi_n^ \vee + y_n - w^Tz_n -b) \neq 0$</p>

<p>$\to \alpha_n^ \vee =0,\ \alpha_n^ \land=0$</p>

<p>$\to \beta_n=0$</p>

<p>对于support vector来说，$\beta_n \neq 0$，是在tube上或者tube外的。综上可以得到sparse $\beta$。</p>

<u>总结得到的Linear/Kernel Model如下图：</u>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-1/58915472.jpg" width="450px" /></p>

<ul>
  <li>first row: less used due to worse performance</li>
  <li>second row: popular in <strong>LIBLINEAR</strong></li>
  <li>third row: less used due to dense $\beta$</li>
  <li>fourth row: popular in <strong>LIBSVM</strong></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Support Vector Machine]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/27/svm/"/>
    <updated>2016-02-27T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/27/svm</id>
    <content type="html"><![CDATA[<p>支持向量机(support vector machine, SVM)是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可以形式化为凸二次规划问题的求解，也等价于正则化的合页损失函数的最小化问题。SVM还包括kernel trick，使得它可以成为实质上的非线性分类器。下面就介绍Perceptron到三种类型的SVM模型。</p>

<p><img src="http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/figs/svm2.PNG" width="400px" /></p>

<!--more-->

<h2 id="perceptron">Perceptron</h2>

<p>SVM可以说是Perceptron的一种进化。什么是Perceptron，Wiki的解释如下：</p>

<blockquote>
  <p>the perceptron is an algorithm for supervised learning of binary classifiers</p>
</blockquote>

<p>实则是一个二元线性分类器，通过一个线性的预测函数将观察点分成两类，这个预测函数就是特征空间中的一个分离超平面。对应于方程 $wx+b=0$, $w$ 为法向量或者权值，$b$ 是截距或偏置。</p>

<p>能够将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，即对所有 $y_i＝+1$ 的实例 $i$，有 $wx_i+b&gt;0$，对所有 $y_i＝-1$ 的实例 $i$，有 $wx_i+b&lt;0$，则称数据集为线性可分数据集（linearly separable data set）;否则，称数据集线性不可分。</p>

<p>对于误分类点有 $y_i(wx_i+b) &lt; 0$, 设误分类点集 $M$, 采用0/1损失函数, 则得到感知机的损失函数如下：</p>

<script type="math/tex; mode=display"> L(w, b) = -\sum_{x_i \in M} y_i(w x_i + b) </script>

<p>要使损失函数最小，可以采用随机梯度下降法。任意选取一个超平面 $w_0, b_0$，然后用梯度下降法不断地最小化目标函数，每次选取一个误分类点使其梯度下降。每次迭代如下，随机选取一个误分类点 $(x_i, y_i)$, 对 $(w, b)$ 更新, $\eta$ 为步长：</p>

<script type="math/tex; mode=display"> w \gets w + \eta y_ix_i </script>

<script type="math/tex; mode=display"> b \gets b + \eta y_i </script>

<u>下面我们来证明下经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。</u>

<p>存在超平面 $y_i(\hat{w}_{opt} \cdot \hat{x}_i) = w_{opt} \cdot x_i + b_{opt} = 0$，使 $|\hat{w}_{opt}| = 1$，那么可以对于任意的点 $i$，$y_i(\hat{w}_{opt} \cdot \hat{x}_i) &gt; 0$，所有存在 $\gamma$，使得</p>

<script type="math/tex; mode=display">y_i(\hat{w}_{opt} \cdot \hat{x}_i) = w_{opt} \cdot x_i + b_{opt} \ge \gamma</script>

<p>感知机算法从 $\hat{w}_0 = 0$ 开始，如果实例被误分类，则更新权重。设 $\hat{w}_{k-1}$ 是第 $k$ 个误分类点之前扩充的权值向量，则第 $k$ 个误分类点满足$y_i(\hat{w}_{k-1} \cdot \hat{x}_i) \le 0$，$\hat{w}$ 更新后有</p>

<script type="math/tex; mode=display"> \hat{w}_{k} = \hat{w}_{k-1} + \eta y_i \hat{x}_i </script>

<p>可以得到</p>

<script type="math/tex; mode=display"> \hat{w}_{k} \cdot \hat{w}_{opt} = \hat{w}_{k-1} \cdot \hat{w}_{opt} + \eta y_i \hat{w}_{opt} \cdot \hat{x}_i \ge \hat{w}_{k-1} \cdot \hat{w}_{opt} + \eta \gamma </script>

<script type="math/tex; mode=display">\to \hat{w}_{k} \cdot \hat{w}_{opt} \ge k \eta \gamma</script>

<p>另外假设 $R = max(|\hat{x}_i|)$，有</p>

<script type="math/tex; mode=display"> \|\hat{w}_{k}\|^2 = \|\hat{w}_{k-1}\|^2 + 2\eta y_i \hat{w}_{k-1} \cdot \hat{x}_i + \eta^2 \|\hat{x}_i\|^2 \le \|\hat{w}_{k-1}\|^2 + \eta^2 \|\hat{x}_i\|^2 \le \|\hat{w}_{k-1}\|^2 \eta^2 R^2 </script>

<script type="math/tex; mode=display">\to \|\hat{w}_{k}\|^2  \le k \eta^2 R^2 </script>

<p>我们可以得到 </p>

<script type="math/tex; mode=display">k\eta\gamma \le \hat{w}_{k} \cdot \hat{w}_{opt} \le \|\hat{w}_{k}\| \|\hat{w}_{opt}\| \le \sqrt{k}\eta R</script>

<p>于是 $k \le (R / \gamma)^2$，表示误分类次数 $k$ 是有上界的，也就是经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。</p>

<h3 id="pocket">pocket</h3>

<p>这里想另外介绍一种算法，Pocket算法。当训练集线性不可分时，感知机学习算法不收敛，迭代结果会发生震荡。 Pocket算法也就是用来权衡分离超平面和误分类点的。</p>

<p>从直觉上，我们知道如果当前超平面犯错越少越好，Pocket本质上就是在改错的时候多做一步，判断当前改正犯的错是否比之前更小，也就是贪心选择。</p>

<p>方法如图所示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/79944104.jpg" width="500px" /></p>

<h2 id="linear-support-vector-machine">Linear Support Vector Machine</h2>

<p>Perceptron的问题是什么？它存在许多种解，只要是能够分割观察点的超平面全是它的解，既依赖于初值的选择，也依赖于迭代过程中误分类点的选择。这样的算法带来了不稳定性。为了得到唯一的超平面，需要增加一些约束条件。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/18916886.jpg" width="400px" /></p>

<p>我们认为点距离超平面越远，则越能够容忍噪声，并且对于overfitting的安全边界更大，也就是置信度越大。所以希望能够找到一个距离观察点最远的超平面作为我们的解，这个距离称为Margin，这样的超平面是唯一的。</p>

<p>点到平面的距离为沿着法向量方向的距离，所以有</p>

<script type="math/tex; mode=display"> distance(x, b, w) = \frac{1}{\|w\|} \vert w^Tx + b \vert </script>

<p>顺便提下，上式对法向量进行规范化，使得法向量为单位法向量，这个距离称<strong>几何间隔</strong>，否则是<strong>函数间隔</strong>。接下来，我们想要优化的目标可以写作：</p>

<script type="math/tex; mode=display"> \underset{b,w}{max} \frac{1}{\|w\|} </script>

<script type="math/tex; mode=display">s.t.\ every\ y_n(w^T x_n + b) > 0, \underset{n=1,2..N}{min} y_n(w^T x_n + b) = 1</script>

<p>这里我们有对distance进行缩放，除以 $w^Tx + b$。进一步对问题优化我们得到：</p>

<script type="math/tex; mode=display"> \underset{b,w}{max} \frac{1}{2}w^T w </script>

<script type="math/tex; mode=display">s.t.\ y_n(w^T x_n + b) \ge 1\ for\ all\ n</script>

<p>这样的一个问题其实就是<strong>凸二次规划问题</strong>。可以看下凸二次规划的解法：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/59800326.jpg" width="500px" /></p>

<p>使用任意一款可以解决二次规划的语言包就可以套用上图解决我们的目标问题。这个时候解出来的 $b，w$ 称之为hard-margin，因为没有任何一个点违反我们的限制条件。后面我们会看到一个soft-margin，这个就类似于pocket之于perceptron，可以解决线性不可分的数据集。</p>

<p>对于少量的数据集可以用凸二次规划直接求解，但是数据量一旦增多，求解的速度就成问题。我们可以用拉格朗日乘子法求解原始问题的对偶问题，得到最优解。定义的拉格朗日函数为：</p>

<script type="math/tex; mode=display"> L(b, w, \alpha) = \frac{1}{2}w^Tw + \sum_{n=1}^N \alpha_n(1-y_n(w^T z_n +b)) </script>

<p>这里的 $z_n = \phi(x_n)$ 是为了表示可以对 $x_n$ 做非线性的转换，也就是下一章中提到的kernel function，这里可以直接理解为 $z_n=x_n$。可以这么理解上式：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/6390373.jpg" width="450px" /></p>

<p>根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题，下面我们需要证明：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/47082134.jpg" width="400px" /></p>

<p>假设对于任意的 $\alpha’$，所有的 $\alpha_n’ \ge 0$, 那么</p>

<script type="math/tex; mode=display"> \underset{b,w}{min}(\underset{\alpha_n \ge 0}{max}\ L(b, w, \alpha)) \ge \underset{b,w}{min}\ L(b, w,\alpha’)</script>

<p>因为 $max \ge any$。则对于右式的最优解 $\alpha’$ 有 $best \in any$</p>

<script type="math/tex; mode=display"> \underset{b,w}{min}(\underset{\alpha_n \ge 0}{max}\ L(b, w, \alpha)) \ge \underset{\alpha_n' \ge 0}{max}\underset{b,w}{min}\ L(b, w,\alpha’)</script>

<p>对于大于等于符号来说，这是一个weak duality。如果等号成立则是strong duality，也就是对偶问题和原始问题的最优值相等。需要满足一些限制条件，那就是<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">KKT条件</a>。</p>

<p>求解对偶问题，首先求 （1）$\underset{b,w}{min}\ L(w, b, \alpha)$ </p>

<script type="math/tex; mode=display"> \nabla_w L(w, b, \alpha) = w - \sum_{i=1}^N \alpha_i y_i z_i = 0 \to w=\sum_{i=1}^N \alpha_i y_i z_i</script>

<script type="math/tex; mode=display">\nabla_b L(w, b, \alpha) = \sum_{i=1}^N \alpha_i y_i = 0 \to \sum_{i=1}^N \alpha_i y_i=0</script>

<p>带入原公式得到</p>

<script type="math/tex; mode=display"> L(w, b, \alpha)= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_j y_i y_j (z_i \cdot z_j) + \sum_{i=1}^N \alpha_i </script>

<p>接下来求解 （2） $\underset{b,w}{min}\ L(w, b, \alpha)$ 对 $\alpha$ 的极大值，极大值可以变为极小值</p>

<script type="math/tex; mode=display"> \underset{\alpha}{min}\ \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_j y_i y_j (z_i \cdot z_j) - \sum_{i=1}^N \alpha_i</script>

<script type="math/tex; mode=display"> s.t.\ \sum_{i=1}^N \alpha_i y_i=0,\ \alpha_i \ge 0</script>

<p>求解（2）可以用到<a href="http://www.cnblogs.com/biyeymyhjob/archive/2012/07/17/2591592.html">SMO</a>（序列最小最优化）算法。现在回过头来看 $\alpha$ 的最优解，我们发现至少会有一个 $\alpha_j &gt; 0$，因为根据KKT条件有complementary slackness：</p>

<script type="math/tex; mode=display"> \alpha_i(y_i(w \cdot z_i +b)-1) = 0,\ i=1,2,...N</script>

<p>如果 $\alpha=0$ 则会导致 $w=0$，对于$\alpha_j &gt; 0$，我们看到会有 $y_j(w \cdot z_j +b)-1=0$。如此，可以定义分离超平面为</p>

<script type="math/tex; mode=display"> \sum_{i=1}^N \alpha_i y_i (z \cdot z_i) + b = 0 </script>

<script type="math/tex; mode=display"> b = y_i - \sum_{i=1}^N \alpha_i y_i (z_i \cdot z_j)</script>

<p>上面的推导表明，这些点 $(z_j, y_j)$ 也就是站在分离超平面的margin上的点，所以说SVM只依赖于边界上的点，它们被称为support vectors，支持向量，这也是SVM的由来。</p>

<h2 id="kernel-support-machine">Kernel Support Machine</h2>

<p>在上文中，我们已经了解到了SVM处理线性可分的情况，而对于非线性的情况，SVM 的处理方法是选择一个核函数 $K(⋅,⋅)$，<u>通过将数据映射到高维空间，来解决在原始空间中线性不可分的问题</u>。</p>

<p><img src="http://my.csdn.net/uploads/201206/02/1338612063_1634.JPG" width="400px" /></p>

<p>例如，对于上面的数据集中两类数据，分别分布为两个圆圈的形状，这样的数据本身就是线性不可分的。理想的分界应该是一个二次曲面，可以写成：</p>

<script type="math/tex; mode=display">a_1X_1 + a_2X_1^2 + a_3X_2 + a_4X_2^2 + a_5X_1X_2 + a_6 = 0</script>

<p>上式其实就是一个五维的空间。一般地对于二次多项式的转换形式，我们有</p>

<script type="math/tex; mode=display"> \phi_2(x) = (1, x_1, x_2....x_d, x_1^2, x_1x_2,...x_1x_d,x_2x_1, x_2^2...x_d^2) </script>

<p>在这个 $O(d^2)$ 高维空间做计算无疑非常困难。幸运的是从上一章推导出的分离超平面中，我们可以看到<strong>分类决策其实只依赖输入和训练样本输入的内积</strong>，也就是说，我们可以直接计算 </p>

<script type="math/tex; mode=display"> \phi_2(x)^T \phi_2(x') = 1 + \sum_{i=1}^dx_ix_i' +  \sum_{i=1}^d\sum_{j=1}^d x_ix_j'x_ix_j' = 1 + x^Tx' + (x^Tx')^2</script>

<p>这里我们直接计算高维转换后的内积，有什么好处呢？注意到计算可以在原来的低维空间$O(d)$中发生，不需要再高维空间中计算。这样，称呼<strong>计算两个向量在隐式映射过后的空间中的内积的函数叫做核函数</strong>。可以对原有空间进行一些线性变换，得到</p>

<script type="math/tex; mode=display"> \phi_2(x) = (1, \sqrt{2\gamma}x_1,....\gamma x_d^2) \to K_2(x, x')=1 + 2\gamma x^Tx' + \gamma^2 (x^Tx')^2 </script>

<p>推广之后，我们得到一般的多项式Kernel：</p>

<script type="math/tex; mode=display">K_n(x, x')= (\xi + \gamma x^Tx')^n,\ \xi>0,\gamma>0</script>

<p>对于不同的 $\xi,\gamma$ SVM是不同的，它们的支持向量也是不同的，因为对于SVM来说变化Kernel就意味着重新定义margin。下面是二次多项式Kernel的一些例子：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/72039507.jpg" width="450px" /></p>

<p>其他常用的核函数还包括高斯核，它可以把原来的低维空间扩展到无线大的高维空间中，它的一般公式为 $K(x,x’)=exp(-\gamma |x-x’|^2),\gamma&gt;0$。高斯核函数也被称为 Radial Basis Function(RBF) kernel。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/61331101.jpg" width="500px" /></p>

<p>满足核函数的充要条件是Mercer’s condition，包括：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/48999470.jpg" width="450px" /></p>

<h2 id="soft-margin-support-vector-machine">Soft-Margin Support Vector Machine</h2>

<p>下面我们来讨论下 Soft-Margin SVM。Soft-Margin可以支持数据集线性不可分的情况，允许一些误分类点的存在，在目标优化函数上会对这些误分类点增加处罚：</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi}{min} \frac{1}{2}w^T w  + C\sum_{n=1}\xi_n</script>

<script type="math/tex; mode=display">s.t.\ y_i(w^T z_n + b) \ge 1-\xi_n,\ \xi_n \ge 0\ for\ all\ n</script>

<p>对于参数 $C$ 而言，它是大margin和误分类点的trade-off，大 $C$ 表示少误分类点，小 $C$ 表示大margin。同样计算拉格朗日对偶问题：</p>

<script type="math/tex; mode=display">L(b, w, \xi, \alpha, \beta) = \frac{1}{2}w^Tw + C\sum_{n=1}\xi_n + \sum_{n=1}^N \alpha_n(1-\xi_n-y_n(w^T z_n +b)) + \sum_{n=1}^N \beta_n (-\xi_n)</script>

<script type="math/tex; mode=display">want\ \underset{\alpha \ge 0, \beta \ge 0}{max}(\underset{b,w,\xi}{min}\ L(b, w, \xi, \alpha, \beta))</script>

<p>和hard-margin一样的计算后可以得到</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/23447671.jpg" width="350px" /></p>

<p>对于soft-margin的complementary slackness有</p>

<script type="math/tex; mode=display"> \alpha_n(1- \xi_n - y_n(w^T z_n +b)) = 0,\ (C-\alpha_n)\xi_n=0</script>

<p>存在以下三种情况：</p>

<ul>
  <li>$\alpha_n=0$: $\xi_n=0$, 在边界之外正确分类的点.</li>
  <li>$0&lt;\alpha_n&lt;C$: $\xi_n=0$，支持向量落在边界上。也正是通过这种情况计算截距 $b$.</li>
  <li>$\alpha_n=C$：这种情况比较复杂，可以有下图表示，支持向量的位置由$\xi_n$决定。$0&lt;\xi_n&lt;1$则分类正确，在间隔边界和分离超平面之间；$\xi_n=1$则在分离超平面上；$\xi_n&gt;1$则位于超平面误分类的一侧.</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/76271972.jpg" width="300px" /></p>

<h2 id="hinge-loss-function">Hinge Loss Function</h2>

<p>最后我们说明下SVM可以用合页损失函数表示，就是最小化以下目标函数：</p>

<script type="math/tex; mode=display"> \sum_{i=1}^N[1-y_i(w \cdot x_i + b)]_+ + \lambda\|w\|^2 </script>

<p>下标“+”表示，对 $[z]_+ = z,\ z&gt;0; [z]_+ = 0,\ z \le 0$</p>

<p>可以看到 $1-y_i(w \cdot x_i + b)$ 可以写成</p>

<script type="math/tex; mode=display"> y_i(w \cdot x_i + b) \ge 1-\xi_i,\ \xi_i \ge 0, \ i=1,2,...N </script>

<p>也就是soft-margin SVM的限制条件，那么取 $\lambda= 1/2C$ 则有</p>

<script type="math/tex; mode=display"> \underset{b,w}{min} \frac{1}{C}(\frac{1}{2}\|w\|^2 + C\sum_{n=1}\xi_n)</script>

<p>也就是soft-margin SVM的目标优化函数。合页损失函数的形状如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/97100573.jpg" width="400px" /></p>

<p>虚线显示的是感知机的损失函数 $[y_i(w \cdot x_i+b)]_+$。这时，当样本点 $(x_i，y_i)$ 被正确分类时，损失是0，否则损失是 $-y_i(w \cdot x_i+b)$。相比之下，合页损失函数不仅要分类正确，而且置信度足够高时损失才是0。也就是说，合页损失函数对学习有更高的要求。</p>

]]></content>
  </entry>
  
</feed>
