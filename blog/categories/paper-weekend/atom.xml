<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: Paper Weekend | Tech Digging and Sharing]]></title>
  <link href="http://billowkiller.github.io/blog/categories/paper-weekend/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2016-12-07T15:29:21+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Photon: fault-tolerant and scalable joining of continuous data streams]]></title>
    <link href="http://billowkiller.github.io/blog/2016/11/19/photon/"/>
    <updated>2016-11-19T11:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/11/19/photon</id>
    <content type="html"><![CDATA[<h2 id="intro-and-issues">Intro and Issues</h2>

<p>Photon 是 Google 的数据流合并的系统，目的是 “perform continuous stream joining in real-time”，例如 query log 和 click log 合并。为什么需要对数据流合并呢？</p>

<p>先看下用户使用的场景：用户先 query 一个搜索词，这时候的日志可以直接通过 Google 的网关服务器直接落盘，这里的日志称为 query log，也就是展示广告，表示发给用户的广告信息；之后的一段时间，用户浏览网页，可能会点击到某一条广告，这时候再将用户的 click log 发到某个 log datacenter。</p>

<p>这两个日志所附带的内容区别很大，query log 可以附带很多的信息，类似于展示位、广告主出价等，而 click log 的内容是受限的：虽然可以把需要的信息附带到广告的 url 上，但是传输量变大增加延迟降低用户体验，另外 url 的长度也是受限的。因此很有必要进行日志的合并以用于后续的计费、报表、模型训练等等。</p>

<p>那么处理这个问题的难点在哪里？</p>

<!--more-->

<ul>
  <li>Exactly-once semantics: 任意时刻 at-most-once，实时的 near-exact，最终 exactly-once。</li>
  <li>Automatic datacenter-level fault-tolerance</li>
  <li>High scalability</li>
  <li>Low latency</li>
  <li>unordered streams: 特别的，由于网络或者其他原因，query log 可能会落后于 click log。</li>
</ul>

<h2 id="big-ideas">Big Ideas</h2>

<p>从对系统的要求来看，有两个重要的概念：</p>

<ul>
  <li><code>Persistent State Consistency</code></li>
  <li><code>Exactly Once Eventually</code></li>
</ul>

<h3 id="persistent-state-consistency">1. Persistent State Consistency</h3>

<p>高可用，容错的系统的最简单方法就是冗余，Photon 也如此。导致的问题是在不同的数据中心可能会处理同一份数据。这时候需要对 Worker 进行协调，保证它们不对同一份数据处理。方案是对处理好的 click_id 存储下来，各个 Worker 处理的时候查询下，并在输出 joined log 之前先存储 click_id 以保证 at most once 语义。</p>

<p>Photon 使用基于 <code>Multi-Paxos</code> 的容错、强一致的 <code>IdRegisty</code>。Paxos 能够保证在大多数副本之间同步状态，实现一致性。如下图是一个 IdRegistry 的架构：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-26/63413408.jpg" width="450px" /></p>

<p>不同的数据中心来回的传输时间可能高达100ms，导致 IdRegistry 的 TPS 最高只有 10，对于每秒需要处理上万日志的 photon 来说是不可以接受的。那么如何增加吞吐呢？有两个措施：<code>server-side batching</code>，<code>sharding</code>。这是两个经典的扩大吞吐量的方法，批量和分治。原文如下：</p>

<blockquote>
  <p>Server-side batching combine multiple event-level commits into one bigger commit. The registry thread dequeues multiple requests and batches them into a single PaxosDB transaction.</p>
</blockquote>

<p>但是对于一个批量的 Paxos RPC 怎么区分有冲突的 event_id 原文并没有做过多的说明。</p>

<blockquote>
  <p>To take advantage of the event_id independence, we partition the event id space handled by the IdRegistry into disjoint shards such that event ids from separate shards are managed by separate IdRegistry servers. </p>
</blockquote>

<p>sharding 需要 resharding 是比较麻烦的，需要考虑向后兼容性。对于落后的 log 来说它必须在 resharding 之后还能找到原来的 shard，原文称为 “deterministic mapping”。Photon 通过增加时间窗口实现，在 timestamp 在 [0, now + S] 内使用之前的sharding。这个时间会通过 True Time API 校正，这个 API 是 Google 特有的，通过原子时钟校正，不具有普适性。这里不得不感叹 Google 的基础架构之强大。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-26/39260007.jpg" width="500px" /></p>

<h3 id="exactly-once-eventually">2. Exactly Once Eventually</h3>

<p>这个语义和架构有关，所以我们先看下 Photon 的架构，了解里面的组件如何实现 Exactly-once，这里说明下印象比较深的是在 Paper 中， Photon 使用两个非常普遍的技术：<code>异步 PRC</code>, <code>throttling</code>，在提高效率和稳定性方面带来很大的帮助：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-26/70920655.jpg" width="500px" /></p>

<p><strong>Dispatcher</strong></p>

<p>Dispatcher 负责监控日志文件，并将它们及时的传送到系统。需要注意读取文件的状态元数据会保存在GFS上，用于 failover。发送前需要查看 event_id 是否在 IdRegistry 中，这里的 event_id 需要保持唯一，Photon 使用 &lt;ServerIP, ProcessID, Timestamp&gt; 作为 event_id。</p>

<p>Dispatcher 异步的发送日志到 joiner，等待 joiner 的 ack。如果失败，则会将 click log 存入 GFS，稍后使用指数回退算法重试。一旦重试时间超过阈值，则判定日志为 unjoinable。通过这种方式达到 Dispatcher 的 at least once。</p>

<p>另外至少会有两条 Photon 流在运行，即使一个数据中心挂了，另外一个也可以正常工作。并且在恢复之后会执行 backlog，追上 IdRegistry 中已有的信息，需要注意的是追赶时候的 throttling，防止 IdRegistry 压力过大。</p>

<p><strong>joiner</strong></p>

<p>joiner 接收 dispatcher 传来的数据，并且协调 EventStore 和 IdRegistry，执行日志合并的业务逻辑。joiner 解析 click log 的 click_id 和 query_id，异步获取 EventStore 的 query log 进行比较，一旦获取失败或者 dispatcher 发送过多数据，则会导致失败使得dispatcher 进入重试逻辑。这里的 throttling 是用于 joiner 能维持平滑的数据流。</p>

<p>joiner 使用 adaptor 库处理业务逻辑。一旦 join 成功，则异步地注册 click_id 到 IdRegistry，成功注册后才允许下发 joined log 给下游。这两个步骤在 Photon 中并不是事务地进行，所以一旦在下发前宕机或者 ack 丢失就会导致 joined log 丢失。</p>

<p>之所以不进行事务处理，原因应该是想让 joiner <code>无状态</code>，提高可扩展性。导致的风险可以用下面的方法解决。</p>

<p>提交 click_id 给 IdRegistry 时，joiner 会附带自己的 &lt;ServerIP, ProcessID, Timestamp&gt; 信息作为 <code>unique token</code> 一并提交。当 IdRegistry 收到 click_id 的提交信息时，会比较 token，
相同则说明是上一次没有收到 ack 的那个 joiner 发过来的。IdRegistry 此时返回成功，允许 joiner 下发合并日志。</p>

<p>但此种方法并没有解决宕机带来的不一致。Photon 给的方案是使用另外一个 <code>verification system</code> 作为补充。一旦检测到 IdRegistry 中的 event 并不在 output log 中，则删除 IdRegistry 的 click_id，并重新注入 click log。</p>

<p>以上其实是通过内部机制实现尽力而为的 exactly-once，最后通过类似的 lambda 架构实现最终 exactly-once。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MillWheel: Fault-Tolerant Stream Processing at Internet Scale]]></title>
    <link href="http://billowkiller.github.io/blog/2016/11/13/millwheel/"/>
    <updated>2016-11-13T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/11/13/millwheel</id>
    <content type="html"><![CDATA[<h2 id="intro-and-issues">Intro and Issues</h2>
<p>MillWheel 是 Google 开发的一个低延时的流式处理系统。用户指定计算的 DAG 图，以及图中每个节点的计算代码，MillWheel 负责数据流的计算，保证整个计算过程的分布式以及容错性。从宏观上看，MillWheel 提供了数据计算的幂等性，在用户视角提供不重不丢的语义。</p>

<p>在论文中，还存在一个使用场景。Google 的 Zeitgeist 服务用来监测网络搜索的趋势，输入端是持续不断的搜索内容，经过异常检测，异常检测通过模型预测来排除false positive，输出 spike 或者 dip 的搜索。这要求解决：</p>

<ul>
  <li>Persistent storage： 模型预测和峰值判断分别依赖于长期和短期的存储。</li>
  <li>Low Watermarks: 流量低谷的判断需要有一个标志来判断期待时间窗口内的数据都到达。</li>
  <li>Duplicate Prevention: 在各种情况下用户无需考虑重复流量，系统保证数据传输和处理的 exactly-once 语义。</li>
</ul>

<!--more-->

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-22/53383350.jpg" width="600px" /></p>

<p>综合而言，对比于一般的分布式流式系统，存在一些特别的要求：</p>

<ul>
  <li>处理数据乱序的问题。</li>
  <li>处理数据到达延时问题。</li>
  <li>提供 exactly-once 的保证，尤其在 failover 的时候。</li>
  <li>需要有持久存储，读写权限暴露给用户，提供保证一致性。</li>
</ul>

<h2 id="big-ideas">Big Ideas</h2>

<p>从对系统的要求来看，有两个重要的概念：<code>low watermark</code> 和 <code>exactly-once</code>。low watermark 解决前两个问题，exactly-once 解决后两个问题。</p>

<h3 id="low-watermark">low watermark</h3>

<p>low watermark 在原文的作用如下：</p>

<blockquote>
  <p>The low watermark for a computation provides a bound on the timestamps of future 
records arriving at that computation.</p>
</blockquote>

<blockquote>
  <p>Strip away outliers and offer heuristic low watermark values for pipelines that are more interested in speed than accuracy. </p>
</blockquote>

<p>即时间窗口内所有事件的时间下限，目的是为了让这个窗口可以正常的划出，更快的计算出结果。它其实是提供了一个折衷, 这个折衷就是在watermark这个点认为不会有比 watermark 值更老的数据到来了，本质上是一个barrier, 即系统中所有正在流动的数据的 timestamp 都大于或等于该 watermark。</p>

<p>之所有需要有这个概念，是由于网络环境或者故障导致数据流乱序，窗口无法判断何时数据已经全部到达。这里的时间计算一般是基于eventtime的，即时间发生时间，如logtime。文中也给了一个应用的例子：</p>

<blockquote>
  <p>In the case of Zeitgeist, our input would be a continuously arriving set of search queries, and our output would be the set of queries that are spiking or dipping.</p>
</blockquote>

<p>it is important to be able to distinguish whether a flurry of expected Arabic queries at t = 1296167641 is simply delayed on the wire, or actually not there.</p>

<p>波谷由于数据量小，对到达的数据比较敏感，所以需要判断是真的到达波谷，还仅仅是由于延迟导致数据还在传输途中。之前的做法是再设置一个安全时间，延迟几分钟再计算，但安全时间如何设置？过长则影响时效性，过短无法奏效。或者采取右端开放窗口的补偿方法，先产出数据，当延迟数据到来时再予以修改，但需要业务场景适用、下游系统支持修改。</p>

<p>除了aggregation计算对时序性有要求外，一些策略计算可能也会要求数据完整、有序。那么 low watermark 的定义如下：</p>

<pre><code>low watermark of A = min(oldest work of A, low watermark of C: C outputs to A)
If there are no input streams, the low watermark and oldest work values are equivalent.
</code></pre>

<p>A 点的 low watermark 的值等于 A 点所有待处理的消息的 timestamp 和 A 所有上游 C 的 low watermark 的最小值。这是一个递归的定义，终止条件处于流的源头，即由外围注入的injection或者数据订阅端生成；生成之后会驱动 watermark 传递给下游。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-23/12047055.jpg" width="600px" /></p>

<p>由上图可以看出，low watermark 是根据事件到达后的处理时间递增的，反映的是系统中所有 <em>pending work</em>；并且事件其实并不是有序到达和处理的，但是在某个时间可以确保所有的事件都已经到达了，即在文中所强调的：</p>

<blockquote>
  <p>By waiting for the low watermark of a computation to advance past a certain value, the user can determine that they have a complete picture of their data up to that time</p>
</blockquote>

<p>对于处于 low watermark 下的事件，有两种处理方案：抛弃或者更正已有的状态。</p>

<p>low watermark 除了提供系统事件处理的完成情况，还有一个作用，触发trigger（文中用Timer）。trigger 实际是窗口内部累积状态的记录器，根据不同的触发类型来累积状态，达到一定的条件就允许外围触发，将窗口内的数据计算后 emit 给下游。MillWheel 的触发条件有 wall time 和 low watermark value，这个交给用户来定义。</p>

<h3 id="exactly-once">exactly-once</h3>

<p>这个概念涉及两个方面：</p>

<ul>
  <li>Persistent storage available at all nodes in the stream graph</li>
  <li>Exactly once delivery semantics.</li>
</ul>

<p>前者的概念好理解，Persistent state 在 MillWheel 中表现为一个键值对，值是 protobuf 的一个二进制字符串。用户代码可以方便的获取和设置各种状态。常用的状态为窗口数据聚合中保存的 counter，join 要使用的 buffer 等。</p>

<p>MillWheel 的状态存储在 bigtable 或者 Spanner 中，另外它还提供一个 soft state，用于内存 cache 或者 聚合。为了保证可能存在的状态不一致性，对所有的 per-key update 都封装在一个原子的操作中，防止在处理过程中可能出现的各种意外。</p>

<p>但是在 failover 或者 load balancing 的时候，计算会被迁移，这时候可能存在 zombie writer 或者 stale writer。因此，为了保证原子性，需要保证每个 key 只有一个 writer 可以写入。MillWheel 的解决方案是给每个 writer 附带一个 sequencer token，后台存储的协调者在每个写入前会检查 token 的有效性使得新 worker 可以阻止其他的 sequencer 的有效性。这其实就是一个 lease 机制，在一段时间内对于特定的key只有一个worker可以写入。</p>

<p>保证 Exactly Once 语义有个很重要的简化途径是将用户的非幂等操作变成幂等。通过以下措施来保证：</p>

<ul>
  <li>Exactly Once delivery</li>
  <li>Strong Production</li>
</ul>

<p>Exactly Once delivery 通常的方法是保证 at least once 基础上进行去重。MillWheel 也是通过这个方法保证，发送方发送数据后没有接收到 ack 重新发送数据。另外接收方接收到数据会进行 state modificaton，这时候将数据的 unique ID 也一并原子写入到后端存储；接收端为了加速去重，使用 bloom filter，这时候需要考虑 false postive，如果发生 filter miss，需要去后端存储进行比较，如果确认是重复数据，会返回 duplicate ACK 通知发送方。</p>

<p>在发送方发送数据之前可以进行 checkpoint，用于 failover 后恢复原来的状态。在发送的数据被 ACK 后，checkpoint可以删除。这个 <code>Checkpoint-&gt;Delivery-&gt;ACK-&gt;GC</code> 的运行模式在 MillWheel 中称为 <code>Strong Production</code>。即使用户代码不是幂等的，在 Strong Production 中，无论 retry 多少次，用户的运行逻辑都是正确的。</p>

<p>与之对应的是 <code>Weak Production</code>，这时的用户代码是幂等的，无需strong procution，即 checkpointing；无需 exactly once delivery（把 deduplication 逻辑去掉）。这在延迟和资源消耗上无疑更加友好，但是对于取消 checkpointing 有一个 straggler latency 问题。在 strong production中，只要 checkpoint 就可以返回上游表示这个阶段的任务结束，但是现在需要下游返回 ack 才可以保证，并且这是级联的。Millwheel 采用 checkpointing 一部分 straggler 的 pending production 来缓解，如下图：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-23/46647429.jpg" width="400px/" /></p>

<h2 id="other-details">Other Details</h2>

<p>MillWheel 集群可以动态扩缩容，根据 key interval 划分计算，并以此通过 master 进行负载分配、均衡。当监控进程检测到机器的负载过高的时候，会进行 key interval 的重分配：split、merge、move。</p>

<p>failover 时，key interval 被分配到新的 owner，它可以从后端存储中获取计算需要的元数据，包括 heap of pending timers 以及 queue of checkpointed productions。一个节点的例子如下，每个计算都是一个pipeline，即输入计算输出。数据的传输通过RPC。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-24/94589760.jpg" width="400px" /></p>

<p>另外关于 low watermark 的管理和流动，Millwheel 是基于一个全局的订阅发布中央系统。</p>

<ul>
  <li>每个 processer 将自己持有的所有work（in fly, stored, pending）计算出最小的 timestamp发给中央系统。</li>
  <li>不同的 processer 在不同的 key interval 下，low watermark 也是根据 key interval 来存储。</li>
  <li>为了保证计算的准确性，订阅发布系统会查询后台存储，以保证每个 key interval 都有 low watermark。感兴趣的节点会订阅每个发送端的 low watermark，计算所有的最小值作为 low watermark。</li>
  <li>之所以不在中央系统算最小值是为了保证一致性：中央系统的 low watermark 不能大于节点上的，否则在 failover 后容易出现 low watermark 的回退。在节点上计算最小值则保证中央系统永远不会领先于节点上的。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Mesa: Google's near real-time OLAP warehouse]]></title>
    <link href="http://billowkiller.github.io/blog/2016/08/06/mesa/"/>
    <updated>2016-08-06T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/08/06/mesa</id>
    <content type="html"><![CDATA[<blockquote>
  <p>Ashish et al. VLDB 2014</p>
</blockquote>

<p>谷歌Mesa是一个服务于谷歌广告业务的近实时分析型数据仓库，主要用于广告主的报表、内部审计和预测服务。作为底层的存储系统，Mesa能处理PB级的数据，每秒百万的行更新，并且需要应对每日上亿的查询请求，因此它需要满足的设计目标是：</p>

<blockquote>
  <p>near real-time data ingestion and query ability, as well as high availability, reliability, fault tolerance, and scalability for large data and query volumes.</p>
</blockquote>

<!--more-->

<p>据Google描述，随着他们的广告平台的不断发展，客户对各自的广告活动的可视化提出了更高的要求。对于更具体和更细粒度的信息需求，直接导致了数据规模的急速增长。Google构建了Mesa从而能处理持续增长的数据量，同时它还提供了一致性和近实时查询数据的能力。为了应付如此持续增长并且重要数据的处理、存储和查询需求，Mesa的具体需求包括：</p>

<ul>
  <li>
    <p><code>原子更新</code>。某一单个的用户行为可能会引起多个关系数据级别的更新，从而影响定义在某个指标集上（例如：点击和成本）跨某个维度集（例如：广告客户和国家）的数千张一致性视图。所以系统状态不会在查询时处于一个只有部分更新生效的状态。</p>
  </li>
  <li>
    <p><code>一致性和正确性</code>。出于业务和法律的原因，该系统必须返回一致和正确的数据。即使某个查询牵涉到多个数据中心，我们仍然需要提供强一致性和可重复的查询结果。</p>
  </li>
  <li>
    <p><code>可用性</code>。系统不允许出现单点故障。不会出现由于计划中或非计划中的维护或故障所造成的停机，即使出现影响整个数据中心或地域性的断电也不能造成停机。</p>
  </li>
  <li>
    <p><code>近实时的更新吞吐率</code>。系统必须支持大约每秒几百万行规模的持续更新，包括添加新数据行和对现有数据行的增量更新。这些更新必须在几分钟内对跨不同视图和数据中心的查询可见。</p>
  </li>
  <li>
    <p><code>查询性能</code>。系统必须对那些对时间延迟敏感的用户提供支持，按照超低延迟的要求为他们提供实时的客户报表，而分批提取用户需要非常高的吞吐率。总的来说，系统必须支持将99%的点查询的延迟控制在数百毫秒之内，并且整体查询控制在每天获取万亿行的吞吐量。</p>
  </li>
  <li>
    <p><code>可伸缩性</code>。系统规模必须可以随着数据规模和查询总量的增长而伸展。举个例子，它必须支持万亿行规模和PB级的数据。但是即使上述参数再出现显著增长，更新和查询的性能必须仍然得以保持。</p>
  </li>
  <li>
    <p><code>在线的数据和元数据转换</code>。为了支持新功能的启用或对现有数据粒度的变更，客户端经常需要对数据模式进行转换或对现有数据的值进行修改。这些变更必须对正常的查询和更新操作没有干扰。</p>
  </li>
</ul>

<p>所有Google现有的大数据技术都无一能满足所有以上的需求。BigTable无法提供<code>原子性和强一致性</code>。而Megastore、Spanner和F1虽然为跨地域复制的数据提供了<code>强一致性</code>的访问，但是他们无法支持Mesa客户端所有需要的<code>峰值更新吞吐率</code>。既有的ROLAP或者MOLAP方法也不能在提供<code>近实时查询</code>同时支持分钟级别的<code>数据更新和聚合</code>。但是Mesa在其不同的基础设施中充分利用了现有的Google技术组件。它使用了BigTable来存储所有<code>持久化的元数据</code>，使用了Colossus (Google的分布式文件系统)来存储数据文件。此外，Mesa还利用了MapReduce来处理连续的数据。</p>

<p>以下有几个技术要点：</p>

<ul>
  <li>为了存储的可伸缩性和可用性，数据是水平分片，并且重复的。</li>
  <li>为了得到一致性和update时候的查询可用性，利用了多版本控制。</li>
  <li>为了更新可伸缩行，数据的更新是批量的和周期性的，并且赋值一个新的版本。</li>
  <li>为了多数据中心数据更新的一致性，Mesa利用基于Paxos的分布式同步协议。</li>
</ul>

<p>Mesa的contributions包括以下一些内容：</p>

<ul>
  <li>高吞吐量的PB级别的数据仓库，同时维持ACID属性以提供事务的处理能力</li>
  <li>新的版本管理方式，利用批量更新，得到低延迟和高吞吐量</li>
  <li>应用数据是通过一个独立和冗余的程序进行异步复制，但是关键的元数据是同步复制。这样可以减少管理副本的同步消耗，并且得到数据更新的高吞吐量</li>
  <li>在线的schema change，并不会影响现有程序的正确性和性能</li>
  <li>软件错误或硬件错误带来的数据损毁的容忍性</li>
</ul>

<h3 id="section">数据模型</h3>

<p>在Mesa的数据是多维度的，定义了细粒度的一个事实表。在这个事实表中分为两种属性，一个是 Key， 一个是 Value。Key是多维的，并且具有层级，例如 date 可以组织成 day, month, year。<strong>单个事实表在这些层级之间的聚合可以被物化，这样就支持数据分析的上卷和下钻。</strong>Value 也就是一些数据 Metrics。</p>

<p>数据是组织成表的，每个表有 schema 用于指定表结构。schema 里面包含了<code>Key空间</code>和<code>Value空间</code>，指明他们的<strong>类型</strong>和<strong>聚合方式</strong>：aggregation function $F: V \times V \to V$。一般来说聚合方法有 SUM、MAX、MIN 和 REPLACE；schema 还指明了table的一个或多个索引方法。</p>

<p>数据按对应的索引序排序分割成限定大小的文件，每个文件内部再按<strong>行分割成行组row blocks进行压缩存储</strong>，每个行组内部的数据在实际存储时，<strong>按列式存储的layout进行转换压缩，提高压缩率</strong>。而<strong>索引文件</strong>由行键取固定长度的前缀组成，映射到对应数据行在行组内部的存储偏移量。因为是一个前缀，所以索引可能不能精确定位一行的位置，而是定位这一行在行组内的偏移范围，在通过二分查找的方式在行组内部定位到具体的行。</p>

<h3 id="section-1">查询和更新</h3>

<p>Mesa中存储的数据是多版本的，更新时版本号是向前叠加的，只有处理完当前的版本才会更新下一个版本。这使得当新的更新正在处理时，Mesa可以向用户提供前置状态的<code>一致性数据</code>，也就是 update 的<code>原子性</code>。这种<strong>严格的版本顺序</strong>还可以保证数据的正确性。</p>

<p>通常，每隔几分钟，上游系统就会执行一次数据更新的批处理，结果为产生数据提交文件。独立的各个<code>无状态</code>的数据提交者实例，负责对跨（Mesa运行所在的）全部数据中心的更新操作进行协调。提交者为每个更新批处理分配一个新的版本号，并基于<code>Paxos一致算法</code>向版本数据库<strong>发布全部与该更新关联的元数据</strong>。当一个更新满足提交的条件时，意味着一个给定的更新已经被全球范围内的大量Mesa实例进行了合并，提交者会将该次更新的版本号声明为新的提交版本号，并将该值存储在版本数据库里。</p>

<p>查询通常都是根据提交版本号来分发的，因为<strong>查询通常都是根据提交版本号来分发的，所以Mesa不需要在更新和查询之间进行任何的锁操作</strong>。更新都是由Mesa实例在批处理中进行异步实施的。这些属性使得Mesa获得了非常高的查询和更新吞吐率，同时也对数据一致性提供了保障。</p>

<h3 id="section-2">版本管理</h3>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-8-7/25645530.jpg" width="500px" /></p>

<p>为了支持查询的高效性，如上图，Mesa中的版本分为Base，Cumulative和Singleton，含义在图中也有了清晰的表达，主要的目的是为了<strong>打平查询时计算的消耗，将数据聚合前置</strong>。Singleton就是上文中的上游产生的数据，每个几分钟产生一个。Base，Cumulative分别是由Base Compaction和Cumulative Compaction产生。二者都会按照一定的规则进行，显然后者的频率会远高于前者。</p>

<p>singleton中因为row都是有序，所以两个singleton归并的时间是线性的。多个文件的归并可以使用<strong>最小堆算法</strong>，达到 nlogn 的时间。如何找到需要版本号的多个文件，可以使用<strong>最短路径算法</strong>。</p>

<p>归并方法与HBase的<code>Memory Store -&gt; flush -&gt; Minor compaction -&gt; major compaction</code>的整体流程概念也很相似。但是与HBase／Bigtable的区别有三点：</p>

<p>第一，批量的写操作，Mesa是直接通过外部系统提交批量数据来实现，HBase则是借助于Memory Store／Flush机制来缓冲，将随机写累积成批量写，Mesa因此需要外部系统配合，不过，也减少了服务自身的复杂性。</p>

<p>第二，底层文件合并，目的都是为了提升检索效率，但是HBase更多的是做简单（或者说通用）的数据归并动作，将无效数据（比如Delte掉的数据，超过历史版本数量的数据）剔除，减少文件数量等，本质上不改变数据的形态，性能的收益是从检索本身的开销上获得的，而对于Mesa来说，其工作的重点是历史数据的聚合（剔除一行的动作是通过负值Value来实现），本质上是将细粒度数据转化为粗粒度数据的过程（当然，和前面说的，实际上，取决于聚合函数的定义，可能可以达到其它目的），性能的改善更多的是从数据的形态变化上获得的。</p>

<p>第三，Mesa中Version版本的概念也与BigTable／HBase相比较，形式类似，但是整体目的用途，还是不同的。HBase系统中版本，尽管理论上可以认为是行／列以外的又一个存储维度，但实际系统的设计导向，基本就是作为区分数据历史版本使用，有不少其它系统（比如Percolator／Trafodion）借助于HBase的Cell版本功能，构建起MVCC的机制来实现例如跨行跨表原子操作，OLTP等特性。但是在Mesa中，除了构建原子操作，从查询方式（返回所有0-n版本聚合后的数据）和预聚合合并Delta文件等系统整体设计思路的角度来看，其版本的功能指向，更接近时间序列的概念，用来罗列相同Key下的可聚合的细粒度数据，当然，实际应用可能性取决于聚合函数的定义（比如假设有一个聚合函数是LastVersion，那就接近HBase的版本概念了）。</p>

<h3 id="section-3">其他工程优化</h3>

<p>delta 剪枝：类似于key range，bloomfilter等，可以快速数据块中是否含有需要的信息。</p>

<p>Scan to seek： 如果查询条件的过滤字段不是索引组合键的第一个字段，对过滤字段的左侧字段进行枚举检索，尽量减少需要进行范围检索的工作</p>

<p>Resume key：海量数据的返回是分批返回的，返回结果中附带一个Resume key用作标识当前进度，便于后续查询可以在此基础上继续进行</p>

<p>Mesa系统内部的日常数据维护工作可能涉及到大量读写工作，采用了MR作业来分布式的进行，而要保证MR作业的时间可控性，正确的进行分区，避免数据倾斜会是一个需要妥善解决的问题，Mesa采用数据采样的方式，对每个Delta文件同步存储一个采样文件，通过预读采样文件，决定MR任务分区的键值</p>

<p>对于表结构Schema的在线变更，Mesa提供两种方式，一是使用新的schema全量拷贝数据到新的版本上，二是在特定的表结构变更场景中（比如增加字段的这种表结构变更操作），在查询的时候动态判断schema版本，对返回数据进行转换，（增加字段的变更为例，Mesa会为老数据补上默认值），这个过程只需要维持一段特定的时间，因为MESA内的数据经过一段时间会进行Delta增量合并操作，在合并过程中Mesa再对涉及到的历史数据进行格式转换操作。</p>

<p>数据校验采用线上和线下两种方式。线上测试在每个update和query操作中进行，针对每个数据文件和index文件，检查checksum，并且查看row key的排序和范围。线下测试会进行全局的checksum校验，这个checksum依赖row的顺序，对于不同粒度（table，version，index）会有不同的checksum粒度。</p>

<h3 id="lessons-learned">Lessons Learned</h3>

<ul>
  <li>分布式并行化，非中心化的思想横贯其中。</li>
  <li>注意模块化和抽象化，以及分层的设计理念</li>
  <li>减少对应用层的假设，需要设计的更加通用化，对现在和未来应用的假设越少越好</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Column-Stores vs. Row-Stores]]></title>
    <link href="http://billowkiller.github.io/blog/2016/07/31/column-stores-row-stores/"/>
    <updated>2016-07-31T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/07/31/column-stores-row-stores</id>
    <content type="html"><![CDATA[<blockquote>
  <p>Abadi et al. SIGMOD 2008</p>
</blockquote>

<p>在数据分析领域，例如数据仓库、决策支持、BI应用等，面向列的存储结构通常会比面向行的存储结构表现要好一个数量级以上，因为只需要读取需要的属性，列存储对于只读的查询 IO 更高效。本文否定了用列存储的思想优化行存储的方式，提出对两种存储方式都有效的优化，并探讨列存储真正高效的原因。</p>

<!--more-->

<h3 id="row-vs-column">Row vs. column</h3>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-31/39462037.jpg" width="500px" /></p>

<p>Row store 更加适合添加和修改一条记录，但读取不必要的数据；Column Store 适合读取相关数据，但写的时候需要多次磁盘IO。所以 Column stores 适合读密集型的数据集。对比如下：</p>

<table border="1" cellspacing="0" cellpadding="0"> <tbody><tr>  <td valign="top" style="background:#5B9BD5;"><p align="left"><strong><span style="color:white;">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; </span></strong></p></td>  <td valign="top" style="background:#5B9BD5;"><p align="center"><strong><span style="color:white;">行式存储</span></strong></p></td>  <td valign="top" style="background:#5B9BD5;"><p align="center"><strong><span style="color:white;">列式存储</span></strong></p></td> </tr> <tr>  <td valign="top" style="background:#DEEAF6;"><p align="center"><strong>优点</strong></p></td>  <td valign="top" style="background:#DEEAF6;"><p align="left">Ø&nbsp; 数据被保存在一起</p>  <p align="left">Ø&nbsp; INSERT/UPDATE容易</p></td>  <td valign="top" style="background:#DEEAF6;"><p>Ø&nbsp; 查询时只有涉及到的列会被读取</p>  <p>Ø&nbsp; 投影(projection)很高效</p>  <p>Ø&nbsp; 任何列都能作为索引</p></td> </tr> <tr>  <td valign="top"><p align="center"><strong>缺点</strong></p></td>  <td valign="top"><p align="left">Ø&nbsp; 选择(Selection)时即使只涉及某几列，所有数据也都会被读取</p></td>  <td valign="top"><p>Ø&nbsp; 选择完成时，被选择的列要重新组装</p>  <p>Ø&nbsp; INSERT/UPDATE比较麻烦</p></td> </tr></tbody></table>

<p>通常来说它比 Row store 在某些应用中更快的原因有：</p>

<ul>
  <li>只读取需要的列</li>
  <li>更好的缓存有效性</li>
  <li>适合压缩</li>
</ul>

<h3 id="row-oriented-execution">Row-oriented Execution</h3>

<p>首先看下在商用的行存储DBMS中如何实现列数据库：</p>

<ol>
  <li>
    <p>Vertical Partitioning</p>

    <blockquote>
      <p>The most straightforward way to emulate a column-store approach in a row-store is to fully vertically partition each relation.</p>
    </blockquote>

    <p>垂直切割表格形成两列的tuple表（table key, attribute）, 查询的时候直接访问必要的列。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-31/64076524.jpg" width="450px" /></p>

    <p>遇到的问题： 需要添加 Position 列，浪费磁盘和带宽；Tuple 有额外 Header，例如 PostgreSQL 里有 24 bytes。</p>
  </li>
  <li>
    <p>Index-only Plan</p>

    <blockquote>
      <p>base relations are stored using a standard, row-oriented design, but an additional unclustered B+Tree index is added on every column of every table.</p>
    </blockquote>

    <p>构造在query中所需要用到的所有列的数据块的集合，所以查询的时候根本不需要查询底层的（按行存储的）表。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-31/2612463.jpg" width="450px" /></p>

    <p>遇到的问题：分开的数据块如果需要全表扫表的话，会很慢。</p>
  </li>
  <li>
    <p>Materialized Views</p>

    <blockquote>
      <p>Create optimal set of MVs for given query workload to provide just the required data, avoid overheads and perform better.</p>
    </blockquote>

    <p>使用query中所需要用到的列的物化视图集合，尽管使用很多空间，但是可以得到更好的效率，典型的空间换时间。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-31/44662651.jpg" width="300px" /></p>

    <p>遇到的问题：适用性比较窄；需要知道查询的先验知识。</p>
  </li>
</ol>

<h3 id="column-oriented-execution">Column-oriented Execution</h3>

<p>下面来看下面向列存储的一些优化方法：</p>

<ol>
  <li>
    <p>Compression</p>

    <blockquote>
      <p>Low information entropy (high data value locality) leads to High compression ratio.</p>
    </blockquote>

    <p>这个比较重要，有结果显示压缩和不压缩性能上会差别一个数量级，具体的好处是：</p>

    <ul>
      <li>节省磁盘空间</li>
      <li>减少磁盘和网络IO</li>
      <li>如果能在压缩数据上面做计算，那 CPU 消耗也可以降低</li>
    </ul>

    <p>几个注意点：</p>

    <ul>
      <li>注意压缩率和解压效率的权衡，使用轻量级的压缩算法，牺牲一些压缩率。</li>
      <li>使用类似run-length encoding (1,1,1,2,2 -&gt; 1<em>3,2</em>2)，可以直接在压缩数据上做计算。</li>
      <li>特别是对于排好序的数据，压缩效率会更高。</li>
    </ul>
  </li>
  <li>
    <p>Late Materialization</p>

    <p>通常来说，查询结果是要得到一个 entity，而不是一个 column，所以需要对多个列进行 join。比较朴素的做法是，数据按列存储在磁盘上，当一个query需要多个 column 的时候，会从这些属性中构造 tuples，接着进行一些其他操作（select，aggregate，join…）。虽然这样做仍然会优于 row-oriented 的存储，但是会有许多优化空间，使用延迟物化就是一个。</p>

    <p>举一个例子，<code>SELECT R.a FROM R WHERE R.c = 5 AND R.b = 10</code>。首先，<code>R.c</code> 和 <code>R.b</code> 的输出是一个 bit string，这个其实就是中间结果 position lists，对着两个结果进行 <code>bitwise and</code>，最后这个 final position list 提取 <code>R.a</code>。</p>

    <p>带来的好处有：</p>

    <ul>
      <li>非必要的 tuple 构建省略了（selection 和 aggregation带来的）</li>
      <li>可以直接对着压缩数据进行操作</li>
      <li>更好的 cache performance，没有其他属性的数据污染 cache</li>
      <li>可以结合下一个优化点</li>
    </ul>
  </li>
  <li>
    <p>Block Iteration</p>

    <blockquote>
      <p>Operators operate on blocks of tuples at once like batch processing.</p>
    </blockquote>

    <p>对 Block 而不是 Tuple 进行操作，这个同样可以应用在 Row-oriented stores 上，带来的好处有：</p>

    <ul>
      <li>如果列是固定宽度的，则可以变成对数组的操作</li>
      <li>减少 tuple 的 overhead</li>
      <li>有效利用并行化</li>
    </ul>
  </li>
</ol>

<h3 id="section">结论</h3>

<p>Vertical portioning 和 Index only plan 并不能起到很好的效果，Materialized view 表现的最好。</p>

<ul>
  <li>Block processing improves the performance by a factor of 5% to 50%</li>
  <li>Compression improves the performance by almost a factor of two on avg</li>
  <li>Late materialization improves performance by almost a factor of three</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Realtime Data Processing at Facebook]]></title>
    <link href="http://billowkiller.github.io/blog/2016/07/13/realtime-data-processing-at-facebook/"/>
    <updated>2016-07-13T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/07/13/realtime-data-processing-at-facebook</id>
    <content type="html"><![CDATA[<blockquote>
  <p>Chen et al. SIGMOD 2016</p>
</blockquote>

<p>论文说明Facebook是如何建立实时系统的。有段话说明batch和stream的关系：</p>

<blockquote>
  <p>Streaming versus batch processing is not an either/or decision. Originally, all data warehouse processing at Facebook was batch processing. We began developing [some of our streaming systems] about five years ago… using a mix of streaming and batch processing can speed up long pipelines by hours. Furthermore, streaming-only systems can be authoritative. We do not need to treat realtime system results as an approximation and batch results as “the truth.”</p>
</blockquote>

<!--more-->

<p>典型的实时系统有Twitter的<code>Storm</code>和<code>Heron</code>、Google的<code>Millwheel</code>，LinkedIn的<code>Samza</code>。Facebook有<code>Puma</code>、<code>Swift</code>、<code>Stylus</code>，在实时系统中他们有以下几方面的考虑：</p>

<ol>
  <li>易用性：处理要求有多复杂，sql是否足够，还是需要通用语言？用户对新应用的编写，测试、调试和部署有多快，如何对应用进行监控？</li>
  <li>性能：延迟，吞吐量，每台机器的以及聚合时候的？</li>
  <li>容错性：容忍错误种类，数据处理和输出时的语义保证，系统如何存储恢复内存状态？</li>
  <li>扩展性：数据分片以及重新分片的并行处理，数据量增加和减小时候系统如何处理，对于老数据的重放？</li>
  <li>正确性：ACID保证？</li>
</ol>

<p>数据处理需求允许秒级的延迟，所以fb中的数据传输是通过一个持久存储的；分离传输和处理带来的好处是易用、容错和可扩展以及一部分正确性保证。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-13/63234135.jpg" width="500px" /></p>

<ul>
  <li>
    <p>scribe</p>

    <p>Scribe从各种数据源上收集数据，放到一个共享队列上，然后push到后端的中央存储系统上。当中央存储系统出现故障时，scribe可以暂时把日志写到本地文件中，待中央存储系统恢复性能后，scribe把本地日志续传到中央存储系统上。
需要注意的是，各个数据源须通过thrift向scribe传输数据（每条数据记录包含一个category和一个message）。可以在scribe配置用于监听端口的thrift线程数。在后端，scribe可以将不同category的数据存放到不同目录中，以便于进行分别处理。后端的日志存储方式可以是各种各样的store，包括file（文件），buffer（双层存储，一个主储存，一个副存储），network（另一个scribe服务器），bucket（包含多个store，通过hash的将数据存到不同store中），null(忽略数据)，thriftfile（写到一个Thrift TFileTransport文件中）和multi（把数据同时存放到不同store中）</p>
  </li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-14/99114695.jpg" width="500px" /></p>

<ul>
  <li>puma 使用支持Java UDF的类sql语言，目的在于快速开发部署</li>
  <li>swift 使用脚本语言支持流式处理，简单的API和checkpointing。</li>
  <li>stylus C++编写，类似Strom的流处理引擎。</li>
  <li>Laser 高吞吐低延迟的内存KV存储，基于RocksDB（基于Google的LevelDB）<a href="https://influxdata.com/blog/benchmarking-leveldb-vs-rocksdb-vs-hyperleveldb-vs-lmdb-performance-for-influxdb/">benchmark</a></li>
  <li>Scuba fast slice-and-dice analysis data store，支ad-hoc query和可视化</li>
  <li>Hive  数据仓库</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-7-13/55531065.jpg" width="600px" /></p>

<ul>
  <li>Language paradigm
    <ul>
      <li>声明语言，SQL，编写作为最简单和快速，群众基础好。缺点是表达能力不够。</li>
      <li>函数语言，使用预制的算子串联处理过程，简单并且对算子的组合增加表达能力。</li>
      <li>过程语言，C++，JAVA，Python，灵活，性能最高，对数据结构和执行过程有完全掌控力，但是要求也最高。S4/Storm/Heron/Samza。</li>
    </ul>
  </li>
  <li>Data transfer
    <ul>
      <li>直接传输，RPC或者内存消息队列。延迟少，毫秒级。</li>
      <li>Broker，另外一个broker进程处理数据传输，增加overhead但是扩展性好。支持多对多的传输，支持反压。典型的是Heron。</li>
      <li>持久存储，persistent message bus。多路复用，输入输出不同的速度，不同的时间点，重复读。</li>
    </ul>

    <p>邻近节点处于DAG中，两种依赖关系，窄依赖和宽依赖，实现在数据传输中。</p>
  </li>
  <li>
    <p>Processing semantics</p>

    <p>stream processor有三种行为：</p>

    <ul>
      <li>处理input event，反序列化输入event，查询外部系统，更新内存状态，并没有side-effect</li>
      <li>输出产生，根据input event和内存状态，向下游产生输出。可以在检查点之前或之后。</li>
      <li>保存检查点，内存状态、input stream offset、output value</li>
    </ul>

    <p>根据这些行为的实现方式，有两种语义信息：</p>

    <ul>
      <li>状态语义，input event是at-least once, at-most once, exactly</li>
      <li>输出语义，output value….</li>
    </ul>

    <p>无状态的处理器只有输出语义，有状态的有两种语义。状态语义只依赖于保存offset和内存状态的顺序。</p>

    <ul>
      <li>at-least-once，先内存状态后offset</li>
      <li>at-most-once，先offset，再内存状态</li>
      <li>exactly，原子的</li>
    </ul>

    <p>输出语义依赖数据保存到checkpint的顺序：</p>

    <ul>
      <li>at-least-once，先emit output再offset和内存状态</li>
      <li>at-most-once，先offset和内存状态，再emit output</li>
      <li>exactly，原子的事务性</li>
    </ul>

    <p>可以做一些side-effect-free的操作加速吞吐量，例如保存checkpoint的同时进行反序列化。</p>
  </li>
  <li>
    <p>State-saving mechanism </p>

    <ul>
      <li>Replication</li>
      <li>local database persistence</li>
      <li>remote database persistence</li>
      <li>upstream backup</li>
      <li>global consistent snapshot</li>
    </ul>
  </li>
  <li>
    <p>Backfill processing</p>

    <ul>
      <li>stream only.</li>
      <li>保存两个系统，一个用于batch，一个用于流处理</li>
      <li>开发流处理系统可以运行在batch环境中，spark streaming 和 flink. </li>
    </ul>
  </li>
</ul>

<h3 id="lessons-learned">Lessons learned</h3>

<ol>
  <li>拥有多个不同的实时处理系统是有好处的. “Writing a simple application lets our users deploy something quickly and prove its value first, then invest the time in building a more complex and robust application.”</li>
  <li>回放对于debug来说很重要.</li>
  <li>“Writing a new streaming application requires more than writing the application code. The ease or hassle of deploying and maintaining the application is equally important. Laser and Puma apps are deployed as a service. Stylus apps are owned by the individual teams who write them, but we provide a standard framework for monitoring them.” Making Puma apps self-service was key to scaling to the hundreds of data pipelines using Puma today.</li>
  <li>使用告警来检查应用的处理速度低于输入速度，未来考虑自动缩放。</li>
  <li>Streaming versus batch processing does not need to be an either/or decision.</li>
  <li>易用性很重要.</li>
</ol>

]]></content>
  </entry>
  
</feed>
