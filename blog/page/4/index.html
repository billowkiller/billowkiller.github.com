<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Tech Digging and Sharing</title>
  <meta name="author" content="wutao">

  
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://billowkiller.github.io/blog/page/4">
  <link href="/favicon.png" type="image/png" rel="icon">
  <link href="/atom.xml" rel="alternate" title="Tech Digging and Sharing" type="application/atom+xml">

  <link href="/javascripts/libs/bootstrap-3.0.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/javascripts/libs/bootstrap-3.0.0/dist/css/bootstrap-theme.min.css" rel="stylesheet" type="text/css">
<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<style type="text/css">
body {
  font-family: Lucida Grande,Helvetica, arial, sans-serif;
  font-size: 15px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

    table {
  padding: 0; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      text-align: left;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      text-align: left;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }
    }
</style>


  <script src="/javascripts/libs/jquery/jquery-2.0.3.min.js"></script>
  

</head>

  <body   >
    <div id="wrap">
      <header role="banner">
        <nav class="navbar navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Tech Digging and Sharing</a>
        </div>

        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                <li class="active">
                    <a href="/">Blog</a>
                </li>
                <li >
                    <a href="/blog/archives">Archives</a>
                </li>
				<li >
                    <a href="/blog/tags">Tags</a>
                </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a class="subscribe-rss" href="/atom.xml" title="subscribe via RSS">
                        <span class="visible-xs">RSS</span>
                        <img class="hidden-xs" src="/images/rss.png" alt="RSS">
                    </a>
                </li>
                
            </ul>
            
                <form class="search navbar-form navbar-right" action="http://google.com/search" method="GET">
                    <input type="hidden" name="q" value="site:billowkiller.github.io">
                    <div class="form-group">
                        <input class="form-control" type="text" name="q" placeholder="Search">
                    </div>
                </form>
            
        </div>
    </div>
</nav>


      </header>
      <div id="main" class="container">
        <div id="content">
          <div class="row">
  <div class="page-content col-md-9">
    <div class="blog-index">
      
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-03-19T14:00:00+08:00" pubdate data-updated="true">Mar 19<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/03/19/hmm/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/03/19/hmm/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/03/19/hmm/">Hidden Markov Model</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程（Markov process）。HMM 被用来对有序的序列数据建模，例如句子中的单词，基因中的基本序列，所以常被应用在语音识别、信息提取、基因测序、股票预测等领域。</p>

<p>在 HMM 中，马尔可夫过程是一类随机过程，原始模型是马尔可夫链。它包含一个状态的有限集，状态的变化只依赖于上一个时间点，而与再之前的时间无任何关系，且状态的轮换是有一定的概率发生。所以可以把马尔可夫过程当成是一个有限状态自动机的概率变种。PageRank 其实也是一种马尔可夫过程。</p>

<p>但是在 HMM 中，状态是未知的，这就是 hidden 的由来，我们只能看到观察值，也就是由状态产生的结果。下图是一个 HMM 的例子。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/24496294.jpg" width="300px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/03/19/hmm/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-03-06T14:00:00+08:00" pubdate data-updated="true">Mar 6<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/03/06/apriori/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/03/06/apriori/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/03/06/apriori/">Apriori and FP-Growth</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>如果说监督学习的形式化表达是 $Pr(Y \vert X)$, 找到最佳的参数最小化每个 $x$ 的epxected error： $argmin_{\theta}\ E_{Y \vert X} L(Y, \theta)$。那么非监督学习的形式化表达就是 $Pr(X)$，目标是在没有 $Y$ 引导的情况下，推测出 $Pr(X)$ 的潜在属性。本文要提到的apriori算法也是一种非监督学习算法，wiki的定义为</p>

<blockquote>
  <p>The Apriori Algorithm is an influential algorithm for mining frequent itemsets for boolean association rules.</p>
</blockquote>

<p>著名的啤酒和尿布例子就是指这个算法。它是属于关联分析中的一种，也就是从大规模数据集中寻找物品间的隐含关系。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/03/06/apriori/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-03-05T14:00:00+08:00" pubdate data-updated="true">Mar 5<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/03/05/em/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/03/05/em/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/03/05/em/">Expectation Maximization</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>Expectation Maximization, EM算法在参数估计里面有极大的用处，它用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率（MAP）估计。隐变量的概率模型参数的极大似然估计可以理解为，使用的方法还是的极大似然估计，但是要处理隐变量。极大后验概率是一种Beyesian Inference，其实就是把极大似然估计中的参数赋予权值，这个权值是预先定义好的先验概率。可以来看下下表中Frequentist-Bayesian对峙的部分，来感受下EM算法的应用范围：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/88568881.jpg" width="500px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/03/05/em/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-03-01T14:00:00+08:00" pubdate data-updated="true">Mar 1<span>st</span>, 2015</time>
        
           | <a href="/blog/2015/03/01/klr-svr/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/03/01/klr-svr/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/03/01/klr-svr/">Kernel Logistic Regression Versus SVM</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>Logistic Regression和SVM都是分类方法，它们定义线性决策边界（linear decision boundaries）作为划分的依据。但二者在motivation方便完全不同，区别如下</p>

<ul>
  <li>LR初衷是为了让linear regression能够输出二元分类，估计一个实例属于某一类的概率；线性决策边界也只是回归函数的结果，在回归函数中使用阈值作为分类的标准，一般是0.5。决策边界在SVM中来的更为重要，整个模型的目标就是为了获得最优的决策边界。</li>
  <li>每个训练样本都对LR的过程有一定的影响，但SVM只依赖于在决策边界附近的某些点。</li>
  <li>LR适应于低维空间，并且由于使用最大似然估计，所以对噪声不敏感；SVM更适应于高维空间</li>
  <li>没有正规化的LR无法保证获得最好的分离超平面，只能获得margin附近的较高的置信度; SVM则能获得最优的分离超平面。</li>
</ul>

<p>那么二者会有什么联系呢，SVM的kernel function又是如何应用到LR模型的呢？</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/03/01/klr-svr/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-02-27T14:00:00+08:00" pubdate data-updated="true">Feb 27<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/02/27/svm/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/02/27/svm/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/02/27/svm/">Support Vector Machine</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>支持向量机(support vector machine, SVM)是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可以形式化为凸二次规划问题的求解，也等价于正则化的合页损失函数的最小化问题。SVM还包括kernel trick，使得它可以成为实质上的非线性分类器。下面就介绍Perceptron到三种类型的SVM模型。</p>

<p><img src="http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/figs/svm2.PNG" width="400px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/02/27/svm/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-02-26T14:00:00+08:00" pubdate data-updated="true">Feb 26<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/02/26/pca-svd/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/02/26/pca-svd/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/02/26/pca-svd/">PCA and SVD</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>PCA即为（Principal Components Analysis）主成分分析，SVD是（Singular value decomposition）奇异值分解。从字面上的理解就可以看出这两个并不是在同一语义层面的东西。之所以把这两个放在一块，一是为了文章的完整性，二是为了说明二者在数据转换（基转换）上的共性。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/02/26/pca-svd/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-02-18T14:00:00+08:00" pubdate data-updated="true">Feb 18<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/02/18/ensemble/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/02/18/ensemble/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/02/18/ensemble/">Ensemble Methods</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>Ensemble<code>|ɒnˈsɒmbl|</code> Methods 称为集成方法，它还有其他类似的名字，meta-algorithm、aggregation model，这些都代表这同一个意思，就是不同弱分类器的组合成一个强分类器。这里的弱分类器要比随机猜测的结果好，错误率小于50%；弱分类器可以是决策树、逻辑回归、朴素贝叶斯等算法。Ensemble的形式有很多种：</p>

<ul>
  <li>不同算法的集成;</li>
  <li>同一算法在不同设置下的集成;</li>
  <li>数据集不同部分分配给不同分类器之后的集成。</li>
</ul>

<p>那么这多个弱分类器又是如何组合的呢，下面给出一个big picture，后面的文章也是对其的阐述。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-18/38802537.jpg" width="450px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/02/18/ensemble/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-02-17T14:00:00+08:00" pubdate data-updated="true">Feb 17<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/02/17/lr-and-lda/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/02/17/lr-and-lda/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/02/17/lr-and-lda/">Logistic Regression and Linear Discriminant Analysis</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>在回归方法中，我们找一个超平面作为类与类之间的decision boundary。回归方法为每个分类建立一个判别函数 $\sigma_k (x)$, 对任意的 $x$，选出得到最大值的判别函数最为归属类。对于后验概率模型 $Pr(G = k|X = x)$ 也是使用同样的方法。对于$\sigma_k (x) 和 Pr(G = k|X = x)$ 来说，只要它们是线性的，那么得到的decision boundary也是线性的。</p>

<p>虽然无法直接使得 $\sigma_k (x) 和 Pr(G = k|X = x)$ 是线性的，但是如果有一个单调的转化函数能够使得是线性的，那么我们也可以得到一个超平面分割数据点。</p>

<p>Logistic Regression 和 Linear Discriminant Analysis就是基于这样的需求构造的模型。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/02/17/lr-and-lda/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-02-15T14:00:00+08:00" pubdate data-updated="true">Feb 15<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/02/15/gradient-descent-and-newton-method/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/02/15/gradient-descent-and-newton-method/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/02/15/gradient-descent-and-newton-method/">Gradient Descent and Newton Method</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>梯度下降和牛顿法都是最优化算法，二者都是求解无约束优化问题的方法，通过递归地逼近最优值来达到求解值。区别在于梯度下降是一阶收敛，而牛顿法是二阶收敛的，所以牛顿法通常会更快，因为牛顿法是用一个二次曲面去拟合当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面。wiki上有张图形象地说明了这个问题：</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/da/Newton_optimization_vs_grad_descent.svg" width="200px" /></p>

<p>下面给出两种方法的具体推导。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/02/15/gradient-descent-and-newton-method/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2015-02-13T14:00:00+08:00" pubdate data-updated="true">Feb 13<span>th</span>, 2015</time>
        
           | <a href="/blog/2015/02/13/concepts-ml/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2015/02/13/concepts-ml/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2015/02/13/concepts-ml/">Some Pre-Concepts in Machine Learning</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>几个容易模糊的机器学习前置概念。做下记录，包括classifier, Hypothesis, Model等。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-21/78335003.jpg" width="400px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2015/02/13/concepts-ml/">Read on &rarr;</a>
    </footer>
  


        </article>
      
    </div>

    <ul class="pager">
      
        <li class="previous"><a href="/blog/page/5/">&larr;&nbsp;Older</a></li>
      
      <li><a href="/blog/archives">Blog Archives</a></li>
      
        <li class="next"><a href="/blog/page/3/">Newer&nbsp;&rarr;</a></li>
      
    </ul>
  </div>

  
    <aside class="sidebar col-md-3">
      
        <section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Recent Posts</h3>
  </div>
  
  <div id="recent_posts" class="list-group">
    
    <a class="list-group-item " href="/blog/2016/11/19/bigdata-perf-tunning/">BigData Performance Tunning</a>
    
    <a class="list-group-item " href="/blog/2016/11/19/photon/">Photon: Fault-tolerant and Scalable Joining of Continuous Data Streams</a>
    
    <a class="list-group-item " href="/blog/2016/11/13/millwheel/">MillWheel: Fault-Tolerant Stream Processing at Internet Scale</a>
    
    <a class="list-group-item " href="/blog/2016/11/10/cache/">Cache</a>
    
    <a class="list-group-item " href="/blog/2016/10/27/distribute-design/">Distributed System Design</a>
    
  </div>
</section>
<section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Categories</h3>
  </div>
  <div class="list-group">
    
    
    <a class="list-group-item " href="/blog/categories/language/index.html">
        <span class="badge">9</span>
        language
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/tools/index.html">
        <span class="badge">7</span>
        tools
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/book/index.html">
        <span class="badge">7</span>
        book
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/paper-weekend/index.html">
        <span class="badge">9</span>
        Paper Weekend
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/linux/index.html">
        <span class="badge">13</span>
        linux
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/film/index.html">
        <span class="badge">3</span>
        film
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/rework/index.html">
        <span class="badge">12</span>
        rework
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/algorithm/index.html">
        <span class="badge">9</span>
        algorithm
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/machine-learning/index.html">
        <span class="badge">13</span>
        Machine Learning
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/big-data/index.html">
        <span class="badge">14</span>
        Big Data
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/notebook/index.html">
        <span class="badge">2</span>
        NoteBook
      </a>
    
  </div>
</section>
<section class="panel panel-default clearfix">
  <div class="panel-heading">
      <h3 class="panel-title">GitHub Repos</h3>
  </div>
  
    <div class="gh-profile-link pull-right text-muted">
      <a href="https://github.com/billowkiller">@billowkiller</a> on GitHub
    </div>
  
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">On Delicious</h3>
  </div>
  <div class="panel-body">
    <div id="delicious"></div>
    <script type="text/javascript" src="http://feeds.delicious.com/v2/json/billowkiller?count=3&amp;sort=date&amp;callback=renderDeliciousLinks"></script>
    <p><a href="http://delicious.com/billowkiller">My Delicious Bookmarks &raquo;</a></p>
  </div>
</section>


      
    </aside>
  
</div>

        </div>
      </div>
    </div>
    <footer role="contentinfo"><div class="container">
    <p class="text-muted credits">
  Copyright &copy; 2016 - wutao<br>
  <small>
      <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>,
      <span class="credit">customized with <a href="https://github.com/kAworu/octostrap3">octostrap3</a></span>.
  </small>
</p>

</div>
</footer>
    <script src="/javascripts/libs/bootstrap-3.0.0/dist/js/bootstrap.min.js"></script>
<script src="/javascripts/modernizr-2.0.js"></script>


<script type="text/javascript">
      var disqus_shortname = 'billowkiller';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





  </body>
</html>
