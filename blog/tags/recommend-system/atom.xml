<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[tags: recommend system | Tech Digging and Sharing]]></title>
  <link href="http://billowkiller.github.io/blog/tags/recommend-system/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2017-01-19T11:14:18+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Practice in Recommend System]]></title>
    <link href="http://billowkiller.github.io/blog/2015/07/16/rs-note/"/>
    <updated>2015-07-16T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2015/07/16/rs-note</id>
    <content type="html"><![CDATA[<p>本文作为推荐系统实践笔记。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/11336234.jpg" width="350px" /></p>

<p>推荐系统是为了解决信息过载问题，一般说来这个问题还可以用搜索引擎解决，但是搜索引擎需要需要用户主动提供准确的关键词来寻找信息；推荐系统不需要用户提供明确的需求,而是通过分析用户的历史行为给用户的兴趣建模,从而主动给用户推荐能够满足他们兴趣和需求的信息。</p>

<p>总的来说，<strong>搜索引擎满足了用户有明确目的时的主动查找需求,而推荐系统能够在用户没有明确目的的时候帮助他们发现感兴趣的新内容</strong>。</p>

<!--more-->

<p>推荐系统可以更好地发掘物品的长尾，推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。个性化推荐系统应用包括：</p>

<ul>
  <li>电子商务</li>
  <li>电影和视频网站</li>
  <li>个性化音乐网站电台</li>
  <li>社交网络</li>
  <li>个性化阅读</li>
  <li>基于位置的服务</li>
  <li>个性化邮件</li>
  <li>个性化广告</li>
</ul>

<p>一般来说,一个新的推荐算法最终上线，需要完成3个实验：</p>

<ul>
  <li>首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。</li>
  <li>然后，需要通过用户调查确定它的用户满意度不低于现有算法。</li>
  <li>最后，通过在线的AB测试确定它在我们关系的指标上由于现有的算法。</li>
</ul>

<p>指标包括以下：</p>

<ol>
  <li>
    <p>用户满意度，反馈按钮，点击率，用户停留时间，转化率</p>
  </li>
  <li>
    <p>预测准确度，可以通过离线实验计算</p>

    <ul>
      <li>
        <p>评分预测的预测准确度一般通过均方根误差(RMSE)和平均绝对误差(MAE)计算。</p>

        <script type="math/tex; mode=display"> RMSE = \frac{\sqrt{\sum_{u,i \in T}(r_{ui}-\hat{r}_{ui})^2}}{\vert T \vert}，MAE = \frac{\sum_{u,i \in T} \vert r_{ui}-\hat{r}_{ui} \vert}{\vert T \vert} </script>

        <ul>
          <li>用户u和物品i，$r_{ui}$ 是用户u对物品i的实际评分，$\hat{r}_{ui}$ 是推荐算法给出的预测评分</li>
          <li>RMSE加大了对预测不准的用户物品评分的惩罚，因而对系统的评测更加苛刻；如果评分系统是基于整数建立的，那么对预测结果取整会降低MAE的误差。</li>
        </ul>
      </li>
      <li>
        <p>TopN推荐的预测准确率一般通过准确率(precision)/召回率(recall)度量</p>

        <script type="math/tex; mode=display"> Recall = \frac{\sum_{u \in U} \vert R(u) \cap T(u) \vert }{\sum_{u \in U} \vert  T(u) \vert}，Precision = \frac{\sum_{u \in U} \vert R(u) \cap T(u) \vert }{\sum_{u \in U} \vert  R(u) \vert} </script>

        <ul>
          <li>$R(u)$ 是根据用户在训练集上的行为给用户作出的推荐列表，而 $T(u)$ 是用户在测试集上的行为列表。</li>
          <li>
            <u>召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中,而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录</u>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>覆盖率</p>

    <ul>
      <li>描述一个推荐系统对物品长尾的发掘能力。表示推荐系统能够推荐出来的物品占总物品集合的比例。</li>
      <li>系统的用户集合为 $U$，推荐系统给每个用户推荐一个长度为N的物品列表 $R(u)$。</li>
      <li>物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力，可以用信息熵和基尼系数定义覆盖率。分配不均匀，基尼系数大，表示覆盖率低。</li>
    </ul>
  </li>
  <li>
    <p>多样性</p>

    <ul>
      <li>为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性，描述推荐列表物品两两之间的不相似性。</li>
    </ul>
  </li>
  <li>
    <p>新颖性</p>
  </li>
  <li>
    <p>惊喜度</p>
  </li>
  <li>
    <p>信任度</p>

    <ul>
      <li>需要增加推荐系统的透明度</li>
      <li>虑用户的社交网络信息,利用用户的好友信息给用户做推荐,并且用好友进行推荐解释</li>
    </ul>
  </li>
  <li>
    <p>实时性</p>

    <ul>
      <li>实时地更新推荐列表来满足用户新的行为变化</li>
      <li>能够将新加入系统的物品推荐给用户</li>
    </ul>
  </li>
  <li>
    <p>健壮性</p>
  </li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-14/24652935.jpg" width="500px" /></p>

<h2 id="section">一 利用用户行为数据</h2>

<p>存储的日志种类：</p>

<ul>
  <li>raw log：网站在运行过程中都产生大量原始日志</li>
  <li>session log：原始日志按照用户行为汇总成会话日志，其中每个会话表示一次用户行为和对应的服务</li>
  <li>impression log：展示日志，session log的一种，在搜索引擎和搜索广告系统中,服务会为每次查询生成一个展示日志，记录了查询和返回结。</li>
  <li>click log：点击了某个结果,这个点击信息会被服务器截获并存储在点击日志</li>
</ul>

<p>一个并行程序会周期性地归并展示日志和点击日志,得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。会话日志通常存储在分布式数据仓库中,如支持离线分析的Hadoop Hive和支持在线分析的Google Dremel。</p>

<p>用户行为在个性化推荐系统中一般分两种</p>

<ul>
  <li>显性反馈行为(explicit feedback)</li>
  <li>隐性反馈 行为(implicit feedback)</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-14/78274688.jpg" width="500px" /></p>

<p>仅仅基于用户行为数据设计的推荐算法一般称为<strong>协同过滤算法</strong>，包括但不限于：</p>

<ul>
  <li>基于邻域的方法(neighborhood-based)
    <ul>
      <li>基于用户的协同过滤算法</li>
      <li>基于物品的协同过滤算法</li>
    </ul>
  </li>
  <li>隐语义模型 (latent factor model)</li>
  <li>基于图的随机游走算法(random walk on graph)</li>
</ul>

<h3 id="section-1">1.1 基于用户的协同过滤算法</h3>

<p>基于用户的协同过滤算法主要包括两个步骤。</p>

<ol>
  <li>找到和目标用户兴趣相似的用户集合。</li>
  <li>找到这个集合中的用户喜欢的,且目标用户没有听说过的物品推荐给目标用户.</li>
</ol>

<p>步骤1的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要利用行为的相似度计算兴趣的相似度。给定用户u和用户v，$N(u)$ 表示用户u曾经有过正反馈的物品集合，$N(v)$ 为用户v曾经有过正反馈的物品集合。</p>

<p>可以通过如下的Jaccard公式简单地计算u和v的兴趣相似度:</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\vert N(u) \cup N(v) \vert} </script>

<p>或者通过余弦相似度计算:</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\sqrt{\vert N(u) \vert  \vert N(v) \vert}} </script>

<p>事实上,很多用户相互之间并没有对同样的物品产生过行为,即很多时候 $\vert N(u) \cap N(v) \vert = 0$。我们可以首先计算出$\vert N(u) \cap N(v) \vert \neq 0$ 的用户对 $(u,v)$，然后再对这种情况除以分母。</p>

<p>为此,可以首先建立物品到用户的倒排表,对于每个物品都保存对该物品产生过行为的用户列表。令稀疏矩阵 $C[u][v] = \vert N(u) \cap N(v) \vert$。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/4819139.jpg" width="300px" /></p>

<p>得到用户之间的兴趣相似度后,UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度:</p>

<script type="math/tex; mode=display"> p(u,i) = \sum_{v \in S(u,K) \cap N(i)} w_{uv} r_{vi} </script>

<p>其中, $S(u, K)$ 包含和用户u兴趣最接近的K个用户, $N(i)$ 是对物品i有过行为的用户集合, $w_{uv}$ 是用户u和用户v的兴趣相似度, $r_{vi}$ 代表用户v对物品i的兴趣。</p>

<p>可以使用改进的余弦相似度公式来提高UserCF的推荐性能：</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\sum_{i \in  N(u) \cap N(v)}\frac{1}{log(1+N(i))}}{\sqrt{\vert N(u) \vert  \vert N(v) \vert}} </script>

<p>该公式惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响。</p>

<h3 id="section-2">1.2 基于物品的协同过滤算法</h3>

<p>基于物品的协同过滤算法(简称ItemCF)给用户推荐那些和他们之前喜欢的物品相似的物品。ItemCF算法并不利用物品的内容属性计算物品之间的相似度,它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为,物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。</p>

<p>基于物品的协同过滤算法主要分为两步。</p>

<ol>
  <li>计算物品之间的相似度。</li>
  <li>根据物品的相似度和用户的历史行为给用户生成推荐列表。</li>
</ol>

<p>可以用下面的公式定义物品的相似度, $\vert N(i) \vert$ 是喜欢物品i的用户数:</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\vert N(i) \cap N(j) \vert}{\sqrt{\vert N(i) \vert \vert N(j) \vert}} </script>

<p>上述公式惩罚了物品j的权重,因此减轻了热门物品会和很多物品相似的可能性。和UserCF算法类似,用ItemCF算法计算物品相似度时也可以首先建立用户—物品倒排表,然后对于每个用户,将他物品列表中的物品两两在共现矩阵C中加1。</p>

<p>如果j非常热门,那么上面公式的分子 就会越来越接近 $N(i)$。尽管上面的公式分母已经考虑到了j的流行度,但在实际应用中,热门的j仍然会获得比较大的相似度。可以采用下面的公式加大惩罚：</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\vert N(i) \cap N(j) \vert}{\vert N(i) \vert^{1-\alpha} \vert N(j) \vert ^{\alpha}} </script>

<p>其中 $\alpha \in [0.5 ,1]$。通过提高$\alpha$, 就可以惩罚热门的j。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/51979298.jpg" width="400px" /></p>

<p>在得到物品之间的相似度后,ItemCF通过如下公式计算用户u对一个物品j的兴趣:</p>

<script type="math/tex; mode=display"> p(u,j) = \sum_{i \in S(j,K) \cap N(u)} w_{ji} r_{ui} </script>

<p>这里 $N(u)$ 是用户喜欢的物品的集合, $S(j,K)$ 是和物品j最相似的K个物品的集合, $w_{ji}$ 是物品j和i的相似度, $r_{ui}$是用户u对物品i的兴趣。该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。</p>

<p>类似UserCF中的惩罚公式，ItemCF中认为不活跃的用户的贡献程度要比活跃用户更大，所以应该加上Inverse User Frequence修正物品相似度的计算公式：</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\sum_{u \in  N(i) \cap N(j)}\frac{1}{log(1+N(u))}}{\sqrt{\vert N(i) \vert  \vert N(j) \vert}} </script>

<p>另外如果将ItemCF的相似度矩阵按最大值归一化,可以提高推荐的准确率。如果已经得到了物品相似度矩阵 $w$, 那么可以用如下公式得到归一化之后的相似度 矩阵 $w’$：</p>

<script type="math/tex; mode=display"> w'_{ij} = \frac{w_{ij}}{max_j w_{ij}} </script>

<p>归一化的好处不仅仅在于增加推荐的准确度,它还可以提高推荐的覆盖率和多样性。一般来说,热门的类其类内物品相似度一般比较大。如果不进行归一化,就会推荐 比较热门的类里面的物品,而这些物品也是比较热门的。因此,推荐的覆盖率就比较低。相反, 如果进行相似度的归一化,则可以提高推荐系统的覆盖率。</p>

<h3 id="usercfitemcf">1.3 UserCF和ItemCF的综合比较</h3>

<p>UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品,而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算法的原理可以看到,UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点,而ItemCF的推荐结果着重于维系用户的历史兴趣。</p>

<p>UserCF适合用于新闻推荐</p>

<ul>
  <li>可以给用户推荐有相似爱好的其他用户看的新闻，这样在抓住热点和时效性的同时，保证了一定程度的个性化。</li>
  <li>技术角度考量，物品的更新速度远远快于新用户的加入速度。</li>
</ul>

<p>ItemCF适合于图书、电子商务和电影网站等的推荐：</p>

<ul>
  <li>在这些网站中，用户的兴趣是比较固定和持久的</li>
  <li>用户不需要流行物品，而是通过自己熟悉领域的知识自己判断物品的质量</li>
  <li>从技术上考虑，用户数目往往非常庞大，物品的数目则是比较少的</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/2625074.jpg" width="700px" /></p>

<h3 id="section-3">1.4 隐语义模型</h3>

<p>除了使用UserCF、ItemCF外，还可以对书和物品的兴趣进行分类做推荐。要解决自动地找到那些类,然后进行个性化推荐，可以使用隐含语义分析技术(latent variable analysis)，采取基于用户行为统计的自动聚类。</p>

<p>隐含语义分析技术从诞生到今天产生了很多著名的模型和方法,其中和该技术相关且耳熟能详的名词有pLSA、LDA、隐含类别模型(latent class model)、隐含主题模型(latent topic model)、 矩阵分解(matrix factorization)。</p>

<h3 id="section-4">1.5 基于图的模型</h3>

<p>如果 将个性化推荐算法放到二分图模型上,那么给用户u推荐物品的任务就可以转化为度量用户顶点 $v_u$ 和与 $v_u$ 没有边直接相连的物品节点在图上的相关性,相关性越高的物品在推荐列表中的权重就越高。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/23922601.jpg" width="400px" /></p>

<p>相关性高的一对顶点一般具有如下特征:</p>

<ul>
  <li>两个顶点之间有很多路径相连</li>
  <li>连接两个顶点之间的路径长度都比较短;</li>
  <li>连接两个顶点之间的路径不会经过出度比较大的顶点。</li>
</ul>

<p>基于这三个要素，可以使用一种基于随机游走的PersonRank算法：</p>

<p>假设要给用户u进行个性化推荐，可以从用户u对应的节点 $v_u$ 开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率 $\alpha$ 决定是继续游走，还是停止这次游走并从 $v_u$ 节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/56306116.jpg" width="500px" /></p>

<h2 id="section-5">二 推荐系统冷启动问题</h2>

<p>冷启动问题(cold start)主要分3类。</p>

<ul>
  <li><strong>用户冷启动</strong>  用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐 </li>
  <li><strong>物品冷启动</strong>  物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。 </li>
  <li><strong>系统冷启动</strong>  系统冷启动主要解决如何在一个新开发的网站上设计个性化推荐系统,从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。</li>
</ul>

<p>对于这3种不同的冷启动问题,有不同的解决方案。一般来说,可以参考如下解决方案</p>

<ul>
  <li><strong>提供非个性化的推荐</strong>   非个性化推荐的最简单例子就是热门排行榜,我们可以给用户推荐热门排行榜,然后等到用户数据收集到一定的时候,再切换为个性化推荐。</li>
  <li>利用用户注册时提供的年龄、性别等数据做粗粒度的个性化推荐。</li>
  <li>利用用户的社交网络获取好友信息，然后给用户推荐好友喜欢的物品。</li>
  <li>要求用户登录时对一些物品进行反馈，收集用户对这些物*品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。</li>
  <li>对于新加入的物品,可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。</li>
  <li>在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。</li>
</ul>

<p>可以用一个决策树解决启动用户兴趣的物品问题：</p>

<p>首先,给定一群用户用这群用户对物品评分的方差度量这群用户兴趣的一 致程度。如果方差很大,说明这一群用户的兴趣不太一致,反之则说明这群用户的兴趣比较一致。</p>

<script type="math/tex; mode=display">D(i) = \sigma_{u \in N^+(i)} + \sigma_{u \in N^-(i)} + \sigma_{u \in N^*(i)}</script>

<p>其中，$N^+(i)$ 是喜欢物品i的用户集合，$N^-(i)$ 是不喜欢物品i的用户集合，$N^*(i)$ 是没有对物品
i评分的用户集合。</p>

<p>接着会从所有用户中找到具有最高区分度的物品i，然后将用户分成3 类。接着在每类用户中再找到最具区分度的物品，如此迭代到叶子节点。</p>

<h3 id="section-6">2.1 利用物品的内容信息</h3>

<p>UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。那么需要解决的是第一个用户从哪儿发现新的物品。可以考虑利用物品的 内容信息,将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</p>

<p>对于ItemCF算法来说,物品冷启动就是一个严重的问题。新物品的加入需要更新物品相似度表，但这个操作非常耗时。为此,我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表(比如半小时计算一次)。</p>

<p>物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个关键词向量。每个关键词都有权重，可以用TF-IDF表示。得到向量后，就可以用余弦相似度等计算物品的相似度。这里同样可以建立关键词—物品的倒排表加速文档集合相似度的计算过程。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/58154911.jpg" width="400px" /></p>

<p>另外，如果两篇文章的关键词虽然不同，但关键词所属的话题是相同的时，可以使用话题模型，代表算法是LDA。</p>

<blockquote>
  <p>任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。</p>
</blockquote>

<h2 id="section-7">三 利用用户标签数据</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/51079519.jpg" width="500px" /></p>

<p>上图中的第三种方式是通过一些特征(feature)联系用户和物品，给用户推荐那些具有用户喜欢的特征的物品。特征有不同的表现方式</p>

<ul>
  <li>物品的属性集合</li>
  <li>隐语义向量(latent factor vector)</li>
  <li>物品的标签，包括作者或者专家给物品打标签;另一种是UGC标签</li>
</ul>

<p>UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的 语义，从而将用户和物品联系了起来。</p>

<p>一个简单的算法如下：</p>

<ul>
  <li>统计每个用户最常用的标签。</li>
  <li>对于每个标签，统计被打过这个标签次数最多的物品。</li>
  <li>对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。</li>
</ul>

<p>用户u对物品i的兴趣公式为：$p(u,i)=\sum_b n_{u,b} n_{b,i}$</p>

<p>$B(u)$ 是用户u打过的标签集合, $B(i)$ 是物品i被打过的标签集合, $n_{u,b}$ 是用户u打过标签b的次数, $n_{b,i}$是物品i被打过标签b的次数。</p>

<p>可以进行如下改进：</p>

<ul>
  <li>TF-IDF： 上式给热门标签和物品过大的权重,从而不能反应用户个性化的兴趣。改进公式如下，$n_b^{(u)}$ 记录了标签b被多少个不同的用户使用过，$n_i^{(u)}$记录了物品i被多少个不同的用户打过标签：</li>
</ul>

<script type="math/tex; mode=display"> p(u,i)=\underset{b}{sum} \frac{n_{u,b}}{log(1+n_b^{(u)})} \frac{n_{b,i}}{log(1+n_i^{(u)})}</script>

<ul>
  <li>
    <p>数据稀疏性：通过标签扩展解决，方法包括话题模型，基于邻域的方法（从数据中统计出标签的相似度）</p>
  </li>
  <li>
    <p>标签清理：只保留正向推荐的标签词；另外可以将标签作为推荐解释。</p>
  </li>
</ul>

<h2 id="section-8">四 利用上下文信息</h2>

<p>用户所处的上下文(context)包括用户访问推荐系统的时间、地点、心情等。时间信息对于用户兴趣的影响表现在以下几个方面：</p>

<ul>
  <li>用户兴趣是变化的</li>
  <li>物品是有生命周期和时效性
    <ul>
      <li>物品平均在线天数</li>
      <li>相隔T天系统物品流行度向量的平均相似度</li>
    </ul>
  </li>
  <li>季节效应</li>
</ul>

<p>实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，推荐算法实时性意味着：</p>

<ul>
  <li>要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计推荐列表。</li>
  <li>需要平衡考虑用户的近期行为和长期行为。</li>
</ul>

<p>推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。首先，需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。</p>

<p>如果用户没有行为，可以：</p>

<ul>
  <li>在生成推荐结果时加入一定的随机性。</li>
  <li>记录用户每天看到的推荐结果，对之前的推荐结果进行降权。</li>
  <li>每天给用户使用不同的推荐算法。</li>
</ul>

<h3 id="section-9">4.1 时间上下文推荐算法</h3>

<ol>
  <li>
    <p>最近最热门</p>

    <p>给定时间T, 物品i最近的流行度 $n_i(T)$ 可以定义为</p>

    <script type="math/tex; mode=display">% &lt;![CDATA[
n_i(T)=\underset{(u,i,t) \in Train, t<T}{\Sigma} \frac{1}{1+\alpha (T-t)} %]]&gt;</script>
  </li>
  <li>
    <p>时间上下文相关的ItemCF算法</p>

    <ul>
      <li>用户在相隔很短的时间内喜欢的物品具有更高相似度</li>
      <li>用户近期行为相比用户很久之前的行为,更能体现用户现在的兴趣。</li>
    </ul>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/45373851.jpg" width="600px" /></p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/9416103.jpg" width="350px" /></p>

    <p>其中, $t_0$ 是当前时间。</p>
  </li>
  <li>
    <p>时间上下文相关的UserCF算法</p>
    <ul>
      <li>类似于ItemCF算法，在权重和预测部分增加时间衰减因子</li>
      <li>对于用户u和用户v共同喜欢的物品i增加了一个时间衰减因子。</li>
      <li>考虑和用户u兴趣相似用户的最近兴趣</li>
    </ul>
  </li>
</ol>

<h2 id="section-10">五 利用社交网络数据</h2>

<p>社会化推荐之所以受到很多网站的重视，是缘于如下优点：</p>

<ul>
  <li>好友推荐可以增加推荐的信任度</li>
  <li>社交网络可以解决冷启动问题</li>
</ul>

<ol>
  <li>
    <p>基于邻域的社会化推荐算法</p>

    <p>也就是给用户推荐好友喜欢的物品集合。$p_{ui} = \underset{v \in out(u)}{\Sigma} w_{uv} r_{vi}$</p>

    <p>其中 $out(u)$ 是用户u的好友集合，如果用户v喜欢物品i，则 $r_{vi}=1$，否则 $r_{vi}=0$。$w_{uv}$ 由两部分相似度构成，一部分是用户u和用户v的熟悉程度，另一部分是用户u和用户v的兴趣相似度。</p>

    <script type="math/tex; mode=display"> familiarity(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\vert out(u) \cup out(v) \vert}</script>

    <script type="math/tex; mode=display"> similiarity(u,v) = \frac{\vert N(u) \cap N(v) \vert}{\vert N(u) \cup N(v) \vert}</script>

    <p>其中 $N(u)$ 是用户u喜欢的物品集合。</p>
  </li>
  <li>
    <p>基于图的社会化推荐算法</p>

    <p>在社交网站中存在两种关系，一种是用户对物品的兴趣关系，一种是用户之间的社交网络关系。需要将这两种关系建立到图模型中。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/68899610.jpg" width="300px" /></p>

    <p>该图上有用户顶点（圆圈）和物品顶点（方块）两种顶点。在定义完图中的顶点和边后,需要定义边的权重。其中用户和用户之间边的权重可以定义为用户之间相似度的 $\alpha$ 倍（包括熟悉程度和兴趣相似度）,而用户和物品之间的权重可以定义为用户对物品喜欢程度的 $\beta$ 倍。$\alpha,\beta$ 根据应用的需求确定。</p>
  </li>
</ol>

<p>大型网站中用户数目、历史行为记录非常庞大，所以不太可能将用户的所有行为都缓存在内存中，只能在数据库前做一个热数据的缓存。如果我们需要比较实时的数据，这个缓存中的数据就要比较频繁地更新，因而避免不了数据库的查询。数据库查询一般是很慢的，所以在实际做推荐时获取用户历史行为数据比较困难。</p>

<p>可以从几个方面改进基于邻域的社会化推荐算法,让它能够具有比较快的响应时间:</p>

<ul>
  <li>只拿出和用户相似度最高的N个好友；只返回用户最近1个月的行为。</li>
  <li>重新设计数据库
    <ul>
      <li>首先，为每个用户维护一个消息队列，用于存储他的推荐列表;</li>
      <li>当一个用户喜欢一个物品时，就将(物品ID、用户ID和时间)这条记录写入关注该用户的推荐列表消息队列中;</li>
      <li>当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，重新计算该物品的权重。</li>
    </ul>
  </li>
</ul>

<u>对比于协同过滤推荐，社会化推荐的优势不在于增加预测准确度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐 结果。</u>

<p>信息流推荐可以参考Facebook的EdgeRank算法。</p>

<p>另外好友推荐算法在社交网络上被称为链接预测(link prediction)，可以基于以下方法做推荐：</p>

<ul>
  <li>基于内容的匹配</li>
  <li>基于共同兴趣的好友推荐</li>
  <li>基于社交网络图的好友推荐</li>
</ul>

<h2 id="section-11">六 推荐系统实例</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/94386004.jpg" width="400px" /></p>

<p>从实时存取的角度上看，购买、收藏、评论、评分、分享等行为都是需要实时存取的，因为只要用户有了这些行为，界面上就需要体现出来，比如用户购买了商品后，用户的个人购买列表中就应立即显示用户购买的商品。而有些行为，比如浏览网页的行为和搜索行为并不需要实时存取。</p>

<p>数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，给用户进行实时推荐。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/79737632.jpg" width="600px" /></p>

<p>推荐系统由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。多个推荐引擎还可以：</p>

<ul>
  <li>可以方便地增加/删除引擎,控制不同引擎对推荐结果的影响。</li>
  <li>可以实现推荐引擎级别的用户反馈。</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/32415777.jpg" width="500px" /></p>

<p>如上图所示推荐引擎架构主要包括3部分：</p>

<ul>
  <li>该部分负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。</li>
  <li>该部分负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。</li>
  <li>该部分负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。</li>
</ul>

<p>具体对不同部分解释下。</p>

<ol>
  <li>
    <p><strong>用户特征向量</strong>包括两种：</p>

    <ul>
      <li>用户的注册信息中可以提取出来的,主要包括用户 的人口统计学特征。</li>
      <li>
        <p>从用户的行为中计算出来的，需要考虑：</p>

        <ul>
          <li>用户行为的种类（按行为的成本划分）</li>
          <li>用户行为产生的时间，近期行为比较重要</li>
          <li>用户行为的次数</li>
          <li>物品的热门程度</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>特征—物品相关推荐</p>

    <p>在得到用户的特征向量后,我们可以根据离线的相关表得到初始的物品推荐列表。在线使用的特征物品相关表一般都不止一张，推荐引擎可以在配置文件中配置很多相关表以及它们的权重。</p>

    <p>特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。</p>
  </li>
  <li>
    <p>过滤模块</p>

    <ul>
      <li>用户已经产生过行为物品</li>
      <li>候选物品以外的物品</li>
      <li>某些质量很差的物品</li>
    </ul>
  </li>
  <li>
    <p>排名模块</p>

    <ul>
      <li>新颖性排名，对推荐结果中热门的物品进行降权。</li>
      <li>多样性，推荐结果分类；控制不同推荐结果的推荐理由出现的次数。</li>
      <li>时间多样性</li>
      <li>用户反馈，通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。
        <ul>
          <li>CTR预测</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="section-12">七 评分预测问题</h2>

<p>前面主要介绍TopN推荐，因为它非常接近于满足实际系统的需求。评分预测问题却是推荐系统研究的核心。</p>

<ol>
  <li>
    <p>基于邻域的方法</p>

    <p>基于用户的邻域算法和基于物品的邻域算法都可以应用到评分预测中。基于用户的邻域算法：</p>

    <script type="math/tex; mode=display">\hat{r}_{ui} = \overline{r}_u + \frac{\sum_{v \in S(u,K) \cap N(i)} w_{uv}(r_{vi} -\overline{r}_v)}{\sum_{v \in S(u,K) \cap N(i)} \vert w_{uv} \vert}</script>

    <p>这里, $S(u, K)$ 是和用户u兴趣最相似的K个用户的集合, $N(i)$ 是对物品i评过分的用户集合, $r_{vi}$ 是用户v对物品i的评分, $\overline{r}_v$ 是用户v对他评过分的所有物品评分的平均值。$w_{uv}$ 是相似度，有以下几种：</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/86649362.jpg" width="420px" /></p>

    <p>基于物品的领域算法类似。</p>
  </li>
  <li>
    <p>隐语义模型与矩阵分解模型</p>

    <p>传统的SVD分解有一下几个缺点：</p>

    <ul>
      <li>该方法首先需要用一个简单的方法补全稀疏评分矩阵。</li>
      <li>该方法依赖的SVD分解方法的计算复杂度很高</li>
    </ul>

    <p>基于此，Simon Funk提出的基于新的矩阵分解方法Latent Factor Model (LFM)。</p>

    <p>将评分矩阵R分解为两个低维矩阵相乘 $\hat{R} = P^TQ$，其中 $P_{f \times m}$ 和 $Q_{f \times n}$ 是两个降维后的矩阵。那么，对于用户u对物品i的评分的预测值 $\hat{R}(u,i)=\hat{r}_{ui}$，可以表示为 $\hat{r}_{ui} = \sum_f p_{uf} q_{if}$。</p>

    <p>Simon Funk的思想很简单:可以直接通过训练集中的观察值利用最小化RMSE学习P、Q矩阵。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/90816576.jpg" width="620px" /></p>

    <p>要最小化上面的损失函数，可以利用随机梯度下降法。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/9179243.jpg" width="620px" /></p>
  </li>
  <li>
    <p>加入偏置项后的LFM</p>

    <p>LFM预测公式通过隐类将用户和物品联系在了一起。但是，实际情况下，一个评分系统有些固有属性和用户物品无关，而用户也有些属性和物品无关，物品也有些属性和用户无关。所以提出加入偏置项后的LFM：</p>

    <script type="math/tex; mode=display">\hat{r}_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i</script>

    <p>$\mu$ 是训练集中所有记录的评分的全局平均数。$b_u$ 是用户偏置(user bias)项，表示了用户的评分习惯中和物品没有关系的因素。$b_i$ 是物品偏置(item bias)项，表示了物品接受的评分中和用户没有什么关系的因素。</p>

    <p>$b_u,b_i$ 通过机器学习训练出来的。同样可以求导，然后用梯度下降法求解这两个参数。</p>
  </li>
  <li>
    <p>考虑邻域影响的LFM</p>

    <p>前面的LFM模型中并没有显式地考虑用户的历史行为对用户评分预测的影响。新的算法成为SVD++。可以将ItemCF的预测算法改成如下方式:</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/88102444.jpg" width="620px" /></p>
  </li>
</ol>

<p>另外还可以增加时间因素进行考虑。</p>

]]></content>
  </entry>
  
</feed>
