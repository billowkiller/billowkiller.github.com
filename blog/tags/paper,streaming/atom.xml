<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[tags: paper，streaming | Tech Digging and Sharing]]></title>
  <link href="http://billowkiller.github.io/blog/tags/paper,streaming/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2016-11-27T20:56:02+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Photon: fault-tolerant and scalable joining of continuous data streams]]></title>
    <link href="http://billowkiller.github.io/blog/2016/11/19/photon/"/>
    <updated>2016-11-19T11:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/11/19/photon</id>
    <content type="html"><![CDATA[<h2 id="intro-and-issues">Intro and Issues</h2>

<p>Photon 是 Google 的数据流合并的系统，目的是 “perform continuous stream joining in real-time”，例如 query log 和 click log 合并。为什么需要对数据流合并呢？</p>

<p>先看下用户使用的场景：用户先 query 一个搜索词，这时候的日志可以直接通过 Google 的网关服务器直接落盘，这里的日志称为 query log，也就是展示广告，表示发给用户的广告信息；之后的一段时间，用户浏览网页，可能会点击到某一条广告，这时候再将用户的 click log 发到某个 log datacenter。</p>

<p>这两个日志所附带的内容区别很大，query log 可以附带很多的信息，类似于展示位、广告主出价等，而 click log 的内容是受限的：虽然可以把需要的信息附带到广告的 url 上，但是传输量变大增加延迟降低用户体验，另外 url 的长度也是受限的。因此很有必要进行日志的合并以用于后续的计费、报表、模型训练等等。</p>

<p>那么处理这个问题的难点在哪里？</p>

<!--more-->

<ul>
  <li>Exactly-once semantics: 任意时刻 at-most-once，实时的 near-exact，最终 exactly-once。</li>
  <li>Automatic datacenter-level fault-tolerance</li>
  <li>High scalability</li>
  <li>Low latency</li>
  <li>unordered streams: 特别的，由于网络或者其他原因，query log 可能会落后于 click log。</li>
</ul>

<h2 id="big-ideas">Big Ideas</h2>

<p>从对系统的要求来看，有两个重要的概念：</p>

<ul>
  <li><code>Persistent State Consistency</code></li>
  <li><code>Exactly Once Eventually</code></li>
</ul>

<h3 id="persistent-state-consistency">1. Persistent State Consistency</h3>

<p>高可用，容错的系统的最简单方法就是冗余，Photon 也如此。导致的问题是在不同的数据中心可能会处理同一份数据。这时候需要对 Worker 进行协调，保证它们不对同一份数据处理。方案是对处理好的 click_id 存储下来，各个 Worker 处理的时候查询下，并在输出 joined log 之前先存储 click_id 以保证 at most once 语义。</p>

<p>Photon 使用基于 <code>Multi-Paxos</code> 的容错、强一致的 <code>IdRegisty</code>。Paxos 能够保证在大多数副本之间同步状态，实现一致性。如下图是一个 IdRegistry 的架构：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-26/63413408.jpg" width="450px" /></p>

<p>不同的数据中心来回的传输时间可能高达100ms，导致 IdRegistry 的 TPS 最高只有 10，对于每秒需要处理上万日志的 photon 来说是不可以接受的。那么如何增加吞吐呢？有两个措施：<code>server-side batching</code>，<code>sharding</code>。这是两个经典的扩大吞吐量的方法，批量和分治。原文如下：</p>

<blockquote>
  <p>Server-side batching combine multiple event-level commits into one bigger commit. The registry thread dequeues multiple requests and batches them into a single PaxosDB transaction.</p>
</blockquote>

<p>但是对于一个批量的 Paxos RPC 怎么区分有冲突的 event_id 原文并没有做过多的说明。</p>

<blockquote>
  <p>To take advantage of the event_id independence, we partition the event id space handled by the IdRegistry into disjoint shards such that event ids from separate shards are managed by separate IdRegistry servers. </p>
</blockquote>

<p>sharding 需要 resharding 是比较麻烦的，需要考虑向后兼容性。对于落后的 log 来说它必须在 resharding 之后还能找到原来的 shard，原文称为 “deterministic mapping”。Photon 通过增加时间窗口实现，在 timestamp 在 [0, now + S] 内使用之前的sharding。这个时间会通过 True Time API 校正，这个 API 是 Google 特有的，通过原子时钟校正，不具有普适性。这里不得不感叹 Google 的基础架构之强大。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-26/39260007.jpg" width="500px" /></p>

<h3 id="exactly-once-eventually">2. Exactly Once Eventually</h3>

<p>这个语义和架构有关，所以我们先看下 Photon 的架构，了解里面的组件如何实现 Exactly-once，这里说明下印象比较深的是在 Paper 中， Photon 使用两个非常普遍的技术：<code>异步 PRC</code>, <code>throttling</code>，在提高效率和稳定性方面带来很大的帮助：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-26/70920655.jpg" width="500px" /></p>

<p><strong>Dispatcher</strong></p>

<p>Dispatcher 负责监控日志文件，并将它们及时的传送到系统。需要注意读取文件的状态元数据会保存在GFS上，用于 failover。发送前需要查看 event_id 是否在 IdRegistry 中，这里的 event_id 需要保持唯一，Photon 使用 &lt;ServerIP, ProcessID, Timestamp&gt; 作为 event_id。</p>

<p>Dispatcher 异步的发送日志到 joiner，等待 joiner 的 ack。如果失败，则会将 click log 存入 GFS，稍后使用指数回退算法重试。一旦重试时间超过阈值，则判定日志为 unjoinable。通过这种方式达到 Dispatcher 的 at least once。</p>

<p>另外至少会有两条 Photon 流在运行，即使一个数据中心挂了，另外一个也可以正常工作。并且在恢复之后会执行 backlog，追上 IdRegistry 中已有的信息，需要注意的是追赶时候的 throttling，防止 IdRegistry 压力过大。</p>

<p><strong>joiner</strong></p>

<p>joiner 接收 dispatcher 传来的数据，并且协调 EventStore 和 IdRegistry，执行日志合并的业务逻辑。joiner 解析 click log 的 click_id 和 query_id，异步获取 EventStore 的 query log 进行比较，一旦获取失败或者 dispatcher 发送过多数据，则会导致失败使得dispatcher 进入重试逻辑。这里的 throttling 是用于 joiner 能维持平滑的数据流。</p>

<p>joiner 使用 adaptor 库处理业务逻辑。一旦 join 成功，则异步地注册 click_id 到 IdRegistry，成功注册后才允许下发 joined log 给下游。这两个步骤在 Photon 中并不是事务地进行，所以一旦在下发前宕机或者 ack 丢失就会导致 joined log 丢失。</p>

<p>之所以不进行事务处理，原因应该是想让 joiner <code>无状态</code>，提高可扩展性。导致的风险可以用下面的方法解决。</p>

<p>提交 click_id 给 IdRegistry 时，joiner 会附带自己的 &lt;ServerIP, ProcessID, Timestamp&gt; 信息作为 <code>unique token</code> 一并提交。当 IdRegistry 收到 click_id 的提交信息时，会比较 token，
相同则说明是上一次没有收到 ack 的那个 joiner 发过来的。IdRegistry 此时返回成功，允许 joiner 下发合并日志。</p>

<p>但此种方法并没有解决宕机带来的不一致。Photon 给的方案是使用另外一个 <code>verification system</code> 作为补充。一旦检测到 IdRegistry 中的 event 并不在 output log 中，则删除 IdRegistry 的 click_id，并重新注入 click log。</p>

<p>以上其实是通过内部机制实现尽力而为的 exactly-once，最后通过类似的 lambda 架构实现最终 exactly-once。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[MillWheel: Fault-Tolerant Stream Processing at Internet Scale]]></title>
    <link href="http://billowkiller.github.io/blog/2016/11/13/millwheel/"/>
    <updated>2016-11-13T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/11/13/millwheel</id>
    <content type="html"><![CDATA[<h2 id="intro-and-issues">Intro and Issues</h2>
<p>MillWheel 是 Google 开发的一个低延时的流式处理系统。用户指定计算的 DAG 图，以及图中每个节点的计算代码，MillWheel 负责数据流的计算，保证整个计算过程的分布式以及容错性。从宏观上看，MillWheel 提供了数据计算的幂等性，在用户视角提供不重不丢的语义。</p>

<p>在论文中，还存在一个使用场景。Google 的 Zeitgeist 服务用来监测网络搜索的趋势，输入端是持续不断的搜索内容，经过异常检测，异常检测通过模型预测来排除false positive，输出 spike 或者 dip 的搜索。这要求解决：</p>

<ul>
  <li>Persistent storage： 模型预测和峰值判断分别依赖于长期和短期的存储。</li>
  <li>Low Watermarks: 流量低谷的判断需要有一个标志来判断期待时间窗口内的数据都到达。</li>
  <li>Duplicate Prevention: 在各种情况下用户无需考虑重复流量，系统保证数据传输和处理的 exactly-once 语义。</li>
</ul>

<!--more-->

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-22/53383350.jpg" width="600px" /></p>

<p>综合而言，对比于一般的分布式流式系统，存在一些特别的要求：</p>

<ul>
  <li>处理数据乱序的问题。</li>
  <li>处理数据到达延时问题。</li>
  <li>提供 exactly-once 的保证，尤其在 failover 的时候。</li>
  <li>需要有持久存储，读写权限暴露给用户，提供保证一致性。</li>
</ul>

<h2 id="big-ideas">Big Ideas</h2>

<p>从对系统的要求来看，有两个重要的概念：<code>low watermark</code> 和 <code>exactly-once</code>。low watermark 解决前两个问题，exactly-once 解决后两个问题。</p>

<h3 id="low-watermark">low watermark</h3>

<p>low watermark 在原文的作用如下：</p>

<blockquote>
  <p>The low watermark for a computation provides a bound on the timestamps of future 
records arriving at that computation.</p>
</blockquote>

<blockquote>
  <p>Strip away outliers and offer heuristic low watermark values for pipelines that are more interested in speed than accuracy. </p>
</blockquote>

<p>即时间窗口内所有事件的时间下限，目的是为了让这个窗口可以正常的划出，更快的计算出结果。它其实是提供了一个折衷, 这个折衷就是在watermark这个点认为不会有比 watermark 值更老的数据到来了，本质上是一个barrier, 即系统中所有正在流动的数据的 timestamp 都大于或等于该 watermark。</p>

<p>之所有需要有这个概念，是由于网络环境或者故障导致数据流乱序，窗口无法判断何时数据已经全部到达。这里的时间计算一般是基于eventtime的，即时间发生时间，如logtime。文中也给了一个应用的例子：</p>

<blockquote>
  <p>In the case of Zeitgeist, our input would be a continuously arriving set of search queries, and our output would be the set of queries that are spiking or dipping.</p>
</blockquote>

<p>it is important to be able to distinguish whether a flurry of expected Arabic queries at t = 1296167641 is simply delayed on the wire, or actually not there.</p>

<p>波谷由于数据量小，对到达的数据比较敏感，所以需要判断是真的到达波谷，还仅仅是由于延迟导致数据还在传输途中。之前的做法是再设置一个安全时间，延迟几分钟再计算，但安全时间如何设置？过长则影响时效性，过短无法奏效。或者采取右端开放窗口的补偿方法，先产出数据，当延迟数据到来时再予以修改，但需要业务场景适用、下游系统支持修改。</p>

<p>除了aggregation计算对时序性有要求外，一些策略计算可能也会要求数据完整、有序。那么 low watermark 的定义如下：</p>

<pre><code>low watermark of A = min(oldest work of A, low watermark of C: C outputs to A)
If there are no input streams, the low watermark and oldest work values are equivalent.
</code></pre>

<p>A 点的 low watermark 的值等于 A 点所有待处理的消息的 timestamp 和 A 所有上游 C 的 low watermark 的最小值。这是一个递归的定义，终止条件处于流的源头，即由外围注入的injection或者数据订阅端生成；生成之后会驱动 watermark 传递给下游。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-23/12047055.jpg" width="600px" /></p>

<p>由上图可以看出，low watermark 是根据事件到达后的处理时间递增的，反映的是系统中所有 <em>pending work</em>；并且事件其实并不是有序到达和处理的，但是在某个时间可以确保所有的事件都已经到达了，即在文中所强调的：</p>

<blockquote>
  <p>By waiting for the low watermark of a computation to advance past a certain value, the user can determine that they have a complete picture of their data up to that time</p>
</blockquote>

<p>对于处于 low watermark 下的事件，有两种处理方案：抛弃或者更正已有的状态。</p>

<p>low watermark 除了提供系统事件处理的完成情况，还有一个作用，触发trigger（文中用Timer）。trigger 实际是窗口内部累积状态的记录器，根据不同的触发类型来累积状态，达到一定的条件就允许外围触发，将窗口内的数据计算后 emit 给下游。MillWheel 的触发条件有 wall time 和 low watermark value，这个交给用户来定义。</p>

<h3 id="exactly-once">exactly-once</h3>

<p>这个概念涉及两个方面：</p>

<ul>
  <li>Persistent storage available at all nodes in the stream graph</li>
  <li>Exactly once delivery semantics.</li>
</ul>

<p>前者的概念好理解，Persistent state 在 MillWheel 中表现为一个键值对，值是 protobuf 的一个二进制字符串。用户代码可以方便的获取和设置各种状态。常用的状态为窗口数据聚合中保存的 counter，join 要使用的 buffer 等。</p>

<p>MillWheel 的状态存储在 bigtable 或者 Spanner 中，另外它还提供一个 soft state，用于内存 cache 或者 聚合。为了保证可能存在的状态不一致性，对所有的 per-key update 都封装在一个原子的操作中，防止在处理过程中可能出现的各种意外。</p>

<p>但是在 failover 或者 load balancing 的时候，计算会被迁移，这时候可能存在 zombie writer 或者 stale writer。因此，为了保证原子性，需要保证每个 key 只有一个 writer 可以写入。MillWheel 的解决方案是给每个 writer 附带一个 sequencer token，后台存储的协调者在每个写入前会检查 token 的有效性使得新 worker 可以阻止其他的 sequencer 的有效性。这其实就是一个 lease 机制，在一段时间内对于特定的key只有一个worker可以写入。</p>

<p>保证 Exactly Once 语义有个很重要的简化途径是将用户的非幂等操作变成幂等。通过以下措施来保证：</p>

<ul>
  <li>Exactly Once delivery</li>
  <li>Strong Production</li>
</ul>

<p>Exactly Once delivery 通常的方法是保证 at least once 基础上进行去重。MillWheel 也是通过这个方法保证，发送方发送数据后没有接收到 ack 重新发送数据。另外接收方接收到数据会进行 state modificaton，这时候将数据的 unique ID 也一并原子写入到后端存储；接收端为了加速去重，使用 bloom filter，这时候需要考虑 false postive，如果发生 filter miss，需要去后端存储进行比较，如果确认是重复数据，会返回 duplicate ACK 通知发送方。</p>

<p>在发送方发送数据之前可以进行 checkpoint，用于 failover 后恢复原来的状态。在发送的数据被 ACK 后，checkpoint可以删除。这个 <code>Checkpoint-&gt;Delivery-&gt;ACK-&gt;GC</code> 的运行模式在 MillWheel 中称为 <code>Strong Production</code>。即使用户代码不是幂等的，在 Strong Production 中，无论 retry 多少次，用户的运行逻辑都是正确的。</p>

<p>与之对应的是 <code>Weak Production</code>，这时的用户代码是幂等的，无需strong procution，即 checkpointing；无需 exactly once delivery（把 deduplication 逻辑去掉）。这在延迟和资源消耗上无疑更加友好，但是对于取消 checkpointing 有一个 straggler latency 问题。在 strong production中，只要 checkpoint 就可以返回上游表示这个阶段的任务结束，但是现在需要下游返回 ack 才可以保证，并且这是级联的。Millwheel 采用 checkpointing 一部分 straggler 的 pending production 来缓解，如下图：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-23/46647429.jpg" width="400px/" /></p>

<h2 id="other-details">Other Details</h2>

<p>MillWheel 集群可以动态扩缩容，根据 key interval 划分计算，并以此通过 master 进行负载分配、均衡。当监控进程检测到机器的负载过高的时候，会进行 key interval 的重分配：split、merge、move。</p>

<p>failover 时，key interval 被分配到新的 owner，它可以从后端存储中获取计算需要的元数据，包括 heap of pending timers 以及 queue of checkpointed productions。一个节点的例子如下，每个计算都是一个pipeline，即输入计算输出。数据的传输通过RPC。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/public/16-11-24/94589760.jpg" width="400px" /></p>

<p>另外关于 low watermark 的管理和流动，Millwheel 是基于一个全局的订阅发布中央系统。</p>

<ul>
  <li>每个 processer 将自己持有的所有work（in fly, stored, pending）计算出最小的 timestamp发给中央系统。</li>
  <li>不同的 processer 在不同的 key interval 下，low watermark 也是根据 key interval 来存储。</li>
  <li>为了保证计算的准确性，订阅发布系统会查询后台存储，以保证每个 key interval 都有 low watermark。感兴趣的节点会订阅每个发送端的 low watermark，计算所有的最小值作为 low watermark。</li>
  <li>之所以不在中央系统算最小值是为了保证一致性：中央系统的 low watermark 不能大于节点上的，否则在 failover 后容易出现 low watermark 的回退。在节点上计算最小值则保证中央系统永远不会领先于节点上的。</li>
</ul>

]]></content>
  </entry>
  
</feed>
