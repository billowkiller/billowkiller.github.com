<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[tags: mapreduce | Billowkiller's Blog]]></title>
  <link href="http://billowkiller.github.io/blog/tags/mapreduce/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2016-03-05T15:42:47+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Design Patterns for MapReduce Algorithms]]></title>
    <link href="http://billowkiller.github.io/blog/2015/07/26/mr-design-pattern/"/>
    <updated>2015-07-26T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2015/07/26/mr-design-pattern</id>
    <content type="html"><![CDATA[
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[mapreduce framework]]></title>
    <link href="http://billowkiller.github.io/blog/2015/07/26/mapreduce-framework/"/>
    <updated>2015-07-26T17:23:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2015/07/26/mapreduce-framework</id>
    <content type="html"><![CDATA[<h2 id="mapreduce">MapReduce框架</h2>

<p>mapReduce 的输入是hdfs上存储的一系列文件集。在hadoop中，这些文件被一种定义了如何分割一个文件成分片的input format来分割，一个分片是一个文件基于字节的可以被一个map任务加载的一个块。</p>

<ul>
  <li>每个map任务被分为以下阶段：<code>record reader</code>，<code>mapper</code>，<code>combiner</code>，<code>partitioner</code>。Map任务的输出叫中间数据，包括keys和values，发送到reduce端。</li>
  <li>Reduce任务分为以下阶段：<code>shuffle</code>，<code>sort</code>，<code>reduce</code>，<code>output format</code>。运行map任务的节点会尽量选择数据所在的节点。这种情况下，不会出现网络传输，在本地节点就可以完成计算。</li>
</ul>

<p>过程如图所示，接下来的章节会一一介绍。</p>

<p><img src="https://farm3.static.flickr.com/2275/3529146683_c8247ff6db_o.png" alt="" /></p>

<!--more-->

<h3 id="input-format">Input Format</h3>

<p>Record reader会把根据input fromat生成输入分片翻译成records。Record reader的目的是把数据解析成记录，而不是解析数据本身。它把数据以键值对的形式传递给mapper。通常情况下键是偏移量，值是这条记录的整个字节块。从Input file到map的中间过程如下图所示</p>

<p><img src="http://i12.tietuku.com/691b0fd1648b0497.png" width="450px" /></p>

<p>InputFormat其实做了三件事：</p>

<ul>
  <li>校验job的input configuration（比如，查看数据是否存在）。</li>
  <li>split输入的数据文件为逻辑上分片InputSplit，每个InputSplit给接下来的map task处理。</li>
  <li>创建RecordReader从InputSplit中解析出一个个键值对，这个键值对就是Record。</li>
</ul>

<p>如果要自定义InputFormat则最重要的是两个方法：</p>

<ul>
  <li><code>public List&lt;InputSplit&gt; getSplits(JobContext context)</code></li>
  <li><code>public RecordReader createRecordReader(InputSplit split, TaskAttemptContext context)</code></li>
</ul>

<p>通常在处理文本文件的时候，为了保证记录的完整性，RecorderReader会读取超过InputSplit边界的数据。</p>

<p><img src="http://i5.tietuku.com/392e9f9f99737b4d.jpg" alt="" /></p>

<p>在上图中共有三个InputSplit，在hadoop中默认的InputSplit大小为HDFS中每个Block的大小，所以共产生三个map task，它们读取数据的情况如下：</p>

<table>
  <thead>
    <tr>
      <th> </th>
      <th>Start</th>
      <th>Actual Start</th>
      <th>End</th>
      <th>Line(s)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Mapper1</td>
      <td>B1:0</td>
      <td>B1:0</td>
      <td>B2:150</td>
      <td>L1, L2, L3</td>
    </tr>
    <tr>
      <td>Mapper2</td>
      <td>B2:128</td>
      <td>B2:150</td>
      <td>B3:300</td>
      <td>L4, L5, L6</td>
    </tr>
    <tr>
      <td>Mapper3</td>
      <td>B3:256</td>
      <td>B3:300</td>
      <td>B3:300</td>
      <td>N/A</td>
    </tr>
  </tbody>
</table>

<p>现有的InputFormat包括：</p>

<ul>
  <li>TextInputFormat，Hadoop中默认的InputFormat，每行都是一个record，以偏移量为key</li>
  <li>KeyValueTextInputFormat， 可以指定key value分割符的TextInputFormat</li>
  <li>NLineInputFormat, mapper接受固定行数的记录</li>
  <li>SequenceFileInputFormat，二进制的KV
    <ul>
      <li>SequenceFileAsTextInputFormat，文本形式的KV</li>
      <li>SequenceFileAsBinaryInputFormat</li>
      <li>FixedLengthInputFormat</li>
    </ul>
  </li>
  <li>MultipleInputs</li>
  <li>DBInputFormat</li>
</ul>

<h3 id="map">Map</h3>

<p>Map阶段，会对每个从RecordReader读取的Record键值对执行用户代码，这些键值对又叫中间键值对。键和值的选择不是任意的，并且对MapReduce job的成功非常重要。键会用来分组，值是reducer端用来分析的数据。。</p>

<h3 id="combiner">Combiner</h3>
<p>Combiner 是一个map阶段分组数据，可选的，局部reducer。它根据用户提供的方法在一个mapper范围内根据中间键去聚合值。例如：数的总和是各个部分数量的和，你可以先计算中间的数目，最后再把所有中间数目加起来。很多情况下，这样能减少数据的网络传输量。发送（hello world，1）三次很显然要比发送（hello world，3）需要更多的网络传输字节量。</p>

<p><img src="http://i12.tietuku.com/009804b71667c5b9.png" width="500px" /></p>

<p>上图所示就是combiner发生的时机，它发生在map side写入磁盘的时候，可能会发生两次，一次是在Spill的时候，一次是在Merge的时候。在这两个阶段之前，是有一个sort的过程，这是为了最大化地提高combiner效率。其实从结构和作用来看，combiner函数和reducer函数的作用是相同的，很多情况下，Combiner也是直接用Reducer。</p>

<h3 id="partitioner">Partitioner</h3>

<p>Partitioner很简单，它决定哪个reducer接收该mapper数据记录，默认的是一个hash函数，对key进行hash之后取reducer个数的模。Partitioner会获取从mapper（或combiner）来的键值对，并分割成分片，每个reducer一个分片。默认用哈希值，典型使用md5sum。然后partitioner根据reduce的个数执行取余运算：key.hashCode() % (number of reducers)。这样能随即均匀的根据key分发数据到reduce，但仍然要保证不同mapper的相同key要到同一个reduce。Partitioner也可以自定义，使用更高级的样式，例如排序。然而，更改partitioner很少用。Partitioner的每个map的数据会写到本地磁盘，并等待对应的reducer检测，拿走数据。</p>

<h3 id="shuffle-and-sort">Shuffle and sort</h3>
<p>虽然说这个阶段主要是在Reduce端，但是Map端的一些行为也会影响到Reduce端。</p>

<p><img src="http://i5.tietuku.com/952140624345e77f.png" width="500px" /></p>

<p>上图是Map端的Shuffle过程，从整个过程来看，最重的部分在于Spill和Merge这两个I/O相关的操作，所有的数据需要从磁盘中读取后又重新写入到磁盘中，所以理想情况下是能够将所有mapper的output都装入到内存中。</p>

<p>Reduce任务开始于shuffle和sort阶段，Reduce将会开启多个fetcher从每个节点上的shuffle service中获取数据流。这一阶段获取partitioner的输出文件，并下载到reduce运行的本地机器。在下载的过程中，map的output首先会写入到内存中并进行排序，在数据达到一定量之后spill到磁盘，会有一个后台程序不断merge这些spilled file。最终，所有的output会合并成一个大的文件。这一阶段不能自定义，由框架自动处理。需要做的只是key的选择和可以自定义个用于分组的比较器。整个过程如下图所示。</p>

<p><img src="http://i5.tietuku.com/d11419d045f44d9a.png" width="500px" /></p>

<h3 id="reduce">Reduce</h3>
<p>Reduce 任务会把分组的数据作为输入并对每个key组执行reduce方法代码。方法会传递key和可以相关的所有值得迭代集合。很多的处理会在这个方法里执行，也就会有很多的模式。一旦reduce方法完成，会发送0或多个键值对到output format。跟map一样，不同的reduce依据不同的逻辑情形而不同。</p>

<h3 id="output-format">Output format</h3>
<p>Output Format会把reduce阶段的输出键值对根据record writer写到文件里。默认用tab分割键值对，用换行分割不同行。这里也可以自定义为更丰富的输出格式，最后，数据被写到hdfs。整个过程类似于InputFormat。</p>

<p><img src="http://i12.tietuku.com/cbdb549a3e19f898.png" width="500px" /></p>

<p>LazyOutputFormat 用来保证output (part-r-nnnnn) files有数据，不会存在空文件。</p>

<h3 id="output-commiter">Output Commiter</h3>

<p>Hadoop使用<code>OutputCommitter</code>来保证作业和任务的事务性。在旧的API中需要显示的使用<code>setOutputCommitter</code>或者设置<code>mapred.output.committer.class</code>。
而在新的API中，<code>OutputCommitter</code>是由<code>OutputFormat</code>通过<code>getOutputCommitter()</code>方法决定的。默认的是<code>FileOutputCommitter</code>，它适用于所有的基于文件的MapReduce。</p>

<p><code>OutputCommitter</code>API如下：</p>

<pre><code>public abstract class OutputCommitter {
	public abstract void setupJob(JobContext jobContext) throws IOException; 
	public void commitJob(JobContext jobContext) throws IOException { } 
	public void abortJob(JobContext jobContext, JobStatus.State state) throws IOException { }
	public abstract void setupTask(TaskAttemptContext taskContext) throws IOException;
	public abstract boolean needsTaskCommit(TaskAttemptContext taskContext) throws IOException;
	public abstract void commitTask(TaskAttemptContext taskContext) throws IOException;
	public abstract void abortTask(TaskAttemptContext taskContext) throws IOException;
}
</code></pre>

<p><code>setupJob</code>方法在job运行前就被调用，用来服务于作业的初始化，类似创建作业和task的临时目录。</p>

<p>job成功后会调用<code>commitJob()</code>方法，用于删除临时目录和创建<em>_SUCCESS</em>文件。如果job失败，则调用<code>abortJob()</code>方法
表示作业失败或者被kill，默认情况下会删除临时目录。</p>

<p>在task级别的操作类似。Hadoop框架会保证在一个task中的多个task attempt中，只有一个会commit，其他abort。有两种情况：</p>

<ul>
  <li>第一个attempt失败的时候会abort，第二个attempt如果成功则会commit。</li>
  <li>对于预测任务，只要有一个首先成功的话会commit，另外一个则abort。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[google论文：MapReduce]]></title>
    <link href="http://billowkiller.github.io/blog/2013/05/14/googlelun-wen-mapreduce/"/>
    <updated>2013-05-14T01:09:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/05/14/googlelun-wen-mapreduce</id>
    <content type="html"><![CDATA[<p>论文：<a href="http://static.googleusercontent.com/external_content/untrusted_dlcp/research.google.com/en//archive/mapreduce-osdi04.pdf">英文版</a>，<a href="http://blademaster.ixiezi.com/2010/03/27/google-mapreduce%E4%B8%AD%E6%96%87%E7%89%88/">中文版</a></p>

<hr />

<ol>
  <li>
    <h2 id="section">导论</h2>
  </li>
</ol>

<h3 id="section-1">1.1 定义</h3>

<p>先给个定义：
MapReduce是一个编程模型，也是一个处理和生成超大数据集的算法模型的相关实现。用户首先创建一个Map函数处理一个基于key/value
pair的数据集合，输出中间的基于key/value
pair的数据集合；然后再创建一个Reduce函数用来合并所有的具有相同中间key值的中间value值。</p>

<p>使用这个抽象模型，我们只要表述我们想要执行的简单运算即可，而不必关心并行计算、容错、数据分布、负载均衡等复杂的细节，这些问题都被封装在了一个库里面。设计这个抽象模型的灵感来自Lisp和许多其他函数式语言的Map和Reduce的原语。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/mr2_zps9c617225.png" alt="big picture of MapReduce" /></p>

<!--more-->
<p>### 1.2 概述</p>

<ul>
  <li>Programmers must specify:
    <ul>
      <li>map (k, v) → &lt;k’, v’&gt;*</li>
      <li>reduce (k’, v’) → &lt;k’, v’&gt;*
        <ul>
          <li>All values with the same key are reduced together</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Optionally, also:
    <ul>
      <li>partition (k’, number of partitions) → partition for k’
        <ul>
          <li>Often a simple hash of the key, e.g., hash(k’) mod n</li>
          <li>Divides up key space for parallel reduce operations</li>
        </ul>
      </li>
      <li>combine (k’, v’) → &lt;k’, v’&gt;*
        <ul>
          <li>Mini-reducers that run in memory after the map phase</li>
          <li>Used as an optimization to reduce network traffic</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>The execution framework handles everything else…
    <ul>
      <li>Scheduling: assigns workers to map and reduce tasks</li>
      <li>“Data distribution”: moves processes to data</li>
      <li>Synchronization: gathers, sorts, and shuffles intermediate data</li>
      <li>Errors and faults: detects worker failures and restarts</li>
    </ul>
  </li>
  <li>Limited control over data and execution flow
    <ul>
      <li>All algorithms must expressed in m, r, c, p</li>
    </ul>
  </li>
  <li>You don’t know:
    <ul>
      <li>Where mappers and reducers run</li>
      <li>When a mapper or reducer begins or finishes</li>
      <li>Which input a particular mapper is processing</li>
      <li>Which intermediate key a particular reducer is processing</li>
    </ul>
  </li>
</ul>

<ol>
  <li>
    <h2 id="section-2">实现</h2>
  </li>
</ol>

<h3 id="section-3">2.1 流程</h3>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/mr1_zps85dad9ca.png" alt="Execution Overview" height="500px" /></p>

<p>上图展示了我们的MapReduce实现中操作的全部流程。</p>

<ol>
  <li>用户程序首先调用的MapReduce库将输入文件分成M个数据片段，每个数据片段的大小一般从16MB到64MB。然后用户程序在机群中创建大量的程序副本。</li>
  <li>这些程序副本中的有一个特殊的程序–master。副本中其它的程序都是worker程序，由master分配任务。有M个Map任务和R个Reduce任务将被分配，master将一个Map任务或Reduce任务分配给一个空闲的worker。</li>
  <li>被分配了map任务的worker程序读取相关的输入数据片段，从输入的数据片段中解析出key/value
pair，然后把key/value
pair传递给用户自定义的Map函数，由Map函数生成并输出的中间key/value
pair，并缓存在内存中。</li>
  <li>缓存中的key/value
pair通过分区函数分成R个区域，之后周期性的写入到本地磁盘上。缓存的key/value
pair在本地磁盘上的存储位置将被回传给master，由master负责把这些存储位置再传送给Reduce
worker。</li>
  <li>当Reduce
worker程序接收到master程序发来的数据存储位置信息后，使用RPC从Map
worker所在主机的磁盘上读取这些缓存数据。当Reduce
worker读取了所有的中间数据后，通过对key进行排序后使得具有相同key值的数据聚合在一起。由于许多不同的key值会映射到相同的Reduce任务上，因此必须进行排序。如果中间数据太大无法在内存中完成排序，那么就要在外部进行排序。</li>
  <li>Reduce
worker程序遍历排序后的中间数据，对于每一个唯一的中间key值，Reduce
worker程序将这个key值和它相关的中间value值的集合传递给用户自定义的Reduce函数。Reduce函数的输出被追加到所属分区的输出文件。</li>
  <li>当所有的Map和Reduce任务都完成之后，master唤醒用户程序。在这个时候，在用户程序里的对MapReduce调用才返回。</li>
</ol>

<h3 id="mapreduce">2.2 map和Reduce的同步</h3>

<ul>
  <li>Cleverly-constructed data structures
    <ul>
      <li>Bring partial results together</li>
    </ul>
  </li>
  <li>Sort order of intermediate keys
    <ul>
      <li>Control order in which reducers process keys</li>
    </ul>
  </li>
  <li>Partitioner
    <ul>
      <li>Control which reducer processes which keys</li>
    </ul>
  </li>
  <li>Preserving state in mappers and reducers
    <ul>
      <li>Capture dependencies across multiple keys and values</li>
    </ul>
  </li>
</ul>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/mr3_zps5ead0c7b.png" alt="map和Reduce的同步" height="300px" /></p>

<h3 id="section-4">2.3 本地聚合</h3>

<ul>
  <li>Ideal scaling characteristics:
    <ul>
      <li>Twice the data, twice the running time</li>
      <li>Twice the resources, half the running time</li>
    </ul>
  </li>
  <li>Why can’t we achieve this?
    <ul>
      <li>Synchronization requires communication</li>
      <li>Communication kills performance</li>
    </ul>
  </li>
  <li>Thus… avoid communication!
    <ul>
      <li>Reduce intermediate data via local aggregation</li>
      <li>Combiners can help</li>
    </ul>
  </li>
</ul>

<h3 id="shuffle-and-sort">2.4 Shuffle and Sort</h3>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/mr4_zps7ee59e35.png" alt="Shuffle and Sort" height="400px" /></p>

<h3 id="master">2.5 Master</h3>

<p>Master持有一些数据结构，它存储每一个Map和Reduce任务的状态（空闲、工作中或完成)，以及Worker机器(非空闲任务的机器)的标识。</p>

<p>Master就像一个数据管道，中间文件存储区域的位置信息通过这个管道从Map传递到Reduce。因此，对于每个已经完成的Map任务，master存储了Map任务产生的R个中间文件存储区域的大小和位置。当Map任务完成时，Master接收到位置和大小的更新信息，这些信息被逐步递增的推送给那些正在工作的Reduce任务。</p>

<p>master周期性的ping每个worker。如果在一个约定的时间范围内没有收到worker返回的信息，master将把这个worker标记为失效。所有由这个失效的worker完成的Map任务被重设为初始的空闲状态，之后这些任务就可以被安排给其他的worker。同样的，worker失效时正在运行的Map或Reduce任务也将被重新置为空闲状态，等待重新调度。</p>

<p>master周期性的将数据写入磁盘，即检查点（checkpoint）。如果这个master任务失效了，可以从最后一个检查点开始启动另一个master进程。然而，由于只有一个master进程，master失效后再恢复是比较麻烦的，因此我们现在的实现是如果master失效，就中止MapReduce运算。客户可以检查到这个状态，并且可以根据需要重新执行MapReduce操作。</p>

<ol>
  <li>
    <h2 id="section-5">性能优化</h2>
  </li>
</ol>

<h3 id="straggler">3.1 straggler</h3>

<p>影响一个MapReduce的总执行时间最通常的因素是straggler(落伍者)：在运算过程中，如果有一台机器花了很长的时间才完成最后几个Map或Reduce任务，导致MapReduce操作总的执行时间超过预期。</p>

<p>当一个MapReduce操作接近完成的时候，master调度备用（backup）任务进程来执行剩下的、处于处理中状态（in-progress）的任务。无论是最初的执行进程、还是备用（backup）任务进程完成了任务，我们都把这个任务标记成为已经完成。我们调优了这个机制，通常只会占用比正常操作多几个百分点的计算资源。我们发现采用这样的机制对于减少超大MapReduce操作的总处理时间效果显著。</p>

<h3 id="partitioning-function">3.2 分区函数(partitioning function)</h3>

<p>我们在中间key上使用分区函数来对数据进行分区，之后再输入到后续任务执行进程。一个缺省的分区函数是使用hash方法(比如，hash(key)
mod
R)进行分区。hash方法能产生非常平衡的分区。然而，有的时候，其它的一些分区函数对key值进行的分区将非常有用。</p>

<p>使用“hash(Hostname(urlkey)) mod
R”作为分区函数就可以把所有来自同一个主机的URLs保存在同一个输出文件中。</p>

<h3 id="section-6">3.3 顺序保证</h3>

<p>在给定的分区中，中间key/value
pair数据的处理顺序是按照key值增量顺序处理的。</p>

<h3 id="combiner">3.4 Combiner函数</h3>

<p>用户指定一个可选的combiner函数，combiner函数首先在本地将这些记录进行一次合并，然后将合并的结果再通过网络发送出去。</p>

<p>一般情况下，Combiner和Reduce函数是一样的。Combiner函数和Reduce函数之间唯一的区别是MapReduce库怎样控制函数的输出。</p>

<h3 id="section-7">3.5 跳过损坏的记录</h3>

<ul>
  <li>Map/Reduce functions sometimes fail for particular inputs
    <ul>
      <li>Best solution is to debug &amp; fix
        <ul>
          <li>Not always possible \~ third-party source libraries</li>
        </ul>
      </li>
      <li>On segmentation fault:
        <ul>
          <li>Send UDP packet to master from signal handler</li>
          <li>Include sequence number of record being processed</li>
        </ul>
      </li>
      <li>If master sees two failures for same record:
        <ul>
          <li>Next worker is told to skip the record</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<ol>
  <li>
    <h2 id="section-8">要点和例子</h2>
  </li>
</ol>

<h3 id="points-need-to-be-emphasized">4.1 Points need to be emphasized</h3>

<ul>
  <li>No reduce can begin until map is complete</li>
  <li>Master must communicate locations of intermediate files</li>
  <li>Tasks scheduled based on location of data</li>
  <li>If map worker fails any time before reduce finishes, task must be
completely rerun</li>
  <li>MapReduce library does most of the hard work for us!</li>
</ul>

<h3 id="section-9">4.2 例子</h3>

<ol>
  <li>分布式的Grep：Map函数输出匹配某个模式的一行，Reduce函数是一个恒等函数，即把中间数据复制到输出。</li>
  <li>计算URL访问频率：Map函数处理日志中web页面请求的记录，然后输出(URL,1)。Reduce函数把相同URL的value值都累加起来，产生(URL,记录总数)结果。</li>
  <li>倒转网络链接图：Map函数在源页面（source）中搜索所有的链接目标（target）并输出为(target,source)。Reduce函数把给定链接目标（target）的链接组合成一个列表，输出(target,list(source))。</li>
  <li>每个主机的检索词向量：检索词向量用一个(词,频率)列表来概述出现在文档或文档集中的最重要的一些词。Map函数为每一个输入文档输出(主机名,检索词向量)，其中主机名来自文档的URL。Reduce函数接收给定主机的所有文档的检索词向量，并把这些检索词向量加在一起，丢弃掉低频的检索词，输出一个最终的(主机名,检索词向量)。</li>
  <li>倒排索引：Map函数分析每个文档输出一个(词,文档号)的列表，Reduce函数的输入是一个给定词的所有（词，文档号），排序所有的文档号，输出(词,list（文档号）)。所有的输出集合形成一个简单的倒排索引，它以一种简单的算法跟踪词在文档中的位置。</li>
  <li>
    <p>分布式排序：Map函数从每个记录提取key，输出(key,record)。Reduce函数不改变任何的值。这个运算依赖分区机制(在4.1描述)和排序属性(在4.2描述)。</p>
  </li>
  <li>
    <h2 id="hadoop">Hadoop</h2>
  </li>
</ol>

<p><strong>术语对照</strong></p>

<table border="1" cellspacing="0" cellpadding="0">
<tbody>
<tr>
<td width="109">
<p class="TableContents" align="center"><span style="font-size: 14px;"><strong>翻译</strong></span></p>
</td>
<td width="136">
<p class="TableContents" align="center"><span style="font-size: 14px;"><strong>Hadoop</strong><strong>术语</strong></span></p>
</td>
<td width="142">
<p class="TableContents" align="center"><span style="font-size: 14px;"><strong>Google</strong><strong>术语</strong></span></p>
</td>
<td width="277">
<p class="TableContents" align="center"><span style="font-size: 14px;"><strong>相关解释</strong></span></p>
</td>
</tr>
<tr>
<td width="109">
<p class="TableContents" align="center"><span style="font-size: 14px;">作业</span></p>
</td>
<td width="136">
<p class="TableContents" align="center"><span style="font-size: 14px;">Job</span></p>
</td>
<td width="142">
<p class="TableContents" align="center"><span style="font-size: 14px;">Job</span></p>
</td>
<td width="277">
<p class="TableContents"><span style="font-size: 14px;">用户的每一个计算请求，就称为一个作业。</span></p>
</td>
</tr>
<tr>
<td width="109">
<p class="TableContents" align="center"><span style="font-size: 14px;">作业服务器</span></p>
</td>
<td width="136">
<p class="TableContents" align="center"><span style="font-size: 14px;">JobTracker</span></p>
</td>
<td width="142">
<p class="TableContents" align="center"><span style="font-size: 14px;">Master</span></p>
</td>
<td width="277">
<p class="TableContents"><span style="font-size: 14px;">用户提交作业的服务器，同时，它还负责各个作业任务的分配，管理所有的任务服务器。</span></p>
</td>
</tr>
<tr>
<td width="109">
<p class="TableContents" align="center"><span style="font-size: 14px;">任务服务器</span></p>
</td>
<td width="136">
<p class="TableContents" align="center"><span style="font-size: 14px;">TaskTracker</span></p>
</td>
<td width="142">
<p class="TableContents" align="center"><span style="font-size: 14px;">Worker</span></p>
</td>
<td width="277">
<p class="TableContents"><span style="font-size: 14px;">任劳任怨的工蜂，负责执行具体的任务。</span></p>
</td>
</tr>
<tr>
<td width="109">
<p class="TableContents" align="center"><span style="font-size: 14px;">任务</span></p>
</td>
<td width="136">
<p class="TableContents" align="center"><span style="font-size: 14px;">Task</span></p>
</td>
<td width="142">
<p class="TableContents" align="center"><span style="font-size: 14px;">Task</span></p>
</td>
<td width="277">
<p class="TableContents"><span style="font-size: 14px;">每一个作业，都需要拆分开了，交由多个服务器来完成，拆分出来的执行单位，就称为任务。</span></p>
</td>
</tr>
<tr>
<td width="109">
<p class="TableContents" align="center"><span style="font-size: 14px;">备份任务</span></p>
</td>
<td width="136">
<p class="TableContents" align="center"><span style="font-size: 14px;">Speculative Task</span></p>
</td>
<td width="142">
<p class="TableContents" align="center"><span style="font-size: 14px;">Buckup Task</span></p>
</td>
<td width="277">
<p class="TableContents"><span style="font-size: 14px;">每一个任务，都有可能执行失败或者缓慢，为了降低为此付出的代价，系统会未雨绸缪的实现在另外的任务服务器上执行同样一个任务，这就是备份任务。</span></p>
</td>
</tr>
</tbody>
</table>
<p>具体可以看博文<a href="http://www.cnblogs.com/duguguiyu/archive/2009/02/28/1400278.html">http://www.cnblogs.com/duguguiyu/archive/2009/02/28/1400278.html</a></p>

]]></content>
  </entry>
  
</feed>
