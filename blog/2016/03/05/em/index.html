<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Expectation Maximization - Billowkiller's Blog</title>
  <meta name="author" content="wutao">

  
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://billowkiller.github.io/blog/2016/03/05/em">
  <link href="/favicon.png" type="image/png" rel="icon">
  <link href="/atom.xml" rel="alternate" title="Billowkiller's Blog" type="application/atom+xml">

  <link href="/javascripts/libs/bootstrap-3.0.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/javascripts/libs/bootstrap-3.0.0/dist/css/bootstrap-theme.min.css" rel="stylesheet" type="text/css">
<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<style type="text/css">
body {
  font-family: Lucida Grande,Helvetica, arial, sans-serif;
  font-size: 15px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

    table {
  padding: 0; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      text-align: left;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      text-align: left;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }
    }
</style>


  <script src="/javascripts/libs/jquery/jquery-2.0.3.min.js"></script>
  

</head>

  <body   >
    <div id="wrap">
      <header role="banner">
        <nav class="navbar navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Billowkiller's Blog</a>
        </div>

        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                <li class="active">
                    <a href="/">Blog</a>
                </li>
                <li >
                    <a href="/blog/archives">Archives</a>
                </li>
				<li >
                    <a href="/blog/tags">Tags</a>
                </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a class="subscribe-rss" href="/atom.xml" title="subscribe via RSS">
                        <span class="visible-xs">RSS</span>
                        <img class="hidden-xs" src="/images/rss.png" alt="RSS">
                    </a>
                </li>
                
            </ul>
            
                <form class="search navbar-form navbar-right" action="http://google.com/search" method="GET">
                    <input type="hidden" name="q" value="site:billowkiller.github.io">
                    <div class="form-group">
                        <input class="form-control" type="text" name="q" placeholder="Search">
                    </div>
                </form>
            
        </div>
    </div>
</nav>


      </header>
      <div id="main" class="container">
        <div id="content">
          <div class="row">
  <div class="page-content col-md-9">
    <article class="hentry" role="article">
      
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-05T14:00:00+08:00" pubdate data-updated="true">Mar 5<span>th</span>, 2016</time>
        
           | <a href="#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io">Comments</a>
        
      </p>
    
    
    <h1 class="entry-title">
        Expectation Maximization
        
    </h1>
    
  </header>


<div class="entry-content clearfix"><p>Expectation Maximization, EM算法在参数估计里面有极大的用处，它用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率（MAP）估计。隐变量的概率模型参数的极大似然估计可以理解为，使用的方法还是的极大似然估计，但是要处理隐变量。极大后验概率是一种Beyesian Inference，其实就是把极大似然估计中的参数赋予权值，这个权值是预先定义好的先验概率。可以来看下下表中Frequentist-Bayesian对峙的部分，来感受下EM算法的应用范围：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/88568881.jpg" width="500px" /></p>

<!--more-->

<p>下面我们先从一个Two-Component Gaussian Mixture Model为例，介绍EM算法。</p>

<h2 id="two-component-gaussian-mixture-model">Two-Component Gaussian Mixture Model</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/45836233.jpg" width="600px" /></p>

<p>上图是一个mixture example，左边是我们观察到数据的直方图，右边红线是最大似然拟合的高斯密度函数，绿色的点是用来做两个模型的分类用。</p>

<p>这里其实我们得到的是一些数据点，对于这些点的分布完全一无所知。先做出如下假设，这是两个高斯模型混合后的sample data。</p>

<script type="math/tex; mode=display"> Y_1 \sim N(\mu_1, \theta_1^2) </script>

<script type="math/tex; mode=display"> Y_2 \sim N(\mu_2, \theta_2^2) </script>

<script type="math/tex; mode=display"> Y = (1 - \Delta)\cdot Y_1 + \Delta \cdot Y_2,\  \Delta \in \{0,1\}, Pr(\Delta =1) = \pi</script>

<p>那么需要我们估计的参数就为 $(\pi, \theta_1, \theta_2) = (\pi, \mu_1, \sigma_1, \mu_2, \sigma_2)$，一共五个参数。使用似然估计，我们可以得到如下过程：</p>

<script type="math/tex; mode=display"> g_Y(y) = (1-\pi)\phi_{\theta_1}(y) + \pi \phi_{\theta_2}(y) </script>

<script type="math/tex; mode=display">log\ likelihood \to l(\theta; Z) = \sum_{i=1}^N log[(1-\pi)\phi_{\theta_1}(y_i) + \pi \phi_{\theta_2}(y_i)] </script>

<p>最大化 $l(\theta; Z)$ 无疑是困难的，因为对数中含有加号。如果我们知道隐变量 $\Delta$ 的取值，那么参数估计就会变得容易，$\phi$ 的估计也就是 $\Delta_i=1$ 的比例，另外 $\theta_1,\theta_2$ 也就变成 $\Delta_i=0，\Delta_i=1$ 的似然估计。</p>

<p>所以问题的关键是 $\Delta$ 的取值，解决问题的思路是采用迭代的方式，每次都用 $\Delta_i$ 的估计值替换：</p>

<script type="math/tex; mode=display">\gamma_i(\theta) = E(\Delta_i \vert \theta,Z) = Pr(\Delta_i=1 \vert \theta,Z)</script>

<p>如此 $\theta_1,\theta_2$ 自然也就可以由最大似然估计求出。在下一次过程中，$\gamma_i(\theta)$ 又可以由上一步估计的 $\theta_1,\theta_2$ 求出。所以我们首先需要给出参数的初始值，就可以由上述过程得到结果。算法入下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/24344888.jpg" width="550px" /></p>

<p>这里需要注意的是，如果我们在某个点取 $\hat{\mu}_1 = y_i, \hat{\sigma}_1=0$ 那么我们可以去到最大的似然值，无限大，但这并不是有用的解。所以我们其实是求解 <u>a good local maximum of the likelihood</u>，因此我们可以设多个初值，最后选择似然值最大的解。</p>

<h2 id="em-in-general">EM in General</h2>

<p>EM算法被用于data augmentation，关于data augmentation的解释如下：</p>

<blockquote>
  <p>maximization of the likelihodd is difficult, but made easier by enlarging the sample with latent data</p>
</blockquote>

<p>上面的例子中我们设的latent data为 $\Delta$，是出于我们对模型的假设；其他的latent data还可以为丢失的观察值。接下来我们介绍EM的通用形式，先给出算法：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/67870944.jpg" width="550px" /></p>

<p>上面的算法中，$Z$ 为观察值，log likelihood是 $l(\theta, Z)$。latent or missing data 为 $Z^m$， 完整的数据为 $T=(Z, Z^m$)，对比于上面的例子 $(Z, Z^m) = (y, \Delta)$。</p>

<ul>
  <li>E step就是完全数据 $T$ 的对数似然函数 $l_0(\theta’; T)$ 关于在给定观察数据 $Z$ 和当前参数 $\theta^{(j)}$ 下对未观察数据 $Z^m$ 的条件概率分布 $Pr(Z^m \vert Z, \theta^{(j)})$ 的期望，得到的是 $Z^m$ 的估计。</li>
  <li>M step就是通过似然估计方法，求未观察数据 $Z^m$ 的条件概率分布的期望的最大值，得到参数 $\theta$ 的重新估计 $\theta’$，在下一个E中变为 $\theta^{(j+1)}$。</li>
</ul>

<p>上面叙述了EM的算法，那么为什么EM算法能有效，也就是近似实现对观测数据的极大似然估计呢？我们看到</p>

<script type="math/tex; mode=display"> Pr(Z^m \vert Z, \theta') = \frac{Pr(Z^m,Z  \vert \theta')}{Pr(Z \vert  \theta')} </script>

<script type="math/tex; mode=display"> \to Pr(Z \vert  \theta') = \frac{Pr(T  \vert  \theta')}{ Pr(Z^m \vert Z, \theta')} </script>

<script type="math/tex; mode=display"> \to l(\theta'; Z) = l_0(\theta'; T) - l_1(\theta'; Z^m \vert Z) </script>

<p>对由 $\theta$ 控制的分布 $T \vert Z$ 数据求期望可以得到：</p>

<script type="math/tex; mode=display"> l(\theta'; Z) = E[l_0(\theta'; T) \vert Z,\theta] - E[l_1(\theta'; Z^m \vert Z) \vert Z,\theta] = Q(\theta', \theta) - R(\theta', \theta) </script>

<p>在 $M\ step$ 中，EM算法求出可以使 $Q(\theta’, \theta)$ 最大化的 $\theta’$，而不是真正的目标函数 $l(\theta’; Z)$。为什么最大化 $Q(\theta’, \theta)$ 最终可以最大化 $l(\theta’; Z)$呢？</p>

<p>可以看到 $R(\theta^*, \theta)$ 是由 $\theta^*$ 决定的条件分布的log-likelihood的期望，这个分布和由 $\theta$ 决定的条件分布是相同的。因此由 Jensen’s inequality 可以得到，$R(\theta’, \theta) \le R(\theta, \theta)$。具体的推导可以参考《统计学习方法》。所以如果 $\theta’$ 最大化 $Q(\theta’, \theta)$ 则</p>

<script type="math/tex; mode=display"> l(\theta'; Z) - l(\theta; Z) = [Q(\theta', \theta) - Q(\theta, \theta)] - [R(\theta', \theta) - R(\theta, \theta)] \ge 0 </script>

<p>所以说EM迭代中，$l(\theta’; Z)$ 一直都会在增大。</p>

<blockquote>
  <p>Jensen’s inequality, $E[\phi(X)] \ge \phi[E(X)]$, for Random variable $X$ and convex function $\phi(x)$</p>
</blockquote>

<p>也就是说在 $M step$ 中完全的最大化是没有必要的，我们只需要找到一个 $\theta^{(j+1)}$ 使得 $Q(\theta^{(j+1)}, \theta^{(j)}) - Q(\theta^{(j)}, \theta^{(j)})$。所以我们得到的EM收敛条件也就是 </p>

<script type="math/tex; mode=display">% <![CDATA[
 \theta^{(j+1)} - \theta^{(j)} < \epsilon\ or\ Q(\theta^{(j+1)}, \theta^{(j)}) - Q(\theta^{(j)}, \theta^{(j)}) < \epsilon  %]]></script>

<h2 id="em-as-max-max-procedure">EM as max-max Procedure</h2>

<p>EM算法还可以看成是F 函数的极大极大算法， F函数定义如下</p>

<script type="math/tex; mode=display"> F(\theta',  \tilde{P}) = E_{\tilde{P}}[l_0(\theta'; T)] - E_{\tilde{P}}[log \tilde{P}(Z^m)] </script>

<p>$\tilde{P}(Z^m)$也就是隐变量 $Z^m$ 的分布, $- E_{\tilde{P}}[log \tilde{P}(Z^m)]$ 也就是 $\tilde{P}(Z^m)$ 的熵。于是EM算法可以由下图表示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/44573110.jpg" width="500px" /></p>

<p>也就是，设 $\theta^{(i)}$ 为第 $i$ 次迭代参数 $\theta$ 的估计，$\tilde{P}^{(i)}$ 为第 $i$ 次迭代参数 $\tilde{P}$ 的估计。在第 $i+1$ 次迭代的两步为：</p>

<ul>
  <li>对固定的 $\theta^{(i)}$，求 $\tilde{P}^{(i+1)}$ 使得 $F(\theta^{(i)},  \tilde{P})$ 极大化</li>
  <li>对固定的 $\tilde{P}^{(i+1)}$，求 $\theta^{(i+1)}$ 使得 $F(\theta,  \tilde{P}^{(i+1)})$ 极大化</li>
</ul>

</div>


      <footer>
        <p class="meta text-muted">
          
  

<span class="glyphicon glyphicon-user"></span> <span class="byline author vcard">Posted by <span class="fn">wutao</span></span>

          












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-05T14:00:00+08:00" pubdate data-updated="true">Mar 5<span>th</span>, 2016</time>
          

<span class="glyphicon glyphicon-tags"></span>&nbsp;
<span class="categories">
  
    <a class='category' href='/blog/categories/machine-learning/'>Machine Learning</a>
  
</span>


        </p>
        
          <div class="sharing">
  
  <a href="//twitter.com/share" class="twitter-share-button" data-url="http://billowkiller.github.io/blog/2016/03/05/em/" data-via="" data-counturl="http://billowkiller.github.io/blog/2016/03/05/em/" >Tweet</a>
  
  
  
</div>

        
        
          <ul class="meta text-muted pager">
            
            <li class="previous"><a href="/blog/2016/02/29/klr-svr/" title="Previous Post: Kernel Logistic Regression versus SVM">&laquo; Kernel Logistic Regression versus SVM</a></li>
            
            
            <li class="next"><a href="/blog/2016/03/06/apriori/" title="Next Post: Apriori and FP-Growth">Apriori and FP-Growth &raquo;</a></li>
            
          </ul>
        
      </footer>
    </article>
    
      <section>
        <h1>Comments</h1>
        <div id="disqus_thread" aria-live="polite"><noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</div>
      </section>
    
  </div>

  
  <aside class="sidebar col-md-3">
    
      <section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Recent Posts</h3>
  </div>
  
  <div id="recent_posts" class="list-group">
    
    <a class="list-group-item " href="/blog/2016/06/01/mcmc/">MCMC Methods</a>
    
    <a class="list-group-item " href="/blog/2016/05/09/random-process/">Random Process</a>
    
    <a class="list-group-item " href="/blog/2016/04/09/rating/">Funny Facts About Rating</a>
    
    <a class="list-group-item " href="/blog/2016/04/09/recsys-introduction/">Recommender System in a Nutshell</a>
    
    <a class="list-group-item " href="/blog/2016/04/06/kafka/">Kafka Introduction</a>
    
  </div>
</section>
<section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Categories</h3>
  </div>
  <div class="list-group">
    
    
    <a class="list-group-item " href="/blog/categories/language/index.html">
        <span class="badge">9</span>
        language
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/tools/index.html">
        <span class="badge">7</span>
        tools
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/book/index.html">
        <span class="badge">7</span>
        book
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/google/index.html">
        <span class="badge">4</span>
        google
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/linux/index.html">
        <span class="badge">13</span>
        linux
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/film/index.html">
        <span class="badge">3</span>
        film
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/rework/index.html">
        <span class="badge">12</span>
        rework
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/algorithm/index.html">
        <span class="badge">8</span>
        algorithm
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/machine-learning/index.html">
        <span class="badge">13</span>
        Machine Learning
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/big-data/index.html">
        <span class="badge">9</span>
        Big Data
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/math/index.html">
        <span class="badge">1</span>
        math
      </a>
    
  </div>
</section>
<section class="panel panel-default clearfix">
  <div class="panel-heading">
      <h3 class="panel-title">GitHub Repos</h3>
  </div>
  
    <div class="gh-profile-link pull-right text-muted">
      <a href="https://github.com/billowkiller">@billowkiller</a> on GitHub
    </div>
  
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">On Delicious</h3>
  </div>
  <div class="panel-body">
    <div id="delicious"></div>
    <script type="text/javascript" src="http://feeds.delicious.com/v2/json/billowkiller?count=3&amp;sort=date&amp;callback=renderDeliciousLinks"></script>
    <p><a href="http://delicious.com/billowkiller">My Delicious Bookmarks &raquo;</a></p>
  </div>
</section>


    
  </aside>
  
</div>

        </div>
      </div>
    </div>
    <footer role="contentinfo"><div class="container">
    <p class="text-muted credits">
  Copyright &copy; 2016 - wutao<br>
  <small>
      <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>,
      <span class="credit">customized with <a href="https://github.com/kAworu/octostrap3">octostrap3</a></span>.
  </small>
</p>

</div>
</footer>
    <script src="/javascripts/libs/bootstrap-3.0.0/dist/js/bootstrap.min.js"></script>
<script src="/javascripts/modernizr-2.0.js"></script>


<script type="text/javascript">
      var disqus_shortname = 'billowkiller';
      
        
        // var disqus_developer = 1;
        var disqus_identifier = 'http://billowkiller.github.io/blog/2016/03/05/em/';
        var disqus_url = 'http://billowkiller.github.io/blog/2016/03/05/em/';
        var disqus_script = 'embed.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





  </body>
</html>
