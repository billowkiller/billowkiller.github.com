<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Billowkiller's Blog</title>
  <meta name="author" content="wutao">

  
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://billowkiller.github.io">
  <link href="/favicon.png" type="image/png" rel="icon">
  <link href="/atom.xml" rel="alternate" title="Billowkiller's Blog" type="application/atom+xml">

  <link href="/javascripts/libs/bootstrap-3.0.0/dist/css/bootstrap.min.css" rel="stylesheet" type="text/css">
<link href="/javascripts/libs/bootstrap-3.0.0/dist/css/bootstrap-theme.min.css" rel="stylesheet" type="text/css">
<link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">

<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>

<style type="text/css">
body {
  font-family: Lucida Grande,Helvetica, arial, sans-serif;
  font-size: 15px;
  line-height: 1.6;
  padding-top: 10px;
  padding-bottom: 10px;
  background-color: white;
  padding: 30px; }

    table {
  padding: 0; }
  table tr {
    border-top: 1px solid #cccccc;
    background-color: white;
    margin: 0;
    padding: 0; }
    table tr:nth-child(2n) {
      background-color: #f8f8f8; }
    table tr th {
      font-weight: bold;
      border: 1px solid #cccccc;
      text-align: left;
      margin: 0;
      padding: 6px 13px; }
    table tr td {
      border: 1px solid #cccccc;
      text-align: left;
      margin: 0;
      padding: 6px 13px; }
    table tr th :first-child, table tr td :first-child {
      margin-top: 0; }
    table tr th :last-child, table tr td :last-child {
      margin-bottom: 0; }
    }
</style>


  <script src="/javascripts/libs/jquery/jquery-2.0.3.min.js"></script>
  

</head>

  <body   >
    <div id="wrap">
      <header role="banner">
        <nav class="navbar navbar-default" role="navigation">
    <div class="container">
        <div class="navbar-header">
            <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Billowkiller's Blog</a>
        </div>

        <div class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
                <li class="active">
                    <a href="/">Blog</a>
                </li>
                <li >
                    <a href="/blog/archives">Archives</a>
                </li>
				<li >
                    <a href="/blog/tags">Tags</a>
                </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
                <li>
                    <a class="subscribe-rss" href="/atom.xml" title="subscribe via RSS">
                        <span class="visible-xs">RSS</span>
                        <img class="hidden-xs" src="/images/rss.png" alt="RSS">
                    </a>
                </li>
                
            </ul>
            
                <form class="search navbar-form navbar-right" action="http://google.com/search" method="GET">
                    <input type="hidden" name="q" value="site:billowkiller.github.io">
                    <div class="form-group">
                        <input class="form-control" type="text" name="q" placeholder="Search">
                    </div>
                </form>
            
        </div>
    </div>
</nav>


      </header>
      <div id="main" class="container">
        <div id="content">
          <div class="row">
  <div class="page-content col-md-9">
    <div class="blog-index">
      
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-04-09T16:00:00+08:00" pubdate data-updated="true">Apr 9<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/04/09/rating/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/04/09/rating/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/04/09/rating/">Funny Facts About Rating</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>本文分析Wilson score confidence interval，它在Reddit评论评分中的应用，另外分析了Hacker News、Reddit的评分算法。先来看下错误的评分。</p>

<p>Case 1: 网站的内容排名，得分高的排前面，得分低的排后面。如何计算得分。</p>

<p><strong>Solution 1:  Score = (Positive ratings) - (Negative ratings)</strong></p>

<u>未考虑内容的受欢迎程度。</u>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/04/09/rating/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-04-09T14:00:00+08:00" pubdate data-updated="true">Apr 9<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/04/09/recsys-introduction/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/04/09/recsys-introduction/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/04/09/recsys-introduction/">Recommender System in a Nutshell</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>推荐系统（Recommender System An Introduction）读书笔记。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/04/09/recsys-introduction/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-04-06T14:00:00+08:00" pubdate data-updated="true">Apr 6<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/04/06/kafka/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/04/06/kafka/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/04/06/kafka/">Kafka Introduction</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>Kafka最早是由LinkedIn开发的一个分布式发布-订阅消息系统，现在已经是Apache的一个开源项目。它具有以下的一些特点：</p>

<ul>
  <li>作为分布式系统，很容易 scale out</li>
  <li>消息以时间复杂度为O(1)的方式持久化到磁盘，支持离线消费和实时消费</li>
  <li>发布和订阅都支持高吞吐量，单机支持每秒100K条以上消息的传输</li>
  <li>支持多个订阅端，并且可以在异常情况下自动对这些消费者进行负载均衡</li>
</ul>

<p>消息系统的好处包括：</p>

<ul>
  <li>解耦生产者和消费者</li>
  <li>持久化直到消息已经被完全处理</li>
  <li>扩展性</li>
  <li>灵活性 &amp; 峰值处理能力</li>
  <li>可恢复性，系统的一部分组件失效时，不会影响到整个系统。</li>
  <li>顺序保证</li>
  <li>缓冲，有助于控制和优化数据流经过系统的速度。</li>
  <li>异步通信</li>
</ul>

<h2 id="section">名词解释</h2>

<ul>
  <li>
    <p>Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker</p>
  </li>
  <li>
    <p>Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>
  </li>
  <li>
    <p>Partition：Parition是物理上的概念，每个Topic包含一个或多个Partition.</p>
  </li>
  <li>
    <p>Producer：负责发布消息到Kafka broker</p>
  </li>
  <li>
    <p>Consumer：消息消费者，向Kafka broker读取消息的客户端。</p>
  </li>
  <li>
    <p>Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</p>
  </li>
</ul>

<h2 id="section-1">架构图</h2>

<p><img src="http://cdn.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-1/zh/resources/0310020.png" width="500px" /></p>

<p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>

<p><img src="http://cdn.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-1/zh/resources/0310025.png" width="500px" /></p>

<p>上图示意消费者和生产者的工作方式。同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。</p>

<p><img src="http://sookocheff.com/img/kafka/kafka-in-a-nutshell/log-anatomy.png" width="500px" /></p>

<p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。每条消息都被append到某个Partition中，具体存储到哪一个Partition是根据Partition机制。如果Partition机制比较合理，不同的消息可以并行写入不同broker的不同Partition里，能极大的提高了吞吐率。另因为磁盘限制，Kafka提供两种策略删除旧数据：一是基于时间，二是基于Partition文件大小。</p>

<h3 id="kafka-delivery-guarantee">Kafka delivery guarantee</h3>

<p>Producer向broker发送消息时，默认情况下一条消息从Producer到broker是确保了 <code>At least once</code>，但如果设置Producer为异步发送则实现 <code>At most once</code>。<code>Exactly once</code>还未实现（生成一种消息主键，幂等重试）。</p>

<p>Consumer在从broker读取消息后，可以选择<code>autocommit</code>或<code>手动commit</code>。区别在于一个是读完消息先commit再处理消息，一个是读完消息先处理再commit。前者实现 <code>At most once</code>，后者实现 <code>At least once</code>，但如果消息的处理有幂等性，则可以理解为<code>Exactly once</code>。如果要做到严格<code>Exactly once</code>，则让offset和操作输入存在同一个地方，保证数据的输出和offset的更新要么都完成，要么都不完成，参考Spark Kafka的DirectAPI的实现。</p>

<h2 id="high-available">High Available</h2>

<p>Kafka的HA包括Data Replication和Leader Election两方面。</p>

<h3 id="data-replication">Data Replication</h3>

<p><img src="http://cdn4.infoqstatic.com/statics_s2_20160405-0343u1/resource/articles/kafka-analysis-part-2/zh/resources/0416000.png" width="500px" /></p>

<p>为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。Kafka分配Replica的算法如下：</p>

<ol>
  <li>将所有Broker（假设共n个Broker）和待分配的Partition排序</li>
  <li>将第i个Partition分配到第（i mod n）个Broker上</li>
  <li>将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上</li>
</ol>

<p>Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR(in-sync replica)中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW(high watermark)并且向Producer发送ACK。HW会从leader持续发送到follower并被保存到每个broker的磁盘中。</p>

<p>对于Producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks来设置。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。</p>

<p>Consumer读消息也是从Leader读取，只有被commit过的消息（offset低于HW的消息）才会暴露给Consumer。</p>

<h3 id="leader-election">Leader Election</h3>

<p>Kafka在ZooKeeper中动态维护了一个ISR（in-sync replicas），这个ISR里的所有Replica都跟上了leader，只有ISR里的成员才有被选为Leader的可能。在这种模式下，对于f+1个Replica，一个Partition能在保证不丢失已经commit的消息的前提下容忍f个Replica的失败。对比Majority Vote则需要2f+1个Replica。</p>

<p>Kafka中，如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除，包括两种情况：长时间未向leader发送fetch request，消息lag超过阈值。
为了防止ISR里面的慢节点，Producer选择是否被commit阻塞。</p>

<p>选举时候，Kafka会在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。这种方式改善每个follower都使用zk watch的方法进行选举的问题：</p>

<ul>
  <li>brain split</li>
  <li>herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整</li>
  <li>ZooKeeper负载过重 </li>
</ul>

<h2 id="kafka-">Kafka 网络模型</h2>

<p>Kafka使用的网络模型是典型的reactor模式，一个acceptor处理新来的连接请求，分配给N个processor处理，每个processor都有selector从socket中读取数据，生成request对象放到requestChannel中。requestChannel包含一个requestQueue和一个responseQueues，requestQueue是一个blocking queue，它的大小为<code>queued.max.requests</code>；responseQueues 包含N个blocking queue，对应每个processor。Kafka会有M个Handler threads用于处理responseQueues中的request，并且生成response放到对应的response队列中，处理过程如下：KafkaRequestHandler循环从RequestChannel中取Request并交给kafka.server.KafkaApis处理具体的业务逻辑。。</p>

<p>这里面涉及的数目在配置文件中都有体现，上述的每个acceptor包括processor在Kafka中称为NIO socket server，数量在<code>listeners</code>中定义，例如<code>PLAINTEXT://myhost:9092, SSL://:9091 </code>。N 取值 <code>background.threads</code>，M 取值 <code>num.io.threads</code>。</p>

<p>在 NIO socket server 中会给每个processor的responseQueue都注册一个ResponseListener，一旦有Response产生就会通知对应的processor发送Response到客户端。</p>

<h2 id="kafka-clients-operations">Kafka Clients’ Operations</h2>

<p>这一章节介绍一个Kafka client对于Kafka Resources可能的操作类型。</p>

<p>Operation包括以下几种：Read, Write, Create, Delete, Alter, Describe, ClusterAction。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-4-12/80246194.jpg" width="450px" /></p>

<p><a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-4+-+Command+line+and+centralized+administrative+operations">KIP-4</a></p>

<h3 id="createdelete">Create/Delete</h3>

<p>Create/Delete就是创建和删除Topics。</p>

<p>具体过程如下：</p>

<ol>
  <li>broker发送<code>TopicMetadataRequest</code>到controller。</li>
  <li>Controller在ZooKeeper的/brokers/topics节点上注册Watch，一旦某个Topic被创建或删除，则Controller会通过Watch得到新创建/删除的Topic的Partition/Replica分配。</li>
  <li>对于删除Topic操作，Topic工具会将该Topic名字存于/admin/delete_topics。若delete.topic.enable为true，则Controller注册在/admin/delete_topics上的Watch被fire，Controller通过回调向对应的Broker发送StopReplicaRequest，若为false则Controller不会在/admin/delete_topics上注册Watch，也就不会对该事件作出反应。</li>
  <li>对于创建Topic操作，Controller从/brokers/ids读取当前所有可用的Broker列表，对于set_p中的每一个Partition：
    <ul>
      <li>从分配给该Partition的所有Replica（称为AR）中任选一个可用的Broker作为新的Leader，并将AR设置为新的ISR（因为该Topic是新创建的，所以AR中所有的Replica都没有数据，可认为它们都是同步的，也即都在ISR中，任意一个Replica都可作为Leader）</li>
      <li>将新的Leader和ISR写入/brokers/topics/[topic]/partitions/[partition]</li>
    </ul>
  </li>
  <li>直接通过RPC向相关的Broker发送LeaderAndISRRequest。</li>
</ol>

<p>创建Topic顺序图如下所示。</p>

<p><img src="http://cdn4.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-3/zh/resources/0606003.png" width="500px" /></p>

<p>有两点说明：</p>

<ul>
  <li>对于<code>auto.create.topics.enable=false</code>的Kafka，如果对未存在的topic进行produce，则会导致producer <code>org.apache.kafka.common.errors.TimeoutException</code>错误。</li>
  <li>除了使用broker进行创建Topic，还可以通过Kafka的AdminUtils直接指定zk、topic、partitions，replicationFactor，把相关信息写入zk来创建Topic。</li>
</ul>

<h3 id="alterdescribe">Alter/Describe</h3>

<p>alter/describe 是对配置修改或查看的操作，包括Topic和Client两个部分。改变方法也是通过Kafka的AdminUtils和ConfigCommand，指定zk、topic或要修改的properties。</p>

<h3 id="clusteraction">ClusterAction</h3>

<p>包括LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，ControlledShutdownRequest</p>

<h3 id="read">Read</h3>

<p>consumer 订阅Topic数据。consumer根据consumer group的分配算法如下</p>

<pre><code>rebalance process for consumer C_i in group G
For each topic T that C_i subscribes to {
 remove partitions owned by C_i from the ownership registry
 read the broker and the consumer registries from Zookeeper
 compute P_T = partitions available in all brokers under topic T
 compute C_T = all consumers in G that subscribe to topic T
 sort P_T and C_T
 let j be the index position of C_i in C_T and let N = |P_T|/|C_T|
 assign partitions from j*N to (j+1)*N - 1 in P_T to consumer C_i
 for each assigned partition p {
 set the owner of p to C_i in the ownership registry
 let O_p = the offset of partition p stored in the offset registry
 invoke a thread to pull data in partition p from offset O_p
 }
}
</code></pre>

<p>当订阅topic的时候，kafka会注册一个ConsumerRebalanceListener，当发生以下任何一个事件的时候，会引发上述的rebalance算法：</p>

<ul>
  <li>Number of partitions change for any of the subscribed list of topics</li>
  <li>Topic is created or deleted</li>
  <li>An existing member of the consumer group dies</li>
  <li>A new member is added to an existing consumer group via the join API</li>
</ul>

<p>Kafka的Consumer API可以透明地处理上述情况，另外还包括server的fail，partition的聚合。</p>

<p>读取数据发生在<code>poll</code>函数中，每次调用时，consumer都会使用上次消费的offset作为这次的起始offset，并且顺序的读取记录。当然上次消费的offset也可以由<code>seek</code>函数直接指定。</p>

<p>读取数据在Kafka内部是一个FetchRequest，处理的过程为
* authorize
* FetchResponse
* recordAndMaybeThrottle(quota控制)</p>

<h3 id="write">Write</h3>

<p>producer 发布数据的动作。produce的api接口可以选择同步或异步，默认情况下<code>send</code>接口是异步的，它将数据放到缓冲区后就立即返回，等到数据到达一定带下后再发送出去，节约IO开销。可以直接在send()后调用get()，这样可以达到同步的效果。另外一个重要的参数是acks，用来设置produce 请求完成的标准，也就是数据要写到几个broker中才算是完成。</p>

<p>发布数据在Kafka内部是一个ProducerRequest，处理过程为：</p>

<ul>
  <li>authorize</li>
  <li>produceResponse</li>
  <li>recordAndMaybeThrottle(quota控制)</li>
</ul>

<h3 id="partition-and-key">Partition and Key</h3>

<p>这里说下partition和key的关系。注意到，在kafka的api中会有一个key的概念，而实际上kafka只是一个消息的订阅和发布系统，和key应该扯不上一点关系，那么这个key有什么用呢，不用key会有什么影响。</p>

<p>看下没有指定key或者key为null的时候kafka是怎么处理的。首先kafka会随机选择一个partition，然后在一个默认的时间（10min）内所有的数据都会写到这个partition内。这会造成数据不均衡的分布在各个partition中。这时可以通过减少metadata refresh interval 缩短这个默认时间来减轻数据不均衡的现象。</p>

<p>不过更实际的还是指定一个key，因为kafka默认的是使用hashing-based partitioner，可能还会造成数据不均衡。这时候就需要使用自定义的partition，并指定<code>partitioner.class</code>。</p>

<h2 id="authorize">Authorize</h2>

<h3 id="authorizer">Authorizer接口</h3>

<p>Kafka带有Authorizer接口，这个是所有实现授权的插件都必须要实现的接口。启动的时候会读<code>authorizer.class</code>配置，<code>authorizer.class</code>就是实现授权的具体类。</p>

<p>Kafka的授权逻辑是<code>Principal P is [Allowed/Denied] Operation O From Host H On Resource R</code>，P是用户，O是上文提到的各种Operation，Host就是client地址，R是Kafka资源，包括cluster、topic、consumer-group。</p>

<p>Kafka本身自带一个<code>SimpleAclAuthorizer</code>，用它来实现一些简单资源的访问，例如</p>

<blockquote>
  <p>Principals User:Bob and User:Alice are allowed to perform Operation Read and Write on Topic Test-Topic from IP 198.51.100.0 and IP 198.51.100.1</p>
</blockquote>

<h3 id="ranger">Ranger</h3>

<p>Ranger的Kafka plugin也是实现了Authorizer接口。Ranger的实现机制简单的介绍下，Ranger整体分为Admin和Plugin：</p>

<ol>
  <li>Ranger Plugin运行在服务进程内，在Kafka中，Ranger plugin代码就运行在broker内。</li>
  <li>Policy通过Ranger Admin存储在database中，plugin轮询地向admin请求最新的policy；policy存储在本地的一个文件中。</li>
  <li>在service请求到来的时候，ranger plugin中的policy engine会evaluate request，判断是否合法。</li>
</ol>

<p>Ranger的policy engine分为role based和tag based，kafka中使用的是tag based，evaluae的流程图如下：</p>

<p><img src="https://cwiki.apache.org/confluence/download/attachments/61322361/Ranger-Policy-Evaluation-Flow-with-Tags.png?version=2&amp;modificationDate=1444869949000&amp;api=v2" width="600px" /></p>

<p>Ranger Kafka 目前支持的功能还是比较少的，如下图：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-4-12/11458053.jpg" width="600px" /></p>

<p>这些功能在Kafka自带的<code>SimpleAclAuthorizer</code>都是可以实现的。</p>

<h2 id="saslkerberos-and-ssl-implementation">Sasl/Kerberos and SSL implementation</h2>

<p>sasl 是broker的认证机制，ssl是数据传输的加密和认证机制。从协议的角度来说，kafka支持以下四种：</p>

<ul>
  <li>
    <p>PLAINTEXT (non-authenticated, non-encrypted)</p>

    <p>This channel will provide exact behavior for communication channels as previous releases</p>
  </li>
  <li>
    <p>SSL</p>

    <p>SSL  implementation. Authenticated principal in the session will be from the certificate presented or the peer host. </p>
  </li>
  <li>
    <p>SASL+PLAINTEXT</p>

    <p>SASL authentication will be used over plaintext channel. Once the sasl authentication established between client and server . Session will have client’s principal as authenticated user. There won’t be any wire encryption in this case as all the channel communication will be over plain text .</p>
  </li>
  <li>
    <p>SASL+SSL</p>

    <p>SSL will be established initially and  SASL authentication will be done over SSL. Once SASL authentication is established users principal will be used as authenticated user .  This option is useful if users want to use SASL authentication ( for example kerberos ) with wire encryption.</p>
  </li>
</ul>

<p>实现SSL需要做如下配置：</p>

<ol>
  <li>Generate SSL key and certificate for each Kafka broker
    <ul>
      <li>Ensure that common name (CN) matches exactly with the fully qualified domain name (FQDN) of the server. The client compares the CN with the DNS domain name to ensure that it is indeed connecting to the desired server, not the malicious one.</li>
    </ul>
  </li>
  <li>Creating your own CA</li>
  <li>Signing the certificate</li>
  <li>Configuring Kafka Brokers</li>
  <li>Configuring Kafka Clients
    <ul>
      <li>需要将生成的<code>kafka.client.truststore.jks</code>拷贝到client</li>
      <li>如果进行双向认证则还需要生成和配置<code>kafka.client.keystore.jks</code></li>
    </ul>
  </li>
</ol>

<p>实现SASL需要：</p>

<ol>
  <li>Kerberos
    <ul>
      <li>客户端需要安装 kerberos client</li>
    </ul>
  </li>
  <li>Create Kerberos Principals
    <ul>
      <li>需要对应的用户principal</li>
    </ul>
  </li>
  <li>Make sure all hosts can be reachable using hostnames</li>
</ol>

<p>具体过程参考<a href="http://kafka.apache.org/documentation.html#security">http://kafka.apache.org/documentation.html#security</a></p>

<p><strong>zookeeper安全性</strong></p>

<ol>
  <li>不开通ibgw（端口），bcc无法直接访问</li>
  <li>zookeeper限制ip段，</li>
  <li>增加zookeeper authentication</li>
</ol>

<p>对每个resource都应该能够实现管理和控制。</p>

<h2 id="references">REFERENCES:</h2>

<p><a href="https://cwiki.apache.org/confluence/display/RANGER/Kafka+Plugin">https://cwiki.apache.org/confluence/display/RANGER/Kafka+Plugin</a></p>

<p><a href="https://kafka.apache.org/090/configuration.html">https://kafka.apache.org/090/configuration.html</a></p>

<p><a href="https://kafka.apache.org/090/ops.html">https://kafka.apache.org/090/ops.html</a></p>

<p><a href="https://kafka.apache.org/090/security.html">https://kafka.apache.org/090/security.html</a></p>

<p><a href="http://kafka.apache.org/documentation.html">http://kafka.apache.org/documentation.html</a></p>

<p><a href="http://people.csail.mit.edu/matei/courses/2015/6.S897/readings/kafka.pdf">Kafka: A distributed messaging system for log processing</a></p>

</div>
  
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-19T14:00:00+08:00" pubdate data-updated="true">Mar 19<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/03/19/table-join/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/03/19/table-join/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/03/19/table-join/">Table Join Semantics</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>这篇文章主要是记录下各种不同 <code>join</code> 的语义。</p>

<p>在最高层面上，<code>join</code> 分为三种：</p>

<ul>
  <li>INNER</li>
  <li>OUTER</li>
  <li>CROSS</li>
</ul>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/03/19/table-join/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-19T14:00:00+08:00" pubdate data-updated="true">Mar 19<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/03/19/hmm/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/03/19/hmm/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/03/19/hmm/">Hidden Markov Model</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程（Markov process）。HMM 被用来对有序的序列数据建模，例如句子中的单词，基因中的基本序列，所以常被应用在语音识别、信息提取、基因测序、股票预测等领域。</p>

<p>在 HMM 中，马尔可夫过程是一类随机过程，原始模型是马尔可夫链。它包含一个状态的有限集，状态的变化只依赖于上一个时间点，而与再之前的时间无任何关系，且状态的轮换是有一定的概率发生。所以可以把马尔可夫过程当成是一个有限状态自动机的概率变种。PageRank 其实也是一种马尔可夫过程。</p>

<p>但是在 HMM 中，状态是未知的，这就是 hidden 的由来，我们只能看到观察值，也就是由状态产生的结果。下图是一个 HMM 的例子。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/24496294.jpg" width="300px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/03/19/hmm/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-16T14:00:00+08:00" pubdate data-updated="true">Mar 16<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/03/16/rs-note/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/03/16/rs-note/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/03/16/rs-note/">Practice in Recommend System</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>本文作为推荐系统实践笔记。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/11336234.jpg" width="350px" /></p>

<p>推荐系统是为了解决信息过载问题，一般说来这个问题还可以用搜索引擎解决，但是搜索引擎需要需要用户主动提供准确的关键词来寻找信息；推荐系统不需要用户提供明确的需求,而是通过分析用户的历史行为给用户的兴趣建模,从而主动给用户推荐能够满足他们兴趣和需求的信息。</p>

<p>总的来说，<strong>搜索引擎满足了用户有明确目的时的主动查找需求,而推荐系统能够在用户没有明确目的的时候帮助他们发现感兴趣的新内容</strong>。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/03/16/rs-note/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-06T14:00:00+08:00" pubdate data-updated="true">Mar 6<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/03/06/apriori/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/03/06/apriori/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/03/06/apriori/">Apriori and FP-Growth</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>如果说监督学习的形式化表达是 $Pr(Y \vert X)$, 找到最佳的参数最小化每个 $x$ 的epxected error： $argmin_{\theta}\ E_{Y \vert X} L(Y, \theta)$。那么非监督学习的形式化表达就是 $Pr(X)$，目标是在没有 $Y$ 引导的情况下，推测出 $Pr(X)$ 的潜在属性。本文要提到的apriori算法也是一种非监督学习算法，wiki的定义为</p>

<blockquote>
  <p>The Apriori Algorithm is an influential algorithm for mining frequent itemsets for boolean association rules.</p>
</blockquote>

<p>著名的啤酒和尿布例子就是指这个算法。它是属于关联分析中的一种，也就是从大规模数据集中寻找物品间的隐含关系。</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/03/06/apriori/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-03-05T14:00:00+08:00" pubdate data-updated="true">Mar 5<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/03/05/em/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/03/05/em/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/03/05/em/">Expectation Maximization</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>Expectation Maximization, EM算法在参数估计里面有极大的用处，它用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率（MAP）估计。隐变量的概率模型参数的极大似然估计可以理解为，使用的方法还是的极大似然估计，但是要处理隐变量。极大后验概率是一种Beyesian Inference，其实就是把极大似然估计中的参数赋予权值，这个权值是预先定义好的先验概率。可以来看下下表中Frequentist-Bayesian对峙的部分，来感受下EM算法的应用范围：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/88568881.jpg" width="500px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/03/05/em/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-02-29T14:00:00+08:00" pubdate data-updated="true">Feb 29<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/02/29/klr-svr/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/02/29/klr-svr/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/02/29/klr-svr/">Kernel Logistic Regression Versus SVM</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>Logistic Regression和SVM都是分类方法，它们定义线性决策边界（linear decision boundaries）作为划分的依据。但二者在motivation方便完全不同，区别如下</p>

<ul>
  <li>LR初衷是为了让linear regression能够输出二元分类，估计一个实例属于某一类的概率；线性决策边界也只是回归函数的结果，在回归函数中使用阈值作为分类的标准，一般是0.5。决策边界在SVM中来的更为重要，整个模型的目标就是为了获得最优的决策边界。</li>
  <li>每个训练样本都对LR的过程有一定的影响，但SVM只依赖于在决策边界附近的某些点。</li>
  <li>LR适应于低维空间，并且由于使用最大似然估计，所以对噪声不敏感；SVM更适应于高维空间</li>
  <li>没有正规化的LR无法保证获得最好的分离超平面，只能获得margin附近的较高的置信度; SVM则能获得最优的分离超平面。</li>
</ul>

<p>那么二者会有什么联系呢，SVM的kernel function又是如何应用到LR模型的呢？</p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/02/29/klr-svr/">Read on &rarr;</a>
    </footer>
  


        </article>
      
      
        <article class="post">
          
  <header class="page-header">
    
      <p class="meta text-muted text-uppercase">
        












<span class="glyphicon glyphicon-calendar"></span> <time datetime="2016-02-27T14:00:00+08:00" pubdate data-updated="true">Feb 27<span>th</span>, 2016</time>
        
           | <a href="/blog/2016/02/27/svm/#disqus_thread"
             data-disqus-identifier="http://billowkiller.github.io/blog/2016/02/27/svm/">Comments</a>
        
      </p>
    
    
      <h1 class="entry-title"><a href="/blog/2016/02/27/svm/">Support Vector Machine</a></h1>
    
  </header>


  <div class="entry-content clearfix"><p>支持向量机(support vector machine, SVM)是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可以形式化为凸二次规划问题的求解，也等价于正则化的合页损失函数的最小化问题。SVM还包括kernel trick，使得它可以成为实质上的非线性分类器。下面就介绍Perceptron到三种类型的SVM模型。</p>

<p><img src="http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/figs/svm2.PNG" width="400px" /></p>

</div>
  
  
    <footer>
      <a class="btn btn-default" rel="full-article" href="/blog/2016/02/27/svm/">Read on &rarr;</a>
    </footer>
  


        </article>
      
    </div>

    <ul class="pager">
      
        <li class="previous"><a href="/blog/page/2/">&larr;&nbsp;Older</a></li>
      
      <li><a href="/blog/archives">Blog Archives</a></li>
      
        <li class="next disabled"><a href="#">Newer&nbsp;&rarr;</a></li>
      
    </ul>
  </div>

  
    <aside class="sidebar col-md-3">
      
        <section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Recent Posts</h3>
  </div>
  
  <div id="recent_posts" class="list-group">
    
    <a class="list-group-item " href="/blog/2016/04/09/rating/">Funny Facts About Rating</a>
    
    <a class="list-group-item " href="/blog/2016/04/09/recsys-introduction/">Recommender System in a Nutshell</a>
    
    <a class="list-group-item " href="/blog/2016/04/06/kafka/">Kafka Introduction</a>
    
    <a class="list-group-item " href="/blog/2016/03/19/table-join/">Table Join Semantics</a>
    
    <a class="list-group-item " href="/blog/2016/03/19/hmm/">Hidden Markov Model</a>
    
  </div>
</section>
<section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">Categories</h3>
  </div>
  <div class="list-group">
    
    
    <a class="list-group-item " href="/blog/categories/language/index.html">
        <span class="badge">8</span>
        language
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/tools/index.html">
        <span class="badge">10</span>
        tools
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/book/index.html">
        <span class="badge">8</span>
        book
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/google/index.html">
        <span class="badge">4</span>
        google
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/linux/index.html">
        <span class="badge">14</span>
        linux
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/rework/index.html">
        <span class="badge">14</span>
        rework
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/film/index.html">
        <span class="badge">3</span>
        film
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/algorithm/index.html">
        <span class="badge">7</span>
        algorithm
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/machine-learning/index.html">
        <span class="badge">13</span>
        Machine Learning
      </a>
    
    
    <a class="list-group-item " href="/blog/categories/big-data/index.html">
        <span class="badge">8</span>
        Big Data
      </a>
    
  </div>
</section>
<section class="panel panel-default clearfix">
  <div class="panel-heading">
      <h3 class="panel-title">GitHub Repos</h3>
  </div>
  
    <div class="gh-profile-link pull-right text-muted">
      <a href="https://github.com/billowkiller">@billowkiller</a> on GitHub
    </div>
  
  <script src="/javascripts/github.js" type="text/javascript"> </script>
</section>


<section class="panel panel-default">
  <div class="panel-heading">
    <h3 class="panel-title">On Delicious</h3>
  </div>
  <div class="panel-body">
    <div id="delicious"></div>
    <script type="text/javascript" src="http://feeds.delicious.com/v2/json/billowkiller?count=3&amp;sort=date&amp;callback=renderDeliciousLinks"></script>
    <p><a href="http://delicious.com/billowkiller">My Delicious Bookmarks &raquo;</a></p>
  </div>
</section>


      
    </aside>
  
</div>

        </div>
      </div>
    </div>
    <footer role="contentinfo"><div class="container">
    <p class="text-muted credits">
  Copyright &copy; 2016 - wutao<br>
  <small>
      <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>,
      <span class="credit">customized with <a href="https://github.com/kAworu/octostrap3">octostrap3</a></span>.
  </small>
</p>

</div>
</footer>
    <script src="/javascripts/libs/bootstrap-3.0.0/dist/js/bootstrap.min.js"></script>
<script src="/javascripts/modernizr-2.0.js"></script>


<script type="text/javascript">
      var disqus_shortname = 'billowkiller';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = ('https:' == document.location.protocol ? 'https://' : 'http://') + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>







  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = '//platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





  </body>
</html>
