<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Billowkiller's Blog]]></title>
  <link href="http://billowkiller.github.io/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2014-07-28T00:04:06+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Summary of TCP/IP ILLustrated Volume 1]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/18/+TCP-IP/"/>
    <updated>2014-07-18T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/18/ TCP-IP</id>
    <content type="html"><![CDATA[<p>Modified from several blogs. Sorry for failing to detailed list.</p>

<hr />

<p>要快速学习一本书，最简单的途径是在网上找一些靠谱的读书笔记、总结之类的博文，然后细细研读，再根据重要的或者未详尽描述的知识点在书中阅读。根据这样的学习方法，总结了《TCP/IP详解 卷1：协议》这本书。</p>

<p>介绍是以图为驱动的，接下来就开始吧。</p>

<h2 id="tcpip">tcp/ip协议簇</h2>

<p><img src="http://dl.iteye.com/upload/attachment/598180/ebd73be4-de65-38cc-adde-514a3d486844.jpg" alt="" /></p>

<!--more-->

<p>上图左侧是数据包在各个网络层的状态，右侧是数据包在各个网络层的传递。其中，以太网口通过以太网地址来决定丢弃还是交付通过以太网口的数据包（此时称为以太网帧）；以太网驱动程序通过检验和来决定将其丢弃还是交付给上一层；接着，驱动程序通过以太网首部中的“类型”字段对以太网帧进行分用，确定这 是一个ip数据报，还是一个ARP/RARP请求/应答；如果是后者，则通过协议进行应答；如果是ip数据报，则脱去帧头帧尾，将其交付到Ip层。IP层 首先进行检验和计算以决定交付还是丢弃报文，然后通过ip首部中的“协议”字段确定其是UDP数据报、TCP段还是ICMP、IGMP报文，从而对IP数 据报进行分用。如果是ICMP或IGMP，则根据协议对其进行处理，如果是TCP或UDP，则去其头部，将其交付到运输层；TCP/UDP则是通过端口号将数据分用到对该端口进行监听的应用程序。</p>

<h2 id="section">链路层</h2>

<h3 id="section-1">以太网帧</h3>

<p><img src="http://dl.iteye.com/upload/attachment/598848/99c6503e-20d5-34f3-976f-8c1fc239d179.jpg" alt="" /></p>

<p>上图是以太网帧的封装格式。其中的“类型”字段正是用于IP数据报、ARP报文和RARP报文的分用。可以看到，每个以太网帧有最小长度和最大长度，最小长度为64字节，是为了检测冲突；最大长度是1518，最大传输单元MTU为1500字节。</p>

<h3 id="arp--rarp">ARP &amp; RARP</h3>

<p>当一台主机把以太网数据帧发送到位于同一局域网上的另一台主机时，是根据48bit以太网地址来确定目的接口的。设备驱动程序从不检查IP数据报中的目的IP地址。</p>

<p><strong>ARP</strong>（地址解析协议）是设备<strong>通过自己知道的IP地址来获得自己不知道的物理地址</strong>的协议。假如一个设备不知道它自己的IP地址，但是知道自己的物理地址，网络上的无盘工作站就是这种情况，设备知道的只是网络接口卡上的物理地址。这种情况下应该怎么办呢？RARP（逆地址解析协议）正是针对这种情况的一种协议。
RARP以与ARP相反的方式工作。<strong>RARP发出要反向解析的物理地址并希望返回其对应的IP地址</strong>，应答包括由能够提供所需信息的RARP服务器发出的IP地址。虽然发送方发出的是广播信息，RARP规定只有RARP服务器能产生应答。许多网络指定多个RARP服务器，这样做既是为了平衡负载也是为了作为出现问题时的备份。</p>

<p>ARP高效运行的关键是由于每个主机上都有一个ARP高速缓存，这个高速缓存存放了最近IP地址到硬件地址之间的映射记 录。高速缓存中的每一项的生存时间为20分钟，开始时间从被创建时开始算起。可以使用<code>arp -a</code>来检查ARP高速缓存。下图为ARP的分组格式。</p>

<p><img src="http://dl.iteye.com/upload/attachment/599192/e13ec54f-0994-358e-9772-fcfb934e2741.jpg" alt="" /></p>

<ul>
  <li>对于arp请求，其以太网帧首部中的<strong>硬件地址为全1</strong>，<strong>代表广播</strong>，请求主机向它所在的网络广播一份arp请求。</li>
  <li>ARP请求从一个网络发往另一个网络，连接2个网络的路由可以回答该请求，这个过程叫做委托ARP或<strong>代理ARP</strong>。</li>
  <li>arp请求还有另外一个特性叫<strong>免费arp</strong>，它是指主机发送arp查找自己的ip地址。
    <ul>
      <li>一个主机可以通过它来确定另一个主机是否设置了相同的ip地址。检测<strong>网络存在ip冲突</strong>。</li>
      <li>如果发送免费arp的主机正好改变了硬件地址，那么这个分组就可以使其他主机高速缓存中旧的硬件地址进行相应的更新。</li>
    </ul>
  </li>
</ul>

<h2 id="section-2">网络层</h2>

<h3 id="ip">IP协议</h3>

<p><strong>IP提供不可靠、无连接的数据报传送服务</strong>。<strong>不可靠是指它不能保证IP数据报能成功地到达目的地</strong>，如果发生某种错误时（如路由器暂时用完了缓冲 区），IP有一个简单的处理算法：丢弃该数据报，然后发送ICMP消息给信源端。<strong>无连接的意思是，IP数据报不维护任务关于后续数据报的状态信息</strong>，每个数据报的处理是相互独立的。首先看一下IP数据报的格式：</p>

<p><img src="http://dl.iteye.com/upload/attachment/598868/830a6b5c-cf71-39e2-bd0f-6b5bfa25e2ab.jpg" alt="" /></p>

<p>特地说明下检验和是怎么产生的。TCP和IP协议中都有校验和字段。IP协议根据IP首部计算的检验和码，它不对首部后面的数据进行计算。为了计算一份数据报的IP检验和，首先把检验和字段置为0，然后对首部中每16bit进行二进制反码求和。而TCP、UDP协议的检验和需要对数据进行计算，并且要伪造一个IP头，包括IP地址、报文长度等数据。</p>

<p>IP协议的协议字段包含了被IP包封装了的协议，这个逆过程称为分用。包括TCP、UDP、ICMP及IGMP等。</p>

<h3 id="ip-1">IP路由选择</h3>

<p>路由器与主机的本质区别在于，主机从不把数据报从一个接口转发到另一个接口，而路由器则要转发数据。IP可以从TCP、 UDP、ICMP、IGMP接口数据报（即本地待发送的数据），也可以从一个网络接口接收数据报。IP层在内存中有一个路由表，当收到一份数据报并进行发 送时，它都要对该表搜索一次。当数据报来自某个网络接口时，IP首先检查目的目的IP地址是否为本机的IP地址之一或者IP广播地址。如果确实是这样，数 据报就被送到由IP首部协议字段所指定的协议模块进行处理。如果数据报的目的不是这些地址，那么（1）主机将丢弃报文；（2）路由器对数据报进行转发。</p>

<p>路由表中的每一项包括：(通过<code>netstat -rn</code>可以查到该路由表）</p>

<ol>
  <li>目的IP地址，它既可以是一个完整的主机地址，也可以是一个网络地址，主机地址有一个非0的主机号，以指定某一特定的主机，而网络地址中的主机号为0，以指定网络中的主机。</li>
  <li>下一跳路由器的ip地址，或者有直接连接的网络IP地址。</li>
  <li>标志。其中一个标志指明目的IP地址是网络地址还是主机地址，另一个标志指明下一站路由是路由器还是一个直接相连的接口。总共有五种不同的标 志：U（该路由可用）、G（该路由是到一个网关）、H（该路由是到一个主机）、D（该路由是由重写向报文创建的）、M（该路由已被重定向报文修改）。</li>
</ol>

<p>IP路由选择主要完成以下这些功能：</p>

<ol>
  <li>搜索路由表，寻找能与目的IP地址完全匹配的表目，如果找到，就把报文发往该地址；</li>
  <li>搜索路由表，寻找能与目的网络号相匹配的表目，如果找到，则把报文发送给该表目指定的下一站路由器直接连接的网络接口；</li>
  <li>搜索路由表，寻找标为“默认”的表目，如果找到，把报文发送给该表目指定的下一站路由器。</li>
</ol>

<p>如果上面这些步骤都没有成功，那么该数据报就不能被发送。如果不能传送的数据报来自本机，那么一般会向生成数据报的应用程序返回一个“主机不可达”或“网络不可达”的错误。</p>

<p>下图描述了IP层处理过程的简单流程：</p>

<p><img src="http://dl.iteye.com/upload/attachment/599650/5ba5f055-2428-35fa-8791-c03dae480fce.jpg" alt="" /></p>

<p>系统通过三种途径改变路由表的表项，一个是<strong>route命令</strong>，由管理员手动配置路由，一个是<strong>ICMP重定向报文</strong>，这是一种只能由路由器生成的ICMP差错报文，最后一个则是<strong>路由守护程序</strong>，路由守护程序是一个应用程序，它通过发送ICMP路由器请求报文，接收ICMP路由器通告报文来获知相邻的网络情况。</p>

<h3 id="icmp">ICMP</h3>

<p>ICMP是Internet控制报文协议，用于查询和传输出错报告控制信息。</p>

<p>其中<strong>ICMP查询报文</strong>包括：</p>

<ul>
  <li>回显应答/请求， <strong>ping程序使用的报文</strong></li>
  <li>路由器通告/请求，用于IP选路（另一种是RIP路由选择信息协议）</li>
  <li>时间戳请求/应答，允许系统向另一个系统查询当前的时间</li>
  <li>子网掩码请求/应答， 用于无盘系统在引导过程中获取自己的子网掩码</li>
</ul>

<p><strong>ICMP差错报文</strong>：</p>

<ul>
  <li>不可达报文</li>
  <li>超时报文</li>
  <li>重定向差错报文，修改路由表</li>
  <li>源站抑制差错，系统接收数据报的速度大于数据处理的数据</li>
</ul>

<p><strong>ICMP超时+ICMP端口不可达+TTL是traceroute程序的工作原理。</strong>traceroute程序发送一份TTL字段为1的IP数据报文 给目的主机，处理这份数据报的第一个路由器将其TTL值减1，丢弃该数据报，并发回一份ICMP超时报文，通过报文中的信源地址我们将得到该路由器的地 址；接着，traceroute发送一份TTL值为2的IP数据报文给目的主机，这样，第二个路由器将发回一份ICMP超时报文，….，直到最后该报 文到达目的主机并被接收，那么如何判断报文已经到达目的主机了呢？traceroute将选择一个不可能的值作为目的端口号（大于30000），使目的主 机的任何一个应用程序都不可能使用该端口，这样，目的主机收到该报文时，将产生一份“ICMP端口不可达”报文给，这样，当traceroute收到的 ICMP报文是“目的端口不可达”时，可以判断已经完成了整个traceroute的过程。记得IP首部中的“选项”部分还可以设置“严格的源站选路”和 “宽松的源站选路”选项，可以在traceroute发送的IP数据报首部中加入该选项，来规划traceroute的路径。</p>

<h3 id="section-3">互联网的地址、广播、多播</h3>

<p><img src="http://dl.iteye.com/upload/attachment/599740/8fca4629-889a-3533-9abe-bd3915fdbb6f.jpg" alt="" /></p>

<ul>
  <li>A类   0.0.0.0 – 127.255.255.255</li>
  <li>B类 <strong>128</strong>.0.0.0 – 191.255.255.255</li>
  <li>C类 <strong>192</strong>.0.0.0 – 223.255.255.255</li>
  <li>D类 <strong>224</strong>.0.0.0 – 239.255.255.255</li>
  <li>E类 <strong>240</strong>.0.0.0 – 247.255.255.255</li>
</ul>

<p>有三类地址：<strong>单播地址，多播地址和广播地址</strong>。主机号为全0代表网络号，主机号为全1代表在该网络的广播。有<strong>四种广播地址</strong>：</p>

<ol>
  <li>受限的广播地址255.255.255.255.该地址用于主机配置过程中IP数据报的目的地址，在任何情况下，路由器都不转发目的地址为受限的广播地址的数据报，这样数据报仅出现在地址网络中。</li>
  <li>指向网络的广播地址，主机号为全1.如A类广播地址为netid.255.255.255，一个路由器必须转发指向网络的广播。</li>
  <li>指向子网的广播。指向子网的广播地址为主机号为全1且有特定子网号的地址。作为子网直接广播地址的IP地址需要了解子网的掩码，例如，如果路由 器收到发往128.1.2.255的数据报，当B类网络128.1的子网掩码为255.255.255.0时，该地址就是指向子网的广播地址；但如果该子 网的掩码为255.255.254.0，该地址就不是指向子网的广播地址。</li>
  <li>指向所有子网的广播。指向所有子网的广播也需要了解目的网络的子网掩码，以便与指向网络的广播地址区分开来，指向所有子网的广播地址的子网号和 主机号全为1.例如，如果目的子网掩码为255.255.255.0，那么IP地址128.1.255.255就是一个指向所有子网的广播地址，然而，如 果网络没有划分子网，这就是一个指向网络的广播。</li>
</ol>

<p>广播给网络中的主机产生了很多负担，<strong>广播的数据报要直到UDP层才被确定是否为主机所需要</strong>（没有监听的端口）然后才会被丢弃。多播是介于单播与广播之间的一种方式。</p>

<p>能够接收发往一个特定多播组地址数据的主机集合称为主机组。一个主机组可以跨越多个网络，主机组中成员可以随时加入或离开主机组。主机组中对主机的数量没有限制，同时不属于某一主机组的主机可以向该组发送信息。
下图是多播组地址到以太网地址的转换：</p>

<p><img src="http://dl.iteye.com/upload/attachment/599747/65577750-0fa4-3a4c-addd-dcdf7b62e2f9.jpg" alt="" /></p>

<h3 id="igmp">IGMP协议</h3>

<p>Internet组管理协议（IGMP）是因特网协议家族中的一个<strong>组播协议</strong>，用于 IP主机向任一个直接相邻的路由器报告他们的组成员情况。它规定了处于不同网段的主机如何进行多播通信，其前提条件是路由器本身要支持多播。</p>

<p>它用来在IP主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。IGMP不包括组播路由器之间的组成员关系信息的传播与维护，这部分工作由各组播路由协议完成。</p>

<p>参与IP组播的主机可以在任意位置、任意时间、成员总数不受限制地加入或退出组播组。组播路由器不需要也不可能保存所有主机的成员关系，它只是通过IGMP协议了解每个接口连接的网段上是否存在某个组播组的接收者，即组成员。而主机方只需要保存自己加入了哪些组播组。多播路由器并不关心有多少主机属于一个多播组，它只是想知道给定接口上的多播组是否还有人对这个多播组感兴趣。</p>

<h3 id="section-4">选路协议</h3>

<p>当相邻的路由器之间进行通信，以告知对方每个路由器当前所连接的网络，这时就出现了动态选路。路由器之间必须采用选路协议进行通信，这样的协议有很 多种，如RIP、OSPF，路由守护进程运行选路协议，并与其相邻的一些路由器进行通信。路由守护程序将选路策略加入到系统中，选择路由并加入到内核的路 由表中。如果守护程序发现前往同一信宿存在多条路由，那么它将（以某种方法）选择最佳路由并加入内核路由表中。如果路由守护程序发现一条链路已经断开，它 可以删除受影响的路由或加入另一条路由以绕过该问题。</p>

<p>在像Internet这样的系统中，目前采用了许多不同的选路协议。Internet是以一组自治系统的方式组织的，每个自治系统通常由单个实体管 理。常常将一个公司或大学校园定义为一个自治系统。每个自治系统可以选择该自治系统中各个路由器之间的选路协议，这种协议称之为内部网关协议（IGP）， 常用的IGP有RIP和OSPF。不同自治系统的路由器之间进行通信协议称为外部网关协议（BGP）。</p>

<h2 id="section-5">传输层</h2>

<p>终于到了传输层，先来个开胃菜UDP，再介绍TCP。</p>

<h3 id="udp-">UDP 用户数据报协议</h3>
<p>下图是UDP首部的格式：</p>

<p><img src="http://dl.iteye.com/upload/attachment/599727/3174ddc1-a81b-36ea-ac8e-a72a8418188d.jpg" alt="" /></p>

<p>当UDP数据报的长度超过网络的MTU时，必须对其进行分片。如果设置 了DF位但是通过某个网络时需要分片，将会产生ICMP“不可达（需要分片）”的差错报文。</p>

<p>分片需要注意的是：(1)在分片时，除最后一片外，其他每一 片中的数据部分（除IP首部外的其余部分）必须是8整数倍；(2)运输层首部只出现在第一片 中。UDP比较简陋，所有包丢失、重传问题都必须由上层应用程序来管理。</p>

<h3 id="tcp-">TCP 传输控制协议</h3>

<p>TCP提供面向连接的，可靠的字节流服务， 它设计了各种机制以实现丢包、重发、乱序、链路传输错误等传输过程中可能出现的错误。</p>

<p><strong>1. TCP报文格式</strong></p>

<p><img src="http://dl.iteye.com/upload/attachment/599787/eccadd8c-6160-3bda-837c-704c0d09c0b0.jpg" alt="" /></p>

<p>其中6个标志比特，它们中的多个可以被同时设置为1：</p>

<ul>
  <li>URG：紧急指针有效，与后面的紧急指针结合起来</li>
  <li>ACK：确认序号有效</li>
  <li>PSH：接收方尽快将这个报文段交给应用层</li>
  <li>RST：重建连接</li>
  <li>SYN：同步序号用来发起一个连接</li>
  <li>FIN：发端完成发送任务，将要关闭连接</li>
</ul>

<p>其他字段有：</p>

<ul>
  <li>窗口大小表明接收端当前的接收能力，以字节为单位，16位窗口限制了最大值为65535字节，在选项字段中，有一个窗口刻度选项，允许这个值按比例放大。</li>
  <li>紧急指针是一个正的偏移量，和序号中的值相加表示紧急指针最后一个字节的序号。</li>
  <li>选项字段可以包括最长报文大小（MSS），这是最常见的可选字段。每个连接方通常都在通信的第一个报文段中指明这个选项，表明本端所能接收的最大长度的报文段；还有窗口扩大选项以及时间戳选项。</li>
</ul>

<p><strong>2. 连接与终止</strong></p>

<p><img src="http://dl.iteye.com/upload/attachment/599805/5991ccb8-afaa-3670-9f00-4da6f24a38ea.jpg" alt="" /></p>

<p>tcp连接的其中一方发起主动连接，它填写目的端口和源端口号，初始化序列号，设置SYN位，并设置了mss选项，将该TCP段发给连接的另一方。 另一方收到tcp段后，与主动连接方做了同样的事情，同时携带ACK，把对主动连接方的初始序号加1填入确认序列号字段，发送给主动连接方。主动连接方向 被动连接方发去一个ack，连接由此建立。</p>

<p>图中还演示了连接关闭的过程，终止一个连接需要四次握手。任何一方在最后的发送数据段中设置FIN位来终止这个方向的连接。当一端收到一个FIN， 它必须通知应用层另一端已经终止了那个方向的数据传输，也就是说，不再会有数据从那个方向传来，但它仍然能够发送数据，收到FIN方回复一个ack。</p>

<p>由图我们还可以看到，SYN和FIN各占用了一个序号。</p>

<p>图中的端口A、B还让我们想起一个问题，如果不存在用户进程在监听端口B（即端口B没有打开）时，主机A将会收到什么呢？在UDP中，发送端将收到 一份ICMP端口不可达报文，那么在TCP连接中呢？TCP使用复位，即在回应发送端的TCP段中设置了RST位，携带ack主动发送端的确认序列号，自 己的序列号为0.发送端收到这样的tcp段后，即知道连接被拒绝了。</p>

<p>那如果主机B根本就不存在呢？这时主机A将过一段时间再发送一个SYN到主机B请求连接，一般建立一个连接的最长时间限制为75秒。</p>

<p>如果一方已经关闭或导演终止而另一方却不知道，我们将这样的TCP连接称为半打开的。比方说在主机A（客户端）上运行telnet程序，通过它和主 机B（服务器）连接，由于突然停电，主机A没有向主机B的telnet端口发送FIN消息，结果主机B就以为与主机A的连接还在。主机A重新启动后再次与 主机B连接将会启动新的服务器程序，这样将会导致主机B上产生很多半打开的TCP连接。如果是服务器主机B突然当掉了，而客户端A并不知道，它继续向主机 B发送数据，假如主机B很快恢复了，然而先前的所有连接信息都丢失了，收到来自主机A的消息时，它回复以RST消息（相当于没有端口在监听）。</p>

<p>TCP支持同时打开或同时关系，不过同时打开将经历4次握手。</p>

<p><img src="http://blog.chinaunix.net/photo/91603_100713212857.jpg" alt="同时打开" /></p>

<p><img src="http://blog.chinaunix.net/photo/91603_100713213550.jpg" alt="同时关闭" /></p>

<p><strong>3. TCP的状态变迁</strong></p>

<p><img src="http://blog.chinaunix.net/photo/91603_100707001221.jpg" alt="" /></p>

<p>状态图中比较重要的一点就是，主动关闭方在收到对方的对自己FIN的ACK以及对方的FIN后，进入一个状态叫<code>TIME_WAIT</code>，这种状态也称为<code>2MSL</code> 等待状态。每个TCP实现必须选择一个报文段最大生存时间MSL(Maximum Segment Lifetime)，它是任何报文段被丢弃前在网络内的最长时间。对于一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在<code>TIME_WAIT</code>状态停留的时间为2倍的MSL，以防这个ACK丢失的时候，可以重发一个ACK（对应另一端收不到ACK重发最后的FIN消息）。这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和端口号，服务的IP地址和端口号）不能再被使用，这个连接只能在2MSL结束后才能被使用。</p>

<p><img src="http://blog.chinaunix.net/photo/91603_100708211823.jpg" alt="" /></p>

<p><strong>4. 呼叫连接请求队列</strong></p>

<p>TCP处理呼入连接请求规则:</p>

<ol>
  <li>正等待连接的一端有一个固定长度的连接队列，该队列中的连接已经完成3次握手，但还没有被应用层接收。</li>
  <li>
    <p>应用层指定这个连接队列的最大长度，这个值通常叫做积压值(backlog)。取值范围为0至5的整数。</p>

    <p>不同环境下，backlog的含义与实现都将不同：</p>

    <blockquote>
      <p>The behaviour of the backlog parameter on TCP sockets changed with Linux 2.2. Now it specifies the queue length for completely established sockets waiting to be accepted， instead of the number of incomplete connection requests. The maximum length of the queue for incomplete sockets can be set using the tcp_max_syn_backlog sysctl. When syncookies are enabled there is no logical maximum length and this sysctl setting is ignored.</p>
    </blockquote>
  </li>
  <li>当一个请求连接到达(SYN)，TCP根据连接队列中的连接数确认是否接收这个连接。但这时的最大排队连接数并不等于积压值。</li>
  <li>如果连接队列中的连接数少于最大排队的连接数，TCP将确认建立连接。在客户端主动连接成功而服务端应用层还没接收这个连接时，客户端发送的数据将保存在服务端的TCP缓存队列。</li>
  <li>如果连接队列没有空间，TCP将丢弃收到的SYN请求，不发回任何报文(包括RST)。客户端将超时重传SYN请求，等待连接队列有空间。</li>
</ol>

<p>TCP服务器无法使客户端的主动打开失效。因为服务器接收到请求时，TCP的三次握手已经完成。所以对于限定远程IP地址的服务器，必须在客户端三次握手建立连接后才能判断是否合法。</p>

<p><strong>5. TCP的数据流</strong></p>

<p>建立完连接后，两台主机开始进行数据的传输。传输的数据可以分成两种，一种是<strong>交互式数据的传输</strong>，如通过telnet发送指令；一种是<strong>大量数据的传输</strong>，如通过ftp传输文件。TCP显然需要同时能够处理这两种类型的数据，但使用的算法有所不同。</p>

<p><img src="http://blog.chinaunix.net/photo/91603_100717121935.jpg" alt="交互式输入" /></p>

<p>上图为没有优化的字符输入回显的数据传输过程。一共需要四个报文段。</p>

<p>上图第二，三个报文段可以合并—按键确认和按键回显一起发送。这种技术叫做<strong>经受时延的确认</strong>。
通常TCP在接收到数据时并不立即发送ACK，将以不大于TCP定时器的延时等待是否有数据一起发送，有时也称这种现象为<strong>数据捎带ACK</strong>。</p>

<p>ACK延时等待时间不大于TCP定时器的原因：
假如TCP使用200ms的定时器，该定时器将相对于内核引导的200ms固定时间溢出，由于将要确定的数据随机到达，TCP将在下一次内核的200ms定时器溢出时得到通知，所以ACK实际等待的时间为1~200ms中任一刻。</p>

<p><strong>Nagle算法</strong>要求TCP连接上最多只有一个未被确认的未完成小分组，在该分组确认到达之前不能发送其他的小分组。且同时TCP收集这些小分组，在确认到达后以一个大的分组发出去。
该算法可以减少网络上的微小分组，降低拥塞出现的可能。但相应的，也会增加更多的时延。流程:</p>

<ol>
  <li>发送端TCP将从应用进程接收到的第一数据块立即发送，不管其大小，哪怕只有一个字节。</li>
  <li>发送端输出第一块数据后开始收集数据，并等待确认。</li>
  <li>确认未达到时，若收集数据达到窗口的一半或一个MSS段，立即发送。</li>
  <li>确认到达后，把缓冲区中的数据组成一个TCP段，然后发送。</li>
</ol>

<p>对于成块的数据流，TCP更应该关注的是流量的控制。发送端有发送缓冲区（即从应用程序到tcp），接收端有接收缓冲区，并不是接收到的数据马上就能被应用程序处理，如果发送端不断地发送数据，而接收端的缓冲区已经被占满，它必须通知发送端在缓冲区有空隙前，请不要再发送数据了。在TCP中，缓冲区被形象地比喻成一个可以滑动的窗口，TCP通过一些算法来根据窗口的大小发送数据，<strong>滑动窗口协议</strong>。这是端到端的。还有另外一种情况，就是，当发送方和接收方之间存在多个路由器和速率较慢的链路时，就有可能出现一些问题，一些中间路由器必须缓冲分区，并有可能耗存储器的空间。因此，连接建立时，双方应该慢慢了解去往对方的路况，然后以一个比较合适的速率大小发送块数据。TCP支持一种被称为“<strong>慢启动</strong>”的算法，该算法通过观察到新分组进入网速的速率应该与另一端返回确认的速 率相同而进行工作。慢启动为发送方的TCP增加了另一个窗口：<strong>拥塞窗口</strong>，当与另一个网络建立TCP连接时，拥塞窗口被初始化为1个报文段（即另一端通告的 报文段大小）。每收到一个ack，拥塞窗口就增加一个报文段，发送方取拥塞窗口与通告窗口中的最小值作为发送上限。拥塞窗口是发送方使用的流量控制，而通告窗口是接收方使用的流量控制。</p>

<p><strong>PUSH标志：</strong>如果待发送数据会清空发送缓冲区，该包将自动设置PUSH标志。</p>

<ol>
  <li>发送方将发送缓冲区的数据立即发送给接收方。</li>
  <li>接收方将接收缓冲区的数据立即提交给接收进程。</li>
</ol>

<p><strong>6. TCP的超时与重传</strong></p>

<p><img src="http://blog.chinaunix.net/photo/91603_100803210729.jpg" alt="" /></p>

<ul>
  <li>RTT(往返时间)：指发送端发送TCP报文段开始到接收到对方的确定所使用的时间。</li>
  <li>RTO(超时重传时间)：发送端发送TCP报文段后，在RTO时间内没有收到对方确定，即重传该报文段。</li>
</ul>

<p><strong>拥塞避免算法</strong></p>

<p>拥塞避免算法和慢启动算法通常一起使用。维持两个变量：拥塞窗口( cwnd )  慢启动门限( ssthresh )。</p>

<ol>
  <li>对一个给定的连接，初始化cwnd为1个报文段， ssthresh为65535个字节.</li>
  <li>TCP输出例程的输出不能超过cwnd和接收方通告窗口的大小.拥塞避免是发送方使用的流量控制，而通告窗口则是接收方进行的流量控制.前者是发送方感受到的网络拥塞的估计，后者则与接收方在该连接上的可用缓存大小有关.</li>
  <li>当拥塞发生时(超时或收到重复确认)，ssthresh被设置为当前窗口大小的一半(cwnd和接收方通告窗口大小的最小值，但最少为2个报文段).此外，如果是超时引起了拥塞，则cwnd被设置为1个报文段（这就是慢启动).</li>
  <li>当新的数据被对方确认时，就增加cwnd，但增加的方法依赖于我们是否正在进行慢启动或拥塞避免.如果cwnd &lt;= ssthresh，则正在进行慢启动，否则正在进行拥塞避免.</li>
</ol>

<p><strong>cwnd增加方式</strong></p>

<ul>
  <li>慢启动初始cwnd为1，每收到一个确定就加1.成指数增长.</li>
  <li>拥塞避免算法在每个RTT内增加 1/cwnd 个报文，成线性增长.</li>
  <li>慢启动根据收到的ACK次数增加cwnd，而拥塞避免算法在一个RTT不管收有多少ACK也只增加一次.</li>
</ul>

<p><strong>快速重传和快速恢复算法</strong></p>

<p>如果收到3个重复ACK，可认为该报文段已经丢失，此时无需等待超时定时器溢出，直接重传丢失的包，这就叫快速重传算法.而接下来执行的不是慢启动而是拥塞避免算法，这就叫快速恢复算法.</p>

<ol>
  <li>当收到第3个重复的ACK时，将ssthresh设置为当前拥塞窗口cwnd的一半.重传丢失的报文段，设置cwnd为ssthresh加上3倍的报文段大小.</li>
  <li>每次收到另一个重复的ACK时，cwnd增加1个报文段大小并发送1个分组(如果新的cwnd允许发送).</li>
  <li>当下一个确认新数据的ACK到达时，设置cwnd为ssthresh(在第1步中设置的值).这个ACK应该是在进行重传后的一个往返时间内对步骤1中重传的确认.另外，这个ACK也应该是对丢失的分组和收到的第1个重复的ACK之间的所有中间报文段的确认.这一步采用的是拥塞避免，因为当分组丢失时我们将当前的速率减半.</li>
</ol>

<p><strong>7. TCP的四个定时器</strong></p>

<p>对每个连接，TCP管理4个不同的定时器：</p>

<ol>
  <li>
    <p><strong>重传定时器</strong>，用于等待另一端的确认。</p>

    <p>当发送端发送出数据后，经过一段时间后假如仍然没有收到接收端的确认，那么就重传该数据块</p>
  </li>
  <li>
    <p><strong>坚持定时器</strong>，使窗口大小信息保持不断流动，即使另一端关闭了其接收窗口</p>

    <p>当接收方的窗口大小为0时，发送方将不能再向它发送数据，直到 接收方用一个窗口大小为非0的消息来通告发送端。可是，万一这个消息丢失了呢？接收方就一直这样等着发送方发来数据，而发送端就一直等着接收方发来窗口大于0的消息，两方就都僵在那里了。为了避免这种情况的出现，便有了坚持定时器，发送方使用一个坚持定时器来周期性地向接收方查询，以便发现窗口是否已增大。坚持定时器的定时时间也是指数退避的。</p>

    <p><strong>糊涂窗口综合症</strong>是指接收方一旦有非0的窗口大小就向发送方通告，从而引起发送端发送少量的数据这样的情况。可以在任何一方采取措施避免出现这种状况：</p>

    <ol>
      <li>在接收方，接收方不通告小窗口，一般是除非窗口可以增加一个报文段大小或可以增加接收方缓冲区空间的一半，不然通告窗口大小为0.</li>
      <li>在发送方，发送方除非收到一个比较大的窗口（如一个报文段小大、是接收方通告窗口大小一半的报文段）或者是还没有未被确认的数据的情况下，才会发送数据。</li>
    </ol>

    <p>接收方和发送方两方同时进行决策，因为接收方不能通告一个不合理的窗口大小（比方说，原先的窗口大小是1500，报文段长度为1024，发送方发送 了1024字节的数据后，这时候接收方的窗口大小是476，小于一个报文大小，但是如果通告窗口大小为0，岂不是很不合理？），因此在收到这个的窗口通告消息后，就轮到发送方使用它的策略了，发送方设定一个坚持定时器，在这个定时器的时间内，除非收到足够大的通告窗口，否则不发送数据。当然，如果定时器超时了，发送方还是要发送小数据量的报文的。</p>
  </li>
  <li>
    <p><strong>保活定时器</strong>，检测到一个空闲连接的另一端何时崩溃或重启。</p>

    <p>前面我们提到“半打开”的连接，这种情况很可能占用服务器很多端口，因此一般由服务器使用保活选项。如果一个给定的连接在两个小 时之内没有任何动作，则服务器就向客户发送一个探查报文段，客户主机将必须以下四种状态之一：</p>

    <ol>
      <li>客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常工作的。服务器在两个小时后将保活定时器复位。如果在两个小时定时器到时间之前有应用程序的通信量通过此连接，则定时器在交换数据后的未来2个小时再复位。</li>
      <li>客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应，服务器将不能收到对探查的响应，并在75秒后超时。服务器总共发送10个探查，每个间隔75称。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。</li>
      <li>客户主机崩溃并且已经重新启动。这时服务器将收到一个对其保活探查的响应，但是这个响应是一个复位，使得服务器终止这个连接。</li>
      <li>客户主机正常运行，但是从服务器不可达。这跟情况B是一样的。</li>
    </ol>
  </li>
  <li>
    <p><strong>2MSL的时间测量器</strong></p>
  </li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some NB Translations]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/17/Some-NB-translation/"/>
    <updated>2014-07-17T20:07:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/17/Some-NB-translation</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="http://blog.csdn.net/eroswang/article/details/1787456">Unix编程常见问题解答</a></li>
  <li><a href="http://blog.csdn.net/eroswang/article/details/1790351">从程序员角度看ELF</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux thundering herd]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/17/thundering-herd/"/>
    <updated>2014-07-17T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/17/thundering-herd</id>
    <content type="html"><![CDATA[<p><em>modified from <a href="http://blog.csdn.net/russell_tao/article/details/7204260">http://blog.csdn.net/russell_tao/article/details/7204260</a></em></p>

<hr />

<h2 id="section">惊群现象</h2>

<p>什么是“惊群”？简单说来，多线程/多进程（linux下线程进程也没多大区别）等待同一个socket事件，当这个事件发生时，这些线程/进程被同时唤醒，就是惊群。可以想见，效率很低下，许多进程被内核重新调度唤醒，同时去响应这一个事件，当然只有一个进程能处理事件成功，其他的进程在处理该事件失败后重新休眠（也有其他选择）。这种性能浪费现象就是惊群。</p>

<p>惊群通常发生在server 上，当父进程绑定一个端口监听socket，然后fork出多个子进程，子进程们开始循环处理（比如accept）这个socket。每当用户发起一个TCP连接时，多个子进程同时被唤醒，然后其中一个子进程accept新连接成功，余者皆失败，重新休眠。</p>

<p>那么，我们不能只用一个进程去accept新连接么？然后通过消息队列等同步方式使其他子进程处理这些新建的连接，这样惊群不就避免了？没错，惊群是避免了，但是效率低下，因为这个进程只能用来accept连接。对多核机器来说，仅有一个进程去accept，这也是程序员在自己创造accept瓶颈。所以，我仍然坚持需要多进程处理accept事件。</p>

<h2 id="linux">linux解决的惊群</h2>

<p>其实，在linux2.6内核上，<strong>accept系统调用已经不存在惊群了</strong>（至少我在2.6.18内核版本上已经不存在）。大家可以写个简单的程序试下，在父进程中bind,listen，然后fork出子进程，所有的子进程都accept这个监听句柄。这样，当新连接过来时，大家会发现，仅有一个子进程返回新建的连接，其他子进程继续休眠在accept调用上，没有被唤醒。</p>

<p>对于一些已知的惊群问题，内核开发者增加了一个“<strong>互斥等待</strong>”选项。一个互斥等待的行为与睡眠基本类似，主要的不同点在于：</p>

<ul>
  <li>当一个等待队列入口有 WQ_FLAG_EXCLUSEVE 标志置位, 它被添加到等待队列的尾部. 没有这个标志的入口项, 相反, 添加到开始.</li>
  <li>当 wake_up 被在一个等待队列上调用时, 它在唤醒第一个有 WQ_FLAG_EXCLUSIVE 标志的进程后停止。也就是说，对于互斥等待的行为，比如如对一个listen后的socket描述符，多线程阻塞accept时，系统内核只会唤醒所有正在等待此时间的队列的第一个，队列中的其他人则继续等待下一次事件的发生，这样就避免的多个线程同时监听同一个socket描述符时的惊群问题。</li>
</ul>

<h2 id="nginx">nginx解决惊群</h2>

<p>但是很不幸，通常我们的程序没那么简单，不会愿意阻塞在accept调用上，我们还有许多其他网络读写事件要处理，linux下我们爱用epoll解决非阻塞socket。所以，即使accept调用没有惊群了，我们也还得处理惊群这事，因为epoll有这问题。上面说的测试程序，如果我们在子进程内不是阻塞调用accept，而是用<code>epoll_wait</code>，就会发现，新连接过来时，多个子进程都会在<code>epoll_wait</code>后被唤醒！</p>

<p>nginx就是这样，master进程监听端口号（例如80），所有的nginx worker进程开始用<code>epoll_wait</code>来处理新事件（linux下），如果不加任何保护，一个新连接来临时，会有多个worker进程在<code>epoll_wait</code>后被唤醒，然后发现自己accept失败。</p>

<p>nginx在同一时刻只允许一个nginx worker在自己的epoll中处理监听句柄。它的负载均衡也很简单，当达到最大connection的7/8时，本worker不会去试图拿accept锁，也不会去处理新连接，这样其他nginx worker进程就更有机会去处理监听句柄，建立新连接了。而且，由于timeout的设定，使得没有拿到锁的worker进程，去拿锁的频繁更高。</p>

<h2 id="nginx-1">nginx的锁</h2>

<p>在用户空间进程间锁实现的原理很简单，就是能弄一个让所有进程共享的东西，比如mmap的内存，比如文件，然后通过这个东西来控制进程的互斥。</p>

<p>nginx的实现分为两种情况：</p>

<ul>
  <li>一种是支持原子操作的情况，也就是由mmap的内存区域来进行控制的</li>
  <li>一种是不支持原子操作，这是是使用文件锁来实现。 </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux reentrant function]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/15/linux-reentrant-function/"/>
    <updated>2014-07-15T06:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/15/linux-reentrant-function</id>
    <content type="html"><![CDATA[<p>这种情况出现在多任务系统当中，在任务执行期间捕捉到信号并对其进行处理时，进程正在执行的指令序列就被信号处理程序临时中断。如果从信号处理程序返回，则继续执行进程断点处的正常指令序列，从重新恢复到断点重新执行的过程中，函数所依赖的环境没有发生改变，就说这个函数是可重入的，反之就是不可重入的。简单来说，<strong>可重入函数可以被中断的函数</strong>。</p>

<p>在进程中断期间，系统会保存和恢复进程的上下文，然而恢复的上下文仅限于返回地址，cpu寄存器等之类的少量上下文，而函数内部使用的诸如全局或静态变量，buffer等并不在保护之列，所以如果这些值在函数被中断期间发生了改变，那么当函数回到断点继续执行时，其结果就不可预料了。打个比方，比如<code>malloc</code>，将如一个进程此时正在执行<code>malloc</code>分配堆空间，此时程序捕捉到信号发生中断，执行信号处理程序中恰好也有一个<code>malloc</code>，这样就会对进程的环境造成破坏，因为malloc通常为它所分配的存储区维护一个链接表，插入执行信号处理函数时，进程可能正在对这张表进行操作，而信号处理函数的调用刚好覆盖了进程的操作，造成错误。</p>

<p><strong>基本上下面的函数是不可重入的：</strong></p>

<ul>
  <li>函数体内使用了静态的数据结构；</li>
  <li>函数体内调用了malloc()或者free()函数；</li>
  <li>函数体内调用了标准I/O函数。</li>
  <li>进行了浮点运算。许多的处理器/编译器中，浮点一般都是不可重入的 （浮点运算大多使用协处理器或者软件模拟来实现）。</li>
</ul>

<p><strong>两种情况需要考虑：</strong></p>

<ol>
  <li>信号处理程序A内外都调用了同一个不可重入函数B；B在执行期间被信号打断，进入A (A中调用了B),完事之后返回B被中断点继续执行，这时B函数的环境可能改变，其结果就不可预料了。</li>
  <li>多线程共享进程内部的资源，如果两个线程A，B调用同一个不可重入函数F，A线程进入F后，线程调度，切换到B，B也执行了F，那么当再次切换到线程A时，其调用F的结果也是不可预料的。</li>
</ol>

<p><strong>在信号处理程序中即使调用可重入函数也有问题要注意</strong>。作为一个通用的规则，当在信号处理程序中调用可重入函数时，应当在其前保存<code>errno</code>，并在其后恢复<code>errno</code>。（<strong>因为每个线程只有一个errno变量，信号处理函数可能会修改其值，要了解经常被捕捉到的信号是SIGCHLD，其信号处理程序通常要调用一种wait函数，而各种wait函数都能改变errno。</strong>）</p>

<p>如果一个函数对多个线程来说是可重入的，则说这个函数是<strong>线程安全的</strong>。但这并不能说明对信号处理程序来说该函数也是可重入的。如果函数对异步信号处理程序的重入是安全的，那么就可以说函数式<strong>异步-信号安全的</strong>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux epoll module]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/15/linux-epoll-module/"/>
    <updated>2014-07-15T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/15/linux-epoll-module</id>
    <content type="html"><![CDATA[<p>综合了几个blog以及自己查到的一些资料，总结下Linux中的IO多路复用，主要是<code>epoll</code>模型。</p>

<p><code>select</code>，<code>poll</code>，<code>epoll</code>都是Linux下IO多路复用的机制。Windows下为<code>IOCP</code>模型。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个文件描述符就绪，能够通知程序进行相应的读写操作。其中文件描述符是一个简单的整数，用以标明每一个被进程所打开的文件和socket，包括<code>filefd</code>、<code>socketfd</code>、<code>signalfd</code>、<code>timerfd</code>、<code>eventfd</code>等。<code>eventfd</code> 是一个比 <code>pipe </code>更高效的线程间事件通知机制。</p>

<p>但<code>select</code>，<code>poll</code>，<code>epoll</code>本质上都是<strong>同步I/O</strong>，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而<strong>异步I/O</strong>则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</p>

<!--more-->

<h2 id="select">select实现</h2>

<p><img src="http://www.ibm.com/developerworks/cn/linux/l-async/figure4.gif" alt="" /></p>

<p><strong><code>select</code>的几大缺点：</strong></p>

<ul>
  <li>
    <u>每次调用`select`，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大</u>
  </li>
  <li>
    <u>同时每次调用`select`都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大</u>
  </li>
  <li>
    <u>`select`支持的文件描述符数量太小了，默认是`1024`</u>
  </li>
</ul>

<h2 id="poll">poll实现</h2>

<p><code>poll</code>的实现和<code>select</code>非常相似，只是描述fd集合的方式不同，poll使用<code>pollfd</code>结构而不是select的<code>fd_set</code>结构，其他的都差不多。</p>

<h2 id="epoll">epoll</h2>

<p><code>epoll</code>是对<code>select</code>和<code>poll</code>的改进，能避免上述的三个缺点。我们先看一下<code>epoll</code>和<code>select</code>和<code>poll</code>的调用接口上的不同，<code>select</code>和<code>poll</code>都只提供了一个函数——<code>select</code>或者<code>poll</code>函数。而<code>epoll</code>提供了三个函数：</p>

<ul>
  <li><code>epoll_create</code>，创建一个epoll句柄；</li>
  <li><code>epoll_ctl</code>，注册要监听的事件类型；</li>
  <li><code>epoll_wait</code>，等待事件的产生。</li>
</ul>

<p>对于第一个缺点，<code>epoll</code>的解决方案在<code>epoll_ctl</code>函数中。每次注册新的事件到<code>epoll</code>句柄中时（在<code>epoll_ctl</code>中指定<code>EPOLL_CTL_ADD</code>），会把所有的fd拷贝进内核，而不是在<code>epoll_wait</code>的时候重复拷贝。<code>epoll</code>保证了每个fd在整个过程中只会拷贝一次。</p>

<p>对于第二个缺点，<code>epoll</code>的解决方案不像<code>select</code>或<code>poll</code>一样每次都把current轮流加入fd对应的设备等待队列中，而只在<code>epoll_ctl</code>时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。<code>epoll_wait</code>的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用<code>schedule_timeout()</code>实现睡一会，判断一会的效果，和<code>select</code>实现中的是类似的）。</p>

<p>对于第三个缺点，<code>epoll</code>没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以<code>cat /proc/sys/fs/file-max</code>察看,一般来说这个数目和系统内存关系很大。</p>

<h3 id="section">触发模型</h3>

<h4 id="eagain">1. EAGAIN</h4>

<p>先说下<code>EAGIN</code>这个返回值。</p>

<p>在一个非阻塞的socket上调用read/write函数, 返回<code>EAGAIN</code>或者<code>EWOULDBLOCK</code>(注: EAGAIN就是EWOULDBLOCK)。从字面上看, 意思是:EAGAIN: 再试一次，EWOULDBLOCK: 如果这是一个阻塞socket, 操作将被block，perror输出: Resource temporarily unavailable</p>

<p><strong>总结:</strong></p>

<p>这个错误表示资源暂时不够，能read时，读缓冲区没有数据，或者write时，写缓冲区满了。遇到这种情况，如果是阻塞socket，read/write就要阻塞掉。而如果是非阻塞socket，read/write立即返回-1， 同时<code>errno</code>设置为<code>EAGAIN</code>。</p>

<p>所以，<strong>对于阻塞socket，read/write返回-1代表网络出错了。但对于非阻塞socket，read/write返回-1不一定网络真的出错了。可能是Resource temporarily unavailable。这时你应该再试，直到Resource available。</strong></p>

<h4 id="lt--et">2. LT &amp; ET</h4>

<p><code>epoll</code>除了提供<code>select\poll</code>那种IO事件的<strong>电平触发(Level Triggered)</strong>外，还提供了<strong>边沿触发(Edge Triggered)</strong>，这就使得用户空间程序有可能缓存IO状态，减少<code>epoll_wait/epoll_pwait</code>的调用，提供应用程序的效率。</p>

<ul>
  <li>
    <p><strong>LT(level triggered)：</strong>水平触发，缺省方式，同时支持block和no-block socket，在这种做法中，内核告诉我们一个文件描述符是否被就绪了，如果就绪了，你就可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错的可能性较小。传统的<code>select\poll</code>都是这种模型的代表。</p>
  </li>
  <li>
    <p><strong>ET(edge-triggered)：</strong>边沿触发，高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪状态时，内核通过<code>epoll</code>告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如：你在发送、接受或者接受请求，或者发送接受的数据少于一定量时导致了一个EWOULDBLOCK错误)。但是请注意，如果一直不对这个fs做IO操作(从而导致它再次变成未就绪状态)，内核不会发送更多的通知。</p>
  </li>
</ul>

<p><strong>区别：</strong>LT事件不会丢弃，而是只要读buffer里面有数据可以让用户读取，则不断的通知你。而ET则只在事件发生之时通知。</p>

<p><strong>ET方式注意事项：</strong> 必须使用<strong>非阻塞套接口</strong>，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。最好以下面的方式调用ET模式的epoll接口：</p>

<ul>
  <li>基于非阻塞文件句柄</li>
  <li>
    <p>只有当read(2)或者write(2)返回<strong>EAGAIN</strong>时才需要挂起，等待。但这并不是说每次read()时都需要循环读，直到读到产生一个EAGAIN才认为此次事件处理完成，<strong>当read()返回的读到的数据长度小于请求的数据长度时，就可以确定此时缓冲中已没有数据了</strong>，也就可以认为此事读事件已处理完成。</p>

    <pre><code>  while(rs)
  {
    buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0);
    if(buflen &lt; 0)
    {
      // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读
      // 在这里就当作是该次事件已处理处.
      if(errno == EAGAIN)
       break;
      else
       return;
     }
     else if(buflen == 0)
     {
       // 这里表示对端的socket已正常关闭.
     }
     if(buflen == sizeof(buf)
       rs = 1;   // 需要再次读取
     else
       rs = 0;
  }
</code></pre>
  </li>
</ul>

<p><strong>还有，假如发送端流量大于接收端的流量(意思是epoll所在的程序读比转发的socket要快),由于是非阻塞的socket,那么<code>send()</code>函数虽然返回,但实际缓冲区的数据并未真正发给接收端,这样不断的读和发，当缓冲区满后会产生<code>EAGAIN</code>错误(参考<code>man send</code>),同时,不理会这次请求发送的数据.所以,需要封装<code>socket_send()</code>的函数用来处理这种情况,该函数会尽量将数据写完再返回，返回-1表示出错。在<code>socket_send()</code>内部,当写缓冲已满(<code>send()</code>返回-1,且<code>errno</code>为<code>EAGAIN</code>),那么会等待后再重试.这种方式并不很完美,在理论上可能会长时间的阻塞在<code>socket_send()</code>内部,但暂没有更好的办法.</strong></p>

<h4 id="accept">3. 正确的accept</h4>

<p>正确的accept，accept 要考虑 2 个问题</p>

<ol>
  <li>
    <p>阻塞模式 accept 存在的问题</p>

    <p>考虑这种情况：TCP连接被客户端夭折，即在服务器调用accept之前，客户端主动发送RST终止连接，导致刚刚建立的连接从就绪队列中移出，如果套接口被设置成阻塞模式，服务器就会一直阻塞在accept调用上，直到其他某个客户建立一个新的连接为止。但是在此期间，服务器单纯地阻塞在accept调用上，就绪队列中的其他描述符都得不到处理。</p>

    <p><strong>解决办法</strong>是把监听套接口设置为非阻塞，当客户在服务器调用accept之前中止某个连接时，accept调用可以立即返回-1，这时源自Berkeley的实现会在内核中处理该事件，并不会将该事件通知给epool，而其他实现把errno设置为ECONNABORTED或者EPROTO错误，我们应该忽略这两个错误。</p>
  </li>
  <li>
    <p>ET模式下accept存在的问题</p>

    <p>考虑这种情况：多个连接同时到达，服务器的TCP就绪队列瞬间积累多个就绪连接，由于是边缘触发模式，epoll只会通知一次，accept只处理一个连接，导致TCP就绪队列中剩下的连接都得不到处理。</p>

    <p><strong>解决办法</strong>是用while循环抱住accept调用，处理完TCP就绪队列中的所有连接后再退出循环。如何知道是否处理完就绪队列中的所有连接呢？accept返回-1并且errno设置为EAGAIN就表示所有连接都处理完。</p>
  </li>
</ol>

<p>综合以上两种情况，服务器应该使用非阻塞地accept，accept在ET模式下的正确使用方式为：</p>

<pre><code>while ((conn_sock = accept(listenfd,(struct sockaddr *) &amp;remote, (size_t *)&amp;addrlen)) &gt; 0) {
    handle_client(conn_sock);
}
if (conn_sock == -1) {
    if (errno != EAGAIN &amp;&amp; errno != ECONNABORTED &amp;&amp; errno != EPROTO &amp;&amp; errno != EINTR)
    perror("accept");
}
</code></pre>

<h2 id="section-1">总结</h2>
<p><strong>epoll高效的两个原因：</strong></p>

<ul>
  <li><code>epoll</code>会复用文件描述符集合来传递结果而不是迫使开发者每次等待事件之前都必须重新准备要被侦听的文件描述符集合，</li>
  <li>另一个原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ string copy-on-write]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/12/c%2B%2B-string-copy-on-write/"/>
    <updated>2014-07-12T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/12/c++-string-copy-on-write</id>
    <content type="html"><![CDATA[<p>不同版本的C++ string实现时不同的，sizeof(string)得出来的结果也不尽相同，其中有种实现采用copy-on-write的方式来共享内存。</p>

<p>引用计数就是string类中写时才拷贝的原理！当第一个类构造时，string的构造函数会根据 传入的参数从堆上分配内存，当有其它类需要这块内存时，这个计数为自动累加，当有类析构时，这个计数会减一，直到最后一个类析构时，此时的RefCnt为1或是0，此时，程序才会真正的Free这块从堆上分配的内存。</p>

<p>string类的内存是在堆上动态分配的，共享内存的各个类指向的是同一个内存区。这块内存区域还包括引用计数，其位于字符串内存区域的上方，通过<code>_Ptr[-1]</code>来访问。这样所有共享这块内存的类都可以访问到引用计数，也就知道这块内存的引用者有多少了。</p>

<p>于是，有了这样一个机制，每当我们为string分配内存时，我们总是要多分配一个空间用来存放这个引用计数的值，只要发生拷贝构造可是赋值时，这个内存的值就会加一。而在内容修改时，string类为查看这个引用计数是否为0，如果不为零，表示有人在共享这块内存，那么自己需要先做一份拷贝，然后把引用计数减去一，再把数据拷贝过来。</p>

<!--more-->
<p>具体做法如下：</p>

<pre><code>//构造函数（分存内存）
string::string(const char* tmp)
{
	_Len = strlen(tmp);
	_Ptr = new char[_Len+1+1];
	strcpy( _Ptr, tmp );
	_Ptr[-1]=0;  // 设置引用计数  
}

//拷贝构造（共享内存）
string::string(const string&amp; str)
{
	if (*this != str){
	this-&gt;_Ptr = str.c_str();   //共享内存
	this-&gt;_Len = str.szie();
	this-&gt;_Ptr[-1] ++;  //引用计数加一
}

//写时才拷贝Copy-On-Write
char&amp; string::operator[](unsigned int idx)
{
	if (idx &gt; _Len || _Ptr == 0 ) {
		static char nullchar = 0;
		return nullchar;
	}

	_Ptr[-1]--;   //引用计数减一
	char* tmp = new char[_Len+1+1];
	strncpy( tmp, _Ptr, _Len+1);
	_Ptr = tmp;
	_Ptr[-1]=0; // 设置新的共享内存的引用计数
	
	return _Ptr[idx];
}


//析构函数的一些处理
~string()
{ 
	_Ptr[_Len+1]--;   //引用计数减一
	// 引用计数为0时，释放内存
	if (_Ptr[_Len+1]==0) {
		delete[] _Ptr;
	}
}
</code></pre>

<p>但这样的方式也会造成一些麻烦。容易造成内存访问异常。
<strong>两个例子：</strong></p>

<h3 id="section">动态库</h3>
<p>动态链接库中有一个函数返回string类：</p>

<pre><code>string GetIPAddress(string hostname)
{
	static string ip;
	……
	return ip;
}
</code></pre>

<p>主程序中动态地载入这个动态链接库，并调用其中的这个函数：</p>

<pre><code>main()
{
	//载入动态链接库中的函数
	void(*pTest)();
	void*pdlHandle = dlopen("libtest.so", RTLD_LAZY);   
	pTest = dlsym(pdlHandle, "GetIPAddress");
	//调用动态链接库中的函数
	string ip = (*pTest)(“host1”);
	……
	//释放动态链接库
	 dlclose(pdlHandle);
	……
	cout &lt;&lt; ip &lt;&lt; endl;
}
</code></pre>

<p>当主程序释放了动态链接库后，那个共享的内存区也随之释放。所以，以后对ip的访问，必然做造成内存地址访问非法，造成程序crash。即使你在以后没有使用到ip这个变量，那么在主程序退出时也会发生内存访问异常，因为程序退出时，ip会析构，在析构时就会发生内存访问异常。</p>

<h3 id="section-1">多线程</h3>

<p>在多线程中，对于多线程来说，引用计数就是一个全局变量。指向同一个buffer的多个string的引用计数有可能变得混乱，从而导致delete异常。尤其是在.h中定义const string A = “XXXX”， 如果多个对象都引用了A，则可能在多线程中出现问题。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal and fork]]></title>
    <link href="http://billowkiller.github.io/blog/2014/06/28/signal-and-forkmarkdown/"/>
    <updated>2014-06-28T04:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/06/28/signal-and-forkmarkdown</id>
    <content type="html"><![CDATA[<p>当线程调用fork时，就为子进程创建了整个进程地址空间的副本。子进程与父进程是完全不同的进程，只要两者都没有对内存作出改动，父进程和子进程之间还可以共享内存副本。注意一下几个情况：</p>

<ol>
  <li>子进程通过继承整个地址空间的副本，<strong>从父进程那里继承了所有互斥量、读写锁和条件变量的状态</strong>。也就是说，如果它在父进程中被锁住，则它在子进程中也是被锁住的。</li>
  <li>只有调用fork()的线程被复制到子进程（子进程中线程的ID），如果子进程中包含占有锁的线程的副本，那么子进程就没有办法知道它占有了那些锁并且需要释放那些锁，<strong>容易造成死锁</strong>。</li>
  <li>thread-specific data的销毁函数和清除函数都不会被调用。在多线程中调用fork()可能会引起内存泄露。比如在其他线程中创建的thread-specific data，在子进程中将没有指针来存取这些数据，<strong>造成内存泄露</strong>。</li>
</ol>

<p>因为以上这些问题，<strong>在线程中调用fork()的后，我们通常都会在子进程中调用exec()</strong>。因为exec()能让父进程中的所有互斥量，条件变量（pthread objects）在子进程中统统消失（用新数据覆盖所有的内存）。对于那些要使用fork()但不使用exec()的程序，pthread API提供了一个新的函数</p>

<pre><code>pthread_atfor(void (*prepare_func)(void), void(*parent_func)(void), void (*child_func)(void))
</code></pre>

<p>prepare_func在父进程调用fork之前调用，parent_func在fork执行后在父进程内被调用，child_func在fork执行后子进程内被调用。除非你打算很快的exec一个新程序，否则应该避免在一个多线程的程序中使用fork。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal and Thread]]></title>
    <link href="http://billowkiller.github.io/blog/2014/06/28/signal-and-thread/"/>
    <updated>2014-06-28T03:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/06/28/signal-and-thread</id>
    <content type="html"><![CDATA[<p>类UNIX信号以前是专为进程设计的，它比线程的出现早了很多年。当线程模型出现后，专家们试图也在线程上实现信号，这导致了一个问题：即使是在基于进程的编程模式中，信号的处理也可能是很复杂的，因为它打断了正在运行的thread of control， 在signal handler中只能调用可重入函数，修改全局变量的类型必须是<code>sig_atomic_t</code>类型，防止内存访问优化； 而把线程引入编程范型，就使信号的处理变得更加复杂。</p>

<p><strong>避免信号和线程一起使用是明智的选择。</strong>但是，将他们分开又是不可能或不实际的。只要有可能的话，仅仅在主线程内使用<code>pthread_sigmask()</code>来屏蔽信号，然后同步地在专用线程中使用<code>sigwait()</code>来处理信号。</p>

<!--more-->

<h2 id="section">信号模型映射到线程模型</h2>

<p>为了理解信号模型是怎样映射到线程模型的，我们需要知道信号模型的哪些方面是影响进程层面的（process-wide），哪些方面只会影响某个线程的。下面列出几点:</p>

<ol>
  <li>signal actions 是process-wide。如果一个没有处理的信号的默认动作是停止SIGSTOP或终止SIGKILL(该动作是让整个进程停止或终止，而不是只针对某个线程)，那么不管这个信号是发送给哪个线程，整个进程都会停止或终止。</li>
  <li>signal dispositions信号部署是process-wide。每个线程都有自己的信号屏蔽字，但是<strong>信号的处理是进程中所有线程共享的</strong>。这意味着尽管每个线程可以阻止某些信号，但当线程修改了与某个信号相关的处理行为之后，所有的线程都必须共享这个处理行为的改变。</li>
  <li>信号通常是被发送到<strong>任意一个线程</strong>，为了保证不会在多线程进程中一个信号多次被执行。但是以下几种情况是传递到<strong>单个线程</strong>的：
    <ul>
      <li>信号与硬件故障或计时器超时相关。</li>
      <li>当线程尝试向一个broken pipe写数据时，会产生一个SIGPIPE。</li>
      <li>使用<code>pthread_kill()</code>或者<code>pthread_sigqueue()</code>。这些函数允许一个线程发送信号到同一进程的另一个线程。</li>
    </ul>
  </li>
  <li><strong>信号掩码(signal mask)是线程私用的。</strong>在多线程的进程中，不存在process-wide的信号掩码。线程可以使用<code>pthread_sigmask()</code>来独立的屏蔽某些信号。通过这种方法，程序员可以控制那些线程响应那些信号。当线程被创建时，它将继承创建它的线程的信号掩码。</li>
  <li><strong>内核为每个线程和进程分别维护了一个未决信号的表</strong>。当使用<code>sigpending()</code>时，该函数返回的是整个进程未决信号表和调用该函数的线程的未决信号表的并集。当新线程被创建时，线程的pending signals被设置为空。当线程A阻塞某个信号S后，发送到A中的信号S将会被挂起，直到线程取消了对信号S的阻塞。</li>
  <li>如果一个信号处理函数打断了<code>pthread_mutex_lock()</code>，该<strong>函数会自动的重新执行</strong>。如果信号处理函数打断了<code>pthread_cond_wait()</code>，该函数要么自动重新自行（linux是这样实现的），或者返回0（这时应用要检查返回值，判断是否为假唤醒）。</li>
</ol>

<h2 id="section-1">异步信号的处理</h2>

<p>一个函数要么是可重入的（reentrant）,要么是不能被信号处理函数打断的，我们把这种函数叫做是<code>async-signal-safe</code>的。调用非<code>async-signal-safe</code>的函数是危险的，比如，考虑在线程A中，我们调用<code>malloc()</code>来进行内存分配，<code>malloc()</code>刚用互斥量锁住了全局链表，这是异步信号到达，在信号处理函数中也调用<code>malloc()</code>，这时该函数会阻塞在互斥量上，形成死锁（这个例子在单线程的进程中也会出现）。Pthread API不是<code>async-signal-safe</code>的，也就是说在信号处理函数中不要使用pthread相关的函数。</p>

<p><strong>解决这个问题</strong>的最好办法是，在不打断正常程序的前提下，把所有的异步信号都在同一处处理。在单线程程序中，这是做不到的，因为所有发送的信号都会打断程序。而在多线程程序中，我们可以<u>单独创建一个线程来接受信号，处理需要的信号，而不会打断其他线程的工作。</u></p>

<p>上面举的这个例子中还有一点没说到，就是<strong>信号处理函数也会被其他信号所打断</strong>。那我们怎么处理这个问题呢？<u>在处理信号之前，对所有的异步信号进行阻塞，等工作处理完毕后，再恢复阻塞的信号。</u>这个工作就靠下面这个函数执行：</p>

<pre><code>int sigwait(const sigset_t *set, int *sig)
</code></pre>

<ul>
  <li><code>sigwait()</code>的好处在于它可以简化信号处理，允许把异步产生的信号用同步方式处理。</li>
  <li>调用<code>sigwait()</code>等待的信号必须在调用线程中屏蔽，通常我们在所有线程中都会屏蔽。</li>
  <li>信号仅仅被交付一次。如果两个线程在<code>sigwait()</code>上阻塞（等待同一个信号），只有一个线程（不确定的线程）将收到送给进程的信号。这意味着不能让两个独立的子系统使用<code>sigwait()</code>来捕获相同的信号。信号捕获<code>sigaction</code>建立的信号处理程序和<code>sigwait</code>也同样只有一个可以执行。</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal status and lifecycle]]></title>
    <link href="http://billowkiller.github.io/blog/2014/06/28/signal-status-and-lifecycle/"/>
    <updated>2014-06-28T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/06/28/signal-status-and-lifecycle</id>
    <content type="html"><![CDATA[<p><i><strong>modified from</strong> <a href="http://blog.csdn.net/sunyubo458/article/details/4484957">http://blog.csdn.net/sunyubo458/article/details/4484957</a></i></p>

<p><em>Lost original source</em></p>

<hr />

<h3 id="section">信号状态</h3>

<p>信号的”未决“是一种状态，指的是从信号的产生到信号被处理前的这一段时间；信号的”阻塞“是一个开关动作，指的是阻止信号被处理，但不是阻止信号产生。 </p>

<p>每个进程都有一个信号屏蔽字，它规定了当前要阻塞地送到该进程的信号集，对于每种可能的信号，该屏蔽字中都有一位与之对应。对于某种信号，若其对应为已设定，则它当前是被阻塞的。进程可以调用<code>sigprocmask</code>来检测和更改当前信号屏蔽字。</p>

<p>APUE例题在<code>sleep</code>前用<code>sigprocmask</code>阻塞了退出信号，然后<code>sleep</code>,然后在<code>sleep</code>的过程中产生一个退出信号，但是此时退出信号被阻塞过，（中文的”阻塞”在这里容易被误解为一种状态，实际上是一种类似于开关的动作，所以说“被阻塞过”，而不是“被阻塞”）所以处于“未决”状态，在 <code>sleep</code>后又用<code>sigprocmask</code>关掉退出信号的阻塞开关，因为之前产生的退出信号一直处于未决状态，当关上阻塞开关后，马上退出“未决”状态，得到处理，这一切发生在<code>sigprocmask</code>返回之前。 </p>

<h3 id="section-1">信号生命周期</h3>

<p>对于一个完整的信号生命周期(从信号发送到相应的处理函数执行完毕)来说，可以分为三个重要的阶段，这三个阶段由四个重要事件来刻画：1.信号诞生；2. 信号在进程中注册完毕；3.信号在进程中的注销完毕；4.信号处理函数执行完毕。相邻两个事件的时间间隔构成信号生命周期的一个阶段。</p>

<!--more-->

<p>下面阐述四个事件的实际意义：</p>

<ol>
  <li>
    <p>信号”诞生”；</p>

    <p>信号的诞生指的是触发信号的事件发生（如检测到硬件异常、定时器超时以及调用信号发送函数kill()或sigqueue()等）。 </p>
  </li>
  <li>
    <p>信号在目标进程中”注册”；</p>

    <p>进程的<code>task_struct</code>结构中有关于本进程中未决信号的数据成员：</p>

    <pre><code> struct sigpending pending;
 struct sigpending
 {
     struct sigqueue *head, **tail;
     sigset_t signal;
 };
</code></pre>

    <p>第一、第二个成员分别指向一个<code>sigqueue</code>类型的结构链（称之为”未决信号信息链”）的首尾，第三个成员是进程中所有未决信号集，信息链中的每个sigqueue结构体刻画一个特定信号所携带的信息，并指向下一个sigqueue结构: </p>

    <pre><code> struct sigqueue
 {
     struct sigqueue *next;
     siginfo_t info;
 };
</code></pre>

    <p>信号在进程中注册指的就是信号值加入到进程的未决信号集中（<code>sigpending</code>结构的第二个成员<code>sigset_t signal</code>），并且信号所携带的信息被保留到未决信号信息链的某个<code>sigqueue</code>结构中。只要信号在进程的未决信号集中，表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。 </p>

    <p><strong>注：</strong> 
 当一个实时信号发送给一个进程时，不管该信号是否已经在进程中注册，都会被再注册一次，因此，信号不会丢失，因此，实时信号又叫做”可靠信号”。这意味着同一个实时信号可以在同一个进程的未决信号信息链中占有多个<code>sigqueue</code>结构（进程每收到一个实时信号，都会为它分配一个结构来登记该信号信息，并把该结构添加在未决信号链尾，即所有诞生的实时信号都会在目标进程中注册）； </p>

    <p>当一个非实时信号发送给一个进程时，如果该信号已经在进程中注册，则该信号将被丢弃，造成信号丢失。因此，非实时信号又叫做”不可靠信号”。这意味着同一个非实时信号在进程的未决信号信息链中，至多占有一个<code>sigqueue</code>结构（一个非实时信号诞生后，（1）、如果发现相同的信号已经在目标结构中注册，则不再注册，对于进程来说，相当于不知道本次信号发生，信号丢失；（2）、如果进程的未决信号中没有相同信号，则在进程中注册自己）。 </p>
  </li>
  <li>
    <p>信号在进程中的注销。</p>

    <p>在目标进程执行过程中，会检测是否有信号等待处理（每次从系统空间返回到用户空间时都做这样的检查）。如果存在未决信号等待处理且该信号没有被进程阻塞，则在运行相应的信号处理函数前，进程会把信号在未决信号链中占有的结构卸掉。是否将信号从进程未决信号集中删除对于实时与非实时信号是不同的。对于非实时信号来说，由于在未决信号信息链中最多只占用一个sigqueue结构，因此该结构被释放后，应该把信号在进程未决信号集中删除（信号注销完毕）；而对于实时信号来说，可能在未决信号信息链中占用多个sigqueue结构，因此应该针对占用gqueue结构的数目区别对待：如果只占用一个sigqueue结构（进程只收到该信号一次），则应该把信号在进程的未决信号集中删除（信号注销完毕）。否则，不在进程的未决信号集中删除该信号（信号注销完毕）。进程在执行信号相应处理函数之前，首先要把信号在进程中注销。 </p>
  </li>
  <li>
    <p>信号生命终止。</p>

    <p>进程注销信号后，立即执行相应的信号处理函数，执行完毕后，信号的本次发送对进程的影响彻底结束。 </p>
  </li>
</ol>

<p><strong>注：</strong> 
1）信号注册与否，与发送信号的函数（如kill()或sigqueue()等）以及信号安装函数（signal()及sigaction()）无关，只与信号值有关（信号值小于SIGRTMIN的信号最多只注册一次，信号值在SIGRTMIN及SIGRTMAX之间的信号，只要被进程接收到就被注册）。 
2）在信号被注销到相应的信号处理函数执行完毕这段时间内，如果进程又收到同一信号多次，则对实时信号来说，每一次都会在进程中注册；而对于非实时信号来说，无论收到多少次信号，都会视为只收到一个信号，只在进程中注册一次。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Inside C++ Object]]></title>
    <link href="http://billowkiller.github.io/blog/2014/04/12/Inside-C%2B%2B-Object/"/>
    <updated>2014-04-12T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/04/12/Inside-C++-Object</id>
    <content type="html"><![CDATA[<p>modified from <a href="http://blog.csdn.net/eroswang/article/details/1749609">http://blog.csdn.net/eroswang/article/details/1749609</a></p>

<hr />

<h2 id="ooob">面对对象（OO）和基于对象（OB）</h2>

<p>基于对象的数据类型可以展示封装的非多态形式，但是不支持类型的扩充。一个OB设计可能比一个对等的OO设计速度更快而且空间更紧凑。速度快是因为所有的函数引发操作都在编译时期解析完成，对象建构起来时不需要设置virtual机制；空间紧凑则是因为每一个class object不需要负担传统上为了支持virtual机制而需要的额外符合。不过，OB设计比较没有弹性。 </p>

<h2 id="c">C++对象模型</h2>

<p>在C++中，有两种<strong>class data members：static和nonstatic</strong>，以及三种<strong>class member functions：static、nonstatic和virtual</strong>。</p>

<p>Nonstatic data members被配置于每一个class object之内，static data members则被存放在所有的class object之外。Static和nonstatic function members也被放在所有的class object之外，Virtual functions则以两个步骤支持之：</p>

<ul>
  <li>每一个class产生出一堆指向virtual functions的指针，放在表格之中，这个表格被称为<strong>virtual table（vtbl）</strong>。每一个class所关联的type_info object（用以支持<strong>runtime type identification，RTTI</strong>）也经由virtual table被指出来，通常是放在表格的第一个slot处。</li>
  <li>每一个class object被添加了一个指针，指向相关的virtual table。通常这个指针被称为<strong>vptr</strong>。</li>
</ul>

<!--more-->

<p><img src="http://p.blog.csdn.net/images/p_blog_csdn_net/arthurkingios/1.JPG" alt="" /></p>

<p><strong>重置vptr：</strong></p>

<p>假设Bear继承于ZooAnimal，如下所示：</p>

<pre><code>Bear b;
ZooAnimal za = b;  // 这会引起切割（sliced）
// 调用 ZooAnimal::rotate()
za.rotate();
</code></pre>

<p><strong>为什么rotate所调用的是ZooAnimal实体而不是Bear实体？</strong></p>

<p>ZooAnimal class object以另一个ZooAnimal class object作为初值，或Bear class object以另一个Bear class object作为初值，都可以直接靠bitwise copy semantics完成（剔除pointer member情况）
。</p>

<p>而当一个base class object以其derived class object内容做初始化操作时，其vptr复制操作也必须保证其安全。编译器必须确保如果某个object含有一个或一个以上的vptrs，那些vptrs的内容不会被base class object初始化改变。</p>

<h2 id="constructor">Constructor的建构操作</h2>
<p>###Default Constructor的建构操作</p>

<p>default constructor仅在编译器需要它时，才会被合成出来。
通常来说，由编译器合成出来的default constructor是没啥用的（trivial），但有以下几种例外：</p>

<ol>
  <li>
    <p>带有“Default Constructor”的Member Class Object</p>

    <p>如果一个class没有任何constructor，但它内含一个member object，而后者有default constructor，那么编译器会在constructor真正需要被调用时未此class合成一个“nontrivial”的default constructor。</p>

    <p>为了避免合成出多个default constructor，解决方法是把合成的default constructor、copy constructor、destructor、assignment copy operator都以inline方式完成。一个inline函数有静态链接（static linkage），不会被档案以外者看到。如果函数太复杂，不适合做成inline，就会合成出一个explicit non-inline static实体。</p>
  </li>
  <li>“带有Default Constructor”的Base Class</li>
  <li>“带有一个Virtual Function”的Class
    <ul>
      <li>class声明（或继承）一个virtual function</li>
      <li>class派生自一个继承串链，其中有一个或更多的virtual base classes</li>
    </ul>
  </li>
  <li>
    <p>“带有一个virtual Base Class”的Class</p>

    <p>编译器需要在derived class object中为每一个virtual base classes安插一个指针，使得所有“经由reference或pointer来存取一个virtual base class”的操作可以通过相关指针完成。</p>
  </li>
</ol>

<p><strong>总结：</strong>
被合成出来的constructor只能满足编译器（而非程序）的需要。
没有存在着四种情况而又没有声明任何constructor的classes，它们拥有的是implicit trivial default constructor，实际上并不会被合成出来。</p>

<p>在合成的default constructor中，只有base class subobjects和member class objects会被初始化，所有其它的nonstatic data member，如整数、整数指针，整数数组等都不会被初始化。</p>

<p><strong>一般会对dafult constructor有两个误解：</strong></p>

<ol>
  <li>任何class如果没有定义default constructor，就会被合成出来。</li>
  <li>编译器合成出来的default constructor会明确设定“class内每一个data memeber”的默认值。</li>
</ol>

<h3 id="copy-constructor">Copy Constructor的建构操作</h3>

<p>有三种情况会以一个object的内容作为另一个class object的初值，即<strong>object赋值、object参数传递、object作为函数返回值</strong>。</p>

<p>如果class没有提供一个explicit copy constructor，其内部是以所谓的default memberwise initialization手法完成的，也就是把每一个内建的或派生的data member（例如一个指针或一个数组）的值，从某个object拷贝一份到另一个object身上，不过它并不会拷贝其中的member class object，而是以递归的方式施行memberwise initialization。</p>

<p>copy constructor仅在必要的时候（class不展现bitwise copy semantics）才由编译器产生出来。</p>

<p>比如，某个类含有<code>String&amp; str</code>成员变量，在这种情况下，编译器必须合成出一个copy constructor以便调用member class String object的copy constructor：</p>

<p><strong>一个class不展现出“bitwise copy semantics”的四种情况：</strong></p>

<ol>
  <li>当class内含一个member object而后者的class声明有一个copy constructor时（无论是被明确声明或被合成而得）</li>
  <li>当class继承自一个base class而后者存在有一个copy constructor时</li>
  <li>
    <p>当class声明了一个或多个virtual functions时</p>

    <p>由于编译器要对每个新产生的class object的vptr设置初值，因此，当编译器导入一个vptr到class之中时，该class就不再展现bitwise semantics了。特别地，当一个base class object以其derived class的object内容做初始化操作时，其vptr复制操作必须保证安全，而如果依旧采用bitwise copy的话，base class object的vptr会被设定指向derived class的virtual table，而这将导致灾难。</p>
  </li>
  <li>
    <p>当class派生自一个继承串链，其中有一个或多个virtual base classes时</p>

    <p>当一个class object以其derived classes的某个object作为初值时，为了完成正确的virtual base class pointer/offset的初值设定，编译器必须合成一个copy constructor，安插一些码以设定virtual base class pointer/offset的初值，对每一个member执行必要的memberwise初始化操作，以及执行其他的内存相关操作。</p>
  </li>
</ol>

<h2 id="section">成员的初始化列表</h2>

<p>下列情况中，为了让你的程序能够被顺利编译，你必须使用member initialization list：</p>

<ul>
  <li>当初始化一个reference member时；</li>
  <li>当初始化一个const member时；</li>
  <li>当调用一个base class的constructor，而它拥有一组参数时；</li>
  <li>当调用一个member class的constructor，而它拥有一组参数时。</li>
</ul>

<h2 id="class">class大小</h2>

<p>考虑下面的代码：</p>

<pre><code>#include "iostream"
using namespace std;

class X {};
class Y : public virtual X {};
class Z : public virtual X {};
class A : public Y,public Z {};

int main()
{
    cout&lt;&lt;"sizeof(X): "&lt;&lt;sizeof(X)&lt;&lt;endl;
    cout&lt;&lt;"sizeof(Y): "&lt;&lt;sizeof(Y)&lt;&lt;endl;
    cout&lt;&lt;"sizeof(Z): "&lt;&lt;sizeof(Z)&lt;&lt;endl;
    cout&lt;&lt;"sizeof(A): "&lt;&lt;sizeof(A)&lt;&lt;endl;

    return 0;
}
</code></pre>

<p>得到的结果是什么呢？答案是</p>

<pre><code>sizeof(X): 1
sizeof(Y): 4
sizeof(Z): 4
sizeof(A): 8
</code></pre>

<ul>
  <li>对于一个class X这样的空的class，由于需要使得这个class的两个objects得以在内存中配置独一无二的地址，故编译器会在其中安插进一个char。因而class X的大小为1。</li>
  <li>由于class Y虚拟继承于class X，而在derived class中，会包含指向visual base class subobject的指针（4 bytes），而由于需要区分这个class的不同对象，因而virtual base class X subobject的1 bytes也出现在class Y中（1 bytes），此外由于Alignment的限制，class Y必须填补3bytes（3 bytes），这样一来，class Y的大小为8。<strong>编译器将一个empty virtual base class视为derived class object最开头的一部分，因而省去了其后的1 bytes，自然也不存在后面Alignment的问题，故实际的执行结果为4。</strong></li>
  <li>不管它在class继承体系中出现了多少次，一个virtual base class subobject只会在derived class中存在一份实体。因此，class A的大小有以下几点决定：（1）被大家共享的唯一一个class X实体（1 byte）；（2）Base class Y的大小，减去“因virtual base class X而配置”的大小，结果是4 bytes。Base class Z的算法亦同。（3）classs A的alignment数量。前述总和为9 bytes，需要填补3 bytes，结果是12 bytes。empty virtual base class所做的处理，class X实体的那1 byte将被拿掉，于是额外的3 bytes填补额也不必了，故实际的执行结果为8。</li>
</ul>

<p><strong>不管是自身class的还是继承于virtual或nonvirtual base class的nonstatic data members，其都是直接存放在每个class object之中的。至于static data members，则被放置在程序的一个global data segment中，不会影响个别的class object的大小，并永远只存在一份实体。</strong></p>

<h2 id="data-member">Data Member</h2>

<h3 id="data-member-1">Data Member布局</h3>

<p>同一个access section中的nonstatic data member在class object中的排列顺序和其被声明的顺序一致，而多个access sections中的data members可以自由排列。（虽然当前没有任何编译器会这么做）</p>

<p>编译器还可能会合成一些内部使用的data members（例如vptr，编译器会把它安插在每一个“内含virtual function之class”的object内），以支持整个对象模型。</p>

<h3 id="data-member-2">Data Member的存取</h3>

<p><strong>Static Data Members：</strong></p>

<ul>
  <li>每一个static data member只有一个实体，存放在程序的data segment之中，每次程序取用static member，就会被内部转化为对该唯一的extern实体的直接参考操作。</li>
  <li>若取一个static data member的地址，会得到一个指向其数据类型的指针，而不是一个指向其class member的指针，因为static member并不内含在一个class object之中。</li>
  <li>如果有两个classes，每一个都声明了一个static member freeList，那么编译器会采用name-mangling对每一个static data member编码，以获得一个独一无二的程序识别代码。</li>
</ul>

<p><strong>Nonstatic Data Members：</strong></p>

<pre><code>Point3d origin, *pt = &amp;origin;
origin.x = 0.0;
pt-&gt;x = 0.0;
</code></pre>

<p><strong>这两种存取方式有什么区别吗？</strong></p>

<p>答案是“<strong>当Point3d是一个derived class，而在其继承结构中有一个virtual base class，并且并存取的member（如本例的x）是一个从该virtual base class继承而来的member时，就会有重大的差异</strong>”。这时候我们不能够说pt必然指向哪一种 class type（因此我们也就不知道编译期间这个member真正的offset位置），所以这个存取操作必须延迟到<strong>执行期</strong>，经由一个额外的简洁导引，才能够解决。但如果使用origin，就不会有这些问题，其类型无疑是Point3d class，而即使它继承自virtual base class，members的offset位置也在<strong>编译时期就固定了</strong>。</p>

<h3 id="data-member-3">继承与Data Member</h3>

<p><strong>1. 只要继承不要多态</strong></p>

<pre><code>class Concrete {
private:
int val;
char bit1;
};

class Concrete2 : public Concrete1 {
private:
char bit2;
};

class Concrete3 : public Concrete2 {
private:
char bit3;
};
</code></pre>

<p>现在Concrete3 object的大小为16 bytes，细分如下：（a）Concrete1内含两个members：val和bit1，加起来是5 bytes，再填补3 bytes，故一个Concrete1 object实际用掉8 bytes；（b）需要注意的是，Concrete2的bit2实际上是被放在填补空间之后的，于是一个Concrete2 object的大小变成12 bytes；（c）依次类推，一个Concrete3 object的大小为16 bytes。</p>

<p><strong>2. 加上多态</strong></p>

<p>virtual function带来的额外负担：</p>

<ul>
  <li>导入一个virtual table，用来存放它声明的每一个virtual function的地址；</li>
  <li>在每一个class object中导入一个vptr；</li>
  <li>加强constructor和destructor，使它们能设置和抹消vptr。</li>
</ul>

<p><strong>3. 多重继承</strong></p>

<p>对一个多重继承对象，将其地址指定给“第一个base class的指针”，情况将和单一继承时相同，因为二者都指向相同的起始地址，需付出的成本只有地址的指定操作而已。至于第二个或后继的base class的地址指定操作，则需要将地址修改过，加上（或减去，如果downcast的话）介于中间的base class subobjects的大小。</p>

<p><strong>4. 虚拟继承</strong></p>

<p>class如果内含一个或多个virtual base class subobject，将被分隔为两部分：一个不变局部和一个共享局部。不变局部中的数据，不管后继如何衍化，总是拥有固定的offset，所以这一部分数据可以被直接存取。至于共享局部，所表现的就是virtual base class subobject。这一部分的数据，其位置会因为每次的派生操作而变化，所以它们只可以被间接存取。
间接存取主要有以下三种主流策略：</p>

<ol>
  <li>在每一个derived class object中安插一些指针，每个指针指向一个virtual base class。要存取继承得来的virtual base class members，可以使用相关指针间接完成。由于虚拟继承串链得加长，导致间接存取层次的增加。</li>
  <li>在上一个的基础上，为了解决每一个对象必须针对每一个virtual base class背负一个额外的指针的问题，Micorsoft编译器引入所谓的virtual base class table。每一个class object如果有一个或多个virtual base classes，就会由编译器安插一个指针，指向virtual base class table。这样一来，就可以保证class object有固定的负担，不因为其virtual base classes的数目而有所变化。</li>
  <li>在virtual function table中放置virtual base class的offset。新近的Sun编译器采取这样的索引方法，若为正值，就索引到virtual functions，若为负值，则索引到virtual base class offsets。</li>
</ol>

<p><strong>小结：一般而言，virtual base class最有效的一种运用方式就是：一个抽象的virtual base class，没有任何data members。</strong></p>

<h3 id="data-members">指向Data Members的指针</h3>

<pre><code>class Point3d {
public:
	virtual ~Point3d();
protected:
	static Point3d origin;
	float x, y, z;
} 
</code></pre>

<p>如果你去取class中某个data member的地址时，得到的都是data member在class object中的实际偏移量加1。例如<code>&amp;Point3d::z</code>得到9或13，根据vptr放在对象头还是对象尾确定。为什么要这么做呢？主要是为了区分一个“没有指向任何data member”的指针和一个指向“的第一个data member”的指针。即，区分一下情况：</p>

<pre><code>float Point3d::*p1 = 0;
float Point3d::*p2 = &amp;Point3d::x;
</code></pre>

<p>为了区分<code>p1</code>和<code>p2</code>每一个真正的member offset值都被加上1。因此，无论编译器或使用者都必须记住，在真正使用该值以指出一个member之前，请先减掉1。</p>

<p>另外正确区分<code>&amp; Point3d::z</code>和<code>&amp;origin.z</code>：取一个nonstatic data member的地址将会得到它在class中的offset，取一个绑定于真正class object身上的data member的地址将会得到该member在内存中的真正地址。</p>

<p>在多重继承之下，若要将第二个（或后继）base class的指针和一个与derived class object绑定之member结合起来那么将会因为需要加入offset值而变得相当复杂。</p>

<pre><code>struct Base1 { int val1; };
struct Base2 { int val2; };
struct Derived : Base1, Base2 { ... };

void func1(int Derived::*dmp, Derived *pd)
{
	// 期望第一个参数得到的是一个“指向derived class之member”的指针
	// 如果传来的却是一个“指向base class之member”的指针，会怎样呢
	pd-&gt;*dmp;
}

void func2(Derived *pd)
{
	// bmp将成为1
	int Base2::*bmp = &amp;Base2::val2;
	// bmp == 1
	// 但是在Derived中，val2 == 5
	func1(bmp,pd);
}
</code></pre>

<p>也就是说<code>pd-&gt;*dmp</code>将存取到<code>Base1::val1</code>，为解决这个问题，当bmp被作为func1()的第一个参数时，它的值必须因介入的Base1 class的大小而调整：</p>

<pre><code>// 内部转换，防止bmp == 0
func1(bmp ? bmp + sizeof(Base1) : 0, pd);
</code></pre>

<h2 id="functions">Functions</h2>

<h3 id="nonstatic-member-functions">非静态成员函数（Nonstatic Member Functions）</h3>

<p>C++的设计准则之一就是：nonstatic member function至少必须和一般的nonmember function有相同的效率。因为编译器内部已将“member函数实体”转化为对等的“nonmember函数实体”。下面是magnitude()的一个nonmember定义：</p>

<pre><code>loat Pointer3d::magnitude() const
{
	return sqrt(_x*_x + _y*_y + _z*_z);
}
// 内部转化为
float magnitude_7Point3dFv(const Point3d *this)  //已对函数名称进行“mangling”处理
{
	return sqrt(this-&gt;_x*this-&gt;_x + this-&gt;_y*this-&gt;_y + this-&gt;_z*this-&gt;_z);
}
</code></pre>

<p>现在，对该函数的每一个调用操作也都必须转换：</p>

<pre><code>obj.magnitude();
// 转换为
magnitude_7Point3dFv(&amp;obj);
</code></pre>

<p>mangling手法可在链接时期检查出任何不正确的调用操作，但由于编码时未考虑返回类型，故<strong>如果返回类型声明错误，就无法检查出来</strong>。</p>

<h3 id="virtual-member-functions">虚拟成员函数（Virtual Member Functions）</h3>

<p>一个class只会有一个virtual table，其中内含其对应的class object中所有active virtual functions函数实体的地址，具体包括：</p>

<ol>
  <li>
    <p>这个class所定义的函数实体</p>

    <p>它会改写一个可能存在的base class virtual function函数实体。若base class中不存在相应的函数，则会在derived class的virtual table增加相应的slot。</p>
  </li>
  <li>
    <p>继承自base class的函数实体</p>

    <p>这是在derived class决定不改写virtual function时才会出现的情况。具体来说，base class中的函数实体的地址会被拷贝到derived class的virtual table相对应的slot之中。</p>
  </li>
  <li>
    <p>pure_virtual_called函数实体</p>
  </li>
</ol>

<p>对于那些不支持多态的对象，经由一个class object调用一个virtual function，这种操作应该总是被编译器像对待一般的nonstatic member function一样地加以决议：</p>

<pre><code>// Point3d obj
obj.normalize();
// 不会转化为
(*obj.vptr[1])(&amp;obj);
// 而会被转化未
normalize_7Point3dFv(&amp;obj);
</code></pre>

<h3 id="static-member-functions">静态成员函数（Static Member Functions）</h3>

<p>编译器的开发者针对static member functions，分别从编译层面和语言层面对其进行了支持：</p>

<p><strong>编译层面</strong>：当class设计者希望支持“没有class object存在”的情况时，可把0强制转型为一个class指针，因而提供出一个this指针实体：</p>

<pre><code>// 函数调用的内部转换
object_count((Point3d*)0);
</code></pre>

<p><strong>语言层面</strong>：static member function的最大特点是没有this指针，如果取一个static member function的地址，获得的将是其在内存中的位置，其地址类型并不是一个“指向class member function的指针”，而是一个“nonmember函数指针”：</p>

<pre><code>unsigned int Point3d::object_count() { return _object_count; }
&amp;Point3d::object_count();
// 会得到一个地址，其类型不是
unsigned int (Point3d::*)();
// 而是
unsigned int (*)();
</code></pre>

<p>static member function经常被用作回调（callback）函数。</p>

<h3 id="virtual-functions">多重继承下的Virtual Functions</h3>

<p>在多重继承中支持virtual functions，其复杂度围绕在第二个及后继的base classes身上，以及“必须在执行期调整this指针”这一点。</p>

<p><strong>多重继承到来的问题：</strong></p>

<ol>
  <li>
    <p>经由指向“第二或后继之base class”的指针（或reference）来调用derived class virtual function，该调用操作连带的“必要的this指针调整”操作，必须在执行期完成；</p>

    <pre><code> Base2 *pbase2 = new Derived;
 //会被内部转化为：
 Derived *temp = new Derived;
 Base2 *pbase2 = temp ? temp + sizeof(Base1) : 0;
 // 必须调用正确的virtual destructor函数实体
 // pbase2需要调整，以指出完整对象的起始点
 delete pbase2;
</code></pre>

    <p>上述的offset加法却不能够在编译时期直接设定，因为pbase2所指的真正对象只有在执行期才能确定。自此，我们明白了在多重继承下所面临的独特问题：经由指向“第二或后继之base class”的指针（或reference）来调用derived class virtual function，该调用操作所连带的“必要的this指针调整”操作，必须在执行期完成。有两种方法来解决这个问题：</p>

    <ol>
      <li>将virtual table加大，每一个virtual table slot不再只是一个指针，而是一个聚合体，内含可能的offset以及地址。</li>
      <li>利用Thunk技术，允许virtual table slot继续内含一个简单的指针，slot中的地址可以直接指向virtual function，也可以指向一个相关的thunk。于是，对于那些不需要调整this指针的virtual function而言，也就不需要承载效率上的额外负担。</li>
    </ol>
  </li>
  <li>
    <p>由于两种不同的可能：（a）经由derived class（或第一个base class）调用；（b）经由第二个（或其后继）base class调用，同一函数在virtual table中可能需要多笔对应的slot；</p>

    <pre><code> Base1 *pbase1 = new Derived;
 Base2 *pbase2 = new Derived;
	
 delete pbase1;
 delete pbase2;
</code></pre>

    <p>虽然两个delete操作导致相同的Derived destructor，但它们需要两个不同的virtual table slots：</p>

    <p><strong>解决方法：</strong>在多重继承下，一个derived class内含n-1个额外的virtual tables，n表示其上一层base classes的数目。按此手法，Derived将内含以下两个tables：vtbl_Derived和vtbl_Base2_Derived。</p>
  </li>
  <li>
    <p>允许一个virtual function的返回值类型有所变化，可能是base type，可能是publicly derived type，这一点可以通过Derived::clone()函数实体来说明。</p>

    <pre><code> Base2 *pb1 = new Derived;

 // 调用Derived::clone()
 // 返回值必须被调整，以指向Base2 subobject
 Base2 *pb2 = pb1-&gt;clone();
</code></pre>

    <p>当运行pb1-&gt;clone()时，pb1会被调整指向Derived对象的起始地址，于是clone()的Derived版会被调用：它会传回一个指针，指向一个新的Derived对象；该对象的地址在被指定给pb2之前，必须先经过调整，以指向Base2 subobject。</p>
  </li>
</ol>

<h2 id="section-1">其他</h2>

<h3 id="section-2">纯虚拟函数</h3>

<p>在设计抽象基类时，需要注意以下几点：</p>

<ol>
  <li>
    <p>不要将destructor声明为pure virtual function；</p>

    <p>如果将destructor声明为pure virtual function，则设计者一定得定义它。因为每一个derived class destructor会被编译器加以扩展，以静态调用得方式调用其“每一个virtual base class”以及“上一层base class”的destructor。</p>
  </li>
  <li>不要将那些函数定义内容并不与类型有关的函数设计为virtual function，因为其几乎不会被后继的derived class改写。</li>
  <li>对于其derived class可能修改某一个data member的函数，不应被声明为const。</li>
</ol>

<h3 id="section-3">对象构造</h3>

<pre><code>class Point {
public:
	Point(float x = 0.0, float y = 0.0) : _x(x),_y(y) {}
	virtual float z();
protected:
	float _x,_y;
};
</code></pre>

<p>不能小看z()这个virtual function给class Point带来的巨大变化。virtual function的引入促使每一个class Point拥有一个vtpr，这样一来，编译器在constructor中添加了对vptr进行初始化的代码，而copy constructor和copy assignment operator也会对vptr进行设定，而不再是原先简单的bitwise操作了。</p>

<p>一般而言，如果你的设计之中有很多函数都需要以传值方式（by value）传回一个local class object，那么提供一个copy constructor就比较合理。</p>

<p><strong>constructor的执行算法通常如下：</strong></p>

<ul>
  <li>在derived class constructor中，所有virtual base classes的constructor会被调用；</li>
  <li>在derived class constructor中，上一层base class的constructor会被调用；</li>
  <li>上述完成之后，对象的vptr(s)被初始化，指向相关的virtual table(s)；</li>
  <li>如果class有member class object，而后者拥有constructor，那么它们会以其声明顺序的相反顺序被调用；</li>
  <li>用户所定义的代码。</li>
</ul>

<h3 id="section-4">析构函数</h3>

<p>如果class没有定义destructor，那么只有在class内含的member object（或是class自己的base class）拥有destructor的情况下，编译器才会自动合成出一个来。
其解构顺序与建构顺序正好相反。</p>

<p>一般而言，我们会把object尽可能放置在使用它的那个程序区段附近，这样做可以节省不必要的对象产生操作和销毁操作。</p>

<h3 id="section-5">全局对象</h3>

<p>全局对象的静态初始化策略包括以下几个步骤：</p>

<ol>
  <li>为每一个需要静态初始化的对象产生一个<code>_sti_...()</code>函数，内含必要的constructor调用操作或inline expansions；</li>
  <li>为每一个需要静态的内存释放操作的对象产生一个<code>_std_...()</code>函数，内含必要的destructor调用操作或inline expansions；</li>
  <li>在main()函数的首尾分别添加一个<code>_main()</code>函数（用以调用可执行文件中的所有<code>_sti()</code>函数）和一个<code>_exit()</code>函数（用以调用可执行文件中的所有<code>_std()</code>函数）。</li>
</ol>

<p><strong>建议根本不要用那些需要静态初始化的全局对象。</strong> </p>

<h3 id="section-6">局部静态对象</h3>

<pre><code>const Matrix&amp; identity() {
	static Matrix mat_identity;
	// ...
	return mat_identity;
}
</code></pre>

<p>此处的local static class object保证了以下语意：</p>

<ul>
  <li><code>mat_identity</code>的constructor必须只能施行一次，虽然上述函数可能会被调用多次；</li>
  <li><code>mat_identity</code>的destructor必须只能施行一次，虽然上述函数可能会被调用多次。</li>
</ul>

<p>编译器的实际做法如下：在第一次调用<code>identity()</code>时把<code>mat_identity</code>构造出来，而在与相应文件关联的静态内存释放函数中将其解构。（局部静态对象的地址在downstream component中将会被转换到程序内用来放置global object的data segment中）</p>

<h3 id="section-7">对象数组</h3>

<p>如何支持以下的语句：<code>complex::complex(double=0.0, double=0.0);</code></p>

<pre><code>complex c_array[10];
//内部转换
vec_new(&amp;c_array,sizeof(complex),10,&amp;complex::complex,0);
</code></pre>

<p>为了解决这个问题，可由编译器产生一个内部的constructor，没有参数，在其函数内调用由程序员提供的constructor，并将default参数值明确地指定过去：</p>

<pre><code>complex::complex() {
	complex(0.0, 0.0);
}
</code></pre>

<h3 id="new--delete">new &amp; delete</h3>

<p>以constructor来配置一个class object：<code>Point3d *origin = new Point3d;</code>
转为</p>

<pre><code>Point3d *origin;
if(origin = _new(sizeof(Point3d))) {
	try {
		origin = Point3d::Point3d(origin);
	}
	catch( ... ) {
		_delete(origin);  // 释放因new而配置的内存
		throw;  // 将原来的exception上传
	}
}
</code></pre>

<p>如果我们配置一个数组，内带10个Point3d objects，我们预期Point和Point3d的constructor被调用各10次，每次作用于数组中的一个元素：</p>

<pre><code>// 危险
Point *ptr = new Point3d[10];
// 只有Point::~Point被调用
delete []ptr;
</code></pre>

<p>由于其触发的<code>vec_delete()</code>是通过迭代走过每一个数组元素，而本例中被传递过去的是Point class object的大小而不是Point3d class object的大小，整个运行过程将会失败。
解决之道在于程序层面，而非语言层面：</p>

<pre><code>for(int ix = 0; ix &lt; 10; ix++)
{
	Point3d *p = &amp;((Point3d*)ptr)[ix];
	delete p;
}
</code></pre>

<p>当然，最好还是<strong>避免以一个base class指针指向一个derived class objects所组成的数组。</strong></p>

<h3 id="template">Template</h3>

<p><strong>member functions只有在member functions被使用的时候，C++ Standard才要求它们被“具现”出来</strong>。这个规则的由来主要有两个原因：</p>

<ol>
  <li>空间和效率的考虑。对于未使用的函数进行“具现”将会花费大量的时间和空间；</li>
  <li>尚未实现的功能。并不是一个template具现出来的所有类型一定能够完整支持一组member functions，因而只需具现真正需要的member functions。</li>
</ol>

<p>举个例子：<code>Point&lt;float&gt; *p = new Point&lt;float&gt;;</code></p>

<p>只有（a）Point template的float实例、（b）new 运算符、（c）default constructor需要被“具现”。</p>

<p><strong>并且所有与类型相关的检验，如果涉及到template参数，都必须延迟到真正的具现操作发生</strong>。</p>

<p>区分以下两种意义：一种是“<strong>scope of the template definition</strong>”，也就是“定义出template”的程序，另一种是“<strong>scope of the template instantiation</strong>”，也就是“具现出template”的程序。</p>

<pre><code>// scope of the template definition
extern double foo(double);

template &lt;class type&gt;
class ScopeRules {
public:
	void invariant() { _member = foo(_val); }
	type type_dependent() { return foo(_member); }
	// ...
private:
	int _val;
	type _member;
};

// scope of the template instantiation
extern int foo(int);

ScopeRules&lt;int&gt; sr0;
</code></pre>

<p>在“scope of the template definition”中，只有一个foo()函数声明位于scope之内；然而在“scope of the template instantiation”中，两个foo()函数声明都位于scope之内。对于以下函数操作：<code>sr0.invariant();</code>，那么，在invariant()中调用的究竟是哪一个foo()函数实体呢？</p>

<p>Template之中，对于一个nonmember name的决议结果是根据这个name的使用是否与“用以具现出该template的参数类型”有关而决定的，如果其使用互不相关，那么就以“scope of the template definition”来决定name，否则就以“scope of the template instantiation”来决定name。</p>

<pre><code>// 因为_val的类型是int，而函数的决议只和函数原型有关，与函数返回值无关
// 被用来具现这个template的真正类型对于_val的类型没有影响
_member = foo(_val);
</code></pre>

<p>故此处的调用操作由“scope of the template definition”来决议。</p>

<p>若是如下的函数调用：<code>sr0.type_dependent();</code>。由于_member的类型与template参数有关，故此处由“scope of the template instantiation”来决议。</p>

<h3 id="section-8">执行期类型识别</h3>

<p><code>dynamic_cast</code>运算符可以在执行期决定真正的类型。如果downcast是安全的（也就是说，一个base type pointer指向一个derived class object），这个运算符会传回被适当转型过的指针；如果downcast不是安全的，这个运算符会传回0。</p>

<pre><code>typedef type *ptype;
typedef fct *pfct;

simplify_conv_op(ptype pt)
{
	if(pfct pf = dynamic_cast&lt;pfct&gt;(pt)) {
	...
	}
	else { ... }
}
</code></pre>

<p>什么是<code>dynamic_cast</code>的真正成本？<code>pfct</code>的一个类型描述器会被编译器产生出来，由<code>pt</code>指向之class object类型描述器必须在执行期通过vptr取得。下面是可能的转换：</p>

<pre><code>// 取得pt的类型描述器
((type_info*)(pt-&gt;vptr[0]))-&gt;_type_description;
</code></pre>

<p>其中，<code>type_info</code>是C++ Standard所定义的类型描述器的class名称，该class中放置着待索求的类型信息。virtual table的第一个slot内含<code>type_info</code> object的地址，此<code>type_info</code> object与pt所指之class type有关。</p>

<p><code>dynamic_cast</code>运算符也适用于reference身上，然而对于一个non-type-safe-cast，其结果不会与施行于指针的情况一样。一个reference不可以像指针那样“把自己设为0便代表了no object”；若将一个reference设为0，会引起一个临时性对象（拥有被参考到的类型）被产生出来，该临时对象的初值为0，这个reference然后被设定为该临时变量的一个别名。</p>

<p>因而，如果reference并不真正是某一种derived class，那么可通过丢出一个<code>bad_cast exception</code>进行处理：</p>

<pre><code>simplify_conv_op(const type &amp;rt)
{
	try {
		fct &amp;rf = dynamic_cast&lt;fct&amp;&gt;(rt);
	}
	catch(bad cast) {
		// ...
	}
}
</code></pre>

<p>当然，你也可以使用typeid运算符来达到同样的目的：</p>

<pre><code>simplify_conv_op(const type &amp;rt)
{
	if(typeid(rt) == typeid(fct))
	{
		fct &amp;rf = dynamic_cast&lt;fct&amp;&gt;(rt);
	}
	else { ... }
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ inline]]></title>
    <link href="http://billowkiller.github.io/blog/2014/02/16/c%2B%2B-inline/"/>
    <updated>2014-02-16T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/02/16/c++-inline</id>
    <content type="html"><![CDATA[<p><code>inline</code>定义的函数，比起没有<code>inline</code>的函数来说，没有执行函数调用所带来的负担，因此它是高效率的；比起宏来，它具有<strong>函数的可预期行为和参数类型检验</strong>。</p>

<p><code>inline</code>对于编译器而言，意味着“在编译阶段，将调用动作以被调用函数的本体替换之”。但是它只是一种建议，编译器可以去做，也可以不去做。从逻辑上来说，编译器将函数<code>inline</code>的步骤如下：</p>

<ol>
  <li>将<code>inline</code>函数体复制到<code>inline</code>函数调用点处；</li>
  <li>为所用<code>inline</code>函数中的局部变量分配内存；</li>
  <li>将<code>inline</code>函数的的输入参数和返回值映射到调用方法的局部变量空间中；</li>
  <li>如果<code>inline</code>函数有多个返回点，将其转变为<code>inline</code>函数代码块末尾的分支（使用GOTO）。</li>
</ol>

<p><code>inline</code>函数的缺点有哪些呢？</p>

<ol>
  <li><strong>代码膨胀。</strong>如果<code>inline</code>函数体过大且编译器还让它<code>inline</code>成功，那么你最终的程序会代码膨胀，从而造成设备缓冲命中率低，引起较多的页面错误，读写硬盘的次数增多，这样程序的性能就下降了！建议：<strong><code>inline</code>函数体一般不要超过5行，不包括循环，不包括递归调用。</strong></li>
  <li><strong><code>inline</code>函数内部不要有static变量。</strong><code>inline</code>函数的定义几乎总是放在头文件（.h）里，这允许多个实现文件（.cpp）得以引用。我们知道编译器是分别编译的，所以这个时候，在多个实现文件里就会有多个<code>inline</code>函数的展开，也就是说有个多个static变量，这恐怕不是我们期望的！</li>
  <li><strong><code>inline</code>函数无法随着函数库升级而升级。</strong>如果f是函数库中的一个<code>inline</code>函数，使用它的用户会将f函数实体编译到他们的程序中。一旦函数库实现者改变f，所有用到f的程序都必须重新编译。如果f是non-<code>inline</code>的，用户程序只需重新连接即可。如果函数库采用的是动态连接，那这一升级的f函数可以不知不觉的被程序使用。</li>
  <li><strong>不要获取<code>inline</code>函数的地址。</strong>如果要取得一个<code>inline</code>函数的地址，编译器就必须为此函数产生一个函数实体，无论如何，编译器无法交出一个“不存在函数”的指针。注意，有些编译器可能会使用类的constructors和destructors的函数指针，用以构造和析构一个class对象的数组。另外类的constructors和destructors可能简单，但是其父类的类的constructors和destructors可能是复杂的，所以<strong>类的constructors和destructors往往不是<code>inline</code>函数的最佳选择</strong>！</li>
  <li><strong><code>inline</code>虚函数往往是无效的。</strong>虚函数往往是运行时确定的，而<code>inline</code>是在编译时进行的，所以<code>inline</code>虚函数往往无效。当然如果直接用类的对象来使用虚函数，那么对有的编译器而言，也可起到优化的作用。</li>
  <li><strong><code>inline</code>函数无法调试。</strong>原因请参见上面编译器将函数<code>inline</code>的步骤。所以请在项目后期，<strong>对程序进行profile后，再决定将那些函数<code>inline</code>化。</strong></li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Large site technical architecture]]></title>
    <link href="http://billowkiller.github.io/blog/2013/12/31/large-site-technical-architecture/"/>
    <updated>2013-12-31T18:09:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/12/31/large-site-technical-architecture</id>
    <content type="html"><![CDATA[<p>本文是李智慧的<a href="http://book.douban.com/subject/25723064/">《大型网站技术架构》</a>的读书笔记。</p>

<p>何为架构，要有大局观，大局观就是提前预防掉那些通用的问题：高可用，工程化，伸缩性，扩展性。对应需要的能力：了解分布式的一些东西，了解项目的业务和流程和运维使之工程化，了解负载均衡，能够对业务的分割和代码的分层。 </p>

<p><img src="http://img3.douban.com/lpic/s27040583.jpg" height="250px" /></p>

<p>本书并没有什么特别的东西，且都比较泛，但是都是很实在的东西，而且能很好的组织起来，也不失为互联网架构的一张蓝图。另外本书还处处透露着一些为人处世的人生哲学，这也是我喜欢的。</p>

<!--more-->

<p>下面就先从目录部分总结勾勒一下蓝图，然后再摘抄一些自己喜欢的句子。</p>

<h2 id="section">蓝图部分</h2>

<ul>
  <li><strong>大型网站架构演化发展历程</strong>
    <ul>
      <li>初始阶段的网站架构
        <ul>
          <li>应用程序、数据库、文件等所有资源都在一台服务器上</li>
        </ul>
      </li>
      <li>应用服务和数据服务分离 </li>
      <li>使用缓存改善网站性能</li>
      <li>使用应用服务器集群改善网站的并发处理能力</li>
      <li>数据库读写分离</li>
      <li>使用反向代理和CDN加速网站响应	</li>
      <li>使用分布式文件系统和分布式数据库系统</li>
      <li>使用NoSQL和搜索引擎</li>
      <li>业务拆分</li>
      <li>分布式服务</li>
    </ul>
  </li>
  <li>
    <p><strong>网站架构模式</strong></p>

    <blockquote>
      <p>关于什么是模式，这个来自建筑学的词汇是这样定义的：“每一个模式描述了一个在我们周围不断重复发生的问题及该问题解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复工作”。模式的关键在于<strong>模式的可重复性</strong>，问题与场景的可重复性带来解决方案的可重复使用。
 - 分层
     - 将系统在横向维度上切分成几个部分，每个部分负责一部分相对比较单一的职责，然后通过上层对下层的依赖和调用组成一个完整的系统	 
 - 分割
     - 如果说分层是将软件在横向方面进行切分，那么分割就是在纵向方面对软件进行切分 
 - 分布式
     - 分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。 
 -  集群
 - 缓存
     - CDN、反向代理、本地缓存、分布式缓存
     - 28原理 
 -  异步
     - 降低软件耦合性<br />
 -  冗余，自动化，安全</p>
    </blockquote>
  </li>
  <li>大型网站核心架构要素
    <ul>
      <li>性能，可用性，伸缩性，扩展性，安全性</li>
    </ul>
  </li>
</ul>

<h3 id="section-1">网站的高性能架构</h3>
<ul>
  <li>网站性能测试
    <ul>
      <li>不同视角下的网站性能</li>
      <li>性能测试指标
        <ul>
          <li>响应时间、并发数、吞吐量、性能计数器（服务器或操作系统的一些数据指标）  </li>
        </ul>
      </li>
      <li>性能测试方法
        <ul>
          <li>性能测试、负载测试、压力测试、稳定性测试 </li>
        </ul>
      </li>
      <li>性能测试报告</li>
      <li>性能优化策略</li>
    </ul>
  </li>
  <li>Web前端性能优化
    <ul>
      <li>浏览器访问优化
        <ul>
          <li>减少http请求（合并请求）、使用浏览器缓存、压缩数据、CSS和JS顺序 </li>
        </ul>
      </li>
      <li>CDN加速 </li>
      <li>反向代理</li>
    </ul>
  </li>
  <li>应用服务器性能优化	
    <ul>
      <li>分布式缓存
        <ul>
          <li><strong>网站性能优化第一定律：优先考虑使用缓存优化性能</strong> </li>
          <li>缓存的本质是一个内存Hash表</li>
          <li>合理使用缓存：数据的读写比在2:1以上；数据不一致与脏读（应用要容忍一定时间的数据不一致）；缓存雪崩；缓存预热；缓存穿透</li>
          <li>架构方式有两种，一种是以<code>JBoss Cache</code>为代表的需要更新同步的分布式缓存，一种是以<code>Memcached</code>为代表的不互相通信的分布式缓存</li>
        </ul>
      </li>
      <li>异步操作
        <ul>
          <li>消息队列具有很好的消峰作用</li>
          <li>业务异步处理时候可能需要业务流程配合</li>
          <li><strong>任何可以晚点做的事情都应该晚点再做</strong> </li>
        </ul>
      </li>
      <li>使用集群</li>
      <li>代码优化
        <ul>
          <li>多线程，线程安全手段：将对象设计为无状态对象；使用局部对象；并发访问使用锁</li>
          <li>资源复用：单例模式和对象池</li>
          <li>数据结构</li>
          <li>垃圾回收 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>存储性能优化
    <ul>
      <li>机械硬盘vs. 固态硬盘</li>
      <li>B+树vs. LSM树</li>
    </ul>

    <p><img src="http://img1.tuicool.com/NbeUnm.jpg" alt="LSM树" />
  - RAID vs. HDFS</p>

    <p><img src="http://www.2cto.com/uploadfile/2013/1016/20131016045031342.jpg" alt="常用的RAID技术原理图" /></p>
  </li>
</ul>

<h3 id="section-2">网站的高可用架构</h3>

<ul>
  <li>高可用的应用	
    <ul>
      <li>通过负载均衡进行无状态服务的失效转移	</li>
      <li>应用服务器集群的Session管理	
        <ul>
          <li>Session复制</li>
          <li>Session绑定</li>
          <li>利用Cookie记录Session</li>
          <li>Session服务器 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>高可用的服务
    <ul>
      <li>分级管理，核心应用和服务优先使用更好的硬件</li>
      <li>超时设置</li>
      <li>异步调用，避免一个服务失败导致整个应用请求失败</li>
      <li>服务降级：拒绝服务和关闭服务</li>
      <li>幂等性设计 	</li>
    </ul>
  </li>
  <li>高可用的数据	
    <ul>
      <li><code>CAP</code>原理
        <ul>
          <li>在设计和部署分布式应用的时候，存在三个核心的系统需求，这个三个需求之间存在一定的特殊关系。三个需求如下：<code>Consistency</code>所有程序都能访问得到相同的数据; <code>Availability</code>任何时候，任何应用程序都可以读写访问; <code>Partition Tolerance</code>系统可以跨网络分区线性伸缩。</li>
          <li><code>CAP</code>理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。</li>
          <li>大型网站设计中，通常选择强化分布式存储系统的可用性(A)和伸缩性(P)，而在某种程度放弃一致性(C)
  <img src="http://hi.csdn.net/attachment/201109/6/0_1315316512jhTH.gif" alt="" /></li>
        </ul>
      </li>
      <li>数据备份
        <ul>
          <li>异步热备：写一份，存储系统异步写其他副本。Master-Slave</li>
          <li>同步热备：多份副本同步写入。传统的企业级关系数据库</li>
        </ul>
      </li>
      <li>失效转移
        <ul>
          <li>失效确认、访问转移、数据恢复 	</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>高可用网站的软件质量保证	
    <ul>
      <li>网站发布	</li>
      <li>自动化测试	</li>
      <li>预发布验证	</li>
      <li>代码控制
        <ul>
          <li>主干开发、分支发布</li>
          <li>分支开发、主干发布 	</li>
        </ul>
      </li>
      <li>自动化发布	</li>
      <li>灰度发布	</li>
    </ul>
  </li>
  <li>网站运行监控	
    <ul>
      <li>监控数据采集
        <ul>
          <li>用户行为日志收集，服务器端和客户端</li>
          <li>服务器性能监控</li>
          <li>运行数据报告，缓冲命中、平均响应延迟时间、每分钟发送邮件数目… </li>
        </ul>
      </li>
      <li>监控管理
        <ul>
          <li>系统报警，失效转移，自动降级 </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="section-3">网站的伸缩性架构</h3>

<blockquote>
  <p>所谓<strong>网站的伸缩性</strong>是指不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或缩小网站的服务处理能力。</p>
</blockquote>

<ul>
  <li>网站架构的伸缩性设计
    <ul>
      <li>不同功能进行物理分离实现伸缩
        <ul>
          <li>纵向分离（分层后分离）：将业务处理流程上的不同部分分离部署，实现系统伸缩性。</li>
          <li>横向分离（业务分割后分离）：将不同的业务模块分离部署，实现系统伸缩性。 </li>
        </ul>
      </li>
      <li>单一功能通过集群规模实现伸缩
        <ul>
          <li>应用服务器集群伸缩性、数据服务器集群伸缩性 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>应用服务器集群的伸缩性设计
    <ul>
      <li>HTTP重定向负载均衡</li>
      <li>DNS域名解析负载均衡	</li>
      <li>反向代理负载均衡</li>
      <li>IP负载均衡	</li>
      <li>数据链路层负载均衡
        <ul>
          <li>虚拟IP、LVS </li>
        </ul>
      </li>
      <li>负载均衡算法
        <ul>
          <li>轮询、加权轮询、随机、最少连接、源地址散列 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>分布式缓存集群的伸缩性设计
    <ul>
      <li>Memcached分布式缓存集群的访问模型
  <img src="http://blog.chinaunix.net/attachment/201211/20/27767798_1353432372hzgp.png" alt="" /> 
  Memcached依赖于libevent，网络模型是典型的reactor模式，主线程通过自己的<code>event_base</code>绑定端口监听网络中的连接。每个worker线程的初始任务就是轮询管道上的<code>notify_receive_fd</code>的读事件，如果有连接，主线程往相应的worker线程的管道的输入端<code>notify_send_fd</code>写入关键字‘c’，代表着网络上有新的连接要派发给worker线程，这样worker进程直接accept就能得到连接的fd了，同时把这个fd的读事件放到每个worker进程的<code>event_base</code>中，如图，每个worker的进程同时监听<code>notify_receive_fd</code>和外部连接的fd上的事件。每个worker都应该为连接上的fd分配一个conn结构体，这个结构体记录了这个连接全部的信息，如连接的fd，读写buf，操作的item，当前connection的状态等等。</li>
      <li>Memcached分布式缓存集群的伸缩性挑战
        <ul>
          <li>数据库的负载能力是以有缓存的前提而设计的，当大部分被缓存的数据因为服务器扩容而不能正确读取时，这些数据访问的压力就落到数据库身上，超过数据库负载能力，造成数据库宕机。</li>
        </ul>
      </li>
      <li>分布式缓存的一致性Hash算法</li>
    </ul>
  </li>
  <li>数据存储服务器集群的伸缩性设计
    <ul>
      <li>关系数据库集群的伸缩性设计</li>
      <li>NoSQL数据库的伸缩性设计</li>
    </ul>
  </li>
</ul>

<h3 id="section-4">网站的可扩展架构</h3>

<ul>
  <li>构建可扩展的网站架构
    <ul>
      <li>扩展性是对功能而言，应用之间较少依赖和耦合，对需求可以敏捷响应。</li>
      <li>伸缩性是以资源的规模换取处理事务的能力，更多表现在服务器数量，事务吞吐能力。</li>
      <li>设计网站可扩展性的核心是<strong>模块化</strong>，并在此基础上，减低模块间的耦合性，提高模块的复用性。	 </li>
    </ul>
  </li>
  <li>利用分布式消息队列降低系统耦合性
    <ul>
      <li>事件驱动架构</li>
      <li>分布式消息队列</li>
    </ul>
  </li>
  <li>利用分布式服务打造可复用的业务平台
    <ul>
      <li>Web Service与企业级分布式服务</li>
      <li>大型网站分布式服务的需求与特点
        <ul>
          <li>负载均衡、失效转移、高效的远程通信、整合异构系统、对应用最少侵入、版本管理、实时监控 </li>
        </ul>
      </li>
      <li>分布式服务框架设计</li>
    </ul>
  </li>
  <li>可扩展的数据结构</li>
  <li>利用开放平台建设网站生态圈</li>
</ul>

<h2 id="section-5">摘抄与处事哲学</h2>

<p>创新的业务发展模式对网站架构逐步提出更高要求，才使得创新的网站架构得以发展成熟。是业务成就了技术，是事业成就了人，而不是相反。所以网站架构师应该对成就自己技术成绩的网站事业心存感恩，并努力提高技术回馈业务，才能在快速发展的胡两位领域保持持续进步。</p>

<p>网站架构的几个设计误区</p>

<ul>
  <li>以为追随大公司的解决方案</li>
  <li>为了技术而技术</li>
  <li>企图用技术解决所有问题</li>
</ul>

<p>前沿技术总是出现在前沿业务领域。近几年，以Google为首的互联网企业领跑IT前沿技术潮流，是因为互联网企业的业务发展远超传统IT企业领域，面了更多挑战，对IT系统提出了更高的要求；新技术的出现又会驱动企业开展新的业务。亚马逊等互联网公司利用自己的技术优势进军企业级市场，以技术驱动业务，开展云计算、SaaS等新兴IT业务，逐步蚕食IBM、HP、Oracle、微软等传统软件巨头的市场。</p>

<p>好的设计绝对不是模仿、不是生搬硬套某个模式，而是在对问题深刻理解之上的创造与创新，即使是‘微创新’，也是让人耳目一新的似曾相识。山寨与创新的最大区别不在于是否抄袭、是否模仿，而在于对问题和需求是否真正理解与把握。</p>

<p>一个具有良好伸缩性架构设计的网站，其设计总是走在业务发展的前面，在业务需要处理更多访问和服务之前，就做好充足准备，当业务需要是时候，只需要购买或租用服务器简单部署实施就可以了，技术团队亦可以高枕无忧。反之，设计和技术走在业务的后面，采购来的机器根本就没有方法加入集群，勉强加了进去，却发现瓶颈不在这里，系统整体处理能力依然上不去。技术团队每天加班，却总是托公司发展的后退。架构师对网站伸缩性的把握，一线之间，天堂与地狱。</p>

<p>高手定律：这个世界只有遇不到的问题，没有解决不了的问题，高手之所以成为高手，是因为他们遇到了常人很难遇到的问题，并解决了。所以百度有很多广告搜索高手，淘宝有很多海量数据高手，腾讯有很多高并发业务的高手。</p>

<p>WikiPedia如果Master数据库宕机，立即将应用切换到Salve数据库，同时关闭数据写服务，意味着词条编辑功能关闭。WidiPedia通过约束业务获得更大的技术方案选择余地，很多时候业务后退一小步，技术就可以前进一大步。这个也是他们能够那么省钱的原因啊。</p>

<p>秒杀从根本上来讲并不是很难，首先是页面的静态化，开始秒杀的按钮通过js来实现，js不缓存，js尽量小。开始秒杀的时候使用可以秒杀的js。秒杀很少能达数据层，因为就那么几个能成功。主要的压力在应用服务器，但是用一个记数服务器，收到请求更新这个数字，大于数字的直接返回秒杀失败。所以大部分都会进入失败的逻辑，整个也很简单。只要业务服务器能抗住这些访问压力就基本ok了，如果业务服务器不够，可以直接在负载均衡那边随机失败一部分。 </p>

<hr />

<p>是事情成就了人，而不是人成就了事。</p>

<p>要想成就自己，就必须首先成就他人。我们工作不只是生成产品，还要成就人，并最终成就我们自己。关注人而不是产品。</p>

<p>学会妥协。很多时候，对架构和技术方案的反对意见，其实意味着架构和技术方案被关注、被试图理解和接受。架构师不应该对意见过于敏感，这时架构师应该做的事坦率地分享自己的设计思路，让别人理解自己的想法并努力理解别人的想法，求同存异。</p>

<p>新员工Tips</p>

<ul>
  <li>刚开始加入的时候不要急于证明自己，要先融入</li>
</ul>

<p>提出问题Tips</p>

<ul>
  <li>把“我的问题”表述成“我们的问题”</li>
  <li>给上司提出封闭式问题，给下属提出开放式问题</li>
  <li>指出问题而不是批评人，所谓直言有讳是指想要表达的意图要直截了当说明白，不要兜圈子，但是在表达方式上要有所避讳，照顾当事人的感受</li>
  <li>用赞同的方式提出问题</li>
</ul>

<p>解决问题Tips</p>

<ul>
  <li>在解决我的问题之前，先解决你的问题</li>
  <li>适当的逃避问题</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[gcc summary]]></title>
    <link href="http://billowkiller.github.io/blog/2013/12/31/gcc-summary/"/>
    <updated>2013-12-31T18:07:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/12/31/gcc-summary</id>
    <content type="html"><![CDATA[<p>本文介绍在Linux平台下应用程序的编译过程，以及编译程序<a href="http://gcc.gnu.org/">GCC</a>在编译应用程序的过程的具体用法，同时详细说明了GCC的常用选项、模式和警告选项。</p>

<p><img src="https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQkcpI6uyaKSbXltFKcLfpuPyMjC8aw-VZH7x9uUt8bFQMTpsczYg" alt="gcc" /></p>

<!--more-->

<h3 id="compile-process">Compile Process</h3>

<h4 id="four-steps">Four Steps</h4>

<p>对于GUN编译器来说，程序的编译要经历预处理、编译、汇编、连接四个阶段.</p>

<center>![四个阶段](http://new.51cto.com/files/uploadimg/20060926/1714230.jpg)</center>

<p>从功能上分，预处理、编译、汇编是三个不同的阶段，但<code>gcc</code>的实际操作上，它可以把这三个步骤合并为一个步骤来执行。下面我们以C语言为例来谈一下不同阶段的输入和输出情况。</p>

<p>在预处理阶段，输入的是C语言的源文件，通常为<code>*.c</code>。它们通常带有<code>.h</code>之类头文件的包含文件。这个阶段主要处理源文件中的<code>#ifdef</code>、 <code>#include</code>和<code>#define</code>命令。该阶段会生成一个中间文件<code>*.i</code>，但实际工作中通常不用专门生成这种文件，因为基本上用不到；若非要生成这种文件不可，可以利用下面的示例命令：</p>

<pre><code>gcc -E  test.c -o test.i
</code></pre>

<p>在编译阶段，输入的是中间文件<code>*.i</code>，编译后生成汇编语言文件<code>*.s</code> 。这个阶段对应的<code>gcc</code>命令如下所示：</p>

<pre><code>gcc -S test.i -o test.s 
</code></pre>

<p>在汇编阶段，将输入的汇编文件<code>*.s</code>转换成机器语言<code>*.o</code>。这个阶段对应的<code>gcc</code>命令如下所示：</p>

<pre><code>gcc -c test.s -o test.o 
</code></pre>

<p>最后，在连接阶段将输入的机器代码文件<code>*.s</code>（与其它的机器代码文件和库文件）汇集成一个可执行的二进制代码文件。这一步骤，可以利用下面的示例命令完成：</p>

<pre><code>gcc test.o -o test 
</code></pre>

<h4 id="two-modes">Two Modes</h4>

<p>gcc常用的两种模式：编译模式和编译连接模式。下面以一个例子来说明各种模式的使用方法。为简单起见，假设我们全部的源代码都在一个文件<code>test.c</code>中，要想把这个源文件直接编译成可执行程序，可以使用以下命令：</p>

<pre><code>gcc test.c -o test
</code></pre>

<p>这里<code>test.c</code>是源文件，生成的可执行代码存放在一个名为<code>test</code>的文件中（该文件是机器代码并且可执行）。<code>-o</code>是生成可执行文件的输出选项。如果我们只想让源文件生成目标文件（给文件虽然也是机器代码但不可执行），可以使用标记<code>-c</code>，详细命令如下所示：</p>

<pre><code>gcc -c test.c
</code></pre>

<p>默认情况下，生成的目标文件被命名为<code>test.o</code>，但我们也可以为输出文件指定名称，如下所示：</p>

<pre><code>gcc -c test.c -o mytest.o
</code></pre>

<p>上面这条命令将编译后的目标文件命名为<code>mytest.o</code>，而不是默认的<code>test.o</code>。</p>

<p>迄今为止，我们谈论的程序仅涉及到一个源文件；现实中，一个程序的源代码通常包含在多个源文件之中，这该怎么办？没关系，即使这样，用gcc处理起来也并不复杂，见下例：</p>

<pre><code>gcc -o test  first.c second.c third.c
</code></pre>

<p>该命令将同时编译三个源文件，即<code>first.c</code>、<code>second.c</code>和 <code>third.c</code>，然后将它们连接成一个可执行程序，名为<code>test</code>。</p>

<h3 id="compile-option">Compile Option</h3>

<h4 id="debug">Debug</h4>
<p>在<code>gcc</code>编译源代码时指定<code>-g</code>选项可以产生带有调试信息的目标代码,<code>gcc</code>可以为多个不同平台上帝不同调试器提供调试信息,默认<code>gcc</code>产生的调试信息是为<code>gdb</code>使用的,可以使用<code>-gformat</code>指定要生成的调试信息的格式以提供给其他平台的其他调试器使用.</p>

<p>常用的格式有 </p>

<ul>
  <li>-ggdb:生成gdb专 用的调试信息,使用最适合的格式(DWARF 2,stabs等)会有一些gdb专用的扩展,可能造成其他调试器无法运行. </li>
  <li>-gstabs:使用 stabs格式,不包含gdb扩展,stabs常用于BSD系统的DBX调试器. </li>
  <li>-gcoff:产生COFF格式的调试信息,常用于System V下的SDB调试器; </li>
  <li>-gxcoff:产生XCOFF格式的调试信息,用于IBM的RS/6000下的DBX调试器; </li>
  <li>-gdwarf-2:产生DWARF version2 的格式的调试信息,常用于IRIXX6上的DBX调试器.<code>gcc</code>会使用DWARF version3的一些特性. </li>
</ul>

<h4 id="common-option">Common Option</h4>

<p>–help&lt;/br&gt;
–target-help &lt;/br&gt;
显示 <code>gcc</code> 帮助说明。‘target-help’是显示目标机器特定的命令行选项。</p>

<p>–version &lt;/br&gt;
显示 <code>gcc</code> 版本号和版权信息 。</p>

<p>-o outfile &lt;/br&gt;
输出到指定的文件。</p>

<p>-x language &lt;/br&gt;
指明使用的编程语言。允许的语言包括：c c++ assembler none 。 ‘none’意味着恢复默认行为，即根据文件的扩展名猜测源文件的语言。</p>

<p>-v &lt;/br&gt;
打印较多信息，显示编译器调用的程序。</p>

<p>-### &lt;/br&gt;
与 -v 类似，但选项被引号括住，并且不执行命令。</p>

<p><strong>-E</strong>&lt;/br&gt;
仅作预处理，不进行编译、汇编和链接。如上图所示。</p>

<p>-S &lt;/br&gt;
仅编译到汇编语言，不进行汇编和链接。如上图所示。</p>

<p><strong>-c</strong> &lt;/br&gt;
编译、汇编到目标代码，不进行链接。如上图所示。</p>

<p>-pipe &lt;/br&gt;
使用管道代替临时文件。</p>

<p>-combine &lt;/br&gt;
将多个源文件一次性传递给汇编器。</p>

<h4 id="other-option">Other Option</h4>

<p>更多有用的<code>gcc</code>选项：</p>

<p>-l library&lt;/br&gt;
-llibrary &lt;/br&gt;
进行链接时搜索名为library的库。 &lt;/br&gt;
例子： $ <code>gcc</code> test.c -lm -o test</p>

<p>-Idir &lt;/br&gt;
把dir 加入到搜索头文件的路径列表中。 &lt;/br&gt;
例子： $ <code>gcc</code> test.c -I../inc -o test</p>

<p>-Ldir &lt;/br&gt;
把dir 加入到搜索库文件的路径列表中。 &lt;/br&gt;
例子： $ <code>gcc</code> -I/home/foo -L/home/foo -ltest test.c -o test</p>

<p>-Dname &lt;/br&gt;
预定义一个名为name 的宏，值为1。 &lt;/br&gt;
例子： $ <code>gcc</code> -DTEST_CONFIG test.c -o test</p>

<p>-Dname =definition &lt;/br&gt;
预定义名为name ，值为definition 的宏。</p>

<p>-ggdb &lt;/br&gt;
-ggdblevel &lt;/br&gt;
为调试器 gdb 生成调试信息。level 可以为1，2，3，默认值为2。</p>

<p>-g &lt;/br&gt;
-glevel &lt;/br&gt;
生成操作系统本地格式的调试信息。-g 和 -ggdb 并不太相同， -g 会生成 gdb 之外的信息。level 取值同上。</p>

<p>-s &lt;/br&gt;
去除可执行文件中的符号表和重定位信息。用于减小可执行文件的大小。</p>

<p>-M &lt;/br&gt;
告诉预处理器输出一个适合make的规则，用于描述各目标文件的依赖关系。对于每个 源文件，预处理器输出 一个make规则，该规则的目标项(target)是源文件对应的目标文件名，依赖项(dependency)是源文件中<code>#include</code>引用的所有文件。生成的规则可以是单行，但如果太长，就用<code>\</code>-换行符续成多行。规则 显示在标准输出，不产生预处理过的C程序。</p>

<p>-C &lt;/br&gt;
告诉预处理器不要丢弃注释。配合`-E’选项使用。</p>

<p>-P &lt;/br&gt;
告诉预处理器不要产生<code>#line</code>命令。配合<code>-E</code>选项使用。</p>

<p>-static &lt;/br&gt;
在支持动态链接的系统上，阻止连接共享库。该选项在其它系统上无效。</p>

<p>-nostdlib&lt;/br&gt; 
不连接系统标准启动文件和标准库文件，只把指定的文件传递给连接器。</p>

<h4 id="warnings-option">Warnings Option</h4>

<p>-Wall &lt;/br&gt;
会打开一些很有用的警告选项，建议编译时加此选项。</p>

<p>-W &lt;/br&gt;
-Wextra&lt;/br&gt; 
打印一些额外的警告信息。</p>

<p>-w &lt;/br&gt;
禁止显示所有警告信息。</p>

<p>-Wshadow &lt;/br&gt;
当一个局部变量遮盖住了另一个局部变量，或者全局变量时，给出警告。很有用的选项，建议打开。 -Wall 并不会打开此项。</p>

<p>-Wpointer-arith &lt;/br&gt;
对函数指针或者void *类型的指针进行算术操作时给出警告。也很有用。 -Wall 并不会打开此项。</p>

<p>-Wcast-qual &lt;/br&gt;
当强制转化丢掉了类型修饰符时给出警告。 -Wall 并不会打开此项。</p>

<p>-Waggregate-return &lt;/br&gt;
如果定义或调用了返回结构体或联合体的函数，编译器就发出警告。</p>

<p>-Winline &lt;/br&gt;
无论是声明为 inline 或者是指定了-finline-functions 选项，如果某函数不能内联，编译器都将发出警告。如果你的代码含有很多 inline 函数的话，这是很有用的选项。</p>

<p>-Werror &lt;/br&gt;
把警告当作错误。出现任何警告就放弃编译。</p>

<p>-Wunreachable-code&lt;/br&gt; 
如果编译器探测到永远不会执行到的代码，就给出警告。也是比较有用的选项。</p>

<p>-Wcast-align&lt;/br&gt; 
一旦某个指针类型强制转换导致目标所需的地址对齐增加时，编译器就发出警告。</p>

<p>-Wundef&lt;/br&gt;
当一个没有定义的符号出现在 #if 中时，给出警告。</p>

<p>-Wredundant-decls&lt;/br&gt; 
如果在同一个可见域内某定义多次声明，编译器就发出警告，即使这些重复声明有效并且毫无差别。</p>

<h4 id="standard">Standard</h4>

<p>-ansi &lt;/br&gt;
支持符合ANSI标准的C程序。这样就会关闭GNU C中某些不兼容ANSI C的特性。</p>

<p>-std=c89 &lt;/br&gt;
-iso9899:1990 &lt;/br&gt;
指明使用标准 ISO C90 作为标准来编译程序。</p>

<p>-std=c99 &lt;/br&gt;
-std=iso9899:1999 &lt;/br&gt;
指明使用标准 ISO C99 作为标准来编译程序。</p>

<p>-std=c++98 &lt;/br&gt;
指明使用标准 C++98 作为标准来编译程序。</p>

<p>-std=gnu9x &lt;/br&gt;
-std=gnu99 &lt;/br&gt;
使用 ISO C99 再加上 GNU 的一些扩展。</p>

<p>-fno-asm &lt;/br&gt;
不把asm, inline或typeof当作关键字，因此这些词可以用做标识符。用 <strong>asm</strong>， __inline__和__typeof__能够替代它们。 <code>-ansi</code> 隐含声明了<code>-fno-asm</code>。</p>

<p>-fgnu89-inline &lt;/br&gt;
告诉编译器在 C99 模式下看到 inline 函数时使用传统的 GNU 句法。</p>

<h4 id="c-options">C options</h4>

<p>-fsigned-char &lt;/br&gt;
-funsigned-char &lt;/br&gt;
把char定义为有/无符号类型，如同signed char/unsigned char。</p>

<p>-traditional &lt;/br&gt;
尝试支持传统C编译器的某些方面。详见GNU C手册。</p>

<p>-fno-builtin &lt;/br&gt;
-fno-builtin-function &lt;/br&gt;
不接受没有 <em>_builtin</em> 前缀的函数作为内建函数。</p>

<p>-trigraphs &lt;/br&gt;
支持ANSI C的三联符（ trigraphs）。`-ansi’选项隐含声明了此选项。</p>

<p>-fsigned-bitfields &lt;/br&gt;
-funsigned-bitfields &lt;/br&gt;
如果没有明确声明<code>signed</code>或<code>unsigned</code>修饰符，这些选项用来定义有符号位域或无符号位域。缺省情况下，位域是有符号的，因为它们继承的基本整数类型，如<code>int</code>，是有符号数。</p>

<p>-Wstrict-prototypes &lt;/br&gt;
如果函数的声明或定义没有指出参数类型，编译器就发出警告。很有用的警告。</p>

<p>-Wmissing-prototypes &lt;/br&gt;
如果没有预先声明就定义了全局函数，编译器就发出警告。即使函数定义自身提供了函数原形也会产生这个警告。这个选项 的目的是检查没有在头文件中声明的全局函数。</p>

<p>-Wnested-externs &lt;/br&gt;
如果某<code>extern</code>声明出现在函数内部，编译器就发出警告。</p>

<h4 id="c-options-1">C++ options</h4>

<p>-ffor-scope &lt;/br&gt;
从头开始执行程序，也允许进行重定向。</p>

<p>-fno-rtti &lt;/br&gt;
关闭对 dynamic_cast 和 typeid 的支持。如果你不需要这些功能，关闭它会节省一些空间。</p>

<p>-Wctor-dtor-privacy &lt;/br&gt;
当一个类没有用时给出警告。因为构造函数和析构函数会被当作私有的。</p>

<p>-Wnon-virtual-dtor &lt;/br&gt;
当一个类有多态性，而又没有虚析构函数时，发出警告。-Wall会开启这个选项。</p>

<p>-Wreorder &lt;/br&gt;
如果代码中的成员变量的初始化顺序和它们实际执行时初始化顺序不一致，给出警告。</p>

<p>-Wno-deprecated &lt;/br&gt;
使用过时的特性时不要给出警告。</p>

<p>-Woverloaded-virtual &lt;/br&gt;
如果函数的声明隐藏住了基类的虚函数，就给出警告。</p>

<p>Machine Dependent Options (Intel)&lt;/br&gt;</p>

<p>-mtune=cpu-type &lt;/br&gt;
为指定类型的 CPU 生成代码。cpu-type 可以是：i386，i486，i586，pentium，i686，pentium4 等等。</p>

<p>-msse &lt;/br&gt;
-msse2 &lt;/br&gt;
-mmmx &lt;/br&gt;
-mno-sse &lt;/br&gt;
-mno-sse2 &lt;/br&gt;
-mno-mmx &lt;/br&gt;
使用或者不使用MMX，SSE，SSE2指令。</p>

<p>-m32 &lt;/br&gt;
-m64 &lt;/br&gt;
生成32位/64位机器上的代码。</p>

<p>-mpush-args &lt;/br&gt;
-mno-push-args &lt;/br&gt;
（不）使用 push 指令来进行存储参数。默认是使用。</p>

<p>-mregparm=num &lt;/br&gt;
当传递整数参数时，控制所使用寄存器的个数。</p>

<h4 id="optimization-option">Optimization Option</h4>

<p>-O0 &lt;/br&gt;
禁止编译器进行优化。默认为此项。</p>

<p>-O&lt;/br&gt;
-O1&lt;/br&gt;
尝试优化编译时间和可执行文件大小。</p>

<p>-O2 &lt;/br&gt;
更多的优化，会尝试几乎全部的优化功能，但不会进行“空间换时间”的优化方法。</p>

<p>-O3 &lt;/br&gt;
在 -O2 的基础上再打开一些优化选项：-finline-functions， -funswitch-loops 和 -fgcse-after-reload 。</p>

<p>-Os &lt;/br&gt;
对生成文件大小进行优化。它会打开 -O2 开的全部选项，除了会那些增加文件大小的。</p>

<p>-finline-functions &lt;/br&gt;
把所有简单的函数内联进调用者。编译器会探索式地决定哪些函数足够简单，值得做这种内联。</p>

<p>-fstrict-aliasing &lt;/br&gt;
施加最强的别名规则（aliasing rules）。</p>

<p><code>gcc</code>默认提供了5级优化选项的集合: </p>

<ul>
  <li>-O0:无优化(默认)</li>
  <li>-O和-O1:使用能减少目标文件大小以及执行时间并且不会使编译时间明显增加的优化.在编译大型程序的时候会显著增加编译时内存的使用. </li>
  <li>-O2: 包含-O1的优化并增加了不需要在目标文件大小和执行速度上进行折衷的优化.编译器不执行循环展开以及函数内联.此选项将增加编译时间和目标文件的执行性 能. </li>
  <li>-Os:专门优化目标文件大小,执行所有的不增加目标文件大小的-O2优化选项.并且执行专门减小目标文件大小的优化选项. </li>
  <li>-O3: 打开所有-O2的优化选项并且增加 -finline-functions, -funswitch-loops,-fpredictive-commoning, -fgcse-after-reload and -ftree-vectorize优化选项. </li>
</ul>

<pre>
-O1包含的选项-O1通常可以安全的和调试的选项一起使用:
           -fauto-inc-dec -fcprop-registers -fdce -fdefer-pop -fdelayed-branch 
           -fdse -fguess-branch-probability -fif-conversion2 -fif-conversion 
           -finline-small-functions -fipa-pure-const -fipa-reference 
           -fmerge-constants -fsplit-wide-types -ftree-ccp -ftree-ch 
           -ftree-copyrename -ftree-dce -ftree-dominator-opts -ftree-dse 
           -ftree-fre -ftree-sra -ftree-ter -funit-at-a-time 
</pre>

<p>以下所有的优化选项需要在名字前加上-f,如果不需要此选项可以使用-fno-前缀 </p>

<ul>
  <li>defer-pop:延迟到只在必要时从函数参数栈中pop参数; </li>
  <li>thread-jumps:使用跳转线程优化,避免跳转到另一个跳转; </li>
  <li>branch-probabilities:分支优化; </li>
  <li>cprop-registers:使用寄存器之间copy-propagation传值; </li>
  <li>guess-branch-probability:分支预测; </li>
  <li>omit-frame-pointer:可能的情况下不产生栈帧; </li>
</ul>

<pre>
-O2:以下是-O2在-O1基础上增加的优化选项: 
           -falign-functions  -falign-jumps -falign-loops  -falign-labels 
           -fcaller-saves -fcrossjumping -fcse-follow-jumps  -fcse-skip-blocks 
           -fdelete-null-pointer-checks -fexpensive-optimizations -fgcse 
           -fgcse-lm -foptimize-sibling-calls -fpeephole2 -fregmove 
           -freorder-blocks  -freorder-functions -frerun-cse-after-loop 
           -fsched-interblock  -fsched-spec -fschedule-insns 
           -fschedule-insns2 -fstrict-aliasing -fstrict-overflow -ftree-pre 
           -ftree-vrp
</pre>

<p>cpu架构的优化选项,通常是-mcpu(将被取消);-march,-mtune </p>

<h3 id="warning-interpretation">Warning Interpretation</h3>

<ul>
  <li>unused-function:警告声明但是没有定义的static函数; </li>
  <li>unusedlabel:声明但是未使用的标签; </li>
  <li>unused-parameter:警告未使用的函数参数; </li>
  <li>unused-variable:声明但是未使用的本地变量; </li>
  <li>unused-value:计算了但是未使用的值; </li>
  <li>format:printf和scanf这样的函数中的格式字符串的使用不当; </li>
  <li>implicit-int:未指定类型; </li>
  <li>implicit-function:函数在声明前使用; </li>
  <li>charsubscripts:使用char类作为数组下标(因为char可能是有符号数); </li>
  <li>missingbraces:大括号不匹配; </li>
  <li>parentheses: 圆括号不匹配; </li>
  <li>return-type:函数有无返回值以及返回值类型不匹配; </li>
  <li>sequence-point:违反顺序点的代码,比如 a[i] = c[i++]; </li>
  <li>switch:switch语句缺少default或者switch使用枚举变量为索引时缺少某个变量的case; </li>
  <li>strictaliasing=n:使用n设置对指针变量指向的对象类型产生警告的限制程度,默认n=3;只有在-fstrict-aliasing设置的情况下有效; </li>
  <li>unknow-pragmas:使用未知的#pragma指令; </li>
  <li>uninitialized:使用的变量为初始化,只在-O2时有效; </li>
  <li>以下是在-Wall中不会激活的警告选项: </li>
  <li>cast-align:当指针进行类型转换后有内存对齐要求更严格时发出警告; </li>
  <li>signcompare:当使用signed和unsigned类型比较时; </li>
  <li>missing-prototypes:当函数在使用前没有函数原型时; </li>
  <li>packed:packed 是<code>gcc</code>的一个扩展,是使结构体各成员之间不留内存对齐所需的空间 ,有时候会造成内存对齐的问题; </li>
  <li>padded:也是<code>gcc</code>的扩展,使结构体成员之间进行内存对齐的填充,会 造成结构体体积增大. </li>
  <li>unreachable-code:有不会执行的代码时. </li>
  <li>inline:当inline函数不再保持inline时 (比如对inline函数取地址); </li>
  <li>disable-optimization:当不能执行指定的优化时.(需要太多时间或系统资源). </li>
  <li>可以使用 -Werror时所有的警告都变成错误,使出现警告时也停止编译.需要和指定警告的参数一起使用. </li>
</ul>

<h4 id="warning-multi-character-character-constant">1. Warning: multi-character character constant</h4>

<p>Could be suppressed by -Wno-multichar</p>

<p>There’re three kinds of character constants: Normal character constants, Multicharacter constants and Wide-character constants.</p>

<pre><code>char ch = 'a';
int mbch = '1234';
wchar_t wcch = L'ab';
</code></pre>

<p>Mbch is of type int(signed), has 4 meaningful characters.</p>

<p><code>gcc</code> compiler evaluates a multi-character character constant a character at a time, shifting the previous value left by the number of bits per target character, and then or-ing in the bit-pattern of the new character truncated to the width of a target character.</p>

<p>‘ab’ for a target with an 8-bit char would be interpreted as:</p>

<p>(int) ((unsigned char) ‘a’ * 256 + (unsigned char) ‘b’) = 97*256+98</p>

<p>‘1’,x          0x31
‘12’,x        0x3132
‘123’,x      0x313233
‘1234’,x    0x31323334</p>

<p>判断系统是big endian还是little endian的方法：</p>

<pre><code>if (('1234' &gt;&gt; 24) == '1')
{
    //Little endian
}
else if (('4321' &gt;&gt; 24) == '1')
{
    //Big endian
}
</code></pre>

<h4 id="warning-operation-on-xx-may-be-undefined">2. Warning: operation on xx may be undefined</h4>

<p>序列点问题。为什么 a[i] = i++; 不能正常工作？子表达式 i++ 有一个副作用，它会改变 i 的值。由于 i 在同一表达式的其它地方被引用，这会导致无定义的结果，无从判断该引用(左边的 a[i] 中)是旧值还是新值。(尽管 在 K&amp;R 中建议这类表达式的行为不确定，但 C 标准却强烈声明它是无定义的），具体实现取决于编译器。</p>

<h4 id="warning-conversion-to-xxx-from-yyy-may-alter-its-value">3.  Warning: conversion to xxx from yyy may alter its value</h4>

<p><code>gcc</code> promotes unsigned char/uint16_t/uint8_t  to type int for for all arithmetic. Need to apply static_cast&lt;&gt;.</p>

<h4 id="warning-function-might-be-possible-candidate-for-attribute-noreturn">4.  Warning: function might be possible candidate for attribute ‘noreturn’</h4>

<p>打开了 -Wmissing-noreturn。A few standard library functions, such as abort and exit, cannot return. <code>gcc</code> knows this automatically. With noreturn attribute it can then optimize without regard to what would happen if function ever did return. This makes slightly better code. More importantly, it helps avoid spurious warnings of uninitialized variables. The noreturn keyword does not affect the exceptional path. 给函数加上 <strong>attribute</strong>((noreturn)) 即可消除这个warning。</p>

<h4 id="warning-deprecated-conversion-from-string-constant-to-char-">5. Warning: deprecated conversion from string constant to “char *”</h4>

<p>void SomeFunc (char* str)
{
}</p>

<p>int _tmain(int argc, _TCHAR* argv[])
{
    SomeFunc(“Hello!”);
    return 0;
}</p>

<p>SomeFunc() 的输入时char<em>，含义是：给我个字符串，我要修改它。而传给它的字面常量是没办法修改的，将char</em> 改成 const char*，消除这个warning.</p>

<h4 id="warning-implicit-declaration-of-function-mallocfree-incompatible-implicit-declaration-of-built-in-function-mallocfree">6.  Warning: implicit declaration of function ‘malloc’/’free’, incompatible implicit declaration of built-in function ‘malloc’/’free’</h4>

<p>要显示的#include <stdlib.h></stdlib.h></p>

<h4 id="warning-dereferencing-type-punned-pointer-will-break-strict-aliasing-rules">7.  Warning: Dereferencing type-punned pointer will break strict-aliasing rules</h4>

<p>打开了-fstrict-aliasing and -Wstrict-aliasing. Suppress with -fno-strict-aliasing</p>

<p>Strict-aliasing rule: An object of one type is assumed never to reside at the same address as an object of a different type, unless the types are almost the same. 编译器希望不同类型的对象不会指向同一个地址。</p>

<h4 id="warning-inlining-failed-in-call-to-xxx-call-is-unlikely-and-code-size-would-grow">8.  Warning: inlining failed in call to xxx: call is unlikely and code size would grow</h4>

<p>打开了-Winline: Warn if a function can not be inlined and it was declared as inline. Even with this option, the compiler will not warn about failures to inline functions declared in system headers.</p>

<p>相关选项：</p>

<p>-fno-inline: Don’t compile statement functions inline. Might reduce the size of a program unit–which might be at expense of some speed (though it should compile faster). Note that if you are not optimizing, no functions can be expanded inline.</p>

<p>-finline-functions: Interprocedural optimizations occur. However, if you specify -O0, the default is OFF. Enables function inlining for single file compilation.</p>

<h4 id="warning-cannot-optimize-loop-the-loop-counter-may-overflow">9.  Warning: cannot optimize loop, the loop counter may overflow</h4>

<p>打开了-Wunsafe-loop-optimizations: Warn if the loop cannot be optimized because the compiler could not assume anything on the bounds of the loop indices. With -funsafe-loop-optimizations warn if the compiler made such assumptions.</p>

<p>相关选项：</p>

<p>-funsafe-loop-optimizations: Enable unsafe loop optimizations, e.g. assume loop indices never overflow, etc</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx architecture(4)--Modularity]]></title>
    <link href="http://billowkiller.github.io/blog/2013/11/26/nginx-architecture-4-modularity/"/>
    <updated>2013-11-26T16:52:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/11/26/nginx-architecture-4-modularity</id>
    <content type="html"><![CDATA[<h2 id="section">1. 概述</h2>

<p>这章的题目说的有些不对，nginx的模块化只是模块化编程的一个案例，我用它来分析所谓的模块化编程，接下来在其他的例子中也有体现模块化，但是为了形成nginx架构这一系列文章，我还是把它命名为nginx架构——模块化。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/nginx-logo_zpsabde8e46.png" /></p>

<!--more-->

<p>好了，言归正传。现代编程的一大特点是：模块化编程，具体来说就是好几个人来完成一个大的的功能：这一个大的功能又拆分为好几个子功能，每一个人做一块子功能，然后导出子功能的API,而大功能的运行实际上就变成子功能导出的API的相互调用。</p>

<p>换言之，模块化编程并不像我们以前开发的强耦合系统，从头到尾一步步或结构化或对象化的把系统功能添加到代码中，各个子功能之间协商好直接通信的接口——可以互相调用的API，子功能和子功能集成后，调试，运行成功就成了完整的系统。这样的系统可以做到软件代码紧凑，开发效率高，如果是互相熟悉，经验丰富实力强的开发团队，可以达到理想的开发速度，和代码质量。</p>

<p>但如果开发人员数量庞大且良莠不齐，那么核心开发者无法兼顾每个子系统的代码质量，一个子系统的失败也许会导致整个项目的失败，这种损失是无法估量的；如果需要开发的子系统纷杂繁多，这样的设计也无法满足日益增多的个性化子功能。</p>

<p>在这样的背景下，模块化编程是十分必要的。优秀的系统，生命周期长的系统，有革命意义的系统，如Linux、eclipse、NetBeans、nginx，它们所利用的都是模块化设计带来的红利，因为模块化系统有一下几个特点：</p>

<ol>
  <li>而模块化应用由小块的、分散的代码块组成，每一块都是独立的。于是，这些代码块可以由不同的团队进行开发，而他们都有各自的生命周期和时间表。最终的成果则可以由另一个独立的个体，即发行者，进行集成。</li>
  <li>应用程序（或操作系统）的源代码不再处于某一个开发者完全的掌控之中。源代码被散布至世界各地。毫无疑问，构建这样的软件与传统那种源代码完全在代码库的应用构建是完全不同的。</li>
  <li>管理者无需对整个项目的时间表有完全的掌控。不单单是源代码，开发者们也遍布世界各地，并以他们自己的时间表工作。每个人都有这样一个权利：使用一个新版本或旧版本类库的自由。</li>
  <li>使用外部库并使用它们组建应用程序，这意味着人们能够花费更少的时间和精力创造更复杂的软件。比如说，一个模块系统中的组件加入一个XML解析器，或者加入某种数据库驱动。</li>
</ol>

<p>ok，有了这样统一的一个认识后，再来具体谈谈什么是模块化编程。</p>

<h2 id="section-1">2.模块化编程</h2>

<p>百度百科对模块化设计有这样的定义
&gt; 模块化设计是指在对一定范围内的不同功能或相同功能不同性能、不同规格的产品进行功能分析的基础上，划分并设计出一系列功能模块，通过模块的选择和组合可以构成不同的产品，以满足市场的不同需求的设计方法。</p>

<p>它的概念是
&gt; 首先用主程序、子程序、子过程等框架把软件的主要结构和流程描述出来，并定义和调试好各个框架之间的输入、输出链接关系。逐步求精的结果是得到一系列以功能块为单位的算法描述。以功能块为单位进行程序设计，实现其求解算法的方法称为模块化。模块化的目的是为了降低程序复杂度，使程序设计、调试和维护等操作简单化。</p>

<p>这些说法似乎都不够接地气，但它们又能够很好的表现出模块化的特点：总体框架的制定，分功能块的设计减少耦合性，降低代码逻辑复杂性。在我看来，实现一个具有明显物理结构的软件是模块化的，例如带可扩展<code>插件</code>的<code>eclipse</code>；具有明显分层结构的软件是模块化的，例如<code>android</code>手机操作系统；具有明显封装性的软件是模块化的，例如图形引擎<code>OGRE</code>。</p>

<p><img src="https://community.freescale.com/servlet/JiveServlet/showImage/38-1135-1687/android_fig1.png" alt="android architecture" /></p>

<p>可以看出，这些软件都有一个特点：<strong>高对比度</strong>，不会和其他软件代码交杂混合，这可以带来很多显而易见的好处。在开发期，一个模块化的设计有利于程序员实现， 使其在实现过程中一直保持清晰的思路，减少潜伏的BUG；而在维护期，则有利于其他程序 员的理解。</p>

<p>从上面的几个例子中也可以看出，良好模块设计的代码，至少分为两种形式：纵向的模块化和横向的模块化。</p>

<p>横向：整个代码架构是由一个核心和若干外围的模块化代码构成。其中核心构成了软件的业务逻辑，子模块负责子功能的实现。核心和子模块之间有直接的接口，子模块间不需要或很少有交互需求。这样在功能的扩展上具有明显的优势，但对逻辑层的设计带来了更高的要求。</p>

<p>纵向：整个库/软件拥有明显的层次之分，从最底层，与应用业务毫无相关的一层，到最顶层，完全对应用进行直接实现的那一层，每一个相对高层的软件层依赖于更底层的软件层，逐层构建。同一层之中也有独立的子模块，子模块彼此之间耦合甚少，这些子模块构成了一个软件层，共同为上层应用提供服务。</p>

<p>下面就来举两个具体的例子。</p>

<h2 id="nginx">3.nginx的模块化</h2>

<p>网上看到的有关C语言模块化程序设计的一些概念，摘抄一下：</p>

<blockquote>
  <ol>
    <li>模块即是一个.c 文件和一个.h 文件的结合，头文件中是对于该模块接口的声明；</li>
    <li>某模块提供给其它模块调用的外部函数及数据需在.h 中文件中冠以<code>extern</code>关键字声明；</li>
    <li>模块内的函数和全局变量需在.c 文件开头冠以<code>static</code>关键字声明；</li>
    <li>永远不要在.h 文件中定义变量！定义变量和声明变量的区别在于定义会产生内存分配的操作，是汇编阶段的概念；而声明则只是告诉包含该声明的模块在连接阶段从其它模块寻找外部函数和变量。</li>
  </ol>
</blockquote>

<p>意思是暴露在头文件中的信息，则可能被当作该头文件所描述模块的接口描述。所以， 在C语言中任何置于头文件中的信息都需要慎重考虑。</p>

<p>C中默认的作用域是全局的，<code>static</code>用于限定其修饰对象的作用域，用它去修饰某个函数或变量，旨在告诉：这个函数或变量仅被当前文件（模块）使用，它仅用于本模块实现所依赖，它不是提供给模块外的接口！ <strong>封装内部实现 ，暴露够用的接口，也是保持模块清晰的方式之一。</strong></p>

<p>C语言较缺乏模块设计的语言机制——良好的接口封装。所以，在C语言中，良好的设计更依赖于程序员自己的功底。</p>

<p>nginx就是一个十分优秀的模块化编程的C语言实现，在nginx中，除了少量的核心代码，其他一切皆为模块。并且模块对使用用户只是暴露了很少的接口或者说指令更合适。nginx的每个模块都可以实现一些自定义的指令，这些指令写在配置文件的适当配置项中，每一个指令在源码中对应着一个 <code>ngx_command_t</code>结构的变量，nginx会从配置文件中把模块的指令读取出来放到模块的commands指令数组中，这些指令一般是把配置项的参数值赋给一些程序中的变量或者是在不同的变量之间合并或转换数据。</p>

<p>并且nginx的模块与模块间基本上没有任何的通信措施，拿最常用的http模块来说（这里的http模块是一个泛类，nginx中将模块分为core、event、http和mail四类，用宏定义标识四个分类）。根据使用的情况不同，http模块可以分为处理模块和过滤模块，处理模块用于处理请求并输出内容，过滤模块用于过滤处理模块的输出内容。处理模块在一个请求中只能使用1种，而过滤模块可以使用多个。那么这里要考虑的是，处理模块和核心代码，过滤模块和核心代码，处理模块和过滤模块，过滤模块和过滤模块之间的交互。实际上，过滤模块是用链表串联起来的，而处理模块与过滤模块在不同的阶段处理数据内容，所以现在只需要考虑前两者的交互手段。</p>

<p>以上的特点和需求都可以在nginx的模块化架构最基本的数据结构为<code>ngx_module_t</code>中得到体现。这个数据结构是所有模块的共同基础，类似于Java中的接口。</p>

<p>先来看看nginx的模块化架构最基本的数据结构为<code>ngx_module_t</code>，在系列文章1中有简略的介绍，现在看看具体的代码。</p>

<pre><code>struct ngx_module_s{
   ngx_uint_t    ctx_index;  //分类模块计数器
   ngx_uint_t    index;      //模块计数器

   ngx_uint_t    spare0;
   ngx_uint_t    spare1;
   ngx_uint_t    spare2;
   ngx_uint_t    spare3;

   ngx_uint_t    version;    //版本

   void          *ctx;       //该模块的上下文，每个种类的模块有不同的上下文
   ngx_command_t *commands;  //该模块的命令集，指向一个ngx_command_t结构数组
   ngx_uint_t    type;       //该模块的种类，为core/event/http/mail中的一种
   //以下是一些callback函数
   ngx_uint_t    (*init_master)(ngx_log_t *log);      //初始化master

   ngx_uint_t    (*init_module)(ngx_cycle_t *cycle);  //初始化模块

   ngx_uint_t    (*init_process)(ngx_cycle_t *cycle); //初始化工作进程
   ngx_uint_t    (*init_thread)(ngx_cycle_t *cycle);  //初始化线程
   void          (*exit_thread)(ngx_cycle_t *cycle);  //退出线程
   void          (*exit_process)(ngx_cycle_t *cycle); //退出工作进程

   void          (*exit_master)(ngx_cycle_t *cycle);  //退出master

   uintptr_t     spare_hook0;  //这些字段貌似没用过
   uintptr_t     spare_hook1;
   uintptr_t     spare_hook2;
   uintptr_t     spare_hook3;
   uintptr_t     spare_hook4;
   uintptr_t     spare_hook5;
   uintptr_t     spare_hook6;
   uintptr_t     spare_hook7;
};
</code></pre>

<p>在这些回调函数中有初始化模块的回调函数，在这个回调函数中可以注册模块自身实现的其他函数。在核心代码中，http框架将http的处理阶段分为多个，每个阶段都有phase_handler成员，可以通过初始化时赋值给这个成员来达到注册的效果。这样在处理这个阶段内容的时候，自然就会调用模块实现的方法。</p>

<p>对于过滤模块来说实现机制却又有些不同，前面提到过滤模块是用链表串联起来的，核心代码在遍历过滤链表的时候触发回调函数。每个过滤模块需要实现两个回调函数，类似于：</p>

<pre><code>ngx_int_t
ngx_http_send_header(ngx_http_request_t *r)
{
    ...
	return ngx_http_top_header_filter(r);
}

static int
ngx_http_example_body_filter(ngx_http_request_t *r, ngx_chain_t *in)
{
    ...
    return ngx_http_next_body_filter(r, in);
}
</code></pre>

<p>分别用来过滤响应头和内容。注意这里面的<code>ngx_http_top_header_filter</code>和<code>ngx_http_next_body_filter</code>，这里可以看出来，各个模块是由它们是由链表串联起来的，那么是怎么实现这个过程的呢，也就是如何注册过滤模块到核心代码中的链表的。</p>

<p>编译后可以找到<code>ngx_modules.c</code>文件，里面规定了一个数组</p>

<pre><code>ngx_module_t *ngx_modules[] = {
        ...
        &amp;ngx_http_write_filter_module,
        &amp;ngx_http_header_filter_module,
        &amp;ngx_http_chunked_filter_module,
        &amp;ngx_http_range_header_filter_module,
        &amp;ngx_http_gzip_filter_module,
        &amp;ngx_http_postpone_filter_module,
        &amp;ngx_http_ssi_filter_module,
        &amp;ngx_http_charset_filter_module,
        &amp;ngx_http_userid_filter_module,
        &amp;ngx_http_headers_filter_module,
        &amp;ngx_http_copy_filter_module,
        &amp;ngx_http_range_body_filter_module,
        &amp;ngx_http_not_modified_filter_module,
        NULL
};
</code></pre>

<p>模块的执行顺序是反向的。也就是说最早执行的是<code>not_modified_filter</code>，然后各个模块依次执行。所有第三方的模块只能加入到<code>copy_filter</code>和<code>headers_filter</code>模块之间。</p>

<p>Nginx执行的时候是怎么安照次序依次来执行各个模块呢？它采用了一种很隐晦的方法，通过局部的全局变量。比如，在每个filter模块，很可能看到如下代码：</p>

<pre><code>static ngx_http_output_header_filter_pt  ngx_http_next_header_filter;
static ngx_http_output_body_filter_pt    ngx_http_next_body_filter;
...
ngx_http_next_header_filter = ngx_http_top_header_filter;
ngx_http_top_header_filter = ngx_http_example_header_filter;

ngx_http_next_body_filter = ngx_http_top_body_filter;
ngx_http_top_body_filter = ngx_http_example_body_filter;
</code></pre>

<p><code>ngx_http_top_header_filter</code>是一个全局变量。当编译进一个filter模块的时候，就被赋值为当前filter模块的处理函数。而<code>ngx_http_next_header_filter</code>是一个局部全局变量，它保存了编译前上一个filter模块的处理函数。所以整体看来，就像用全局变量组成的一条单向链表。</p>

<p>每个模块想执行下一个过滤函数，只要调用一下<code>ngx_http_next_header_filter()</code>这个局部变量。而整个过滤模块链的入口，只要调用<code>ngx_http_top_header_filter</code>这个全局变量就可以了。<code>ngx_http_top_body_filter</code>的行为与header fitler类似。</p>

<p>所以nginx的模块化可以概括为</p>

<ol>
  <li>核心代码+模块，核心代码负责处理流程的业务逻辑，模块代码负责实现功能。</li>
  <li>核心代码在处理业务逻辑时候用全局字段保留信息，用统一的结构体传递信息，用相同的名称调用回调函数。</li>
  <li>模块代码采用统一的数据结构，结构中包括统一变量和回调函数，以及与模块上下文相关的保留字段。</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx architecture(3)--memory pool]]></title>
    <link href="http://billowkiller.github.io/blog/2013/11/14/nginx-architecture-3-memory-pool/"/>
    <updated>2013-11-14T15:12:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/11/14/nginx-architecture-3-memory-pool</id>
    <content type="html"><![CDATA[<h2 id="section">1. 概述</h2>

<p>Nginx里内存的使用大都十分有特色：申请了永久保存，抑或伴随着请求的结束而全部释放，还有写满了缓冲再从头接着写。这么做的原因也主要取决于Web Server的特殊的场景，内存的分配和请求相关，一条请求处理完毕，即可释放其相关的内存池，降低了开发中对内存资源管理的复杂度，也减少了内存碎片的存在。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/nginx_zps7d735b88.jpg" alt="Nginx logo" /></p>

<!--more-->

<p>所以在Nginx使用内存池时总是只申请，不释放，使用完毕后直接destroy整个内存池。</p>

<p>Nginx的内存模型实现得很精巧，代码也很简洁。总体来说，所有的内存池遵守一个宗旨：申请大块内存，避免“细水长流”。主要实现代码在<code>ngx_palloc.h</code>和<code>ngx_palloc.c</code>文件中。使用内存池的好处是：</p>

<ol>
  <li>在大量的小块内存的申请和释放的时候，能更快地进行内存分配；</li>
  <li>减少内存碎片，防止内存泄露；</li>
</ol>

<p>这种方式处理起来缺点也是显而易见的，即申请一块大的内存比如会导致内存空间的浪费，但是比起频繁地<code>malloc</code>和<code>free</code>，这样做的代价是非常小的，典型的以空间换时间的做法。</p>

<h2 id="section-1">2. 内存分配</h2>

<p>nginx内存分配将内存需求分成了两种：a) 大块内存, b) 小内存。内存大小的判定依据是申请的内存是否比同页大小与pool的size两者都小。</p>

<p>对于大块内存，单独利用malloc来申请，并且使用单向链表管理起来；</p>

<p>对于小块内存，则从已有的pool数据区中划分出一部分出来，这里的内存划分出去后没有特殊的结构来保存，而是等到申请对象生命周期结束后一起释放。小块内存的存储方式非常类似于sk_buffer，通过tail，end指针来表示多少内存已经被分配出去。</p>

<p>下图是linux kernel中数据结构sk_buff的使用示意图。具体可见<a href="http://linux.chinaunix.net/techdoc/system/2008/08/04/1023273.shtml">http://linux.chinaunix.net/techdoc/system/2008/08/04/1023273.shtml</a>
<img src="http://blogimg.chinaunix.net/blog/upfile/070330110745.jpg" alt="linux kernel struct sk_buff" /></p>

<p>nginx中分配内存时总是先判断申请内存是否属于大块内存，如果是则调用<code>ngx_palloc_large</code>申请大内存；如果是小内存则在已经存在的内存池中分配。</p>

<p>内存池的作用在于解决小块内存池频繁申请问题，对于大块内存是可以忍受直接申请的，这块内存会直接挂在内存池头部的large字段下。nginx中每块大内存都对应有一个头部结构，这个头部结构式用来将所有大内存串成一个链表用的。这个头部结构不是直接向操作系统申请的，而是单做小块内存直接在内存池中申请的。这样的大块内存在使用完后，可能需要第一时间释放，节省内存空间。</p>

<p>nginx专门提供了接口函数用来释放内存池中的某个大块内存，但它只会释放大内存，不会释放其对应的头部结构，毕竟头部结构式当做小内存在内存池中申请的；遗留下来的头部结构会作为下次申请大内存之用。</p>

<p><img src="http://blog.chinaunix.net/attachment/201306/16/24830931_1371367358NKxn.jpg" alt="nginx内存分配流程" /></p>

<h2 id="section-2">3. 深入内存池</h2>

<p>先来看看内存池中的数据结构以及之间关系的示意图。</p>

<p><img src="http://images.cnblogs.com/cnblogs_com/xiekeli/201210/201210171140226537.png" alt="" /></p>

<p>从这张图中可以看到<code>ngx_pool_data_t</code>和<code>ngx_pool_s</code>的结构。可以看出，nginx的内存池实际是一个由<code>ngx_pool_data_t</code>和<code>ngx_pool_s</code>构成的链表。</p>

<p>主要的数据结构为：</p>

<pre><code>`ngx_pool_data_t`中：

last：是一个unsigned char 类型的指针，保存的是当前内存池分配到末位地址，即下一次分配从此处开始。

end：内存池结束位置；

next：内存池里面有很多块内存，这些内存块就是通过该指针连成链表的，next指向下一块内存。

failed：内存池分配失败次数。
</code></pre>

<hr />

<pre><code>`ngx_pool_s`

d：内存池的数据块；

max：内存池数据块的最大值；

current：指向当前内存池；

chain：该指针挂接一个ngx_chain_t结构；

large：大块内存链表，即分配空间超过max的情况使用；

cleanup：释放内存池的callback

log：日志信息
</code></pre>

<p>以上是内存池涉及的主要数据结构，内存池对外的主要方法有：</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>创建内存池</strong></td>
      <td> </td>
      <td>ngx_pool_t *  ngx_create_pool(size_t size, ngx_log_t *log);</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><strong>销毁内存池</strong></td>
      <td> </td>
      <td>void ngx_destroy_pool(ngx_pool_t *pool);</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><strong>重置内存池</strong></td>
      <td> </td>
      <td>void ngx_reset_pool(ngx_pool_t *pool);</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><strong>内存申请（对齐）</strong></td>
      <td> </td>
      <td>void *  ngx_palloc(ngx_pool_t *pool,  size_t size);</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><strong>内存申请（不对齐）</strong></td>
      <td> </td>
      <td>void *  ngx_pnalloc(ngx_pool_t *pool, size_t size);</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td><strong>内存清除</strong></td>
      <td> </td>
      <td>ngx_int_t  ngx_pfree(ngx_pool_t *pool, void *p);</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>需要说明的是，内存池中并没有真正意义调用malloc等函数申请内存，而是移动指针标记而已，所以<code>内存对齐</code>的活，C编译器帮不了你了，得自己动手。并且不同的操作系统对齐方式不同。</p>

<p>这几个函数具体的功能可以见<a href="http://www.cnblogs.com/xiekeli/archive/2012/10/17/2727432.html">http://www.cnblogs.com/xiekeli/archive/2012/10/17/2727432.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx architecture(2)--Event Driven]]></title>
    <link href="http://billowkiller.github.io/blog/2013/11/14/nginx-architecture-2-event-driven/"/>
    <updated>2013-11-14T00:16:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/11/14/nginx-architecture-2-event-driven</id>
    <content type="html"><![CDATA[<p>Nginx是一个事件驱动架构的Web服务器。在Linux中，<code>epoll</code>是目前最强大的事件管理机制(I/O多路复用)，定时器事件也是由<code>epoll</code>等事件模块触发的，它是由红黑树实现的。并且Nginx很好的解决多个<code>worker</code>子进程监听同一个端口引起的惊群问题，以及对<code>worker</code>进行负载平衡。最后会讨论下linux内核中的文件异步I/O。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/nginx-logo_zpsabde8e46.png" /></p>

<!--more-->

<h2 id="section">1. 框架概述</h2>

<p>关于事件驱动模型的介绍已经在上篇介绍过了，这里再做一些补充说明。</p>

<p>事件处理框架所要解决的问题是如何收集、管理、分发事件。对于一个基本的web服务器来说，事件通常有三种类型，<strong>网络事件</strong>、<strong>信号</strong>、<strong>定时器</strong>。这里的事件主要是指<code>网络事件</code>（TCP事件）和<code>定时器事件</code>。</p>

<p>网络事件与网卡中断处理程序、内核提供的系统调用密切相关，所以网络事件的驱动受制于不用的操作系统平台，在同一个操作系统中也受制于不同的操作系统内核版本。例如在<code>kernel2.6</code>之前的版本或者大部分类UNIX系统都可以使用<code>poll</code>或<code>select</code>，而2.6后使用<code>epoll</code>。</p>

<p>对比与传统的过程驱动方法(Process-driven method)来说，事件驱动模型可以用更少的线程处理更多的客户请求。</p>

<h3 id="section-1">1.1 事件定义与事件模块</h3>

<p>事件代表过去发生的事件，事件既是技术架构概念，也是业务概念。以事件为驱动的编程模型称为事件驱动架构EDA。</p>

<p>一个事件代表某个发生的事情，在计算机系统中，事件是由一个对象表达，其包含有关事件的数据，比如发生的时间，地点等等。这个事件对象可以存在在一个消息或数据库记录或其他组件的形式中，这样一个对象称为”一个事件”，事件这个概念有两个含义，既代表已经发生的某个事情，也可以表达一个正在发生的对象。至于事件到底是这两个含义中哪一个，取决于事件发生的场景(上下文)。</p>

<p>事件在技术架构上应用能提供无堵塞的高并发性能，如Nginx和<code>Node.js</code>。</p>

<p>所谓事件驱动，简单地说就是你点什么按钮（即产生什么事件），电脑执行什么操作（即调用什么函数）.当然事件不仅限于用户的操作. 事件驱动的核心自然是事件。从事件角度说，事件驱动程序的基本结构是由一个事件收集器、一个事件发送器和一个事件处理器组成。事件收集器专门负责收集所有事件，包括来自用户的（如鼠标、键盘事件等）、来自硬件的（如时钟事件等）和来自软件的（如操作系统、应用程序本身等）。事件发送器负责将收集器收集到的事件分发到目标对象中。事件处理器做具体的事件响应工作，它往往要到实现阶段才完全确定，因而需要运用虚函数机制（函数名往往取为类似于HandleMsg的一个名字）。对于框架的使用者来说，他们唯一能够看到的是事件处理器。这也是他们所关心的内容。</p>

<p>视图（即我们通常所说的“窗口”）是“事件驱动”应用程序的另一个要元。它是我们所说的事件发送器的目标对象。视图接受事件并能够对其进行处理。当我们将事件发送到具体的视图时，实际上我们完成了一个根本性的变化：从传统的流线型程序结构到事件触发方式的转变。这样应用程序具备相当的柔性，可以应付种种离散的、随机的事件。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/ev-server_zps36dcc97a.png" /></p>

<p>在Nginx中，事件都是由<code>ngx_event_t</code>结构体来表示，这个结构体包含了事件的几个要素，方法、状态、参数以及前后事件的链表。</p>

<p>事件模块是一种新的模块类型，<code>ngx_module_t</code>表示Nginx模块的基本接口，而针对每一种不同类型的模块，都有一个结构体来描述这一类模块的通用接口，这个接口保存在<code>ngx_module_t</code>结构体中的<code>ctx</code>成员中。也就是说，不同模块类型的区别就是<code>ctx</code>成员保存内容的区别，而模块还是在一个统一的结构体中表示。事件模块的通用接口则<code>ngx_event_module_t</code>结构体，它里面定义了模块名称、配置项参数的回调函数以及每个事件模块需要实现的10个抽象方法，如初始化添加删除事件等。</p>

<h3 id="nginx">1.2 Nginx事件驱动机制</h3>

<p>在上一篇中提到，Nginx将HTTP请求分为多个阶段进行处理</p>

<table>
  <tbody>
    <tr>
      <td> </td>
      <td><strong>阶段意义</strong></td>
      <td> </td>
      <td><strong>触发条件</strong></td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>建立TCP连接</td>
      <td> </td>
      <td>接收到TCP中的SYN包</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>开始接受用户请求</td>
      <td> </td>
      <td>接收到TCP中的ACK表示连接建立成功</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>接收到用户请求并分析已接收的请求是否完整</td>
      <td> </td>
      <td>接收到用户的数据包</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>接收到完整的用户请求后开始处理用户请求</td>
      <td> </td>
      <td>接收到用户的数据包</td>
      <td> </td>
    </tr>
    <tr>
      <td> </td>
      <td>…</td>
      <td> </td>
      <td>…</td>
      <td> </td>
    </tr>
  </tbody>
</table>

<p>而异步处理是与多阶段相辅相成的，当事件发生时，由<code>epoll</code>等事件分发器收到通知，调用事件消费者处理请求，在每个阶段中，事件消费者都不清楚本次完整的操作纠结什么时候会完成，只能异步被动地等待下一次时间的通知。</p>

<p>这种设计配合事件驱动架构，将会极大地提高网络性能，同时使得进程不会或很少出现休眠现象。因为一旦出现进程休眠，必然减少并发处理事件的数目，一定会降低网络性能，同时会增加请求处理时间的平均时延！这时，如果网络新能无法满足业务需求将智能增加进程数目，进程数目过多就会增加操作系统内核的额外操作：进程间切换，频繁地进行进程切换仍会消耗CPU等资源，从而减低网络性能。同时，休眠的进程会使进程占用的内存得不到有效是否，这最终比如会导致系统可用内存的下降，从而影响系统能够处理的最大并发连接数。</p>

<p>另外，异步非阻塞的事件处理机制与多线程相比，是有很大的优势的，不需要创建线程，每个请求占用的内存也很少，没有上下文切换，事件处理非常的轻量级。并发数再多也不会导致无谓的资源浪费（上下文切换）。更多的并发数，只是会占用更多的内存而已。 我之前有对连接数进行过测试，在24G内存的机器上，处理的并发请求数达到过200万。现在的网络服务器基本都采用这种方式，这也是Nginx性能高效的主要原因。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/mighttpd_e02gif_zpse3ff26a7.gif" /></p>

<h2 id="linuxepoll">2. Linux事件驱动机制——<code>epoll</code></h2>

<p>事件驱动机制也被称为I/O多路复用，其实也就是非阻塞的I/O。<code>poll</code>、<code>select</code>和<code>epoll</code>的功能在本质上是一样的：都允许进程决定是否可以对一个和多个打开文件做非阻塞操作的读取和写入。这些调用也会阻塞进程，直到给定的文件描述符集合中的任何一个可读取或写入。因此，它们常常用于那些要使用多个输入和输出流而又不会阻塞阻于其中任何一个流的应用程序程序中。同一功能之所以要多个独立函数提供，是因为其中两个几乎是同时由两个不同的unix团体分别实现的：<code>select</code>在<code>BSD unix</code>中引入，而<code>poll</code>由<code>System V</code>引入。<code>epoll</code>系统调用，它用于将poll函数的扩展到能个处理数千个文件描述符。对上述系统调用的支持需要来自设备的驱动程序的相应支持。所有三个系统均通过驱动程序的<code>poll</code>方法提供。</p>

<p><code>select</code>和<code>poll</code>在处理事件的时候会造成用户态到内核态内存的大量复制，这是极大的资源浪费。实际上，它会将所有连接的套接字传给操作系统，如果有100万个连接，在某一个时刻，进程收集事件连接的时候，虽然这100万连接中大部分是没有发生的，但<code>select</code>和<code>poll</code>还是会将这100万连接的套接字传给操作系统，而由操作系统内核寻找这些连接上有没有未处理的时间，这是极大的资源浪费，所以它们最多只能处理几千个并发连接。</p>

<p>而<code>epoll</code>不这么做，它在内核中申请了一个简易的文件系统，把原先的一个select或poll调用分成了3个部分：调用<code>epoll_create</code>,建立1个<code>epoll</code>对象（在<code>epoll</code>文件系统中给这个句柄分配资源）、调用<code>epoll_ctl</code>向<code>epoll</code>对象中添加这100万个连接的套接字、调用<code>epoll_wait</code>收集发生事件的连接。这样，只需要在进程启动时建立1个<code>epoll</code>对象，并在需要的时候向它添加或删除连接就可以了。那么再来看看<code>epoll</code>是如何高效的处理事件的。</p>

<p>当某一个进程调用<code>epoll_create</code>方法时，Linux内核会创建一个<code>eventpoll</code>结构体，这个结构体有一棵红黑树（存储所有添加到<code>epoll</code>中过的事件），还有一个双向链表（保持将要通过<code>epoll_wait</code>返回给用户的、满足条件的事件）。所有添加到<code>epoll</code>中的事件都会与设备驱动程序建立回调关系，这个回调方法会把这样的事件放到上面的双向链表中。当调用<code>epoll_wait</code>检测是否有发生事件的连接时，只是检查<code>eventpoll</code>对象中的双向链表是否有元素而已，如果不为空，则把这里的事件复制到用户内存中，同时将时间数量返回给用户。</p>

<p>所以在<code>epoll</code>中，<code>epoll_ctl</code>向<code>epoll</code>对象中添加、修改、删除事件时，从红黑树中查找事件非常快，同时<code>epoll_wait</code>检查事件的效率也是非常的高。可以处理百万级别的并发事件。</p>

<h2 id="section-2">3. 定时器事件</h2>

<p>要弄清Nginx的定时器事件处理，那么需要搞清楚几个问题：</p>

<ol>
  <li>定时器事件是如何组织起来的</li>
  <li>事件超时后又是如何触发的</li>
  <li>时间又是如何更新的</li>
</ol>

<p>出于性能原因，Nginx的时间是缓存在内存中，不是每次都通过<code>gettimeofday</code>这个系统函数来实现。在Nginx中，只有在初始化和更新这个缓存时间的时候才会调用<code>gettimeofday</code>。在内存中可以通过各种已经定制好的格式化方法格式化需要转换的时间。</p>

<p>所有的定时器事件是通过红黑树组织起来的。红黑树用事件的超时时间作为关键字，并且以这个关键字组成二叉排序树。这样需要找出最有可能的超时事件，那么只要将最左边的节点取出来即可，可以判断这个时间是否超时或者还需要多久才会超时。红黑树定时器处理添加删除外，还提供了一些方法可以遍历所有的事件，触发事件的<code>handler</code>回调方法。那么何时调用这些方法呢？</p>

<p>首先在程序开始的时候会检测配置选项中是否有<code>timer_resolution</code>这一项内容即用户希望服务器时间精确度是多少毫秒，如果有则采用这个设置项作为阈值时间<code>timer</code>；如果没有设置这一选项，则在红黑树中寻找最近可能发生事件的时间差，以这个时间作为<code>timer</code>。<code>timer</code>也就是用来收集<code>epoll</code>监控事件是否发生的阈值时间，即如果<code>epoll</code>中没有任何一个事件发生，则最多等待<code>timer</code>毫秒后返回。也就是说如果是通过红黑树中找到的<code>timer</code>则肯定会有事件发生，如果是通过<code>timer_resolution</code>赋值的则不一定。</p>

<p>收集来的事件放在队列中按<code>FIFO</code>顺序处理。而如果收集事件消耗的时间大于0，也就是有等待事件发生，那么这时有可能有新的定时器事件被触发，也就需要遍历所有的时间，触发事件的<code>handler</code>回调方法。</p>

<h2 id="section-3">4. 惊群问题</h2>

<p>惊群问题（Thundering Herd）是指多个进程监听同一个事件，操作系统无法判断由谁来负责这个事件，就会索性唤醒所有进程，但最终只有一个进程成功执行，其他进程失败，造成严重的资源浪费。</p>

<p>Nginx的解决思路：<strong>避免惊群</strong>。具体措施有使用全局互斥锁，每个子进程在<code>epoll_wait()</code>之前先去申请锁，申请到则继续处理，获取不到则等待，并设置了一个负载均衡的算法（当某一个子进程的任务量达到总设置量的7/8时，则不会再尝试去申请锁）来均衡各个进程的任务量。</p>

<p>原因和解决方法对比参见<a href="http://blog.163.com/pandalove@126/blog/static/9800324520122633515612/">这篇博客</a>。</p>

<p><a href="http://blog.csdn.net/randyleonard/article/details/9058567">这篇也很精彩</a>。</p>

<h2 id="io">5. 文件异步I/O</h2>

<p>要使用文件异步I/O，则Linux内核必须要支持。这里的异步I/O不同于<code>glibc</code>提供的文件异步I/O库，它是基于多线程实现的，并不是真正意义上的异步I/O。把读取文件的操作异步地提交给内核后，内核会通知I/O设备独立地执行操作，这样，CPU可以得到充分的利用。而且，当大量读事件发生时候，将会发挥出内核读硬盘中“电梯算法”的优势，从而降低随机读取硬盘扇区的成本。</p>

<p>需要注意的是Linux内核级别的文件异步I/O是不支持缓存操作的，所以说文件异步I/O的使用要看场景，并不是所有情况都可以使用，如果用户请求对文件的操作大部分都会落到文件缓存上，那么就不要使用异步I/O，反之则可以试着使用文件异步I/O，看一下是否会为服务器带来并发能力上的提升。</p>

<p>这个文件异步I/O在linux中的称呼是<code>sendfile</code>，那么<code>sendfile</code>的原理是什么呢？</p>

<p>在传统的文件传输里面（read/write方式），在实现上其实是比较复杂的，需要经过多次上下文的切换，我们看一下如下两行代码：</p>

<p>read(file, tmp_buf, len);     <br />
write(socket, tmp_buf, len);  </p>

<p>以上两行代码是传统的read/write方式进行文件到socket的传输。</p>

<p>当需要对一个文件进行传输的时候，其具体流程细节如下：</p>

<p>1、调用read函数，文件数据被copy到内核缓冲区</p>

<p>2、read函数返回，文件数据从内核缓冲区copy到用户缓冲区</p>

<p>3、write函数调用，将文件数据从用户缓冲区copy到内核与socket相关的缓冲区。</p>

<p>4、数据从socket缓冲区copy到相关协议引擎。</p>

<p>以上细节是传统read/write方式进行网络文件传输的方式，我们可以看到，在这个过程当中，文件数据实际上是经过了四次copy操作：</p>

<p>硬盘—&gt;内核buf—&gt;用户buf—&gt;socket相关缓冲区—&gt;协议引擎</p>

<p>而sendfile系统调用则提供了一种减少以上多次copy，提升文件传输性能的方法。Sendfile系统调用是在2.1版本内核时引进的：</p>

<p>sendfile(socket, file, len);   </p>

<p>运行流程如下：</p>

<p>1、<code>sendfile</code>系统调用，文件数据被copy至内核缓冲区</p>

<p>2、再从内核缓冲区copy至内核中socket相关的缓冲区</p>

<p>3、最后再socket相关的缓冲区copy到协议引擎</p>

<p>相较传统read/write方式，2.1版本内核引进的<code>sendfile</code>已经减少了内核缓冲区到user缓冲区，再由user缓冲区到socket相关缓冲区的文件copy，而在内核版本2.4之后，文件描述符结果被改变，<code>sendfile</code>实现了更简单的方式，系统调用方式仍然一样，细节与2.1版本的 不同之处在于，当文件数据被复制到内核缓冲区时，不再将所有数据copy到socket相关的缓冲区，而是仅仅将记录数据位置和长度相关的数据保存到 socket相关的缓存，而实际数据将由DMA模块直接发送到协议引擎，再次减少了一次copy操作。</p>

<p>目前，Nginx仅支持在读取文件时使用异步I/O，因为正常写入文件时往往是写入内存中就立即返回，效率很高，而使用异步I/O写入时速度会明显的下降。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Nginx architecture(1)--Overview]]></title>
    <link href="http://billowkiller.github.io/blog/2013/10/13/nginx-architecture-1-overview/"/>
    <updated>2013-10-13T00:28:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/10/13/nginx-architecture-1-overview</id>
    <content type="html"><![CDATA[<p>从04年发布以来，Nginx已经成为多个国内外互联网具体首选的高性能Web服务器。其特点是占有内存少，并发能力强，并且由于Nginx使用基于事件驱动的架构能够最有效的利用多核CPU的处理能力，进程可以无阻塞的运行。</p>

<p>特别是Nginx可以利用当前操作系统特有的一些高校API来提高自己的性能，例如Linux上的<code>epoll</code>、Solaris上的event ports和Free BSD上的kqueue。又如对于Linux，Nginx支持其独有的sendfile系统调用，可以高效的讲硬盘中的数据发送到网络上（无需将硬盘数据先复制到用户态内存中）。</p>

<p>所以通过分析Nginx的架构设计，可以怎样充分利用服务器上的硬件资源，以及学习到更为先进的理念。下面就来分析和学习Nginx的架构设计。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/nginx_zps7d735b88.jpg" alt="Nginx logo" /></p>

<!--more-->

<h2 id="section">1. 基础架构</h2>

<p>Nginx是模块化的，事件驱动，异步，单线程的，非无阻塞架构的。</p>

<p><img src="http://www.aosabook.org/images/nginx/architecture.png" width="650px" alt="Diagram of Nginx's architecture" /></p>

<h3 id="nginx">1.1 Nginx配置</h3>

<p><strong>内核参数优化</strong></p>

<p>Nginx需要可以对linux内核参数进行修改，来实现对内核参数的优化，以达到硬件资源的最大化利用。</p>

<p>默认的linux内核参数考虑的是最通用的场景，而高并发访问的Web服务器需要根据具体的业务特点来调整内核参数。Nginx作为静态Web内容服务器、反向代理服务器或是提供内容压缩功能的服务器时，内核参数的调整都是不同的。</p>

<p>具体的文件修改是在<code>/etc/sysctl.conf</code>下。举例来说，滑动窗口的大小与套接字缓存区会在一定程度上影响并发连接的数目。每个TCP连接都会为维护TCP滑动窗口而消耗额昵称，这个窗口会更具服务器的处理速度收缩或扩张。</p>

<p><strong>Nginx配置文件</strong></p>

<p>而Nginx的配置文件则规定了程序运行时几个核心模块的基本配置。具体分为4类：</p>

<ul>
  <li>用于调试、定位问题的配置项</li>
  <li>正常运行的必备配置项</li>
  <li>优化性能的配置项</li>
  <li>事件类配置项</li>
</ul>

<p>其他配置项是针对具体模块的，例如对于一个为完整的静态Web服务器提供了8类配置信息（功能）：</p>

<ul>
  <li>虚拟主机与请求的分发
    <ul>
      <li>对特定的Host域名的请求提供不同的服务，以此实现虚拟主机功能</li>
    </ul>
  </li>
  <li>文件路径的定义</li>
  <li>内存及磁盘资源的分配</li>
  <li>网络连接的设置</li>
  <li>MIME类型的设置</li>
  <li>对客户端请求的限制</li>
  <li>文件操作的优化
    <ul>
      <li>sendfile系统条用</li>
      <li>aio系统调用</li>
    </ul>
  </li>
  <li>对客户端请求的特殊处理
    <ul>
      <li>DNS</li>
      <li>忽略不合法HTTP头部</li>
    </ul>
  </li>
</ul>

<p><strong>配置文件读取</strong></p>

<p>Nginx启动的时候读取配置文件过程：</p>

<ol>
  <li>更具命令行得到配置文件路径</li>
  <li>调用所有核心模块的<code>create_conf</code>方法生成存放配置项的结构体</li>
  <li>针对所有核心模块解析<code>Nginx.conf</code>配置文件</li>
  <li>调用所有核心模块的<code>init_conf</code>方法</li>
</ol>

<h3 id="section-1">1.2. 事件驱动架构</h3>

<p>事件驱动模型就是事件发生源来产生事件，由一个或者多个事件收集器来收集、分发事件，然后许多事件处理器会注册自己感兴趣的事件，同时会消费这些事件。</p>

<p>对于Nginx来说，事件模块将负责事件的收集、分发操作，而所有的模块都可能是事件消费者，首先需要向事件模块注册感兴趣的事件类型，当有事件产生时，事件模块会把事件分发到相应的模块中进行处理。</p>

<p>Nginx完全采用事件驱动架构处理事务，与其他Web服务器不同。传统的Web服务器采用的事件驱动往往局限在TCP连接建立、关闭事件上，连接建立后将这个会话加入队列排队让事件消费者进行消费。在连接建立与关闭之间会退化为按序执行的批处理模式，通常采用线程或进程执行的处理方式。这样的处理会在连接建立后始终占据系统资源，因为这段时间从1毫秒到1分钟都有可能，并且进程线程之间的切换也会有性能损失，这样影响了系统可以处理的并发连接数。</p>

<p>Nginx中只有事件模块才有资格占用进程资源，它们在分发某个事件时调用事件消费模块使用当前占用的进程资源。这种设计使得网络性能、用户感知的请求时延都得到提升，整个服务器的网络吞吐量都会由于事件的及时响应而增加。但是，每个事件消费者都不能有阻塞行为，否则会长时间占用事件分发进程而导致其他事件得不到及时响应。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/_zpscc820489.jpg" width="600px" alt="Nginx事件驱动" /></p>

<h3 id="section-2">1.3 多模块设计</h3>

<p><strong>Nginx的模块</strong></p>

<p>要知道Nginx有哪些模块，一个快速的方法就是编译Nginx。编译之后，会在源代码根目录下生成objs目录，该目录中包含有ngx_auto_config.h和ngx_auto_headers.h，以及ngx_modules.c文件，当然，还有Makefile文件等。</p>

<p>其中，生成的<code>ngx_modules.c</code>文件中，重新集中申明(使用extern关键字)了Nginx配置的所有模块，这些模块可通过编译前的configure命令进行配置，即设置哪些模块需要编译，哪些不被编译。</p>

<p>Nginx的模块化架构最基本的数据结构为<code>ngx_module_t</code>。整个数据结构规定了：</p>

<ol>
  <li>该模块的上下文，每个种类的模块有不同的上下文，用void *ctx表示。</li>
  <li>一些callback函数
    <ul>
      <li><code>master</code>初始化和退出</li>
      <li>模块初始化</li>
      <li>工作进程初始化和退出</li>
      <li>线程初始化和退出</li>
    </ul>
  </li>
  <li>模块的命令集，指向一个<code>ngx_command_t</code>结构数组</li>
  <li>模块的类型，运行定义模块类型这个概念，允许专注于不同领域的模块按照类型来区别。</li>
</ol>

<p>具体的模块解释可以参考[http://www.linuxidc.com/Linux/2011-08/40949.htm]http://www.linuxidc.com/Linux/2011-08/40949.htm</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/nginx_zps3788eefc.jpg" alt="Nginx模块设计" width="650px" /></p>

<p><strong>模块化设计的优点</strong></p>

<p>高度模块化的设计是Nginx的架构基础。在Nginx中，除了少量的核心代码，其他一切皆为模块。这种模块化设计同时具有以下几个特点：</p>

<ol>
  <li>
    <p>高度抽象的模块接口</p>

    <p>所有的模块都遵循同样的<code>ngx_module_t</code>(后面有说明)接口设计规范，这减少整个系统中的变数，这种方式带来良好的简单性、静态可扩展性、可重用性。</p>
  </li>
  <li>
    <p>模块接口非常简单，具有很高的灵活性</p>

    <p>模块的基本接口<code>ngx_module_t</code>足够坚定，只涉及模块的初始化、退出以及对配置项的处理，这同时也带来了足够的灵活性，是的Nginx比较简单地实现了动态可修改性(通过HUP信号在服务正常运行时使用新的配置文件生效，以及通过USR2信号实现平滑升级)。</p>
  </li>
  <li>
    <p>定义基础类型的模块：核心模块。</p>

    <p>这样可以简化Nginx的设计，使得非模块化框架代码只关注于如何调用核心模块(6个)。
核心模块将ctx上下文进一步实例化为<code>ngx_core_module_t</code>结构体，它是以配置项的解析作为基础的，提供了create_conf回调方法来创建存储配置项的数据结构，在读取Nginx.conf文件时，会更具模块中的ngx_command_t解析出的配置项存放在这个数据结构中；还提供init_conf回调方法，用于在解析配置文件后，使用解析出的配置项初始化核心模块功能。</p>
  </li>
  <li>
    <p>多层次、多类别的模块设计</p>

    <p>所有的模块间是分层次和类别的，官方Nginx共有五大类型的模块：核心模块、配置模块、事件模块、HTTP模块、mail模块。核心模块和配置模块是由Nginx的框架代码所定义的。其他三种模块都不会与框架产生直接关系，实际上核心模块各有这三种模块的一个agent，并在同类模块中有一个作为和核心业务与管理功能的模块。</p>
  </li>
</ol>

<h2 id="section-3">2. 请求的多阶段异步处理</h2>

<p>请求的多阶段异步处理是把一个请求的处理过程按照事件的触发方式划分为多个阶段，每个阶段都可以有事件收集、分发来触发。也就是说请求的多阶段异步处理只能基于事件驱动架构实现。</p>

<p>异步处理和多阶段是相辅相成的。只有多阶段了才能进行异步处理，异步处理使得阶段的划分才有意义。那么是什么原则来划分请求阶段呢？一般是找到请求处理流程中的阻塞方法（或造成阻塞的代码段）在阻塞代码段上按照下面4中方式来划分阶段：</p>

<ol>
  <li>将阻塞进程的方法按照相关的触发事件分解为两个阶段
    <ul>
      <li>阻塞方法改为非阻塞，调用这个方法</li>
      <li>处理非阻塞方法结果返回事件</li>
    </ul>
  </li>
  <li>将阻塞方法调用按照事件分解为多个阶段的方法调用
    <ul>
      <li>例如将读取10MB文件(非异步)，这些文件在磁盘中的块未必是联系的，即10MB文件内容不再操作系统的缓存中，可能需要多次驱动硬盘寻址，导致进程休眠或等待。这样可以把文件分为1000份，每份10KB，这样读取的时间就是可控的，系统可以及时地处理其他请求。</li>
    </ul>
  </li>
  <li>等待系统的响应从而导致进程空转时，使用定时器划分阶段</li>
  <li>如果阻塞方法完全无法继续划分，则必须使用独立的进程执行这个阻塞方法</li>
</ol>

<h2 id="section-4">3. 进程管理</h2>

<p>Nginx采用一个<code>master</code>管理进程，多个<code>worker</code>工作进程的设计方式，还包括一个可选的<code>cache manager</code>进程以及<code>cache loader</code>进程。</p>

<p>Nginx的<code>worker</code>代码包括核心和功能模块，Nginx的核心是负责维持一个紧凑的运行循环(tight run-loop)，并执行相应的部分模块的代码、每个请求处理阶段。模块包括Nginx在表现层和业务层的功能。模块读取和写入到网络和硬盘，修改内容，出站(outbound)过滤，应用服务器(apply server-side)包括动作，传递请求给上游代理服务器。</p>

<p>Nginx并没有为每个<code>worker</code>分配连接，这个工作是由操作系统内核做的。启动后，<code>worker</code>创建一组初始的监听套接字 ，然后不断接受，读取和写入到sockets，同时处理HTTP请求和响应。</p>

<p>由于Nginx会产生多个<code>worker</code>，所以它在多核的架构中扩展的很好。每个核一个<code>worker</code>可以充分地利用多核的优势，防止颠簸和锁，并且在单线程的的<code>worker</code>进程中没有资源匮乏和资源控制机制。该模型还允许扩展更多的跨物理存储设备，有利于更大的磁盘利用率，避免磁盘I/O阻塞。</p>

<p>根据磁盘的利用和CPU的负载类型，Nginx的<code>worker</code>数量可以调整。一般来说，如果负载模式是CPU密集型处理，例如，TCP/IP的很多，做的SSL或压缩时，<code>worker</code>的数量应该和核的数目相同；如果负载大多数是在磁盘上，如在磁盘上做不同的内容服务或代理，那么<code>worker</code>的数量应该是核的1.5到2倍。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/3_zpsbb4840cf.png" alt="1 process per core" /></p>

<p>Nginx所有的进程使用的是内存共享的通信机制。<code>master</code>运行作为root用户，<code>cache manager</code>，<code>cache loader</code>和<code>worker</code>作为非特权用户运行。<code>master</code>的功能如下：</p>

<ul>
  <li>读取和验证配置</li>
  <li>创建，绑定和关闭socket</li>
  <li>启动，终止和维护配置数量的<code>worker</code>进程</li>
  <li>在不中断服务的情况下重新配置</li>
  <li>无需停止的系统升级 (启动新的进程，如果有必要则回滚)</li>
  <li>编译嵌入式Perl脚本</li>
  <li>日志文件</li>
</ul>

<p><code>cache loader</code>是负责检查磁盘上的缓存项和填充缓存元数据到Nginx的in-memory数据库。 从本质上讲，<code>cache loader</code>准备Nginx的实例用来在工作在一个专门分配的目录结构存储的磁盘文件上。它遍历目录，检查缓存内容元数据、更新共享内存中的相关条目，然后退出时准备给下次使用。</p>

<p>缓存管理器主要是负责缓存过期和失效。 在Nginx的正常运行时，它驻留在内存中；在失败的情况下，它由主进程重新启动。</p>

<h2 id="section-5">4. 跨平台实现</h2>

<p>Nginx有两个特点：跨平台、使用C语言实现。这两个特点导致Nginx不宜使用一些第三方中间件提供的容器和算法，并且C语言与每一个操作系统都是强相关的，且C库对操作系统的某些系统调用封装的方法并不是跨平台的。</p>

<p>对于这种情况，Nginx的解决方法很简单，在这些必须特殊化处理的地方，对每个操作系统都给一份特意化的实现。而对于基础的数据结构和算法，Nginx则完全从头实现了一遍，如动态数组、链表、二叉排序树、散列表等等。</p>

<p>要学习这些数据结构和算法的实现时可以看看Nginx源码，有些设计思路还是非常值得借鉴的，例如双向链表并不存储元素，只是存储指针，而且提供了简单的插入排序法。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[deep C and C++]]></title>
    <link href="http://billowkiller.github.io/blog/2013/10/12/deep-c-and-c-plus-plus/"/>
    <updated>2013-10-12T16:12:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/10/12/deep-c-and-c-plus-plus</id>
    <content type="html"><![CDATA[<p>摘自<a href="http://share.csdn.net/#/detail/1050">CSDN Share</a></p>

<p>花了一个上午的时间看了下这个PPT，觉得收获颇多。
特别是这个PPT的组织方式，采用两个程序员面试对比的方式，非常的实用，也很有触动和感悟。已经很久没见到这样精彩的PPT了。</p>

<p>本PPT介绍了作为普通的程序员和高级的程序员如何看待C与C++，从编译、链接、运行的角度来介绍，有非常多的干货，也许不是很系统，但确实是非常的实用；特别是在回答面试官的提问上，需要认真思考，从<code>不同的角度</code>、<code>深层次</code>地回答技术官的问话。也许两个程序员的功力差不多，但是在回答技术问题的方法上也许对面试官有很大的影响，最终也就是面试是否成功的关键。</p>

<p><img src="http://www.atmel.com/zh/cn/Images/compiler.jpg" alt="" /></p>

<!--more-->

<p>有一点提示就是，今后在看书的时候，要时常记住一些<code>RULE</code>，语言中更有效的惯用用法(<code>effective conventional language</code>)，特别是深入底层细节的知识，要不断的积累实证，而且得<code>学以致用</code>。一点点细小的差距就是<code>professional programmer</code>与common programmer的区别。最重要的一点是常看优秀的代码，学习与你知识相违背的用例。</p>

<p>&lt;iframe height=620 width=670 scrolling=”no” src=”http://share.csdn.net/#/frame/1050” frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;</p>

<p>截取几张精彩的ppt</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/2_zpsde979321.png" /></p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/_zpsfe2bfd71.png" /></p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/3_zpsc78ac177.png" /></p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/5_zps28849be2.png" /></p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/4_zpsff862edf.png" /></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Probabilistic Graphical Models]]></title>
    <link href="http://billowkiller.github.io/blog/2013/06/02/probabilistic-graphical-models/"/>
    <updated>2013-06-02T13:49:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/06/02/probabilistic-graphical-models</id>
    <content type="html"><![CDATA[<h3 id="pgm">1. PGM介绍</h3>

<p>GM(graphical model)，图模型首先它是一个概率模型，用的是图的数据结构，用来表示随机变量之间的以来关系。
因为是涉及到变量之间的关系，于是在概率理论特别是统计部分得到很长远的应用，另外还包括机器学习。</p>

<p><img src="http://www.stanford.edu/~montanar/TEACHING/Stat375/graph.jpg" width="400px" /></p>

<p>可以看的出来，概率图模型是综合了统计和计算机技术：</p>

<ul>
  <li>统计方面提供了概率基础，包括概率分布的分析，不确定性的处理，决策判定等等。</li>
  <li>计算机方面可以将概率中的条件概率置于高维空间中，用图来表示它们的数据结构，并使用高效的算法计算。</li>
</ul>

<p>使用现实中得到的知识数据来表述图模型，作为declarative representation，它与我们所要使用的算法是
松耦合的，可以将不同的算法应用到图模型上，在图模型中可以加入专家知识，和从其他数据中学习到的知识。
<!--more--></p>

<p><strong>什么时候需要用到PGM？</strong></p>

<ul>
  <li>拥有噪音数据或者不确定性比较大的时候</li>
  <li>拥有很多先验知识的时候, 要比普通的机器学习来的有效</li>
  <li>多个变量的推理(reason)，特别是多个变量之间存在内在联系</li>
  <li>从较小的模块化的模型中建立复杂的模型，疾病诊断或错误诊断</li>
</ul>

<p><strong>应用</strong></p>

<p>概率图模型能够发现和分析复杂分布的结构，提取出原本非结构化的数据，使得这些分布能够被有效的重构和利用。
主要在图像和视频智能信息处理领域已有应用。具体的应该用包括：</p>

<ul>
  <li>Medical diagnosis</li>
  <li>Fault diagnosis</li>
  <li>Natural language processing</li>
  <li>speech recognition</li>
  <li>Social network models</li>
  <li>computer vision
    <ul>
      <li>Image segmentation</li>
      <li>3D reconstruction </li>
      <li>Holistic scene analysis</li>
    </ul>
  </li>
  <li>decoding of low-density parity-check codes</li>
  <li>Robot localization &amp; mapping</li>
</ul>

<p>概率图理论共分为三个部分，分别为<strong>表示理论，推理理论和学习理论</strong>。</p>

<h3 id="section">2. 两种模型</h3>

<p>先说说<strong>生成模型和判别模型</strong>。</p>

<p>假设有观察值序列$Y=(Y_1,Y_2,…,Y_n)$，求其对应的状态序列$X=(X_1,X_2,…,X_n)$，则实际上即使求出状态序列$X^*$，使得条件概率$p(X_1,X_2,…,X_n|Y_1,Y_2,…,Y_n)$最大化，即:</p>

<script type="math/tex; mode=display">
\begin{align}
X^* = arg max_{X_1,X_2,...,X_n}p(X_1,X_2,...,X_n|Y_1,Y_2,...,Y_n)
\end{align}
</script>

<h4 id="generative-models">2.1 生成模型(Generative Models)</h4>

<p>生成模型不直接对$p(X_1,X_2,…,X_n|Y_1,Y_2,…,Y_n)$进行建模，而是先对其进行变换，构建联合概率$p(X_1,X_2,…,X_n\,Y_1,Y_2,…,Y_n)$，即</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{split}
p(X_1,X_2,...,X_n|Y_1,Y_2,...,Y_n) &= \frac{p(X_1,X_2,...,X_n,Y_1,Y_2,...,Y_n)}{p(Y_1,Y_2,...,Y_n)} \\
&= \frac{p(Y_1,Y_2,...,Y_n|X_1,X_2,...,X_n) × p(X_1,X_2,...,X_n)}{p(Y_1,Y_2,...,Y_n)}
\end{split}
\end{equation}
 %]]&gt;</script>

<p>在给定观察值序列的前提下，其出现的概率是一定的，所以得到</p>

<script type="math/tex; mode=display">% &lt;![CDATA[

\begin{equation}
\begin{split}
X^* &= arg max_{X_1,X_2,...,X_n}p(X_1,X_2,...,X_n|Y_1,Y_2,...,Y_n) \\
&= arg max_{X_1,X_2,...,X_n}p(Y_1,Y_2,...,Y_n|X_1,X_2,...,X_n) × p(X_1,X_2,...,X_n)
\end{split}
\end{equation}
 %]]&gt;</script>

<p>生成模型认为观测值是由状态生成的。</p>

<h4 id="discriminative-models">2.2 判别模型(Discriminative Models)</h4>

<p>判别模型克服了生成模型的独立性假设，其直接对条件概率$p(X_1,X_2,…,X_n|Y_1,Y_2,…,Y_n)$进行建模，也就是说，在给定观察序列的条件下，寻找最可能的状态序列的时候，条件分布可以直接使用。</p>

<h4 id="section-1">2.3 生成模型和判别模型对比</h4>

<ul>
  <li>统计建模方式不同。生成模型构建联合分布$p(X,Y)$；判别模型构建条件概率分布$p(X|Y)$。</li>
  <li>训练时，二者优化准则不同。生成模型优化训练数据的联合分布概率；判别模型优化训练数据的条件分布概率，判别模型与序列标记问题有较好的对应性。</li>
  <li>训练复杂度不同。判别模型训练复杂度较高。</li>
  <li>对于观察序列的处理不同。生成模型中，观察序列作为模型的一部分；判别模型中，观察序列只作为条件，因此可以针对观察序列设计灵活的特征。</li>
  <li>是否支持无监督训练。生成模型支持无监督训练。</li>
  <li>应用角度不同。生成模型一般主要是对后验概率建模，从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度；判别模型主要特点是寻找不同类别之间的最优分类面，反映的是异类数据之间的差异。</li>
</ul>

<h4 id="section-2">2.4 举例</h4>

<p>常见的Generative Model主要有：</p>

<ul>
  <li>Gaussians, Naive Bayes, Mixtures of multinomials</li>
  <li>Mixtures of Gaussians, Mixtures of experts, HMMs</li>
  <li>Sigmoidal belief networks, Bayesian networks</li>
  <li>Markov random fields</li>
</ul>

<p>常见的Discriminative Model主要有：</p>

<ul>
  <li>logistic regression</li>
  <li>SVMs</li>
  <li>traditional neural networks</li>
  <li>Nearest neighbor</li>
</ul>

<h3 id="section-3">3. 表示理论</h3>

<p>不同的概率图的模型可以分成3类：有向图模型，无向图模型和混合概率图模型。</p>

<h4 id="section-4">3.1 有向图模型</h4>

<p>有向图概率模型使用有向边连接不同的结点，这些有向边通常表示了结点间的因果关系。典型的代表是隐马尔可夫模型，贝叶斯网络和的动态贝叶斯网络。</p>

<ul>
  <li>
    <p><strong>HMM(Hidden Markov Model)</strong></p>

    <p>看这个名称就知道，隐马尔可夫模型是马尔可夫模型的扩展，它是在马尔可夫链的基础上发展起来的。马尔可夫链是马尔可夫随机过程的特殊情况，即马尔可夫链的状态和时间参数都是离散的马尔可夫过程。它的$m+1$时刻的状态只是和$m$时刻的状态有关，而与之前的状态无关。实际中，马尔可夫链的每一状态可以对应于一个可观测到的物理事件。比如天气预测中的雨晴雪等，根据这个模型可以算出各种天气在某一时刻出现的概率。</p>

    <p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Hmm_temporal_bayesian_net.svg/500px-Hmm_temporal_bayesian_net.svg.png" width="400px" alt="一个典型的HMM，y为观察值，x为状态值，t为时刻" /></p>

    <p>由于实际问题比马尔可夫链模型所描述的更为复杂，观察到的事件并不是与状态一一对应的，而是通过一组概率分布相联系，这个就是HMM。HMM是一个双重的随机过程，其中之一是马尔可夫链，描述状态转移。另外一个随机过程描述状态和观察值，它并不是与状态一一对应的，需要通过一个随机过程去感知状态的存在及特性。这个就是Hidden的由来。</p>

    <p>具体的一个例子为phone HMM，这是一个语音识别的例子，根据单词的发言可以建立HMM，一个随机的有限自动机，每个状态都产生一个evident或observation。识别出得到的声音特征为观察值evidents，从start到end计算得到概率最大的HMM最终状态即为识别到的单词。</p>

    <p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/hmm_zpsf0b66b9e.png" width="600px" alt="一个典型的HMM，y为观察值，x为状态值，t为时刻" /></p>
  </li>
  <li>
    <p><strong>贝叶斯网络(Beyesian Network, BN)</strong></p>

    <p>一般是指带有概率信息的有向无环图(directed acyclic graph, DAG)。由两部分组成：</p>

    <ul>
      <li>图中的节点表示的是随机变量，结点间的连接表示了可能的因果关系。</li>
      <li>每一个结点都附有与该变量相联系的条件概率分布函数(Conditional Probability Distribution, CPD)，如果变量是离散的，则表现为条件概率表(Conditional Probability Table, CPT)。</li>
    </ul>

    <p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/0/0e/SimpleBayesNet.svg/400px-SimpleBayesNet.svg.png" width="400px" alt="一个简单的贝叶斯网络" /></p>

    <p>贝叶斯网络表现的是一个联合概率分布，可以通过Chain Rule来计算$p(X_1,X_2,…,X_n)=\prod{p(X_i|Par_G(X_i))}$。</p>

    <p>贝叶斯网络一个很有用的用途是作为分类器，即通过某对象的先验概率，利用贝叶斯公式计算出其后验概率，即该对象属于某一类的概率，选择具有最大后验概率的类作为该对象所属的类。所谓的先验概率是指在没有观测值的情况下的概率，后验概率是指在加入观测值后的概率。用的比较多的贝叶斯网络分类器有四种: </p>
  </li>
  <li>朴素贝叶斯网络(Naive Bayesian Networks, NBN);</li>
  <li>通用贝叶斯网络(General Bayesian Networks, GBN);</li>
  <li>增强型朴素贝叶斯网络(Tree-Augmented Naive Bayes, TAN);</li>
  <li>
    <p>马尔可夫毯贝叶斯网络(Markov Blanket Bayesian Networks, MBBN)。</p>
  </li>
  <li>
    <p><strong>动态贝叶斯网络(Dynamic Bayesian Networks, DBNs)</strong></p>

    <p>贝叶斯网络只能反映事物的静态特征，也就是在某一个时刻事物不同特征的依赖关系，但在现实生活中，存在着很多的动态随机过程，DBN就是用来对这些过程建模的方法之一。但是动态表示的是一个动态的系统，而系统的结构并不随着时间变化。DBN服从马尔科夫特征：<em>t</em>时刻系统的所有变量的概率分布只与<em>t-1</em>时刻的状态变量概率分布相关。HMM可以当做DBN的一种特殊情况。</p>

    <p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/DBN_zpse19ad96b.gif" width="400px" alt="车辆位置的DBN" /></p>
  </li>
</ul>

<h4 id="section-5">3.2 无向图模型</h4>

<p>无向图概率模型用来建立随机变量间的空间相互关系或只是相互依赖性。典型的代表是马尔科夫随机场和条件随机场。无向连接通常捕捉一对结点之间的互相依赖关系。</p>

<ul>
  <li>
    <p><strong>马尔科夫随机场(Markov Random Fields, MRFs)</strong></p>

    <p>MRF也叫马尔科夫网(Markov Network, MN)，MRF是关于一组有马尔科夫性质随机变量<em>X</em>的全联合概率分布模型。一方面MRF可以表示BN无法表示的依赖关系，如循环关系；另外一方面，它不能表示BN所能够表示的推导关系。</p>

    <p>当概率分布为正的时候，被称为Gibbs随机场，因为根据Hammersley–Clifford理论（MN与Gibbs分布的等价性）和局部马尔科夫性质，无向图的概率分布可以被定义为下面的Gibbs公式，即</p>
  </li>
</ul>

<script type="math/tex; mode=display">
\begin{align}
P(x) = \frac{1}{Z}\prod_C\phi_C(X_C)
\end{align}
</script>

<p>其中，$\phi_C(X_C)$是一个关于$X_C$的非负实数函数，表示的是无向图中团的势函数(potential function)。Z是一个归一化常数(Partition Function)，其取值为$\sum_X\phi_C(X_C)$。</p>

<p>MRF可以用来分析物理现象的空间关系或者非因果上下文关系。在图像处理领域，它能够很好地描述相邻的图像像素或者相关特征间的相互依赖关系。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/Isingmodel_zpsbd31e4ba.png" alt="MN的原型，Ising model" width="400px" /></p>

<ul>
  <li>Pairwise MRF</li>
</ul>

<p>Pairwise MRF模型是广泛使用的一种MRF模型，其结构形式简单和计算量低。
  其联合概率分布可以写成如下形式：</p>

<p>$$
\begin{align}
P(x) = \frac{1}{Z}\prod_{i,j}\Psi(x_i,y_j)\prod_i\phi(x_i,y_j)
\end{align}
$$
式中，$x$为标注类，$y$为观测值。</p>

<p><img src="http://www.hindawi.com/journals/mpe/2012/814356.fig.004.jpg" alt="Pairwise MRF模型" width="300px" /></p>

<ul>
  <li><strong>条件随机场(Conditional Random Fields, CRF)</strong></li>
</ul>

<p>给定输出标识序列X和观察序列Y，CRF通过定义条件概率$p(X|Y)$，而不是联合概率$p(X,Y)$来描述模型。CRF是一个判别模型，在图像分割、形状分析和图像标注等方面优于生成模型MRF。CRF是一种无向图模型，当给定观测值(y)，且能够直接表达类条件概率分布(类变量x)，即</p>

<script type="math/tex; mode=display">
\begin{align}
P(x|y) = \frac{1}{Z(y)}\prod_C\phi_C(X_C,y)
\end{align}
</script>

<p>其中，$\phi_C(X_C,y)$不仅依赖于集合x，同时也依赖于整个观测值y。</p>

<p>CRF同MRF相比，最主要的优点有：CRF关注于最终的预测问题，避免不必要的观察密度计算；CRF不要求像生成模型中对于观察变量之间条件独立关系的假设。</p>

<p>CRF可以被称为Task-Specify Prediction。因为不像MN，它的判别对象是确定的。例如，对于图像分割来说，它的$X$为输入端，可以是像素值和要处理的特征，targe value为$Y$，也就是每个像素的类别，例如草地，天空等。又如对于文本处理来说，输入端可以为句子中的词，目标则是这些词的标注，例如人名，地名等。</p>

<p>这种情况适用于correlated featureas, 也就是特征之间存在依赖关系；这种情况对于其他模型并不适用，例如从Naive Beysian的模型可以看出，它的特征之间是相互独立的。</p>

<h3 id="inference--learning">4. Inference &amp;&amp; Learning</h3>

<p>Inference和Learning我学习的也是一知半解的，很多东西都是知其然不知其所以然，就不误人子弟了，具体的可以参考<a href="http://freemind.pluskid.org/machine-learning/probabilistic-graphical-model/">pluskid</a>的博文，讲的非常的详细。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[最小生成树]]></title>
    <link href="http://billowkiller.github.io/blog/2013/05/14/zui-xiao-sheng-cheng-shu/"/>
    <updated>2013-05-14T01:09:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/05/14/zui-xiao-sheng-cheng-shu</id>
    <content type="html"><![CDATA[<p>算法使用的是二叉堆，时间为O(ElgV)。如果V小于E的话，使用Prim更好。</p>

<p>Kruskal算法：</p>

<p>O(ElgE): E&lt;V<sup>2&nbsp;</sup>,所以有 lgE=O(lgV)</p>

<p>集合A是一个森林，加入集合A中的安全边总是图中连接两个不同连通分支的最小权边。</p>

<p>使用不相交集合数据结构。</p>

<p>测试边时，即测试两端点是否在同一棵树上。</p>

<p>若不在则可以对集合进行合并。</p>

<!--more-->
<p>Prim算法：</p>

<p>集合A形成单棵树，添加集合A的安全边总是连接树与一个不在树中的顶点的最小权边。</p>

<p>使用最小优先队列。优先队列基于Key值，key[v]是所有将v与树中某一顶点相连的边中的最小权值。</p>

<p>一开始除了根节点，其他节点的key为无穷大。</p>
]]></content>
  </entry>
  
</feed>
