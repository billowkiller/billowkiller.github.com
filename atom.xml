<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Billowkiller's Blog]]></title>
  <link href="http://billowkiller.github.io/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2014-08-17T16:02:24+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Number Theory Introduction]]></title>
    <link href="http://billowkiller.github.io/blog/2014/08/09/Number-theory-introduction/"/>
    <updated>2014-08-09T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/08/09/Number-theory-introduction</id>
    <content type="html"><![CDATA[<h2 id="catalan">Catalan数</h2>

<p>卡塔兰数是组合数学中一个常在各种计数问题中出现的数列。卡塔兰数的一般项公式为：</p>

<p><img src="http://upload.wikimedia.org/math/d/1/1/d118d8cea7b639dfd5244fcba65910cf.png" alt="" /></p>

<p>它的另外一个表达式是：</p>

<p><img src="http://upload.wikimedia.org/math/f/7/9/f7943e307a891716ca1266a5f5957cdd.png" alt="" /></p>

<p><strong>递推关系：</strong></p>

<p><img src="http://upload.wikimedia.org/math/6/2/1/6217b3c99a3243afcd5d8dbd58186822.png" alt="" /></p>

<p><img src="http://upload.wikimedia.org/math/8/a/4/8a49332e4a46b3a2c7accec81160f5e3.png" alt="" /></p>

<h3 id="section">组合数学中的应用</h3>

<ol>
  <li>长度2n的dyck word的个数。Dyck word是一个有n个X和n个Y组成的字串，且所有的前缀字串皆满足X的个数大于等于Y的个数。以下为长度为6的dyck words: <code>XXXYYY</code> <code>XYXXYY</code> <code>XYXYXY</code> <code>XXYYXY</code> <code>XXYXYY</code></li>
  <li>将上例的X换成左括号，Y换成右括号，Cn表示所有包含n组括号的合法运算式的个数</li>
  <li>
    <p>Cn表示有n个节点组成不同构二叉树的方案数。下图中，n等于3，圆形表示节点，月牙形表示什么都没有。</p>

    <p><img src="http://upload.wikimedia.org/wikipedia/commons/0/01/Catalan_number_binary_tree_example.png" alt="" /></p>
  </li>
  <li>
    <p>Cn表示有2n+1个节点组成不同构满二叉树（full binary tree）的方案数。</p>

    <p>证明：
 令1表示进栈，0表示出栈，则可转化为求一个2n位、含n个1、n个0的二进制数，满足从左往右扫描到任意一位时，经过的0数不多于1数。显然含n个1、n个0的2n位二进制数共有<img src="http://upload.wikimedia.org/math/c/9/2/c92da943df73dc077dbee5514376346a.png" alt="" />个，下面考虑不满足要求的数目。</p>

    <p>考虑一个含n个1、n个0的2n位二进制数，扫描到第2m+1位上时有m+1个0和m个1（容易证明一定存在这样的情况），则后面的0-1排列中必有n-m个1和n-m-1个0。将2m+2及其以后的部分0变成1、1变成0，则对应一个n+1个0和n-1个1的二进制数。反之亦然（相似的思路证明两者一一对应）。从而：</p>

    <p><img src="http://upload.wikimedia.org/math/4/8/2/4828faf1c29e4b699529f2275cc63453.png" alt="" /></p>
  </li>
  <li>
    <p>Cn表示所有在n × n格点中不越过对角线的单调路径的个数。一个单调路径从格点左下角出发，在格点右上角结束，每一步均为向上或向右。计算这种路径的个数等价于计算Dyck word的个数：X代表“向右”，Y代表“向上”。下图为n = 4的情况：</p>

    <p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/f/f4/Catalan_number_4x4_grid_example.svg/450px-Catalan_number_4x4_grid_example.svg.png" alt="" /></p>
  </li>
  <li>
    <p>Cn表示通过连结顶点而将n + 2边的凸多边形分成三角形的方法个数。下图中为n = 4的情况：</p>

    <p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/a/a8/Catalan-Hexagons-example.svg/400px-Catalan-Hexagons-example.svg.png" alt="" /></p>
  </li>
  <li>
    <p>Cn表示用n个长方形填充一个高度为n的阶梯状图形的方法个数。下图为n = 4的情况：</p>

    <p><img src="http://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Catalan_stairsteps_4.svg/400px-Catalan_stairsteps_4.svg.png" alt="" /></p>
  </li>
</ol>

<h3 id="section-1">面试题</h3>

<p><strong>12个高矮不同的人，排成两排，每排必须是从矮到高排列，而且第二排比对应的第一排的人高，问排列方式有多少种？</strong></p>

<p>我们先把这12个人从低到高排列，然后，选择6个人排在第一排，那么剩下的6个肯定是在第二排。</p>

<p>用0表示对应的人在第一排，用1表示对应的人在第二排，那么含有6个0，6个1的序列，就对应一种方案。问题转换为，这样的满足条件的01序列有多少个。</p>

<p><strong>给乘积X1X,X3……Xn加括号的方法数</strong></p>

<p><strong>n+m个人排队买票，并且满足$n \ge m$，票价为50元，其中n个人各手持一张50元钞票，m个人各手持一张100元钞票，除此之外大家身上没有任何其他的钱币，并且初始时候售票窗口没有钱，问有多少种排队的情况数能够让大家都买到票。</strong></p>

<p>这个题目是Catalan数的变形，不考虑人与人的差异，如果m=n的话那么就是我们初始的Catalan数问题，也就是将手持50元的人看成是+1，手持100元的人看成是-1，任前k个数值的和都非负的序列数。</p>

<p>这个题目区别就在于$n&gt;m$的情况，此时我们仍然可以用原先的证明方法考虑，假设我们要的情况数是$D_{n+m}$，无法让每个人都买到的情况数是$U_{n + m}$，那么就有$D_{n + m} + U_{n +m} = {n + m \choose n}$，此时我们求$U_{n + m}$，我们假设最早买不到票的人编号是k，他手持的是100元并且售票处没有钱，那么将前k个人的钱从50元变成100元，从100元变成50元，这时候就有$n+1$个人手持50元，$m-1$个手持100元的，所以就得到$U_{n + m} = {n + m \choose n + 1}$，于是我们的结果就因此得到了，表达式是$D_{n + m} = {n + m \choose n} - {n + m \choose n + 1}$。</p>

<h2 id="section-2">欧拉函数</h2>

<p>在数论中，对正整数n，欧拉函数$\varphi(n)$是小于或等于n的正整数中与n互质的数的数目。例如$\varphi(8)=4$，因为1,3,5,7均和8互质。</p>

<ul>
  <li>
    <p>$\varphi(1)=1$（小于等于1的正整数中唯一和1互质的数就是1本身）。</p>
  </li>
  <li>
    <p>若$n$是质数$p$的$k$次幂，$\varphi(n)=\varphi(p^k)=p^k-p^{k-1}=(p-1)p^{k-1}$，因为除了$p$的倍数外，其他数都跟$n$互质。</p>
  </li>
  <li>
    <p>若$n = p_1^{k_1} p_2^{k_2} \cdots p_r^{k_r}$, 则$\varphi(n) = \prod_{i=1}^r p_i^{k_i-1}(p_i-1) = \prod_{p\mid n} p^{\alpha_p-1}(p-1) = n\prod_{p|n}\left(1-\frac{1}{p}\right)$。
其中$\alpha_p$是使得$p^{\alpha}$整除$n$的最大整数$\alpha（这里\alpha_{p_i} = k_i）$。</p>

    <p>例如$\varphi(72)=\varphi(2^3\times3^2)=72\times(1 - \frac{1}{2})\times(1 - \frac{1}{3})=24$</p>
  </li>
  <li>
    <p>对任何两个互质的正整数$a, m（即 gcd(a,m) = 1），m\ge2$，有$a^{\varphi(m)} \equiv 1 \pmod m$。即<strong>欧拉定理</strong>。</p>
  </li>
  <li>
    <p>当$m$是质数$p$时，此式则为：$a^{p-1} \equiv 1 \pmod p$。即<strong>费马小定理</strong>。</p>
  </li>
</ul>

<p><strong>欧拉函数的程序:</strong></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
</pre></td><td class="code"><pre><code class="c++"><span class="line"><span class="kt">int</span> <span class="n">phi</span><span class="p">(</span><span class="kt">int</span> <span class="n">x</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="kt">int</span> <span class="n">ans</span> <span class="o">=</span> <span class="n">x</span><span class="p">;</span>
</span><span class="line">    <span class="kt">int</span> <span class="n">m</span> <span class="o">=</span> <span class="p">(</span><span class="kt">int</span><span class="p">)</span><span class="n">sqrt</span><span class="p">(</span><span class="n">x</span><span class="o">+</span><span class="mf">0.5</span><span class="p">);</span>
</span><span class="line">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">m</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">        <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span> <span class="p">{</span>   <span class="c1">// 求素因子</span>
</span><span class="line">            <span class="n">ans</span> <span class="o">=</span> <span class="n">ans</span> <span class="o">/</span> <span class="n">i</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>    <span class="c1">// 运用通项求解欧拉函数</span>
</span><span class="line">            <span class="k">while</span><span class="p">(</span><span class="n">x</span> <span class="o">%</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>  <span class="n">x</span> <span class="o">/=</span> <span class="n">i</span><span class="p">;</span>  <span class="c1">// 每个素因子只计算一次</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">}</span>
</span><span class="line">    <span class="k">if</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">)</span>  <span class="n">ans</span> <span class="o">=</span> <span class="n">ans</span> <span class="o">/</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>  <span class="c1">// 防质数</span>
</span><span class="line">    <span class="k">return</span> <span class="n">ans</span><span class="p">;</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><strong>1-n中所有树的欧拉phi函数值。</strong>并不需要一次计算。可以用与筛法求素数类似的方法，在$O(nloglogn)$时间内计算完毕。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
</pre></td><td class="code"><pre><code class="c++"><span class="line"><span class="kt">void</span> <span class="n">phi_table</span><span class="p">(</span><span class="kt">int</span> <span class="n">n</span><span class="p">,</span> <span class="kt">int</span><span class="o">*</span> <span class="n">phi</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span>  <span class="n">p</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
</span><span class="line">    <span class="n">phi</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
</span><span class="line">
</span><span class="line">    <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="n">N</span><span class="p">;</span> <span class="n">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">        <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">phi</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="p">{</span>
</span><span class="line">            <span class="k">for</span><span class="p">(</span><span class="kt">int</span> <span class="n">j</span> <span class="o">=</span> <span class="n">i</span><span class="p">;</span> <span class="n">j</span> <span class="o">&lt;=</span> <span class="n">n</span><span class="p">;</span> <span class="n">j</span> <span class="o">+=</span> <span class="n">i</span><span class="p">)</span> <span class="p">{</span>    <span class="c1">// 处理素因子phi[i]</span>
</span><span class="line">                <span class="k">if</span><span class="p">(</span><span class="o">!</span><span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">])</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">j</span><span class="p">;</span>
</span><span class="line">                 <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">phi</span><span class="p">[</span><span class="n">j</span><span class="p">]</span> <span class="o">/</span> <span class="n">i</span> <span class="o">*</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">);</span>    <span class="c1">// 先除后乘，防止中间过程超出范围</span>
</span><span class="line">            <span class="p">}</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">    <span class="p">}</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Modules in Network Programming]]></title>
    <link href="http://billowkiller.github.io/blog/2014/08/04/modules-in-network-programming/"/>
    <updated>2014-08-04T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/08/04/modules-in-network-programming</id>
    <content type="html"><![CDATA[<p>发现自己总喜欢把各种东西混合在一块，所以这又是一篇长文…</p>

<p>本文将会介绍网络编程中的几种模型，包括<strong>I/O模型、服务器编程模型、事件模型、并发模型</strong>。</p>

<hr />

<h2 id="io">I/O模型</h2>

<p>I/O模型包括<strong>阻塞模型、非阻塞模型、信号量驱动模型、多路复用模型、异步模型</strong>。</p>

<p>总体来说包括两大类：</p>

<ol>
  <li><strong>同步I/O，向程序通知的是I/O就绪事件</strong>，由程序完成读写。包括前四类I/O模型。</li>
  <li><strong>异步I/O，向程序通知的是I/O完成事件</strong>，读写操作由内核完成。</li>
</ol>

<!--more-->

<h3 id="section">阻塞模型</h3>

<p><img src="http://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig01.gif" alt="" /></p>

<p>在这个模型中，用户空间的应用程序执行一个系统调用，这会导致应用程序阻塞。这意味着应用程序会一直阻塞，直到系统调用完成为止（数据传输完成或发生错误）。调用应用程序处于一种不再消费 CPU 而只是简单等待响应的状态，因此从处理的角度来看，这是非常有效的。</p>

<p>其行为非常容易理解，其用法对于典型的应用程序来说都非常有效。在调用 read 系统调用时，应用程序会阻塞并对内核进行上下文切换。然后会触发读操作，当响应返回时（从我们正在从中读取的设备中返回），数据就被移动到用户空间的缓冲区中。然后应用程序就会解除阻塞（read 调用返回）。</p>

<p><strong>阻塞模型在阻塞的时候可能会被信号量中断！！</strong></p>

<h3 id="section-1">非阻塞模型</h3>

<p><img src="http://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig02.gif" alt="" /></p>

<p>非阻塞的实现是I/O命令可能并不会立即满足，需要应用程序调用许多次来等待操作完成。这可能效率不高，因为在很多情况下，当内核执行这个命令时，应用程序必须要进行忙碌等待，直到数据可用为止，或者试图执行其他工作。这个方法可以引入I/O操作的延时，因为数据在内核中变为可用到用户调用 read 返回数据之间存在一定的间隔，这会导致整体数据吞吐量的降低。</p>

<p>当一个应用程序在一个非阻塞的描述符上反复的调用system call的时候，我们称之为<strong>轮询（polling）</strong>。</p>

<h3 id="io-1">I/O复用模型</h3>

<p><img src="http://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig03.gif" alt="" /></p>

<p>I/O复用模型会用到select或者poll函数，这两个函数也会使进程阻塞，但是和阻塞I/O所不同的是，这两个函数可以同时阻塞多个I/O操作。而且可以同时对多个读操作，多个写操作的I/O函数进行检测，直到有数据可读或可写时，才真正调用I/O操作函数。</p>

<h3 id="io-2">信号驱动I/O模型</h3>

<p><img src="http://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig04.gif" alt="" /></p>

<p>首先我们允许套接口进行信号驱动I/O,并安装一个信号处理函数，进程继续运行并不阻塞。当数据准备好时，进程会收到一个SIGIO信号，可以在信号处理函数中调用I/O操作函数处理数据。</p>

<h3 id="io-3">异步I/O模型</h3>

<p><img src="http://www.masterraghu.com/subjects/np/introduction/unix_network_programming_v1.3/files/06fig05.gif" alt="" /></p>

<p>调用<code>aio_read</code>函数，告诉内核描述字，缓冲区指针，缓冲区大小，文件偏移以及通知的方式，然后立即返回。当内核将数据拷贝到缓冲区后，再通知应用程序。</p>

<p>这个操作和信号驱动的区别就是：<strong>异步模式等操作完毕后才通知用户程序而信号驱动模式在数据到来时就通知用户程序。</strong></p>

<h3 id="io-4">几种I/O模型的比较</h3>

<p><img src="http://www.blogjava.net/images/blogjava_net/lihao336/o_untitled6_thumb.png" alt="" /></p>

<h2 id="section-2">服务器编程模型</h2>

<p>有个简单的总结<a href="http://www.cnblogs.com/hnrainll/archive/2011/10/13/2210481.html">http://www.cnblogs.com/hnrainll/archive/2011/10/13/2210481.html</a></p>

<h3 id="section-3">多进程服务器模型</h3>

<p>服务器进程接受连接，fork一个子进程为客户服务，然后等待下一个连接。
多进程模型<strong>适用于单个客户服务需要消耗较多的CPU资源</strong>，例如需要进行大规模或长时间的数据运算或文件访问。多进程模型具有<strong>较好的安全性</strong>。</p>

<pre><code>pid_t pid;
int listenfd, connfd;

listenfd = Socket( ... );
Bind(listenfd, ...);
Listen(listenfd, LISTENQ)

while(1) {
	connfd = Accept(listenfd, ...); /* probably blocks */
	if( (pid = Fork()) == 0 ) {
		Close(listenfd); /* child closes listenning socket */
		process(connfd); /* process the request */
		Close(connfd);   /* done with this client */
		exit(0);		 /* terminate */
	}
	Close(connfd);       /* parent closes connected socket */
}
</code></pre>

<p>需要仔细体会下，为什么父进程要加最后一个<code>Close</code>。</p>

<h3 id="section-4">单线程模型</h3>

<p>具体实现方式在UNP3e第30章中。</p>

<p>在高性能的网络程序中，使用得最为广泛的恐怕要数“non-blocking IO + IO multiplexing”这种模型，即 Reactor 模式。</p>

<p>在“non-blocking IO + IO multiplexing”这种模型下，程序的基本结构是一个事件循环 (event loop)。它的优点很明显，编程简单，效率也不错。不仅网络读写可以用，连接的建立（connect/accept）甚至 DNS 解析都可以用非阻塞方式进行，以提高并发度和吞吐量 (throughput)。<strong>对于 IO 密集的应用是个不错的</strong>。</p>

<h3 id="section-5">多线程模型</h3>

<p>和多进程模型类似，服务器进程接受连接，新建一个线程为客户服务，然后等待下一个连接。和多进程相比，由于进程消耗的资源比线程大的多，因此，<strong>在需要为较多客户端服务的时候，优先使用多线程</strong>。</p>

<p>具体大概有这么几种做法：</p>

<ol>
  <li>每个请求创建一个线程，使用阻塞式 IO 操作。在 Java 1.4 引入 NIO 之前，这是 Java 网络编程的推荐做法。可惜伸缩性不佳。</li>
  <li>使用线程池，同样使用阻塞式 IO 操作。与 1 相比，这是提高性能的措施。</li>
  <li>使用 non-blocking IO + IO multiplexing。即 Java NIO 的方式。non-blocking IO + one loop per thread 模式。</li>
  <li>Leader/Follower 等高级模式</li>
</ol>

<h2 id="section-6">事件处理模型</h2>

<p>一般地,I/O多路复用机制都依赖于一个<strong>事件多路分离器</strong>(Event Demultiplexer)。<u>分离器对象可将来自事件源的I/O事件分离出来，并分发到对应的read/write事件处理器(Event Handler)</u>。开发人员预先注册需要处理的事件及其<strong>事件处理器</strong>（或回调函数）；事件分离器负责将请求事件传递给事件处理器。两个与事件分离器有关的模式是Reactor和Proactor。Reactor模式采用同步IO，而Proactor采用异步IO。</p>

<p><strong>Reactor框架中用户定义的操作是在实际操作之前调用的</strong>。比如你定义了操作是要向一个SOCKET写数据，那么当该SOCKET可以接收数据的时候，你的操作就会被调用；而<strong>Proactor框架中用户定义的操作是在实际操作之后调用的</strong>。比如你定义了一个操作要显示从SOCKET中读入的数据，那么当读操作完成以后，你的操作才会被调用。</p>

<h3 id="reactor">Reactor</h3>

<p>在Reactor中，事件分离器负责等待文件描述符或socket为读写操作准备就绪，然后将就绪事件传递给对应的处理器，最后由处理器负责完成实际的读写工作。</p>

<p><strong>以读操作为例：</strong></p>

<ul>
  <li>注册读就绪事件和相应的事件处理器</li>
  <li>事件分离器等待事件</li>
  <li>事件到来，激活分离器，分离器调用事件对应的处理器。</li>
  <li>事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。</li>
</ul>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/reactor_zpsc844d1e5.png" alt="" /></p>

<h3 id="proactor">Proactor</h3>

<p>在Proactor模式中，处理器–或者兼任处理器的事件分离器，只负责发起异步读写操作。IO操作本身由操作系统来完成。传递给操作系统的参数需要包括用户定义的数据缓冲区地址和数据大小，操作系统才能从中得到写出操作所需数据，或写入从socket读到的数据。事件分离器捕获IO操作完成事件，然后将事件传递给对应处理器。比如，在windows上，处理器发起一个异步IO操作，再由事件分离器等待IOCompletion事件。典型的异步模式实现，都建立在操作系统支持异步API的基础之上，我们将这种实现称为“系统级”异步或“真”异步，因为应用程序完全依赖操作系统执行真正的IO工作。</p>

<p><strong>以读操作为例：</strong></p>

<ul>
  <li>处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。</li>
  <li>事件分离器等待操作完成事件</li>
  <li>在分离器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成。</li>
  <li>事件分离器呼唤处理器。</li>
  <li>事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分离器。</li>
</ul>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/proactor_zpsc40c6bf2.png" alt="" /></p>

<h3 id="section-7">总结</h3>

<p>可以看出，两个模式的相同点，都是对某个IO事件的事件通知(即告诉某个模块，这个IO操作可以进行或已经完成)。在结构上，两者也有相同点：demultiplexor负责提交IO操作(异步)、查询设备是否可操作(同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下(Proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(can read or can write)。</p>

<h3 id="ioproactor">同步I/O模拟Proactor</h3>

<p>原理：主线程执行数据读写操作，读写完成后，主线程向工作线程通知这一“完成事件”。那么从工作线程的角度来看，它们就直接获得了数据读写的结果，接下来要做的知识对读写的结果进行逻辑处理。</p>

<p>使用同步I/O模拟出的Proactor模式的工作流程如下：</p>

<ol>
  <li>主线程往epoll内核事件表中注册socket上的读就绪事件。</li>
  <li>主线程调用<code>epoll_wait</code>等待socket上有数据可读。</li>
  <li>当socket上有数据可读时，<code>epoll_wait</code>通知主线程。主线程从socket循环读取数据，知道没有更多数据可读，然后将读取到的数据封装成一个请求对象并插入请求队列。</li>
  <li>水木在请求队列上的某个工作线程被唤醒，它获得请求对象并处理客户请求，然后往epoll内核事件表中注册socket上的写就绪事件。</li>
  <li>主线程调用<code>epoll_wait</code>等待socket可写。</li>
  <li>当socket可写时，<code>epoll_wait</code>通知主线程，主线程往socket上写入服务器处理客户请求结果。</li>
</ol>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/aproactor_zps46fafc76.png" alt="" /></p>

<h2 id="section-8">并发模型</h2>

<h3 id="section-9">半异步、半同步</h3>

<p>半异步、半同步模式是reactor模式的一个进化，非完全异步，而是通过队列把reactor分成了2个部分：同步部分，异步部分。</p>

<p>同步，是因为队列是block的，这部分采用多线程，提高吞吐量
reactor部分是单线程的异步的。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/hahs_zps02b41fb9.png" alt="" /></p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/hahs1_zpsb6c7b413.png" alt="" /></p>

<h3 id="leaderfollower">Leader/Follower</h3>

<p>多线程网络服务最简单的方式就是一个连接一个线程，这种模型当客户端连接数快速增长是就会出现性能瓶颈。当然，这时候，我们理所当然会考虑使用线程池，而任何池的使用，都会带来一个管理和切换的问题。 在java 1.4中引入了NIO编程模型，它采用了Reactor模式，或者说观察者模式，由于它的读写操作都是无阻塞的，使得我们能够只用一个线程处理所有的IO事件，这种处理方式是同步的。为了提高性能，当一个线程收到事件后，会考虑启动一个新的线程去处理，而自己继续等待下一个请求。这里可能会有性能问题，就是把工作交给别一个线程的时候的上下文切换，包括数据拷贝。Leader-Follower模型可以用来解决这个问题。</p>

<p><img src="http://my.csdn.net/uploads/201206/30/1341045549_7751.jpg" alt="" /></p>

<p>所有线程会有三种身份中的一种：leader和follower，以及一个干活中的状态：proccesser。它的基本原则就是，永远最多只有一个leader。而所有follower都在等待成为leader。线程池启动时会自动产生一个Leader负责等待网络IO事件，当有一个事件产生时，Leader线程首先通知一个Follower线程将其提拔为新的Leader，然后自己就去干活了，去处理这个网络事件，处理完毕后加入Follower线程等待队列，等待下次成为Leader。这种方法可以增强CPU高速缓存相似性，及消除动态内存分配和线程间的数据交换。</p>

<p>显然地，通过预先分配一个线程池，Leader/Follower设计避免了动态线程创建和销毁的额外开销。将线程放在一个自组织的池中，而且无需交换数据，这种方式将上下文切换、同步、数据移动和动态内存管理的开销都降到了最低。</p>

<p>不过，这种模式在处理短暂的、原子的、反复的和基于事件的动作上可以取得明显的性能提升，比如接收和分发网络事件或者向数据库存储大量数据记录。事件处理程序所提供的服务越多，其体积也就越大，而处理一个请求所需的时间越长，池中的线程占用的资源也就越多，同时也需要更多的线程。相应的，应用程序中其它功能可用的资源也就越少，从而影响到应用程序的总体性能、吞吐量、可扩展性和可用性。</p>

<p>在大多数LEADER/FOLLOWERS设计中共享的事件源封装在一个分配器组件中。如果在一个设计中联合使用了LEADER/FOLLOWERS和REACTOR事件处理基础设施，由reactor组件进行分发。封装事件源将事件分离和分派机制与事件处理程序隔离开来。每个线程有两个方法：一个是join方法，使用这个方法可以把新初始化的线程加入到池中。新加入的线程将自己的执行挂起到线程池监听者条件(monitor condition)上，并开始等待被提升为新的Leader。在它变成一个Leader之后，它便可以访问共享的事件源，等待执行下一个到来的事件。另一个是promote_new_leader方法，当前的Leader线程使用这个方法可以提升新的Leader，其做法是通过线程池监听者条件通知休眠的Follower。收到通知的Follower继续执行(resume)线程池的join方法，访问共享事件源，并等待下一个事件的到来。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Probability Problem]]></title>
    <link href="http://billowkiller.github.io/blog/2014/08/02/probability-problem/"/>
    <updated>2014-08-02T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/08/02/probability-problem</id>
    <content type="html"><![CDATA[<h2 id="section">一、抛硬币问题</h2>

<p><strong>问题1 有一苹果，两个人抛硬币来决定谁吃这个苹果，先抛到正面者吃。问先抛这吃到苹果的概率是多少？</strong></p>

<p>假设第一个人吃到苹果的概率是P。第一次抛硬币若为正面则先抛者赢；若为负面且后抛者也为负面，则主动权回到先抛者，回到原问题。</p>

<p>得到关系：P = 1/2 + 1/2 * 1/2 * P  </p>

<p>得出 P = 2/3</p>

<p><strong>问题2 游戏规则为，连续2次抛到硬币朝上，则游戏结束。问平均抛多少次游戏可以结束？</strong></p>

<!--more-->

<p>平均抛多少次，即是求问题的期望。</p>

<p>首先先抛一枚硬币，如果是花，那么需要重头开始；如果是字，那么再抛一枚硬币，新抛的这枚如果也是字，则游戏结束，如果是花，那么又需要重头开始。根据这个过程，设抛硬币的期望次数为T，可以得到关系：T = 1/2(1 + T) + 1/4 * 2 + 1/4(2 + T)</p>

<p>得出 T = 6 </p>

<p><strong>问题3 连续抛 k 次朝上的解法：</strong></p>

<p>假设连续k次正面朝上的期望为Ek，在连续出现k次正面朝上后，下次一也为正面的期望为</p>

<p>E(k+1) = 1/2 (Ek + 1) + 1/2(Ek + 1 + E(k+1))</p>

<p>推到出公式 (E(k+1) +2) /(Ek +2) = 2 得出 Ek = 2^(k+1) -2</p>

<p><strong>问题4 A和B2人投硬币,正面A得1元,反面B得一元.起始时A有1元,B有100元.游戏持续进行,直到其中1人破产才终止.</strong></p>

<ol>
  <li>
    <p>如果硬币正反概率相同,游戏的期待长度(expected duration)是几次投掷?</p>

    <p>目前认为只有奇数次才可能破产。<code>1*0.5 + 3*0.5^3 + 5*0.5^5+...</code></p>
  </li>
  <li>
    <p>如果硬币是不公正的,正面概率为P,反面概率为Q.(P+Q=1), 那么游戏的期待长度(expectedduration)是几次投掷?</p>

    <p>那么问题的答案是计算E(T(n)),即该事件的期望值。</p>

    <p>第1次出现破产的概率是p  //只可能A破产</p>

    <p>第2次出现            0  //因为A第1次赢了1个，共2个了，最多只能输1个，还会剩1个</p>

    <p>第3次出现            <code>q×p×p</code></p>

    <p>第4次出现            0</p>

    <p>第5次                <code>q*q*p*p*p</code></p>

    <p>第99次               q(49次方)×P(50次方)</p>

    <hr />

    <p>在100次以下投掷次数时，不可能是B破产，只有可能是A破产</p>

    <p>第100次时            只有B破产可能  即  q（100次方）</p>

    <p>第101次              q(50次方)×P(51次方) </p>

    <p>第102次              q(102次方)*p</p>

    <p><strong>综上所述，奇数次时，唯A可能破产，偶数次&gt;=100时，唯B可能破产</strong>。</p>

    <p>E（T(n))=<code>∑ n*T(n)  n=1...+∞</code>
         =<code>∑奇数次  +∑偶数次</code>
          =<code>p/(1-p*q)+q(100次方)/(1-P*q)</code></p>

    <p>其中q=1-p
 问题1把p=q=1/2 代入即可。</p>
  </li>
</ol>

<h2 id="section-1">二、骰子问题</h2>

<p><strong>问题1 一个骰子，6面，1个面是 1， 2个面是2， 3个面是3， 问平均掷多少次能使1,2,3都至少出现一次？</strong></p>

<p>这是一个求数学期望的问题，最终是求1，2，3出现至少一次的最短长度的期望。</p>

<p>这样分叉树的每个节点是一个期望状态，而每个分叉是一次投掷结果。将后续期望出现1、2、3各至少一次的情形记作L123（即题目所求），将后续期望出现1、2各至少一次（3无关）情形记作L12，而1至少一次（2，3无关）情形L1，其余数值符号类推，则树结构如下（列出4级结构已经足够）：</p>

<pre><code>           L123
	   /1    |2    \3
      L23    L13    L12
   /1  |2  \3 
  L23  L3   L2
		  /1 |2 \3  
         L2  P2  L3  

L123 = p1 (L23+ 1) + p2 (L13+1) + p3 (L12 + 1) = p1*L23 +p2*L13+ p3*L12 + 1
L23 = p1*L23 +p2*L3+ p3*L2 + 1
L13 = p1*L3 +p2*L13+ p3*L1 + 1
L12 = p1*L2 +p2*L1+ p3*L12 + 1
L1 = p1 + p2*(L1+1) + p3*(L1 +1) =p2*L1+ p3*L1 + 1
L2 = p1*L2 + p3*L2 + 1
L3 = p1*L3 + p2*L3 + 1

解得：
L1 = 6， L2 = 3， L3 = 2
L12 = 7， L13 = 13/2， L23 = 19/56
L123 = 219/30 = 7.3
</code></pre>

<h2 id="section-2">其他</h2>

<p><strong>从n个数中生成m个不重复的随机数</strong></p>

<p>对于第一个数，可以用概率m/n选取；但是对于下一个，必须考虑之前的数是否被选取而以(m-1)/(n-1)或m/(n-1)的概率选取。</p>

<p>可用下列代码得到结果：</p>

<pre><code>void random_generate(int n, int m)  
{  
    int i=1,t，remain;  
    while(n-i&gt;m)  
    {  
        t = rand()%(n-i);  
        if(t&lt;m){  
            printf("%d ",i);  
            m--;  
        }  
        i++;  
    }  
    while(++i&lt;=n)printf("%d ",i);  
}  
</code></pre>

<p><strong>利用等概率Rand互换</strong></p>

<pre><code>#Rand5到Rand3
def Rand3():
  x = -1
  while not 0 &lt;= x &lt; 3:
    x = Rand5()
  return x

#Rand5到Rand7
def Rand7():
  x = -1
  while not 0 &lt;= x &lt; 21:
    x = Rand5() * 5 + Rand5()
  return x % 7
</code></pre>

<p><strong>单次遍历，等概率随机选取问题</strong></p>

<p><a href="http://www.gocalf.com/blog/random-selection.html">http://www.gocalf.com/blog/random-selection.html</a></p>

<p><strong>条件概率：两个都是男孩的概率</strong></p>

<p><a href="http://www.gocalf.com/blog/the-probability-of-two-boys.html">http://www.gocalf.com/blog/the-probability-of-two-boys.html</a></p>

<p><strong>平均要取多少个(0,1)中的随机数才能让和超过1</strong></p>

<p><img src="http://hi.csdn.net/attachment/201203/13/0_1331634834uu6L.gif" alt="" /></p>

<p><strong>一个口袋内有10个红色球，20个蓝色球，30个绿色球，你随机地
把球一个一个取出来，请问红色球最先被拿完的概率？也就是当第10个红
色球被取出时，口袋内至少还有一个蓝色球和一个绿色球的概率。</strong></p>

<p>60个球随机排列，红球先取完就等于说后面至少还有一个蓝球，
一个绿球。<strong>如果把这个排列倒过来看，就是说看见红球前先看见
蓝球和绿球</strong>。这样一来就容易了。总共有两种情况，先蓝后绿再
红，或者先绿后蓝再红。</p>

<p>先蓝的概率是<code>1/3</code>，绿红两色中先绿再红的概率是<code>3/4</code> （先蓝以后
其它蓝球不影响绿红的概率）。所以第一种情况的概率是<code>1/3×3/4=1/4</code></p>

<p>先绿的概率是1/2，蓝红两色中先蓝再红的概率是<code>2/3</code> （先绿以后
其它绿球不影响蓝红的概率）。所以第二种情况的概率是<code>1/2×2/3=1/3</code></p>

<p>所以，总概率是<code>1/4+1/3=7/12</code>.</p>

<p>仔细看一看上面的解法，我们会发现红蓝绿球的数量不重要，比例最重
要。也就是说如果有100红，200蓝，300绿，答案还是一样的。</p>

<p><strong>在圆环上随机取N个点，请问这N个点正好都在同一半圆环内的概
率是多少？要注意的是这个半圆环可以是任意半圆环。</strong></p>

<p>起来无从下手，但很多概率组合题都是如此，只要想对了思路就容易了。</p>

<p>一共N个点，固定一个点，从这点开始顺时针，逆时针各有一个半圆，其它N-1个点都落在同
一个（比如顺时针）半圆上的概率是1/2^（N-1). 总共N个点，所以总概率是N/2^（N-1）。</p>

<p><strong>你分别写好5封信给5个朋友，你在5个信封上分别写上他们的地址，
如果你把5封信随机地放进5个信封，请问所有5封信都寄错人的概率是多少？</strong></p>

<p>这题是著名的Derangement问题。关键步骤是要找到递推公式。</p>

<p>如果假设N个人有S_n种 derangement。考虑第N+1个与每一个的交换。我们可以证明<code>S_(n+1) = n*(S_n + S_(n-1))</code></p>

<p>有了这个递推公式以后，可以证明Derangement的概率是<code>p_n = sum((-1)^k/k!, k=0,n)</code></p>

<p>对这道题来说，N=6. 当N趋于无穷大时，<code>p_n趋于e^(-1)</code></p>

<p><strong>一个骰子6面分别是1到6，请问你平均要投多少次才能让每个数字都
投中过？</strong></p>

<p>掷第一次可以得到一个数，第二次掷出不同的数的概率是5/6，所以掷出第
二个数的期望长度是6/5，掷出第三个不同的数的概率是4/6，所以掷出第二
个数的期望长度是6/4，以此类推，所以掷出所有六个数的期望长度是</p>

<pre><code>1+6/5+6/4+6/3+6/2+6/1=6×（1/6+1/5+1/4+1/3+1/2+1/1） = 14.7
</code></pre>

<p>当然这个题也可以推广到任意N面的骰子。
在第一个数已经出现的情况下，抛出第二个数的期望次数是</p>

<pre><code>E(x) = 5/6 + 1/6*5/6*2 + 1/6^2 * 5/6 *3 + 1/6^3 * 5/6 * 4 +....
E(x) = 6/5
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Unix Network Programming Notes]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/22/network-programming/"/>
    <updated>2014-07-22T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/22/network-programming</id>
    <content type="html"><![CDATA[<p>记录Linux网络编程中的一些知识点…</p>

<hr />

<h3 id="section">网络编程可能会遇到的三种情况</h3>

<ol>
  <li>当<code>fork</code>子进程时，必须捕获<code>SIGCHLD</code>信号。</li>
  <li>当捕获信号时，必须处理被中断的系统调用；</li>
  <li>
    <p><code>SIGCHLD</code>的信号处理函数必须正确编写，应使用<code>waitpid</code>函数以免留下僵死进程。</p>

    <p><code>waitpid</code>是可以非阻塞的等待信号终止，因此可以使用循环调用。</p>
  </li>
</ol>

<!--more-->

<h3 id="socket">网络socket</h3>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/socket_zpsdcdfab1b.png" alt="" /></p>

<p><strong>对应的TCP分组</strong></p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/TCP_zpsb7790efe.png" alt="" /></p>

<h3 id="shutdown">shutdown函数</h3>

<p>终止网络连接的通常方法是调用<code>close</code>函数。不过<code>close</code>有两个限制，可以使用<code>shutdown</code>来避免。</p>

<ol>
  <li><code>close</code>把描述符的引用计数减1，仅在该计数变为0时才关闭套接字。使用<code>shutdown</code>可以不管引用计数就激发TCP的正常连接终止序列。</li>
  <li><code>close</code>终止读和写两个方向的数据传送。</li>
</ol>

<p>说明：</p>

<ul>
  <li><code>shutdown</code>根本没有关闭socket,任何与socket关联的资源直到调用closesocket才释放。</li>
  <li>TCP连接的socket是全双工的，也就是说它可以发送和接收数据，但是一个方向上的数据流动和另一个方向上的数据流动是不相关的，shutdown函数的功能也就是体现在这里，它通过设置how选择关闭哪条数据通道(发送通道和接收通道)，如果关闭了发送通道，那么这个socket其实还可以通过接收通道接受数据.</li>
  <li>当通过以how=1(<code>SHUT_WR</code>)的方式调用<code>shutdown</code>，就可以保证对方收到一个EOF，而不管其他的进程是否已经打开了套接字，而调用<code>close</code>或closesocket就不能保证，因为直到套接字的引用计数减为0时才会发送FIN消息给对方，也就是说，直到所有的进程都关闭了套接字。</li>
</ul>

<p><strong>为了保证在连接撤销之前，保证双方都能接收到对等方的所有数据，在调用closesocket之前，先调用shutdown关闭发送数据通道。</strong></p>

<h3 id="tcpclosewait">tcp中close_wait状态出现的原因</h3>

<p><code>close_wait</code>出现的原因: 就是某一方在网络连接断开后，对等方没有检测到这个错误（对方断开）而没有调   用 closesocket，导致了这个状态的出现.</p>

<p>模拟这样一个环境:服务器192.168.1.112:4500在接收到一个客户端的连接后，休眠五秒后，服务器关闭与客户 端通讯的socket后正常退出，而客户端在连接服务器后，等待用户输入字符后，发送给客户端。现在有这样几个问题:</p>

<ol>
  <li>
    <p>服务器在休眠五秒后，正常退出了，但是由于客户端还在等待用户输入，此时服务器端TCP的状态是什么？(<code>FIN_WAIT_2</code>)，客户端的TCP状态是什么?(<code>CLOSE_WAIT</code>)</p>
  </li>
  <li>
    <p>服务器在休眠五秒后，正常退出了，在服务器退出后，如果客户端异常退出，那么服务器端TCP的状态是什么？客户端的TCP状态是什么?</p>
  </li>
</ol>

<pre><code>   在服务器正常退出后，客户端异常退出，那么客户端就会向服务器发送RST标志，然后客户端和服务器端的TCP状态都是`CLOSED`
</code></pre>

<ol>
  <li>服务器在休眠五秒后，正常退出了，在服务器退出后,从客户端输入数据后，向服务器发送，此时服务器怎样处理这个数据?</li>
</ol>

<pre><code>   客户端通过PSH标志向服务器段发送数据，能够发送成功，但因为服务器的TCP处于(`FIN_WAIT_2`)状态，此时服务器会向客户端发送一个RST标示，并且服务器端口状态和客户端的TCP状态都变为`CLOSED`。
</code></pre>

<ol>
  <li>在服务器休眠的过程中，杀死服务器进程，服务器端TCP状态是什么?客户端的TCP状态是什么?</li>
</ol>

<pre><code>在服务器休眠的过程中，杀死服务器进程，此时服务器方会向客户端发送一个RST标志，服务器TCP状态是`CLOSED`，客户端的TCP状态也是`CLOSE`.
在服务器休眠五秒后，如果不关闭与客户端通讯的Socket直接正常退出，此时，服务器方也向客户端发送了RST标志。
</code></pre>

<p>对于上面的四个问题，必须注意到服务器正常断开的时候，向客户端发送的FIN根本不能被客户端的所正常处理，因为客户端正处于接收用户的输入。所以由于每次都是服务器主动断开，但是服务器TCP状态却有可能不能进入到<code>Time_Wait</code>状态。</p>

<h3 id="section-1">服务器终止可能出现的情况</h3>

<ol>
  <li><code>accept、read、write、select、open</code>等慢系统调用中断，系统调用可能返回<code>EINTR</code>错误。需要重启被中断的系统调用。并且编写捕获信号的程序时，必须对慢系统调用返回<code>EINTR</code>有所准备。</li>
  <li>三路握手完成后，客户TCP发送一个RST。服务器进程在调用<code>accept</code>的时候RST到达。accept返回一个错误给服务器进程，POSIX指出返回的errno值必须是<code>ECONNABORTED</code>（“software caused connection abort.”）。服务器忽略它，再次调用accept。</li>
  <li>服务器进程终止。服务端调用<code>kill</code>命令杀死服务器子进程。子进程中所有打开的描述符都被关闭，进而会向客户发送一个FIN，客户TCP则响应一个ACK。而客户进程此时阻塞在<code>fgets</code>调用上。由于FIN的接收并没有告知客户服务器进程已经终止，所以客户进程照常发送数据。此时服务端响应RST。客户进程看不到这个RST，因为它在调用<code>writen</code>后立即调用<code>readline</code>，并且由于接收到FIN，<strong>所调用的readline立即返回0（EOF）</strong>。于是以出错信息（“server terminated prematurely”）退出。</li>
  <li>如果客户不理会<code>readline</code>函数返回的错误，写更多的数据到服务器上。当一个进程向某个已收到RST的套接字执行写操作时，内核向该进程发送一个<code>SIGPIPE</code>信号。该信号的默认行为是终止进程，因此进程必须捕获它以免不情愿地被终止。</li>
  <li>服务器主机崩溃。客户端到服务端之间网络断掉，或者服务端断电等，物理连接断掉了，这种情况下客户端不会退出（此情况称为<strong>半开连接</strong>），<code>send</code>函数正常执行，不会感觉到自己出错。因为由于物理网络断开，服务端不会给客户端回应错误消息。此时，客户TCP持续重传数据分节，试图从服务器上接收一个ACK。最终返回的错误是<code>ETIMEDOUT</code>。然而如果某个中间路由器判定服务器主机已不可达，从而响应一个“destination unreachable”ICMP消息，那么返回的错误是<code>EHOSTUNREACH</code>或<code>ENETUNREACH</code>。</li>
  <li>服务器主机崩溃后重启。服务进程对客户端<code>send</code>来的消息会产生RST响应。客户收到RST时，客户正阻塞于<code>read</code>调用，导致该调用返回<code>ECONNESET</code>错误。</li>
  <li>服务器主机关机。unix系统关机时，<code>init</code>进程通常先给所有进程发送<code>SIGTERM</code>信号（可捕获），等待固定一段时间后，给所有仍在运行的进程发送<code>SIGKILL</code>信号。接下里就和3一样。</li>
</ol>

<p>下图是检测各种TCP条件的方法</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/2014-08-01183756__zpse1970a67.jpg" alt="" /></p>

<h3 id="solinger">SO_LINGER套接字选项</h3>

<p>在默认情况下，当调用<code>close</code>关闭socket的使用，<code>close</code>会立即返回；但是，如果send buffer中还有数据，系统会试着先把send buffer中的数据发送出去，然后close才返回。</p>

<p><code>SO_LINGER</code>选项则是用来修改这种默认操作的。于SO_LINGER相关联的一个结构体如下:</p>

<pre><code>#include &lt;sys/socket.h&gt;
struct linger {
      int l_onoff  //0=off, nonzero=on(开关)
      int l_linger //linger time(延迟时间)
}
</code></pre>

<p>当调用<code>setsockopt</code>之后,该选项产生的影响取决于<code>linger</code>结构体中<code>l_onoff</code>和<code>l_linger</code>的值:</p>

<ul>
  <li>当<code>l_onoff</code>被设置为0的时候,将会关闭<code>SO_LINGER</code>选项,即TCP或则SCTP保持默认操作:<code>close</code>立即返回、<code>l_linger</code>值被忽略.</li>
  <li><code>l_lineoff</code>值非0，<code>l_linger</code>为0，那么当<code>close</code>某个连接时TCP将终止该连接。send buffer中未被发送的数据将被丢弃,并向对方发送一个RST信息.值得注意的是，由于这种方式，是非正常的4中握手方式结束TCP链接，所以，TCP连接将不会进入<code>TIME_WAIT</code>状态，这样会导致新建立的可能和就连接的数据造成混乱。</li>
</ul>

<p>设置<code>SO_LINGER</code>套接字选项后，<code>close</code>的成功返回只是告诉我们先前发送的数据（和FIN）已由对端TCP确认，而不能告诉我们对端应用进程是否已读取数据。如果不设置该套接字选项，那么我们连对断TCP是否确认了数据都不知道。
让客户知道服务器已读取其数据的一个方法是改为调用<code>shutdown</code>，并设置它的第二个参数为<code>SHUT_WR</code>，而不是调用<code>close</code>。</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/1_zps7ad163b0.png" alt="" /></p>

<p>关闭连接的本地端（客户端）时，根据所调用的函数（<code>close</code>和<code>shutdown</code>）以及是否设置了<code>SO_LINGER</code>套接字选项，<strong>可在以下3个不同的时机返回</strong>。</p>

<ol>
  <li><code>close</code>立即返回，根本不等待（默认情况）。</li>
  <li><code>close</code>一直拖延到接受了对于客户端FIN的ACK才返回。</li>
  <li>后跟一个<code>read</code>调用的<code>shutdown</code>一直等到接受对端FIN才返回。</li>
</ol>

<p><strong>下图汇总了对shutdown的两种可能调用和对close的三种可能调用，以及它们对TCP套接字的影响。</strong>
<img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/_zps2eb27157.png" alt="" /></p>

<h3 id="soreuseaddr">SO_REUSEADDR套接字选项</h3>

<p>SO_REUSEADDR套接字选项能起到以下功能。</p>

<ol>
  <li>
    <p>SO_REUSEADDR允许一个server程序listen监听并bind到一个端口,既是这个端口已经被一个正在运行的连接使用了.</p>

    <p>例如，以下情况：</p>

    <ol>
      <li>一个监听(listen)server已经启动</li>
      <li>当有client有连接请求的时候,server产生一个子进程去处理该client的事物.</li>
      <li>server主进程终止了,但是子进程还在占用该连接处理client的事情.虽然子进程终止了,但是由于子进程没有终止,该socket的引用计数不会为0，所以该socket不会被关闭.</li>
      <li>server程序重启.</li>
    </ol>

    <p><strong>所有的TCP server都必须设定此选项,用以应对server重启的现象.</strong></p>
  </li>
  <li>
    <p>SO_REUSEADDR允许多个server绑定到同一个port上,只要这些server指定的IP不同</p>

    <p>SO_REUSEADDR需要在bind调用之前就设定。另外，还可以在绑定IP通配符。但是最好是先绑定确定的IP，最后绑定通配符IP。运行在这些端口上的服务器实例可以相同，也可以不同。在TCP中，不允许建立起一个已经存在的相同的IP和端口的连接。但是在UDP中，是允许的，特别是在多播中。</p>
  </li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Summary of TCP/IP ILLustrated Volume 1]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/18/TCP-IP/"/>
    <updated>2014-07-18T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/18/TCP-IP</id>
    <content type="html"><![CDATA[<p>Modified from several blogs. Sorry for failing to detailed list.</p>

<hr />

<p>要快速学习一本书，最简单的途径是在网上找一些靠谱的读书笔记、总结之类的博文，然后细细研读，再根据重要的或者未详尽描述的知识点在书中阅读。根据这样的学习方法，总结了《TCP/IP详解 卷1：协议》这本书。</p>

<p>介绍是以图为驱动的，接下来就开始吧。</p>

<h2 id="tcpip">tcp/ip协议簇</h2>

<p><img src="http://dl.iteye.com/upload/attachment/598180/ebd73be4-de65-38cc-adde-514a3d486844.jpg" alt="" /></p>

<!--more-->

<p>上图左侧是数据包在各个网络层的状态，右侧是数据包在各个网络层的传递。其中，以太网口通过以太网地址来决定丢弃还是交付通过以太网口的数据包（此时称为以太网帧）；以太网驱动程序通过检验和来决定将其丢弃还是交付给上一层；接着，驱动程序通过以太网首部中的“类型”字段对以太网帧进行分用，确定这是一个ip数据报，还是一个ARP/RARP请求/应答；如果是后者，则通过协议进行应答；如果是ip数据报，则脱去帧头帧尾，将其交付到Ip层。IP层首先进行检验和计算以决定交付还是丢弃报文，然后通过ip首部中的“协议”字段确定其是UDP数据报、TCP段还是ICMP、IGMP报文，从而对IP数据报进行分用。如果是ICMP或IGMP，则根据协议对其进行处理，如果是TCP或UDP，则去其头部，将其交付到运输层；TCP/UDP则是通过端口号将数据分用到对该端口进行监听的应用程序。</p>

<h2 id="section">链路层</h2>

<h3 id="section-1">以太网帧</h3>

<p><img src="http://dl.iteye.com/upload/attachment/598848/99c6503e-20d5-34f3-976f-8c1fc239d179.jpg" alt="" /></p>

<p>上图是以太网帧的封装格式。其中的“类型”字段正是用于IP数据报、ARP报文和RARP报文的分用。可以看到，每个以太网帧有最小长度和最大长度，最小长度为64字节，是为了检测冲突；最大长度是1518，最大传输单元MTU为1500字节。</p>

<h3 id="arp--rarp">ARP &amp; RARP</h3>

<p>当一台主机把以太网数据帧发送到位于同一局域网上的另一台主机时，是根据48bit以太网地址来确定目的接口的。设备驱动程序从不检查IP数据报中的目的IP地址。</p>

<p><strong>ARP</strong>（地址解析协议）是设备<strong>通过自己知道的IP地址来获得自己不知道的物理地址</strong>的协议。假如一个设备不知道它自己的IP地址，但是知道自己的物理地址，网络上的无盘工作站就是这种情况，设备知道的只是网络接口卡上的物理地址。这种情况下应该怎么办呢？RARP（逆地址解析协议）正是针对这种情况的一种协议。
RARP以与ARP相反的方式工作。<strong>RARP发出要反向解析的物理地址并希望返回其对应的IP地址</strong>，应答包括由能够提供所需信息的RARP服务器发出的IP地址。虽然发送方发出的是广播信息，RARP规定只有RARP服务器能产生应答。许多网络指定多个RARP服务器，这样做既是为了平衡负载也是为了作为出现问题时的备份。</p>

<p>ARP高效运行的关键是由于每个主机上都有一个ARP高速缓存，这个高速缓存存放了最近IP地址到硬件地址之间的映射记录。高速缓存中的每一项的生存时间为20分钟，开始时间从被创建时开始算起。可以使用<code>arp -a</code>来检查ARP高速缓存。下图为ARP的分组格式。</p>

<p><img src="http://dl.iteye.com/upload/attachment/599192/e13ec54f-0994-358e-9772-fcfb934e2741.jpg" alt="" /></p>

<ul>
  <li>对于arp请求，其以太网帧首部中的<strong>硬件地址为全1</strong>，<strong>代表广播</strong>，请求主机向它所在的网络广播一份arp请求。</li>
  <li>ARP请求从一个网络发往另一个网络，连接2个网络的路由可以回答该请求，这个过程叫做委托ARP或<strong>代理ARP</strong>。</li>
  <li>arp请求还有另外一个特性叫<strong>免费arp</strong>，它是指主机发送arp查找自己的ip地址。
    <ul>
      <li>一个主机可以通过它来确定另一个主机是否设置了相同的ip地址。检测<strong>网络存在ip冲突</strong>。</li>
      <li>如果发送免费arp的主机正好改变了硬件地址，那么这个分组就可以使其他主机高速缓存中旧的硬件地址<strong>进行相应的更新</strong>。</li>
    </ul>
  </li>
</ul>

<h2 id="section-2">网络层</h2>

<h3 id="ip">IP协议</h3>

<p><strong>IP提供不可靠、无连接的数据报传送服务</strong>。<strong>不可靠是指它不能保证IP数据报能成功地到达目的地</strong>，如果发生某种错误时（如路由器暂时用完了缓冲区），IP有一个简单的处理算法：丢弃该数据报，然后发送ICMP消息给信源端。<strong>无连接的意思是，IP数据报不维护任务关于后续数据报的状态信息</strong>，每个数据报的处理是相互独立的。首先看一下IP数据报的格式：</p>

<p><img src="http://dl.iteye.com/upload/attachment/598868/830a6b5c-cf71-39e2-bd0f-6b5bfa25e2ab.jpg" alt="" /></p>

<p>特地说明下检验和是怎么产生的。TCP和IP协议中都有校验和字段。IP协议根据IP首部计算的检验和码，它不对首部后面的数据进行计算。为了计算一份数据报的IP检验和，首先把检验和字段置为0，然后对首部中每16bit进行二进制反码求和。而TCP、UDP协议的检验和需要对数据进行计算，并且要伪造一个IP头，包括IP地址、报文长度等数据。</p>

<p>IP协议的协议字段包含了被IP包封装了的协议，这个逆过程称为<strong>分用</strong>。包括TCP、UDP、ICMP及IGMP等。</p>

<h3 id="ip-1">IP路由选择</h3>

<p>路由器与主机的本质区别在于，主机从不把数据报从一个接口转发到另一个接口，而路由器则要转发数据。IP可以从TCP、 UDP、ICMP、IGMP接口数据报（即本地待发送的数据），也可以从一个网络接口接收数据报。IP层在内存中有一个<strong>路由表</strong>，当收到一份数据报并进行发送时，它都要对该表搜索一次。当数据报来自某个网络接口时，IP首先检查目的目的IP地址是否为本机的IP地址之一或者IP广播地址。如果确实是这样，数 据报就被送到由IP首部协议字段所指定的协议模块进行处理。如果数据报的目的不是这些地址，那么（1）主机将丢弃报文；（2）路由器对数据报进行转发。</p>

<p>路由表中的每一项包括：(通过<code>netstat -rn</code>可以查到该路由表）</p>

<ol>
  <li>目的IP地址，它既可以是一个完整的主机地址，也可以是一个网络地址，主机地址有一个非0的主机号，以指定某一特定的主机，而网络地址中的主机号为0，以指定网络中的主机。</li>
  <li>下一跳路由器的ip地址，或者有直接连接的网络IP地址。</li>
  <li>标志。其中一个标志指明目的IP地址是网络地址还是主机地址，另一个标志指明下一站路由是路由器还是一个直接相连的接口。总共有五种不同的标 志：U（该路由可用）、G（该路由是到一个网关）、H（该路由是到一个主机）、D（该路由是由重写向报文创建的）、M（该路由已被重定向报文修改）。</li>
</ol>

<p>IP路由选择主要完成以下这些功能：</p>

<ol>
  <li>搜索路由表，寻找能与目的IP地址完全匹配的表目，如果找到，就把报文发往该地址；</li>
  <li>搜索路由表，寻找能与目的网络号相匹配的表目，如果找到，则把报文发送给该表目指定的下一站路由器直接连接的网络接口；</li>
  <li>搜索路由表，寻找标为“默认”的表目，如果找到，把报文发送给该表目指定的下一站路由器。</li>
</ol>

<p>如果上面这些步骤都没有成功，那么该数据报就不能被发送。如果不能传送的数据报来自本机，那么一般会向生成数据报的应用程序返回一个“主机不可达”或“网络不可达”的错误。</p>

<p>下图描述了IP层处理过程的简单流程：</p>

<p><img src="http://dl.iteye.com/upload/attachment/599650/5ba5f055-2428-35fa-8791-c03dae480fce.jpg" alt="" /></p>

<p>系统通过三种途径改变路由表的表项，一个是<strong>route命令</strong>，由管理员手动配置路由，一个是<strong>ICMP重定向报文</strong>，这是一种只能由路由器生成的ICMP差错报文，最后一个则是<strong>路由守护程序</strong>，路由守护程序是一个应用程序，它通过发送ICMP路由器请求报文，接收ICMP路由器通告报文来获知相邻的网络情况。</p>

<h3 id="icmp">ICMP</h3>

<p>ICMP是Internet控制报文协议，用于查询和传输出错报告控制信息。</p>

<p>其中<strong>ICMP查询报文</strong>包括：</p>

<ul>
  <li>回显应答/请求， <strong>ping程序使用的报文</strong></li>
  <li>路由器通告/请求，用于IP选路（另一种是RIP路由选择信息协议）</li>
  <li>时间戳请求/应答，允许系统向另一个系统查询当前的时间</li>
  <li>子网掩码请求/应答， 用于无盘系统在引导过程中获取自己的子网掩码</li>
</ul>

<p><strong>ICMP差错报文</strong>：</p>

<ul>
  <li>不可达报文</li>
  <li>超时报文</li>
  <li>重定向差错报文，修改路由表</li>
  <li>源站抑制差错，系统接收数据报的速度大于数据处理的数据</li>
</ul>

<p><strong>ICMP超时+ICMP端口不可达+TTL是traceroute程序的工作原理。</strong>traceroute程序发送一份TTL字段为1的IP数据报文给目的主机，处理这份数据报的第一个路由器将其TTL值减1，丢弃该数据报，并发回一份ICMP超时报文，通过报文中的信源地址我们将得到该路由器的地址；接着，traceroute发送一份TTL值为2的IP数据报文给目的主机，这样，第二个路由器将发回一份ICMP超时报文，….，直到最后该报 文到达目的主机并被接收，那么如何判断报文已经到达目的主机了呢？traceroute将选择一个不可能的值作为目的端口号（大于30000），使目的主机的任何一个应用程序都不可能使用该端口，这样，目的主机收到该报文时，将产生一份“ICMP端口不可达”报文给，这样，当traceroute收到的 ICMP报文是“目的端口不可达”时，可以判断已经完成了整个traceroute的过程。记得IP首部中的“选项”部分还可以设置“严格的源站选路”和 “宽松的源站选路”选项，可以在traceroute发送的IP数据报首部中加入该选项，来规划traceroute的路径。</p>

<h3 id="section-3">互联网的地址、广播、多播</h3>

<p><img src="http://dl.iteye.com/upload/attachment/599740/8fca4629-889a-3533-9abe-bd3915fdbb6f.jpg" alt="" /></p>

<ul>
  <li>A类   0.0.0.0 – 127.255.255.255</li>
  <li>B类 <strong>128</strong>.0.0.0 – 191.255.255.255</li>
  <li>C类 <strong>192</strong>.0.0.0 – 223.255.255.255</li>
  <li>D类 <strong>224</strong>.0.0.0 – 239.255.255.255</li>
  <li>E类 <strong>240</strong>.0.0.0 – 247.255.255.255</li>
</ul>

<p>有三类地址：<strong>单播地址，多播地址和广播地址</strong>。主机号为全0代表网络号，主机号为全1代表在该网络的广播。有<strong>四种广播地址</strong>：</p>

<ol>
  <li>受限的广播地址255.255.255.255.该地址用于主机配置过程中IP数据报的目的地址，在任何情况下，路由器都不转发目的地址为受限的广播地址的数据报，这样数据报仅出现在地址网络中。</li>
  <li>指向网络的广播地址，主机号为全1.如A类广播地址为netid.255.255.255，一个路由器必须转发指向网络的广播。</li>
  <li>指向子网的广播。指向子网的广播地址为主机号为全1且有特定子网号的地址。作为子网直接广播地址的IP地址需要了解子网的掩码，例如，如果路由 器收到发往128.1.2.255的数据报，当B类网络128.1的子网掩码为255.255.255.0时，该地址就是指向子网的广播地址；但如果该子 网的掩码为255.255.254.0，该地址就不是指向子网的广播地址。</li>
  <li>指向所有子网的广播。指向所有子网的广播也需要了解目的网络的子网掩码，以便与指向网络的广播地址区分开来，指向所有子网的广播地址的子网号和主机号全为1。例如，如果目的子网掩码为255.255.255.0，那么IP地址128.1.255.255就是一个指向所有子网的广播地址，然而，如 果网络没有划分子网，这就是一个指向网络的广播。</li>
</ol>

<p>广播给网络中的主机产生了很多负担，<strong>广播的数据报要直到UDP层才被确定是否为主机所需要</strong>（没有监听的端口）然后才会被丢弃。多播是介于单播与广播之间的一种方式。</p>

<p>能够接收发往一个特定多播组地址数据的主机集合称为主机组。一个主机组可以跨越多个网络，主机组中成员可以随时加入或离开主机组。主机组中对主机的数量没有限制，同时不属于某一主机组的主机可以向该组发送信息。
下图是多播组地址到以太网地址的转换：</p>

<p><img src="http://dl.iteye.com/upload/attachment/599747/65577750-0fa4-3a4c-addd-dcdf7b62e2f9.jpg" alt="" /></p>

<h3 id="igmp">IGMP协议</h3>

<p>Internet组管理协议（IGMP）是因特网协议家族中的一个<strong>组播协议</strong>，用于 IP主机向任一个直接相邻的路由器报告他们的组成员情况。它规定了处于不同网段的主机如何进行多播通信，其前提条件是路由器本身要支持多播。</p>

<p>它用来在IP主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。IGMP不包括组播路由器之间的组成员关系信息的传播与维护，这部分工作由各组播路由协议完成。</p>

<p>参与IP组播的主机可以在任意位置、任意时间、成员总数不受限制地加入或退出组播组。组播路由器不需要也不可能保存所有主机的成员关系，它只是通过IGMP协议了解每个接口连接的网段上是否存在某个组播组的接收者，即组成员。而主机方只需要保存自己加入了哪些组播组。多播路由器并不关心有多少主机属于一个多播组，它只是想知道给定接口上的多播组是否还有人对这个多播组感兴趣。</p>

<h3 id="section-4">选路协议</h3>

<p>当相邻的路由器之间进行通信，以告知对方每个路由器当前所连接的网络，这时就出现了动态选路。路由器之间必须采用选路协议进行通信，这样的协议有很多种，如RIP、OSPF，路由守护进程运行选路协议，并与其相邻的一些路由器进行通信。路由守护程序将选路策略加入到系统中，选择路由并加入到内核的路由表中。如果守护程序发现前往同一信宿存在多条路由，那么它将（以某种方法）选择最佳路由并加入内核路由表中。如果路由守护程序发现一条链路已经断开，它可以删除受影响的路由或加入另一条路由以绕过该问题。</p>

<p>在像Internet这样的系统中，目前采用了许多不同的选路协议。Internet是以一组自治系统的方式组织的，每个自治系统通常由单个实体管 理。常常将一个公司或大学校园定义为一个自治系统。每个自治系统可以选择该自治系统中各个路由器之间的选路协议，这种协议称之为内部网关协议（IGP）， 常用的IGP有RIP和OSPF。不同自治系统的路由器之间进行通信协议称为外部网关协议（BGP）。</p>

<h2 id="section-5">传输层</h2>

<p>终于到了传输层，先来个开胃菜UDP，再介绍TCP。</p>

<h3 id="udp-">UDP 用户数据报协议</h3>
<p>下图是UDP首部的格式：</p>

<p><img src="http://dl.iteye.com/upload/attachment/599727/3174ddc1-a81b-36ea-ac8e-a72a8418188d.jpg" alt="" /></p>

<p>当UDP数据报的长度超过网络的MTU时，必须对其进行分片。如果IP层设置了DF位但是通过某个网络时需要分片，将会产生ICMP“不可达（需要分片）”的差错报文。</p>

<p>分片需要注意的是：(1)在分片时，除最后一片外，其他每一 、片中的数据部分（除IP首部外的其余部分）必须是8整数倍；(2)运输层首部只出现在第一片中。UDP比较简陋，所有包丢失、重传问题都必须由上层应用程序来管理。</p>

<h3 id="tcp-">TCP 传输控制协议</h3>

<p>TCP提供<strong>面向连接的，可靠的</strong>字节流服务， 它设计了各种机制以实现丢包、重发、乱序、链路传输错误等传输过程中可能出现的错误。</p>

<p><strong>1. TCP报文格式</strong></p>

<p><img src="http://dl.iteye.com/upload/attachment/599787/eccadd8c-6160-3bda-837c-704c0d09c0b0.jpg" alt="" /></p>

<p>其中6个标志比特，它们中的多个可以被同时设置为1：</p>

<ul>
  <li>URG：紧急指针有效，与后面的紧急指针结合起来</li>
  <li>ACK：确认序号有效</li>
  <li>PSH：接收方尽快将这个报文段交给应用层</li>
  <li>RST：重建连接</li>
  <li>SYN：同步序号用来发起一个连接</li>
  <li>FIN：发端完成发送任务，将要关闭连接</li>
</ul>

<p>其他字段有：</p>

<ul>
  <li>窗口大小表明接收端当前的接收能力，以字节为单位，16位窗口限制了最大值为65535字节，在选项字段中，有一个窗口刻度选项，允许这个值按比例放大。</li>
  <li>紧急指针是一个正的偏移量，和序号中的值相加表示紧急指针最后一个字节的序号。</li>
  <li>选项字段可以包括<strong>最长报文大小（MSS）</strong>，这是最常见的可选字段。每个连接方通常都在通信的第一个报文段中指明这个选项，表明本端所能接收的最大长度的报文段；还有窗口扩大选项以及时间戳选项。</li>
</ul>

<p><strong>2. 连接与终止</strong></p>

<p><img src="http://dl.iteye.com/upload/attachment/599805/5991ccb8-afaa-3670-9f00-4da6f24a38ea.jpg" alt="" /></p>

<p>tcp连接的其中一方发起主动连接，它填写目的端口和源端口号，初始化序列号，设置SYN位，并设置了mss选项，将该TCP段发给连接的另一方。 另一方收到tcp段后，与主动连接方做了同样的事情，同时携带ACK，把对主动连接方的初始序号加1填入确认序列号字段，发送给主动连接方。主动连接方向 被动连接方发去一个ack，连接由此建立。</p>

<p>图中还演示了连接关闭的过程，终止一个连接需要四次握手。任何一方在最后的发送数据段中设置FIN位来终止这个方向的连接。当一端收到一个FIN， 它必须通知应用层另一端已经终止了那个方向的数据传输，也就是说，不再会有数据从那个方向传来，但它仍然能够发送数据，收到FIN方回复一个ack。</p>

<p>由图我们还可以看到，SYN和FIN各占用了一个序号。</p>

<p>图中的端口A、B还让我们想起一个问题，如果不存在用户进程在监听端口B（<strong>即端口B没有打开</strong>）时，主机A将会收到什么呢？在UDP中，发送端将收到一份ICMP端口不可达报文，那么在TCP连接中呢？TCP使用复位，即在回应发送端的TCP段中设置了RST位，携带ack主动发送端的确认序列号，自己的序列号为0。发送端收到这样的tcp段后，即知道连接被拒绝了。</p>

<p>那如果<strong>主机B根本就不存在</strong>呢？这时主机A将过一段时间再发送一个SYN到主机B请求连接，一般建立一个连接的最长时间限制为75秒。</p>

<p>如果一方已经关闭或导演终止而另一方却不知道，我们将这样的TCP连接称为<strong>半打开</strong>的。比方说在主机A（客户端）上运行telnet程序，通过它和主机B（服务器）连接，由于突然停电，主机A没有向主机B的telnet端口发送FIN消息，结果主机B就以为与主机A的连接还在。主机A重新启动后再次与主机B连接将会启动新的服务器程序，这样<strong>将会导致主机B上产生很多半打开的TCP连接</strong>。如果是服务器主机B突然当掉了，而客户端A并不知道，它继续向主机B发送数据，假如主机B很快恢复了，然而先前的所有连接信息都丢失了，收到来自主机A的消息时，它<strong>回复以RST消息</strong>（相当于没有端口在监听）。</p>

<p>TCP支持同时打开或同时关闭，不过同时打开将经历4次握手。同时关闭进入<code>TIME_WAIT</code>状态，要再经过2MSL超时才关闭。</p>

<p><img src="http://blog.chinaunix.net/photo/91603_100713212857.jpg" alt="同时打开" /></p>

<p><img src="http://blog.chinaunix.net/photo/91603_100713213550.jpg" alt="同时关闭" /></p>

<p><strong>3. TCP的状态变迁</strong></p>

<p><img src="http://blog.chinaunix.net/photo/91603_100707001221.jpg" alt="" /></p>

<p>状态图中比较重要的一点就是，主动关闭方在收到对方的对自己FIN的ACK以及对方的FIN后，进入一个状态叫<code>TIME_WAIT</code>，这种状态也称为<code>2MSL</code> 等待状态。每个TCP实现必须选择一个报文段最大生存时间MSL(Maximum Segment Lifetime)，它是任何报文段被丢弃前在网络内的最长时间。对于一个具体实现所给定的MSL值，处理的原则是：当TCP执行一个主动关闭，并发回最后一个ACK，该连接必须在<code>TIME_WAIT</code>状态停留的时间为2倍的MSL，<strong>以防这个ACK丢失的时候，可以重发一个ACK（对应另一端收不到ACK重发最后的FIN消息）</strong>。这种2MSL等待的另一个结果是这个TCP连接在2MSL等待期间，定义这个连接的插口（客户的IP地址和端口号，服务的IP地址和端口号）不能再被使用，这个连接只能在2MSL结束后才能被使用。</p>

<p><img src="http://blog.chinaunix.net/photo/91603_100708211823.jpg" alt="" /></p>

<p><strong><code>TIME_WAIT</code>是执行主动关闭的那一段进入的状态，存在的理由有两个</strong>：</p>

<ol>
  <li>可靠地实现TCP全双工连接的终止，也就是上面的那个理由。</li>
  <li>
    <p>运行老的重复分节在网络中消逝。</p>

    <p>防止上一个连接到达的TCP误解为现在的连接的TCP。<code>TIME_WAIT</code>存在2MSL，而两个方向上的TCP都最多存活MSL秒即被丢弃。</p>
  </li>
</ol>

<p><strong>4. 呼叫连接请求队列</strong></p>

<p>TCP处理呼入连接请求规则:</p>

<ol>
  <li>正等待连接的一端有一个固定长度的连接队列，该队列中的连接已经完成3次握手，但还没有被应用层接收。</li>
  <li>
    <p>应用层指定这个连接队列的最大长度，这个值通常叫做积压值(backlog)。取值范围为0至5的整数。</p>

    <p>不同环境下，backlog的含义与实现都将不同：</p>

    <blockquote>
      <p>The behaviour of the backlog parameter on TCP sockets changed with Linux 2.2. Now it specifies the queue length for completely established sockets waiting to be accepted， instead of the number of incomplete connection requests. The maximum length of the queue for incomplete sockets can be set using the tcp_max_syn_backlog sysctl. When syncookies are enabled there is no logical maximum length and this sysctl setting is ignored.</p>
    </blockquote>
  </li>
  <li>当一个请求连接到达(SYN)，TCP根据连接队列中的连接数确认是否接收这个连接。但这时的最大排队连接数并不等于积压值。</li>
  <li>如果连接队列中的连接数少于最大排队的连接数，TCP将确认建立连接。在客户端主动连接成功而服务端应用层还没接收这个连接时，客户端发送的数据将保存在服务端的TCP缓存队列。</li>
  <li>如果连接队列没有空间，TCP将丢弃收到的SYN请求，不发回任何报文(包括RST)。客户端将超时重传SYN请求，等待连接队列有空间。</li>
</ol>

<p>TCP服务器无法使客户端的主动打开失效。因为服务器接收到请求时，TCP的三次握手已经完成。所以对于限定远程IP地址的服务器，必须在客户端三次握手建立连接后才能判断是否合法。</p>

<p><strong>5. TCP的数据流</strong></p>

<p>建立完连接后，两台主机开始进行数据的传输。传输的数据可以分成两种，一种是<strong>交互式数据的传输</strong>，如通过telnet发送指令；一种是<strong>大量数据的传输</strong>，如通过ftp传输文件。TCP显然需要同时能够处理这两种类型的数据，但使用的算法有所不同。</p>

<p><img src="http://blog.chinaunix.net/photo/91603_100717121935.jpg" alt="交互式输入" /></p>

<p>上图为没有优化的字符输入回显的数据传输过程。一共需要四个报文段。</p>

<p>上图第二，三个报文段可以合并—按键确认和按键回显一起发送。这种技术叫做<strong>经受时延的确认</strong>。
通常TCP在接收到数据时并不立即发送ACK，将以不大于TCP定时器的延时等待是否有数据一起发送，有时也称这种现象为<strong>数据捎带ACK</strong>。</p>

<p>ACK延时等待时间不大于TCP定时器的原因：
假如TCP使用200ms的定时器，该定时器将相对于内核引导的200ms固定时间溢出，由于将要确定的数据随机到达，TCP将在下一次内核的200ms定时器溢出时得到通知，所以ACK实际等待的时间为1~200ms中任一刻。</p>

<p><strong>Nagle算法对发送方要求TCP连接上最多只有一个未被确认的未完成小分组</strong>，在该分组确认到达之前不能发送其他的小分组。且同时TCP收集这些小分组，在确认到达后以一个大的分组发出去。
该算法可以减少网络上的微小分组，降低拥塞出现的可能。但相应的，也会增加更多的时延。流程:</p>

<ol>
  <li>发送端TCP将从应用进程接收到的第一数据块立即发送，不管其大小，哪怕只有一个字节。</li>
  <li>发送端输出第一块数据后开始收集数据，并等待确认。</li>
  <li>确认未达到时，若收集数据达到窗口的一半或一个MSS段，立即发送。</li>
  <li>确认到达后，把缓冲区中的数据组成一个TCP段，然后发送。</li>
</ol>

<p><strong>对于成块的数据流，TCP更应该关注的是流量的控制。</strong>发送端有发送缓冲区（即从应用程序到tcp），接收端有接收缓冲区，并不是接收到的数据马上就能被应用程序处理，如果发送端不断地发送数据，而接收端的缓冲区已经被占满，它必须通知发送端在缓冲区有空隙前，请不要再发送数据了。在TCP中，缓冲区被形象地比喻成一个可以滑动的窗口，TCP通过一些算法来根据窗口的大小发送数据，<strong>滑动窗口协议</strong>。这是端到端的。还有另外一种情况，就是，当发送方和接收方之间存在多个路由器和速率较慢的链路时，就有可能出现一些问题，一些中间路由器必须缓冲分区，并有可能耗存储器的空间。因此，连接建立时，双方应该慢慢了解去往对方的路况，然后以一个比较合适的速率大小发送块数据。TCP支持一种被称为“<strong>慢启动</strong>”的算法，该算法通过观察到新分组进入网速的速率应该与另一端返回确认的速率相同而进行工作。慢启动为发送方的TCP增加了另一个窗口：<strong>拥塞窗口</strong>，当与另一个网络建立TCP连接时，拥塞窗口被初始化为1个报文段（即另一端通告的报文段大小）。每收到一个ack，拥塞窗口就增加一个报文段，发送方取拥塞窗口与通告窗口中的最小值作为发送上限。拥塞窗口是发送方使用的流量控制，而通告窗口是接收方使用的流量控制。</p>

<p><strong>PUSH标志：</strong>如果待发送数据会清空发送缓冲区，该包将自动设置PUSH标志。</p>

<ol>
  <li>发送方将发送缓冲区的数据立即发送给接收方。</li>
  <li>接收方将接收缓冲区的数据立即提交给接收进程。</li>
</ol>

<p><strong>6. TCP的超时与重传</strong></p>

<p><img src="http://blog.chinaunix.net/photo/91603_100803210729.jpg" alt="" /></p>

<ul>
  <li>RTT(往返时间)：指发送端发送TCP报文段开始到接收到对方的确定所使用的时间。</li>
  <li>RTO(超时重传时间)：发送端发送TCP报文段后，在RTO时间内没有收到对方确定，即重传该报文段。</li>
</ul>

<p><strong>拥塞避免算法</strong></p>

<p>拥塞避免算法和慢启动算法通常一起使用。维持两个变量：拥塞窗口( cwnd )  慢启动门限( ssthresh )。</p>

<ol>
  <li>对一个给定的连接，初始化cwnd为1个报文段， ssthresh为65535个字节.</li>
  <li>TCP输出例程的输出不能超过cwnd和接收方通告窗口的大小.拥塞避免是发送方使用的流量控制，而通告窗口则是接收方进行的流量控制.前者是发送方感受到的网络拥塞的估计，后者则与接收方在该连接上的可用缓存大小有关.</li>
  <li>当拥塞发生时(超时或收到重复确认)，ssthresh被设置为当前窗口大小的一半(cwnd和接收方通告窗口大小的最小值，但最少为2个报文段).此外，如果是超时引起了拥塞，则cwnd被设置为1个报文段（这就是慢启动).</li>
  <li>当新的数据被对方确认时，就增加cwnd，但增加的方法依赖于我们是否正在进行慢启动或拥塞避免.如果cwnd &lt;= ssthresh，则正在进行慢启动，否则正在进行拥塞避免.</li>
</ol>

<p><strong>cwnd增加方式</strong></p>

<ul>
  <li>慢启动初始cwnd为1，每收到一个确定就加1.成指数增长.</li>
  <li>拥塞避免算法在每个RTT内增加 1/cwnd 个报文，成线性增长.</li>
  <li>慢启动根据收到的ACK次数增加cwnd，而拥塞避免算法在一个RTT不管收有多少ACK也只增加一次.</li>
</ul>

<p><strong>快速重传和快速恢复算法</strong></p>

<p>如果收到3个重复ACK，可认为该报文段已经丢失，此时无需等待超时定时器溢出，直接重传丢失的包，这就叫<strong>快速重传算法</strong>.而<strong>接下来执行的不是慢启动而是拥塞避免算法</strong>，这就叫<strong>快速恢复算法</strong>.</p>

<ol>
  <li>当收到第3个重复的ACK时，将ssthresh设置为当前拥塞窗口cwnd的一半.重传丢失的报文段，设置cwnd为ssthresh加上3倍的报文段大小.</li>
  <li>每次收到另一个重复的ACK时，cwnd增加1个报文段大小并发送1个分组(如果新的cwnd允许发送).</li>
  <li>当下一个确认新数据的ACK到达时，设置cwnd为ssthresh(在第1步中设置的值).这个ACK应该是在进行重传后的一个往返时间内对步骤1中重传的确认.另外，这个ACK也应该是对丢失的分组和收到的第1个重复的ACK之间的所有中间报文段的确认.这一步采用的是拥塞避免，因为当分组丢失时我们将当前的速率减半.</li>
</ol>

<p><strong>7. TCP的四个定时器</strong></p>

<p>对每个连接，TCP管理4个不同的定时器：</p>

<ol>
  <li>
    <p><strong>重传定时器</strong>，用于等待另一端的确认。</p>

    <p>当发送端发送出数据后，经过一段时间后假如仍然没有收到接收端的确认，那么就重传该数据块</p>
  </li>
  <li>
    <p><strong>坚持定时器</strong>，使窗口大小信息保持不断流动，即使另一端关闭了其接收窗口</p>

    <p>当接收方的窗口大小为0时，发送方将不能再向它发送数据，直到接收方用一个窗口大小为非0的消息来通告发送端。可是，万一这个消息丢失了呢？接收方就一直这样等着发送方发来数据，而发送端就一直等着接收方发来窗口大于0的消息，两方就都僵在那里了。为了避免这种情况的出现，便有了坚持定时器，<strong>发送方使用一个坚持定时器来周期性地向接收方查询，以便发现窗口是否已增大。坚持定时器的定时时间也是指数退避的。</strong></p>

    <p><strong>糊涂窗口综合症</strong>是指接收方一旦有非0的窗口大小就向发送方通告，从而引起发送端发送少量的数据这样的情况。可以在任何一方采取措施避免出现这种状况：</p>

    <ol>
      <li>在接收方，接收方不通告小窗口，一般是除非窗口可以增加一个报文段大小或可以增加接收方缓冲区空间的一半，不然通告窗口大小为0.</li>
      <li>在发送方，发送方除非收到一个比较大的窗口（如一个报文段小大、是接收方通告窗口大小一半的报文段）或者是还没有未被确认的数据的情况下，才会发送数据。</li>
    </ol>

    <p>接收方和发送方两方同时进行决策，因为接收方不能通告一个不合理的窗口大小（比方说，原先的窗口大小是1500，报文段长度为1024，发送方发送 了1024字节的数据后，这时候接收方的窗口大小是476，小于一个报文大小，但是如果通告窗口大小为0，岂不是很不合理？），因此在收到这个的窗口通告消息后，就轮到发送方使用它的策略了，发送方设定一个坚持定时器，在这个定时器的时间内，除非收到足够大的通告窗口，否则不发送数据。当然，如果定时器超时了，发送方还是要发送小数据量的报文的。</p>
  </li>
  <li>
    <p><strong>保活定时器</strong>，检测到一个空闲连接的另一端何时崩溃或重启。</p>

    <p>前面我们提到“半打开”的连接，这种情况很可能占用服务器很多端口，因此一般由服务器使用保活选项。如果一个给定的连接在两个小时之内没有任何动作，则服务器就向客户发送一个探查报文段，客户主机将必须以下四种状态之一：</p>

    <ol>
      <li>客户主机依然正常运行，并从服务器可达。客户的TCP响应正常，而服务器也知道对方是正常工作的。服务器在两个小时后将保活定时器复位。如果在两个小时定时器到时间之前有应用程序的通信量通过此连接，则定时器在交换数据后的未来2个小时再复位。</li>
      <li>客户主机已经崩溃，并且关闭或者正在重新启动。在任何一种情况下，客户的TCP都没有响应，服务器将不能收到对探查的响应，并在75秒后超时。服务器总共发送10个探查，每个间隔75称。如果服务器没有收到一个响应，它就认为客户主机已经关闭并终止连接。</li>
      <li>客户主机崩溃并且已经重新启动。这时服务器将收到一个对其保活探查的响应，但是这个响应是一个复位，使得服务器终止这个连接。</li>
      <li>客户主机正常运行，但是从服务器不可达。这跟情况2是一样的。</li>
    </ol>
  </li>
  <li>
    <p><strong>2MSL的时间测量器</strong></p>
  </li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some NB Translations]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/17/Some-NB-translation/"/>
    <updated>2014-07-17T20:07:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/17/Some-NB-translation</id>
    <content type="html"><![CDATA[<ul>
  <li><a href="http://blog.csdn.net/eroswang/article/details/1787456">Unix编程常见问题解答</a></li>
  <li><a href="http://blog.csdn.net/eroswang/article/details/1790351">从程序员角度看ELF</a></li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux thundering herd]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/17/thundering-herd/"/>
    <updated>2014-07-17T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/17/thundering-herd</id>
    <content type="html"><![CDATA[<p><em>modified from <a href="http://blog.csdn.net/russell_tao/article/details/7204260">http://blog.csdn.net/russell_tao/article/details/7204260</a></em></p>

<hr />

<h2 id="section">惊群现象</h2>

<p>什么是“惊群”？简单说来，多线程/多进程（linux下线程进程也没多大区别）等待同一个socket事件，当这个事件发生时，这些线程/进程被同时唤醒，就是惊群。可以想见，效率很低下，许多进程被内核重新调度唤醒，同时去响应这一个事件，当然只有一个进程能处理事件成功，其他的进程在处理该事件失败后重新休眠（也有其他选择）。这种性能浪费现象就是惊群。</p>

<p>惊群通常发生在server 上，当父进程绑定一个端口监听socket，然后fork出多个子进程，子进程们开始循环处理（比如accept）这个socket。每当用户发起一个TCP连接时，多个子进程同时被唤醒，然后其中一个子进程accept新连接成功，余者皆失败，重新休眠。</p>

<p>那么，我们不能只用一个进程去accept新连接么？然后通过消息队列等同步方式使其他子进程处理这些新建的连接，这样惊群不就避免了？没错，惊群是避免了，但是效率低下，因为这个进程只能用来accept连接。对多核机器来说，仅有一个进程去accept，这也是程序员在自己创造accept瓶颈。所以，我仍然坚持需要多进程处理accept事件。</p>

<h2 id="linux">linux解决的惊群</h2>

<p>其实，在linux2.6内核上，<strong>accept系统调用已经不存在惊群了</strong>（至少我在2.6.18内核版本上已经不存在）。大家可以写个简单的程序试下，在父进程中bind,listen，然后fork出子进程，所有的子进程都accept这个监听句柄。这样，当新连接过来时，大家会发现，仅有一个子进程返回新建的连接，其他子进程继续休眠在accept调用上，没有被唤醒。</p>

<p>对于一些已知的惊群问题，内核开发者增加了一个“<strong>互斥等待</strong>”选项。一个互斥等待的行为与睡眠基本类似，主要的不同点在于：</p>

<ul>
  <li>当一个等待队列入口有 WQ_FLAG_EXCLUSEVE 标志置位, 它被添加到等待队列的尾部. 没有这个标志的入口项, 相反, 添加到开始.</li>
  <li>当 wake_up 被在一个等待队列上调用时, 它在唤醒第一个有 WQ_FLAG_EXCLUSIVE 标志的进程后停止。也就是说，对于互斥等待的行为，比如如对一个listen后的socket描述符，多线程阻塞accept时，系统内核只会唤醒所有正在等待此时间的队列的第一个，队列中的其他人则继续等待下一次事件的发生，这样就避免的多个线程同时监听同一个socket描述符时的惊群问题。</li>
</ul>

<h2 id="nginx">nginx解决惊群</h2>

<p>但是很不幸，通常我们的程序没那么简单，不会愿意阻塞在accept调用上，我们还有许多其他网络读写事件要处理，linux下我们爱用epoll解决非阻塞socket。所以，即使accept调用没有惊群了，我们也还得处理惊群这事，因为epoll有这问题。上面说的测试程序，如果我们在子进程内不是阻塞调用accept，而是用<code>epoll_wait</code>，就会发现，新连接过来时，多个子进程都会在<code>epoll_wait</code>后被唤醒！</p>

<p>nginx就是这样，master进程监听端口号（例如80），所有的nginx worker进程开始用<code>epoll_wait</code>来处理新事件（linux下），如果不加任何保护，一个新连接来临时，会有多个worker进程在<code>epoll_wait</code>后被唤醒，然后发现自己accept失败。</p>

<p>nginx在同一时刻只允许一个nginx worker在自己的epoll中处理监听句柄。它的负载均衡也很简单，当达到最大connection的7/8时，本worker不会去试图拿accept锁，也不会去处理新连接，这样其他nginx worker进程就更有机会去处理监听句柄，建立新连接了。而且，由于timeout的设定，使得没有拿到锁的worker进程，去拿锁的频繁更高。</p>

<h2 id="nginx-1">nginx的锁</h2>

<p>在用户空间进程间锁实现的原理很简单，就是能弄一个让所有进程共享的东西，比如mmap的内存，比如文件，然后通过这个东西来控制进程的互斥。</p>

<p>nginx的实现分为两种情况：</p>

<ul>
  <li>一种是支持原子操作的情况，也就是由mmap的内存区域来进行控制的</li>
  <li>一种是不支持原子操作，这是是使用文件锁来实现。 </li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux reentrant function]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/15/linux-reentrant-function/"/>
    <updated>2014-07-15T06:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/15/linux-reentrant-function</id>
    <content type="html"><![CDATA[<p>这种情况出现在多任务系统当中，在任务执行期间捕捉到信号并对其进行处理时，进程正在执行的指令序列就被信号处理程序临时中断。如果从信号处理程序返回，则继续执行进程断点处的正常指令序列，从重新恢复到断点重新执行的过程中，函数所依赖的环境没有发生改变，就说这个函数是可重入的，反之就是不可重入的。简单来说，<strong>可重入函数可以被中断的函数</strong>。</p>

<p>在进程中断期间，系统会保存和恢复进程的上下文，然而恢复的上下文仅限于返回地址，cpu寄存器等之类的少量上下文，而函数内部使用的诸如全局或静态变量，buffer等并不在保护之列，所以如果这些值在函数被中断期间发生了改变，那么当函数回到断点继续执行时，其结果就不可预料了。打个比方，比如<code>malloc</code>，将如一个进程此时正在执行<code>malloc</code>分配堆空间，此时程序捕捉到信号发生中断，执行信号处理程序中恰好也有一个<code>malloc</code>，这样就会对进程的环境造成破坏，因为malloc通常为它所分配的存储区维护一个链接表，插入执行信号处理函数时，进程可能正在对这张表进行操作，而信号处理函数的调用刚好覆盖了进程的操作，造成错误。</p>

<p><strong>基本上下面的函数是不可重入的：</strong></p>

<ul>
  <li>函数体内使用了静态的数据结构；</li>
  <li>函数体内调用了malloc()或者free()函数；</li>
  <li>函数体内调用了标准I/O函数。</li>
  <li>进行了浮点运算。许多的处理器/编译器中，浮点一般都是不可重入的 （浮点运算大多使用协处理器或者软件模拟来实现）。</li>
</ul>

<p><strong>两种情况需要考虑：</strong></p>

<ol>
  <li>信号处理程序A内外都调用了同一个不可重入函数B；B在执行期间被信号打断，进入A (A中调用了B),完事之后返回B被中断点继续执行，这时B函数的环境可能改变，其结果就不可预料了。</li>
  <li>多线程共享进程内部的资源，如果两个线程A，B调用同一个不可重入函数F，A线程进入F后，线程调度，切换到B，B也执行了F，那么当再次切换到线程A时，其调用F的结果也是不可预料的。</li>
</ol>

<p><strong>在信号处理程序中即使调用可重入函数也有问题要注意</strong>。作为一个通用的规则，当在信号处理程序中调用可重入函数时，应当在其前保存<code>errno</code>，并在其后恢复<code>errno</code>。（<strong>因为每个线程只有一个errno变量，信号处理函数可能会修改其值，要了解经常被捕捉到的信号是SIGCHLD，其信号处理程序通常要调用一种wait函数，而各种wait函数都能改变errno。</strong>）</p>

<p>如果一个函数对多个线程来说是可重入的，则说这个函数是<strong>线程安全的</strong>。但这并不能说明对信号处理程序来说该函数也是可重入的。如果函数对异步信号处理程序的重入是安全的，那么就可以说函数式<strong>异步-信号安全的</strong>。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Linux epoll module]]></title>
    <link href="http://billowkiller.github.io/blog/2014/07/15/linux-epoll-module/"/>
    <updated>2014-07-15T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/07/15/linux-epoll-module</id>
    <content type="html"><![CDATA[<p>综合了几个blog以及自己查到的一些资料，总结下Linux中的IO多路复用，主要是<code>epoll</code>模型。</p>

<p><code>select</code>，<code>poll</code>，<code>epoll</code>都是Linux下IO多路复用的机制。Windows下为<code>IOCP</code>模型。I/O多路复用就通过一种机制，可以监视多个描述符，一旦某个文件描述符就绪，能够通知程序进行相应的读写操作。其中文件描述符是一个简单的整数，用以标明每一个被进程所打开的文件和socket，包括<code>filefd</code>、<code>socketfd</code>、<code>signalfd</code>、<code>timerfd</code>、<code>eventfd</code>等。<code>eventfd</code> 是一个比 <code>pipe </code>更高效的线程间事件通知机制。</p>

<p>但<code>select</code>，<code>poll</code>，<code>epoll</code>本质上都是<strong>同步I/O</strong>，因为他们都需要在读写事件就绪后自己负责进行读写，也就是说这个读写过程是阻塞的，而<strong>异步I/O</strong>则无需自己负责进行读写，异步I/O的实现会负责把数据从内核拷贝到用户空间。</p>

<!--more-->

<h2 id="select">select实现</h2>

<p><img src="http://www.ibm.com/developerworks/cn/linux/l-async/figure4.gif" alt="" /></p>

<p><strong><code>select</code>的几大缺点：</strong></p>

<ul>
  <li>
    <u>每次调用`select`，都需要把fd集合从用户态拷贝到内核态，这个开销在fd很多时会很大</u>
  </li>
  <li>
    <u>同时每次调用`select`都需要在内核遍历传递进来的所有fd，这个开销在fd很多时也很大</u>
  </li>
  <li>
    <u>`select`支持的文件描述符数量太小了，默认是`1024`</u>
  </li>
</ul>

<h2 id="poll">poll实现</h2>

<p><code>poll</code>的实现和<code>select</code>非常相似，只是描述fd集合的方式不同，poll使用<code>pollfd</code>结构而不是select的<code>fd_set</code>结构，其他的都差不多。poll用<strong>nfds</strong>参数指定最多监听多少个文件描述符和事件，能达到系统允许打开的最大文件描述符数目，这点和<code>epoll</code>一样。</p>

<h2 id="epoll">epoll</h2>

<p><code>epoll</code>是对<code>select</code>和<code>poll</code>的改进，能避免上述的三个缺点。我们先看一下<code>epoll</code>和<code>select</code>和<code>poll</code>的调用接口上的不同，<code>select</code>和<code>poll</code>都只提供了一个函数——<code>select</code>或者<code>poll</code>函数。而<code>epoll</code>提供了三个函数：</p>

<ul>
  <li><code>epoll_create</code>，创建一个epoll句柄；</li>
  <li><code>epoll_ctl</code>，注册要监听的事件类型；</li>
  <li><code>epoll_wait</code>，等待事件的产生。</li>
</ul>

<p>对于第一个缺点，<code>epoll</code>的解决方案在<code>epoll_ctl</code>函数中。每次注册新的事件到<code>epoll</code>句柄中时（在<code>epoll_ctl</code>中指定<code>EPOLL_CTL_ADD</code>），会把所有的fd拷贝进内核，而不是在<code>epoll_wait</code>的时候重复拷贝。<code>epoll</code>保证了每个fd在整个过程中只会拷贝一次。</p>

<p>对于第二个缺点，<code>epoll</code>的解决方案不像<code>select</code>或<code>poll</code>一样每次都把current轮流加入fd对应的设备等待队列中，而只在<code>epoll_ctl</code>时把current挂一遍（这一遍必不可少）并为每个fd指定一个回调函数，当设备就绪，唤醒等待队列上的等待者时，就会调用这个回调函数，而这个回调函数会把就绪的fd加入一个就绪链表）。<code>epoll_wait</code>的工作实际上就是在这个就绪链表中查看有没有就绪的fd（利用<code>schedule_timeout()</code>实现睡一会，判断一会的效果，和<code>select</code>实现中的是类似的）。</p>

<p>对于第三个缺点，<code>epoll</code>没有这个限制，它所支持的FD上限是最大可以打开文件的数目，这个数字一般远大于2048,举个例子,在1GB内存的机器上大约是10万左右，具体数目可以<code>cat /proc/sys/fs/file-max</code>察看,一般来说这个数目和系统内存关系很大。</p>

<h3 id="section">触发模型</h3>

<h4 id="eagain">1. EAGAIN</h4>

<p>先说下<code>EAGIN</code>这个返回值。</p>

<p>在一个非阻塞的socket上调用read/write函数, 返回<code>EAGAIN</code>或者<code>EWOULDBLOCK</code>(注: EAGAIN就是EWOULDBLOCK)。从字面上看, 意思是:EAGAIN: 再试一次，EWOULDBLOCK: 如果这是一个阻塞socket, 操作将被block，perror输出: Resource temporarily unavailable</p>

<p><strong>总结:</strong></p>

<p>这个错误表示资源暂时不够，能read时，读缓冲区没有数据，或者write时，写缓冲区满了。遇到这种情况，如果是阻塞socket，read/write就要阻塞掉。而如果是非阻塞socket，read/write立即返回-1， 同时<code>errno</code>设置为<code>EAGAIN</code>。</p>

<p>所以，<strong>对于阻塞socket，read/write返回-1代表网络出错了。但对于非阻塞socket，read/write返回-1不一定网络真的出错了。可能是Resource temporarily unavailable。这时你应该再试，直到Resource available。</strong></p>

<h4 id="lt--et">2. LT &amp; ET</h4>

<p><code>epoll</code>除了提供<code>select\poll</code>那种IO事件的<strong>电平触发(Level Triggered)</strong>外，还提供了<strong>边沿触发(Edge Triggered)</strong>，这就使得用户空间程序有可能缓存IO状态，减少<code>epoll_wait/epoll_pwait</code>的调用，提供应用程序的效率。</p>

<ul>
  <li>
    <p><strong>LT(level triggered)：</strong>水平触发，缺省方式，同时支持block和no-block socket，在这种做法中，内核告诉我们一个文件描述符是否被就绪了，如果就绪了，你就可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错的可能性较小。传统的<code>select\poll</code>都是这种模型的代表。</p>
  </li>
  <li>
    <p><strong>ET(edge-triggered)：</strong>边沿触发，高速工作方式，只支持no-block socket。在这种模式下，当描述符从未就绪变为就绪状态时，内核通过<code>epoll</code>告诉你。然后它会假设你知道文件描述符已经就绪，并且不会再为那个描述符发送更多的就绪通知，直到你做了某些操作导致那个文件描述符不再为就绪状态了(比如：你在发送、接受或者接受请求，或者发送接受的数据少于一定量时导致了一个EWOULDBLOCK错误)。但是请注意，如果一直不对这个fs做IO操作(从而导致它再次变成未就绪状态)，内核不会发送更多的通知。</p>
  </li>
</ul>

<p><strong>区别：</strong>LT事件不会丢弃，而是只要读buffer里面有数据可以让用户读取，则不断的通知你。而ET则只在事件发生之时通知。</p>

<p><strong>ET方式注意事项：</strong> 必须使用<strong>非阻塞套接口</strong>，以避免由于一个文件句柄的阻塞读/阻塞写操作把处理多个文件描述符的任务饿死。最好以下面的方式调用ET模式的epoll接口：</p>

<ul>
  <li>基于非阻塞文件句柄</li>
  <li>
    <p>只有当read(2)或者write(2)返回<strong>EAGAIN</strong>时才需要挂起，等待。但这并不是说每次read()时都需要循环读，直到读到产生一个EAGAIN才认为此次事件处理完成，<strong>当read()返回的读到的数据长度小于请求的数据长度时，就可以确定此时缓冲中已没有数据了</strong>，也就可以认为此事读事件已处理完成。</p>

    <pre><code>  while(rs)
  {
    buflen = recv(activeevents[i].data.fd, buf, sizeof(buf), 0);
    if(buflen &lt; 0)
    {
      // 由于是非阻塞的模式,所以当errno为EAGAIN时,表示当前缓冲区已无数据可读
      // 在这里就当作是该次事件已处理处.
      if(errno == EAGAIN)
       break;
      else
       return;
     }
     else if(buflen == 0)
     {
       // 这里表示对端的socket已正常关闭.
     }
     if(buflen == sizeof(buf)
       rs = 1;   // 需要再次读取
     else
       rs = 0;
  }
</code></pre>
  </li>
</ul>

<p><strong>还有，假如发送端流量大于接收端的流量(意思是epoll所在的程序读比转发的socket要快),由于是非阻塞的socket,那么<code>send()</code>函数虽然返回,但实际缓冲区的数据并未真正发给接收端,这样不断的读和发，当缓冲区满后会产生<code>EAGAIN</code>错误(参考<code>man send</code>),同时,不理会这次请求发送的数据.所以,需要封装<code>socket_send()</code>的函数用来处理这种情况,该函数会尽量将数据写完再返回，返回-1表示出错。在<code>socket_send()</code>内部,当写缓冲已满(<code>send()</code>返回-1,且<code>errno</code>为<code>EAGAIN</code>),那么会等待后再重试.这种方式并不很完美,在理论上可能会长时间的阻塞在<code>socket_send()</code>内部,但暂没有更好的办法.</strong></p>

<h4 id="accept">3. 正确的accept</h4>

<p>正确的accept，accept 要考虑 3 个问题</p>

<ol>
  <li>
    <p><strong>阻塞模式 accept 存在的问题</strong></p>

    <p>考虑这种情况：TCP连接被客户端夭折，即在服务器调用accept之前，客户端主动发送RST终止连接，导致刚刚建立的连接从就绪队列中移出，如果套接口被设置成阻塞模式，服务器就会一直阻塞在accept调用上，直到其他某个客户建立一个新的连接为止。但是在此期间，服务器单纯地阻塞在accept调用上，就绪队列中的其他描述符都得不到处理。</p>

    <p><strong>解决办法是把监听套接口设置为非阻塞</strong>，当客户在服务器调用accept之前中止某个连接时，accept调用可以立即返回-1，这时源自Berkeley的实现会在内核中处理该事件，并不会将该事件通知给epool，而其他实现把errno设置为ECONNABORTED或者EPROTO错误，我们应该忽略这两个错误。</p>
  </li>
  <li>
    <p><strong>慢系统调用被中断</strong></p>

    <p>当阻塞与某个慢系统调用的一个进程捕获某个信号且相应信号处理函数返回是，该系统调用可能返回一个<code>IENTR</code>错误。我们必须对慢系统调用返回<code>EINTR</code>有所准备。对于accept，以及诸如<code>read</code>、<code>write</code>、<code>select</code>和<code>open</code>之类函数来说，<strong>需要自己重启被中断的系统调用</strong>。不过有一个函数我们不能重启：<code>connect</code>。</p>
  </li>
  <li>
    <p><strong>ET模式下accept存在的问题</strong></p>

    <p>考虑这种情况：<strong>多个连接同时到达</strong>，服务器的TCP就绪队列瞬间积累多个就绪连接，由于是边缘触发模式，epoll只会通知一次，accept只处理一个连接，导致TCP就绪队列中剩下的连接都得不到处理。</p>

    <p><strong>解决办法是用while循环抱住accept调用</strong>，处理完TCP就绪队列中的所有连接后再退出循环。如何知道是否处理完就绪队列中的所有连接呢？accept返回-1并且errno设置为EAGAIN就表示所有连接都处理完。</p>
  </li>
</ol>

<p>综合以上两种情况，服务器应该使用非阻塞地accept，accept在ET模式下的正确使用方式为：</p>

<pre><code>while ((conn_sock = accept(listenfd,(struct sockaddr *) &amp;remote, (size_t *)&amp;addrlen)) &gt; 0) {
    handle_client(conn_sock);
}
if (conn_sock == -1) {
    if (errno != EAGAIN &amp;&amp; errno != ECONNABORTED &amp;&amp; errno != EPROTO &amp;&amp; errno != EINTR)
    perror("accept");
}
</code></pre>

<h4 id="section-1">4. 其他</h4>

<p><strong>EPOLLONETSHOT</strong></p>

<p>epoll模式中事件可能被触发多次，比如socket接收到数据交给一个线程处理数据，在数据没有处理完之前又有新数据达到触发了事件，另一个线程被激活获得该socket，从而产生多个线程操作同一socket，即使在ET模式下也有可能出现这种情况。采用EPOLLONETSHOT事件的文件描述符上的注册事件只触发一次，要想重新注册事件则需要调用epoll_ctl重置文件描述符上的事件，这样前面的socket就不会出现竞态。</p>

<p>如果一个工作线程处理完某个socket上的一次请求之后，又收到该socket上新的客户请求，则该线程将继续为这个socket服务，并且因为该socket上注册了EPOLLONESHORT事件，其他线程没有机会接触这个soket。如果工作线程之后没有收到该socket的下一批用户数据，则放弃该socket服务。同时重置该socket上的注册事件，使得epoll有机会再次检查到该socket上的EPOLLIN事件，进而是的其他线程有机会为该socket服务。</p>

<p><strong>注意：监听socket linstenfd上是不能注册EPOLLONESHOT事件，否则应用程序只能处理一个客户连接。后续的客户请求不再触发listenfd上的EPOLLIN事件。</strong></p>

<p><strong>EPOLLONESHOT和ET一样都是为了能进一步减少可读、可写和异常事件被触发的次数。</strong></p>

<h2 id="section-2">总结</h2>
<p><strong>epoll高效的原因：</strong></p>

<ul>
  <li><code>epoll</code>把用户关心的文件描述符上的时间放在内核的一个事件表中，从而无需向<code>select</code>和<code>poll</code>那样每次调用都要重复传入描述符集合。</li>
  <li>另一个原因就是获取事件的时候，它无须遍历整个被侦听的描述符集，只要遍历那些被内核IO事件异步唤醒而加入Ready队列的描述符集合就行了</li>
  <li>使用<code>mmap</code>加速内核与用户空间的消息传递</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal and fork]]></title>
    <link href="http://billowkiller.github.io/blog/2014/06/28/signal-and-forkmarkdown/"/>
    <updated>2014-06-28T04:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/06/28/signal-and-forkmarkdown</id>
    <content type="html"><![CDATA[<p>当线程调用fork时，就为子进程创建了整个进程地址空间的副本。子进程与父进程是完全不同的进程，只要两者都没有对内存作出改动，父进程和子进程之间还可以共享内存副本。注意一下几个情况：</p>

<ol>
  <li>子进程通过继承整个地址空间的副本，<strong>从父进程那里继承了所有互斥量、读写锁和条件变量的状态</strong>。也就是说，如果它在父进程中被锁住，则它在子进程中也是被锁住的。</li>
  <li>只有调用fork()的线程被复制到子进程（子进程中线程的ID），如果子进程中包含占有锁的线程的副本，那么子进程就没有办法知道它占有了那些锁并且需要释放那些锁，<strong>容易造成死锁</strong>。</li>
  <li>thread-specific data的销毁函数和清除函数都不会被调用。在多线程中调用fork()可能会引起内存泄露。比如在其他线程中创建的thread-specific data，在子进程中将没有指针来存取这些数据，<strong>造成内存泄露</strong>。</li>
</ol>

<p>因为以上这些问题，<strong>在线程中调用fork()的后，我们通常都会在子进程中调用exec()</strong>。因为exec()能让父进程中的所有互斥量，条件变量（pthread objects）在子进程中统统消失（用新数据覆盖所有的内存）。对于那些要使用fork()但不使用exec()的程序，pthread API提供了一个新的函数</p>

<pre><code>pthread_atfor(void (*prepare_func)(void), void(*parent_func)(void), void (*child_func)(void))
</code></pre>

<p>prepare_func在父进程调用fork之前调用，parent_func在fork执行后在父进程内被调用，child_func在fork执行后子进程内被调用。除非你打算很快的exec一个新程序，否则应该避免在一个多线程的程序中使用fork。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal and Thread]]></title>
    <link href="http://billowkiller.github.io/blog/2014/06/28/signal-and-thread/"/>
    <updated>2014-06-28T03:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/06/28/signal-and-thread</id>
    <content type="html"><![CDATA[<p>类UNIX信号以前是专为进程设计的，它比线程的出现早了很多年。当线程模型出现后，专家们试图也在线程上实现信号，这导致了一个问题：即使是在基于进程的编程模式中，信号的处理也可能是很复杂的，因为它打断了正在运行的thread of control， 在signal handler中只能调用可重入函数，修改全局变量的类型必须是<code>sig_atomic_t</code>类型，防止内存访问优化； 而把线程引入编程范型，就使信号的处理变得更加复杂。</p>

<p><strong>避免信号和线程一起使用是明智的选择。</strong>但是，将他们分开又是不可能或不实际的。只要有可能的话，仅仅在主线程内使用<code>pthread_sigmask()</code>来屏蔽信号，然后同步地在专用线程中使用<code>sigwait()</code>来处理信号。</p>

<!--more-->

<h2 id="section">信号模型映射到线程模型</h2>

<p>为了理解信号模型是怎样映射到线程模型的，我们需要知道信号模型的哪些方面是影响进程层面的（process-wide），哪些方面只会影响某个线程的。下面列出几点:</p>

<ol>
  <li>signal actions 是process-wide。如果一个没有处理的信号的默认动作是停止SIGSTOP或终止SIGKILL(该动作是让整个进程停止或终止，而不是只针对某个线程)，那么不管这个信号是发送给哪个线程，整个进程都会停止或终止。</li>
  <li>signal dispositions信号部署是process-wide。每个线程都有自己的信号屏蔽字，但是<strong>信号的处理是进程中所有线程共享的</strong>。这意味着尽管每个线程可以阻止某些信号，但当线程修改了与某个信号相关的处理行为之后，所有的线程都必须共享这个处理行为的改变。</li>
  <li>信号通常是被发送到<strong>任意一个线程</strong>，为了保证不会在多线程进程中一个信号多次被执行。但是以下几种情况是传递到<strong>单个线程</strong>的：
    <ul>
      <li>信号与硬件故障或计时器超时相关。</li>
      <li>当线程尝试向一个broken pipe写数据时，会产生一个SIGPIPE。</li>
      <li>使用<code>pthread_kill()</code>或者<code>pthread_sigqueue()</code>。这些函数允许一个线程发送信号到同一进程的另一个线程。</li>
    </ul>
  </li>
  <li><strong>信号掩码(signal mask)是线程私用的。</strong>在多线程的进程中，不存在process-wide的信号掩码。线程可以使用<code>pthread_sigmask()</code>来独立的屏蔽某些信号。通过这种方法，程序员可以控制那些线程响应那些信号。当线程被创建时，它将继承创建它的线程的信号掩码。</li>
  <li><strong>内核为每个线程和进程分别维护了一个未决信号的表</strong>。当使用<code>sigpending()</code>时，该函数返回的是整个进程未决信号表和调用该函数的线程的未决信号表的并集。当新线程被创建时，线程的pending signals被设置为空。当线程A阻塞某个信号S后，发送到A中的信号S将会被挂起，直到线程取消了对信号S的阻塞。</li>
  <li>如果一个信号处理函数打断了<code>pthread_mutex_lock()</code>，该<strong>函数会自动的重新执行</strong>。如果信号处理函数打断了<code>pthread_cond_wait()</code>，该函数要么自动重新自行（linux是这样实现的），或者返回0（这时应用要检查返回值，判断是否为假唤醒）。</li>
</ol>

<h2 id="section-1">异步信号的处理</h2>

<p>一个函数要么是可重入的（reentrant）,要么是不能被信号处理函数打断的，我们把这种函数叫做是<code>async-signal-safe</code>的。调用非<code>async-signal-safe</code>的函数是危险的，比如，考虑在线程A中，我们调用<code>malloc()</code>来进行内存分配，<code>malloc()</code>刚用互斥量锁住了全局链表，这是异步信号到达，在信号处理函数中也调用<code>malloc()</code>，这时该函数会阻塞在互斥量上，形成死锁（这个例子在单线程的进程中也会出现）。Pthread API不是<code>async-signal-safe</code>的，也就是说在信号处理函数中不要使用pthread相关的函数。</p>

<p><strong>解决这个问题</strong>的最好办法是，在不打断正常程序的前提下，把所有的异步信号都在同一处处理。在单线程程序中，这是做不到的，因为所有发送的信号都会打断程序。而在多线程程序中，我们可以<u>单独创建一个线程来接受信号，处理需要的信号，而不会打断其他线程的工作。</u></p>

<p>上面举的这个例子中还有一点没说到，就是<strong>信号处理函数也会被其他信号所打断</strong>。那我们怎么处理这个问题呢？<u>在处理信号之前，对所有的异步信号进行阻塞，等工作处理完毕后，再恢复阻塞的信号。</u>这个工作就靠下面这个函数执行：</p>

<pre><code>int sigwait(const sigset_t *set, int *sig)
</code></pre>

<ul>
  <li><code>sigwait()</code>的好处在于它可以简化信号处理，允许把异步产生的信号用同步方式处理。</li>
  <li>调用<code>sigwait()</code>等待的信号必须在调用线程中屏蔽，通常我们在所有线程中都会屏蔽。</li>
  <li>信号仅仅被交付一次。如果两个线程在<code>sigwait()</code>上阻塞（等待同一个信号），只有一个线程（不确定的线程）将收到送给进程的信号。这意味着不能让两个独立的子系统使用<code>sigwait()</code>来捕获相同的信号。信号捕获<code>sigaction</code>建立的信号处理程序和<code>sigwait</code>也同样只有一个可以执行。</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Signal status and lifecycle]]></title>
    <link href="http://billowkiller.github.io/blog/2014/06/28/signal-status-and-lifecycle/"/>
    <updated>2014-06-28T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/06/28/signal-status-and-lifecycle</id>
    <content type="html"><![CDATA[<p><i><strong>modified from</strong> <a href="http://blog.csdn.net/sunyubo458/article/details/4484957">http://blog.csdn.net/sunyubo458/article/details/4484957</a></i></p>

<p><em>Lost original source</em></p>

<hr />

<h3 id="section">信号状态</h3>

<p>信号的”未决“是一种状态，指的是从信号的产生到信号被处理前的这一段时间；信号的”阻塞“是一个开关动作，指的是阻止信号被处理，但不是阻止信号产生。 </p>

<p>每个进程都有一个信号屏蔽字，它规定了当前要阻塞地送到该进程的信号集，对于每种可能的信号，该屏蔽字中都有一位与之对应。对于某种信号，若其对应为已设定，则它当前是被阻塞的。进程可以调用<code>sigprocmask</code>来检测和更改当前信号屏蔽字。</p>

<p>APUE例题在<code>sleep</code>前用<code>sigprocmask</code>阻塞了退出信号，然后<code>sleep</code>,然后在<code>sleep</code>的过程中产生一个退出信号，但是此时退出信号被阻塞过，（中文的”阻塞”在这里容易被误解为一种状态，实际上是一种类似于开关的动作，所以说“被阻塞过”，而不是“被阻塞”）所以处于“未决”状态，在 <code>sleep</code>后又用<code>sigprocmask</code>关掉退出信号的阻塞开关，因为之前产生的退出信号一直处于未决状态，当关上阻塞开关后，马上退出“未决”状态，得到处理，这一切发生在<code>sigprocmask</code>返回之前。 </p>

<h3 id="section-1">信号生命周期</h3>

<p>对于一个完整的信号生命周期(从信号发送到相应的处理函数执行完毕)来说，可以分为三个重要的阶段，这三个阶段由四个重要事件来刻画：1.信号诞生；2. 信号在进程中注册完毕；3.信号在进程中的注销完毕；4.信号处理函数执行完毕。相邻两个事件的时间间隔构成信号生命周期的一个阶段。</p>

<!--more-->

<p>下面阐述四个事件的实际意义：</p>

<ol>
  <li>
    <p>信号”诞生”；</p>

    <p>信号的诞生指的是触发信号的事件发生（如检测到硬件异常、定时器超时以及调用信号发送函数kill()或sigqueue()等）。 </p>
  </li>
  <li>
    <p>信号在目标进程中”注册”；</p>

    <p>进程的<code>task_struct</code>结构中有关于本进程中未决信号的数据成员：</p>

    <pre><code> struct sigpending pending;
 struct sigpending
 {
     struct sigqueue *head, **tail;
     sigset_t signal;
 };
</code></pre>

    <p>第一、第二个成员分别指向一个<code>sigqueue</code>类型的结构链（称之为”未决信号信息链”）的首尾，第三个成员是进程中所有未决信号集，信息链中的每个sigqueue结构体刻画一个特定信号所携带的信息，并指向下一个sigqueue结构: </p>

    <pre><code> struct sigqueue
 {
     struct sigqueue *next;
     siginfo_t info;
 };
</code></pre>

    <p>信号在进程中注册指的就是信号值加入到进程的未决信号集中（<code>sigpending</code>结构的第二个成员<code>sigset_t signal</code>），并且信号所携带的信息被保留到未决信号信息链的某个<code>sigqueue</code>结构中。只要信号在进程的未决信号集中，表明进程已经知道这些信号的存在，但还没来得及处理，或者该信号被进程阻塞。 </p>

    <p><strong>注：</strong> 
 当一个实时信号发送给一个进程时，不管该信号是否已经在进程中注册，都会被再注册一次，因此，信号不会丢失，因此，实时信号又叫做”可靠信号”。这意味着同一个实时信号可以在同一个进程的未决信号信息链中占有多个<code>sigqueue</code>结构（进程每收到一个实时信号，都会为它分配一个结构来登记该信号信息，并把该结构添加在未决信号链尾，即所有诞生的实时信号都会在目标进程中注册）； </p>

    <p>当一个非实时信号发送给一个进程时，如果该信号已经在进程中注册，则该信号将被丢弃，造成信号丢失。因此，非实时信号又叫做”不可靠信号”。这意味着同一个非实时信号在进程的未决信号信息链中，至多占有一个<code>sigqueue</code>结构（一个非实时信号诞生后，（1）、如果发现相同的信号已经在目标结构中注册，则不再注册，对于进程来说，相当于不知道本次信号发生，信号丢失；（2）、如果进程的未决信号中没有相同信号，则在进程中注册自己）。 </p>
  </li>
  <li>
    <p>信号在进程中的注销。</p>

    <p>在目标进程执行过程中，会检测是否有信号等待处理（每次从系统空间返回到用户空间时都做这样的检查）。如果存在未决信号等待处理且该信号没有被进程阻塞，则在运行相应的信号处理函数前，进程会把信号在未决信号链中占有的结构卸掉。是否将信号从进程未决信号集中删除对于实时与非实时信号是不同的。对于非实时信号来说，由于在未决信号信息链中最多只占用一个sigqueue结构，因此该结构被释放后，应该把信号在进程未决信号集中删除（信号注销完毕）；而对于实时信号来说，可能在未决信号信息链中占用多个sigqueue结构，因此应该针对占用gqueue结构的数目区别对待：如果只占用一个sigqueue结构（进程只收到该信号一次），则应该把信号在进程的未决信号集中删除（信号注销完毕）。否则，不在进程的未决信号集中删除该信号（信号注销完毕）。进程在执行信号相应处理函数之前，首先要把信号在进程中注销。 </p>
  </li>
  <li>
    <p>信号生命终止。</p>

    <p>进程注销信号后，立即执行相应的信号处理函数，执行完毕后，信号的本次发送对进程的影响彻底结束。 </p>
  </li>
</ol>

<p><strong>注：</strong> 
1）信号注册与否，与发送信号的函数（如kill()或sigqueue()等）以及信号安装函数（signal()及sigaction()）无关，只与信号值有关（信号值小于SIGRTMIN的信号最多只注册一次，信号值在SIGRTMIN及SIGRTMAX之间的信号，只要被进程接收到就被注册）。 
2）在信号被注销到相应的信号处理函数执行完毕这段时间内，如果进程又收到同一信号多次，则对实时信号来说，每一次都会在进程中注册；而对于非实时信号来说，无论收到多少次信号，都会视为只收到一个信号，只在进程中注册一次。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ Template]]></title>
    <link href="http://billowkiller.github.io/blog/2014/04/23/Template-in-C%2B%2B/"/>
    <updated>2014-04-23T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/04/23/Template-in-C++</id>
    <content type="html"><![CDATA[<p>modified from <a href="http://www.cnblogs.com/assemble8086/archive/2011/10/02/2198308.html">http://www.cnblogs.com/assemble8086/archive/2011/10/02/2198308.html</a></p>

<h2 id="section">模版</h2>

<p><code>template</code> 是声明类模板的关键字，表示声明一个模板，模板参数可以是一个，也可以是多个，可以是<strong>类型参数</strong> ，也可以是<strong>非类型参数</strong>。类型参数由关键字<code>class</code>或<code>typename</code>及其后面的标识符构成。非类型参数由一个普通参数构成，代表模板定义中的一个常量。</p>

<p><strong>类模板什么时候会被实例化呢？</strong></p>

<ol>
  <li>当使用了类模板实例的名字，并且上下文环境要求存在类的定义时。</li>
  <li>对象类型是一个类模板实例，当对象被定义时。此点被称作类的实例化点。</li>
  <li>一个指针或引用指向一个类模板实例，当检查这个指针或引用所指的对象时。</li>
</ol>

<!--more-->

<p><strong>非类型参数的模板实参</strong></p>

<ol>
  <li>绑定给非类型参数的表达式必须是一个常量表达式。</li>
  <li>从模板实参到非类型模板参数的类型之间允许进行一些转换。包括左值转换、限定修饰转换、提升、整值转换。</li>
  <li>
    <p>可以被用于非类型模板参数的模板实参的种类有一些限制。</p>

    <pre><code> Template&lt;int* ptr&gt; class Graphics{…….};
	
 Template&lt;class Type,int size&gt; class Rect{……..};
	
 const int size=1024;
	
 Graphics&lt;&amp;size&gt; bp1;//错误:从const int*－&gt;int*是错误的。
	
 Graphics&lt;0&gt; bp2;//错误不能通过隐式转换把０转换成指针值
	
 const double db=3.1415;
	
 Rect&lt;double,db&gt; fa1;//错误：不能将const double转换成int.
	
 unsigned int fasize=255;
	
 Rect&lt;String, fasize&gt; fa2;//错误：非类型参数的实参必须是常量表达式，将unsigned改为const就正确。
	
 Int arr[10];
	
 Graphics&lt;arr&gt; gp;//正确
</code></pre>
  </li>
</ol>

<p><strong>类模板的成员函数</strong></p>

<ol>
  <li>类模板的成员函数可以在类模板的定义中定义(<code>inline</code>函数)，也可以在类模板定义之外定义(此时成员函数定义前面必须加上<code>template</code>及模板参数)。</li>
  <li>
    <p>类模板成员函数本身也是一个模板，类模板被实例化时它并不自动被实例化，只有当它被调用或取地址，才被实例化。</p>

    <pre><code> template&lt;class type&gt;
 Class Graphics{
     Graphics(){…}//成员函数定义在类模板的定义中
     void out();
 };
	
 template&lt;class type&gt;//成员函数定义在类模板定义之外
 void Graphics&lt;type&gt;::out(){…}
</code></pre>
  </li>
</ol>

<p><strong>类模板的友元声明</strong></p>

<ol>
  <li>非模板友元类或友元函数</li>
  <li>
    <p>绑定的友元类模板或函数模板。</p>

    <pre><code> template&lt;class type&gt;
 void create(Graphics&lt;type&gt;);
	
 template&lt;class type&gt;
 class Graphics{
     friend void create&lt;type&gt;(Graphics&lt;type&gt;);
 };
</code></pre>
  </li>
  <li>
    <p>非绑定的友元模板</p>

    <pre><code> template&lt;class type&gt;
 class Graphics{
     template&lt;class T&gt;
     friend void create(Graphics&lt;T&gt;);
 };
</code></pre>
  </li>
</ol>

<p><strong>注意：</strong>当把非模板类或函数声明为类模板友元时，它们不必在全局域中被声明或定义，但将一个类的成员声明为类模板友元，该类必须已经被定义，另外在声明绑定的友元类模板或函数模板时，该模板也必须先声明。</p>

<p><strong>类模板的静态数据成员</strong></p>

<ol>
  <li>静态数据成员的模板定义必须出现在类模板定义之外。</li>
  <li>类模板静态数据成员本身就是一个模板，它的定义不会引起内存被分配，只有对其实例化才会分配内存。</li>
  <li>当程序使用静态数据成员时，它被实例化，每个静态成员实例都与一个类模板实例相对应，静态成员的实例引用要通过一个类模板实例。</li>
</ol>

<p><strong>成员模板</strong></p>

<ol>
  <li>在一个类模板中定义一个成员模板,意味着该类模板的一个实例包含了可能无限多个嵌套类和无限多个成员函数．</li>
  <li>只有当成员模板被使用时，它才被实例化.</li>
  <li>成员模板可以定义在其外围类或类模板定义之外．</li>
</ol>

<p><strong>类模板的编译模式</strong></p>

<ol>
  <li>
    <p>包含编译模式</p>

    <p>这种编译模式下，类模板的成员函数和静态成员的定义必须被包含在“要将它们实例化”的所有文件中，如果一个成员函数被定义在类模板定义之外，那么这些定义应该被放在含有该类模板定义的头文件中。</p>
  </li>
  <li>
    <p>分离编译模式</p>

    <p>这种模式下，类模板定义和其inline成员函数定义被放在头文件中，而非inline成员函数和静态数据成员被放在程序文本文件中。</p>

    <pre><code> //------Graphics.h---------
	
 export template&lt;class type&gt;
 Class Graphics
 {void Setup(const type &amp;);};
	
 //-------Graphics.c------------
	
 #include “Graphics.h”
 Template &lt;class type&gt;
 Void Graphics&lt;type&gt;::Setup(const type &amp;){…}
	
 //------user.c-----
	
 #include “Graphics.h”
 Void main(){
     Graphics&lt;int&gt; *pg=new Graphics&lt;int&gt;;
     Int ival=1;
     //Graphics&lt;int&gt;::Setup(const int &amp;)的实例（下有注解）
     Pg-&gt;Setup(ival);
 }
</code></pre>

    <p>Setup的成员定义在User.c中不可见,但在这个文件中仍可调用模板实例Graphics<int>::Setup(const int &amp;)。为实现这一点，须将类模声明为可导出的：**当它的成员函数实例或静态数据成员实例被使用时，编译器只要求模板的定义，它的声明方式是在关键字template前加关键字export**</int></p>
  </li>
  <li>
    <p>显式实例声明</p>

    <p>当使用包含编译模式时，类模板成员的定义被包含在使用其实例的所有程序文本文件中，何时何地编译器实例化类模板成员的定义，我们并不能精确地知晓，为解决这个问题，标准C++提供了显式实例声明：关键字template后面跟着关键字class以及类模板实例的名字。<strong>显式实例化类模板时，它的所有成员也被显式实例化</strong>。</p>

    <pre><code> #include “Graphics.h”
 Template class Graphics&lt;int&gt;;//显式实例声明
</code></pre>
  </li>
</ol>

<p><strong>类模板的特化</strong></p>

<p><code>template&lt;&gt;</code>成员函数特化定义</p>

<ol>
  <li>只有当通用类模板被声明后，它的显式特化才可以被定义。</li>
  <li>若定义了一个类模板特化，则必须定义与这个特化相关的所有成员函数或静态数据成员，此时类模板特化的成员定义不能以符号<code>template&lt;&gt;</code>作为打头。(<code>template&lt;&gt;</code>被省略)</li>
  <li>类模板不能够在某些文件中根据通用模板定义被实例化，而在其他文件中却针对同一组模板实参被特化。</li>
</ol>

<p><strong>类模板部分特化</strong></p>

<p>如果模板有一个以上的模板参数，则有些人就可能希望为一个特定的模板实参或者一组模板实参特化类模板，而不是为所有的模板参数特化该类模板。即，希望提供这样一个模板：它仍然是一个通用的模板，只不过某些模板参数已经被实际的类型或值取代。通过使用类模板部分特化，可以实现这一点。</p>

<pre><code>template&lt;int hi,int wid&gt;
Class Graphics{…};

Template&lt;int hi&gt;//类模板的部分特化
Class Graphics&lt;hi,90&gt;{…};
</code></pre>

<ol>
  <li>部分特化的模板参数表只列出模板实参仍然未知的那些参数。</li>
  <li>类模板部分特化是被隐式实例化的。编译器选择“针对该实例而言最为特化的模板定义”进行实例化，当没有特化可被使用时，才使用通用模板定义。</li>
  <li>类模板部分特化必须有它自己对成员函数、静态数据成员和嵌套类的定义。</li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C/C++ Byte Alignment]]></title>
    <link href="http://billowkiller.github.io/blog/2014/04/22/byte-alignment/"/>
    <updated>2014-04-22T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/04/22/byte-alignment</id>
    <content type="html"><![CDATA[<p><strong>字节对齐的细节和编译器实现相关，但一般而言，满足三个准则</strong>：</p>

<ol>
  <li>结构体变量的首地址能够被其<strong>最宽基本类型</strong>成员的大小所整除；</li>
  <li>结构体每个成员相对于结构体首地址的偏移量（offset）都是<strong>成员大小的整数倍</strong>，如有需要编译器会在成员之间加上填充字节（internal adding）；</li>
  <li>结构体的总大小为结构体最宽基本类型成员大小的整数倍，如有需要编译器会在最末一个成员之后加上填充字节（trailing padding）。</li>
</ol>

<p>需要仔细体会上面的三个准则。</p>

<!--more-->

<ul>
  <li>
    <p>结构体某个成员相对于结构体首地址的偏移量可以通过宏offsetof()来获得，这个宏也在stddef.h中定义，如下：</p>

    <pre><code>  #define offsetof(s,m) (size_t)&amp;(((s *)0)-&gt;m)
</code></pre>
  </li>
  <li>
    <p>基本类型是指前面提到的像char、short、int、float、double这样的内置数据类型。这里所说的“数据宽度”就是指其sizeof的大小。由于结构体的成员可以是复合类型，比如另外一个结构体，所以在寻找最宽基本类型成员时，应当包括复合类型成员的子成员，而不是把复合成员看成是一个整体。但在确定复合类型成员的偏移位置时则是将复合类型作为整体看待。</p>

    <pre><code>  struct S1
  {
      char c;
      int i;
  };

  struct S3
  {
      char c1;
      S1 s;
      char c2;
  };
</code></pre>

    <p>S1的最宽简单成员的类型为int，S3在考虑最宽简单类型成员时是将S1“打散”看的，所以S3的最宽简单类型为int。这样，通过S3定义的变量，其存储空间首地址需要被4整除，整个sizeof(S3)的值也应该被4整除。</p>

    <p>c1的偏移量为0，s的偏移量呢？这时s是一个整体，它作为结构体变量也满足前面三个准则，所以其大小为8，偏移量为4，c1与s之间便需要3个填充字节，而c2与s之间就不需要了，所以c2的偏移量为12，算上c2的大小为13，13是不能被4整除的，这样末尾还得补上3个填充字节。最后得到sizeof(S3)的值为16。</p>
  </li>
</ul>

<h2 id="pragma-pack"><code> #pragma pack</code></h2>

<p><code>#pragma pack</code>规定的对齐长度，实际使用的规则是：</p>

<p>结构，联合，或者类的数据成员，第一个放在偏移为0的地方，以后每个数据成员的对齐，按照<code>#pragma pack</code>指定的数值和这个数据成员自身长度中，比较小的那个进行。也就是说，当<code>#pragma pack</code>的值等于或超过所有数据成员长度的时候，这个值的大小将不产生任何效果。而结构整体的对齐，则按照结构体中最大的数据成员和<code>#pragma pack</code>指定值之间，较小的那个进行。</p>

<pre><code>   #pragma pack(4)
　　class TestB
　　{
　　public:
　　　　int aa; //第一个成员，放在[0,3]偏移的位置，
　　　　char a; //第二个成员，自身长为1，#pragma pack(4),取小值，也就是1，所以
这个成员按一字节对齐，放在偏移[4]的位置。
　　　　short b; //第三个成员，自身长2，#pragma pack(4)，取2，按2字节对齐，所以
放在偏移[6,7]的位置。
　　　　char c; //第四个，自身长为1，放在[8]的位置。
　　};
</code></pre>

<p>这个类实际占据的内存空间是9字节类之间的对齐，是按照类内部最大的成员的长度，和<code>#pragma pack</code>规定的值之中较小的一个对齐的。所以这个例子中，类之间对齐的长度是<code>min(sizeof(int),4)</code>，也就是4。9按照4字节圆整的结果是12，所以<code>sizeof(TestB)</code>是12。</p>

<pre><code>	#pragma pack(2)
    class TestB
　　{
　　public:
　　　　int aa; //第一个成员，放在[0,3]偏移的位置，
　　　　char a; //第二个成员，自身长为1，#pragma pack(4),取小值，也就是1，所以
这个成员按一字节对齐，放在偏移[4]的位置。
　　　　short b; //第三个成员，自身长2，#pragma pack(4)，取2，按2字节对齐，所以
放在偏移[6,7]的位置。
　　　　char c; //第四个，自身长为1，放在[8]的位置。
　　};
</code></pre>

<p>可以看出，上面的位置完全没有变化，只是类之间改为按2字节对齐，9按2圆整的结果是10。所以<code>sizeof(TestB)</code>是10。</p>

<pre><code>	#pragma pack(4)
　　class TestC
　　{
　　public:
　　　　char a;//第一个成员，放在[0]偏移的位置，
　　　　short b;//第二个成员，自身长2，#pragma pack(4)，取2，按2字节对齐，所以
放在偏移[2,3]的位置。
　　　　char c;//第三个，自身长为1，放在[4]的位置。
　　};
</code></pre>

<p>整个类的大小是5字节，按照<code>min(sizeof(short),4)</code>字节对齐，也就是2字节对齐，结果是6</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Effective C++ Rework]]></title>
    <link href="http://billowkiller.github.io/blog/2014/04/17/Effective-C%2B%2B/"/>
    <updated>2014-04-17T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/04/17/Effective-C++</id>
    <content type="html"><![CDATA[<h2 id="c">让自己习惯C++</h2>

<h3 id="item-01-view-c-as-a-federation-of-languages">Item 01： View C++ as a federation of languages</h3>

<p>C++同时支持过程形式、面对对象形式、函数形式、泛型形式、元编程形式。</p>

<p>次语言有</p>

<ul>
  <li>C</li>
  <li>Object-Oriented C++</li>
  <li>Template C++</li>
  <li>STL</li>
</ul>

<p>C++高效编程守则视状况而变化，取决于你使用C++的那一部分。</p>

<!--more-->

<h3 id="item-02-prefer-consts-enums-and-inlines-to-defines">Item 02： Prefer consts, enums and inlines to #defines</h3>

<ul>
  <li><code>#define</code>的变量没有进入记号表。并且没有作用域，不能提供任何封装性。</li>
  <li><code>#define</code>定义宏，需要为所有实参加上小括号，且不能够使用<code>++</code>和<code>--</code>。</li>
</ul>

<p><code>#define</code>难以调试、行为无法预料、类型不安全。</p>

<pre><code>class GamePlayer{
private:
	static const int NumTurns = 5; //常量申明式
};
</code></pre>

<p>通常C++要求你对你所使用的任何东西提供一个定义式，但那如果它是<code>class</code>专属常量又是<code>static</code>且为<strong>整数型</strong>(ints, chars, bools)则需特殊处理。只要是不取它们的地址，你可以申明并使用它们而无需提供定义式。如果需要取址，必须提供定义式：</p>

<pre><code>const int GamePlayer::NumTurns; //申明时获取了初值，定义不必赋值
</code></pre>

<p>“The enum hack”表示一个属于枚举类型的数值可权充int被使用，于是<code>GamePlayer</code>定义为</p>

<pre><code>class GamePlayer{
private:
	enum { NumTurns = 5 };
	static const int NumTurns = 5;
};
</code></pre>

<ul>
  <li>取一个<code>enum</code>地址是非法的。<code>enum</code>和<code>#define</code>一样不会导致非必要的内存分配。</li>
  <li><code>enum hack</code>是<code>template metaprogramming</code>的基础技术。</li>
</ul>

<p><code>template inline</code>可以提供宏带来的效率以及一般函数的所有可预料行为和类型安全。遵守作用域和访问规则。</p>

<h3 id="item-03-use-const-whenever-possible">Item 03： Use const whenever possible</h3>

<p>令函数返回一个常量值，往往可以降低因客户错误而造成的意外，而不至于放弃安全性和高效性。</p>

<pre><code>const Rational operator* (const Rational&amp; lhs, const Rational&amp; rhs);
Rational a, b, c;
...
(a * b) = c;  //错误
</code></pre>

<p>重载<code>operator[]</code>并对不同的版本给予不同的返回类型，就可以令<code>const</code>和<code>non-const</code>获得不同的处理。返回 <code>char&amp;</code>也是必要的。</p>

<pre><code>const char&amp; operator[](std::size_t position) const; //operator[] for const Object
char&amp; operator[](std::size_t position); //operator[] for non-const object
</code></pre>

<ul>
  <li>成员函数式<code>const</code>有两个流行的概念：<code>bitwise constness</code>, <code>logical constness</code>。</li>
  <li><code>mutable</code>变量成员可以再const成员函数中改变。</li>
  <li><code>static_cast</code>将<code>non-const</code>对象转为<code>const</code>对象。<code>const_cast</code>相反。</li>
</ul>

<h3 id="item-04-make-sure-that-objects-are-initialized-before-theyre-used">Item 04： Make sure that objects are initialized before they’re used</h3>

<ul>
  <li><code>C++</code>对定义与不同编译单元(文件)内的<code>non-local static</code>对象的初始化次序并无明确定义。</li>
  <li>函数内的<code>local static</code>对象会在该函数被调用期间首次遇上该对象的定义式时被初始化。</li>
</ul>

<p>为内置对象进行手工初始化，<code>C++</code>不保证初始化它们。
构造函数使用<code>成员初值列</code>，不要在函数内使用赋值操作。其排列次序应该和申明次序相同。
为免除跨编译单元初始化次序问题。以<code>local static</code>对象替代<code>non-local static</code>对象。</p>

<h2 id="constructors-destructors-and-assignment-operators">Constructors, destructors, and Assignment Operators</h2>

<h3 id="item-05-know-what-functions-c-silently-writes-and-calls">Item 05： Know what functions C++ silently writes and calls</h3>

<ul>
  <li><code>default</code>构造函数和析构函数调用<code>base classes</code>和<code>non-static</code>成员变量的构造函数和析构函数。且只有base是<code>virtual</code>析构时，它才是<code>virtual</code>的。</li>
  <li>如果类内含<code>reference</code>或<code>const</code>成员，或者<code>base classes</code>将<code>copy assignment</code>操作符申明为<code>private</code>，则需要自己定义<code>copy assignment</code></li>
</ul>

<h3 id="item-06-explicitly-disallow-the-use-of-compiler-generated-functions-you-do-not-want">Item 06: Explicitly disallow the use of compiler-generated functions you do not want</h3>

<p>不实现<code>copy</code>或<code>copy assignment</code>的方法：</p>

<ol>
  <li>将成员函数声明为private而且故意不实现它们。</li>
  <li>设计一个专门为了组织copying动作的<code>base class</code>， 将<code>copy</code>和<code>copy assigment</code>声明为<code>private</code>。接着私有继承base class</li>
  <li><code>Boost</code>提供的class，<code>nonecopyable</code></li>
</ol>

<h3 id="item-07-declare-destructors-virtual-in-ploymorphic-base-classes">Item 07: Declare destructors virtual in ploymorphic base classes</h3>

<pre><code>Base *pt = new Derived;
delete pt;
</code></pre>

<p><code>derived class</code>对象经由一个<code>base class</code>指针被删除，如果<code>base class</code>有个<code>non-virtual</code>析构函数，则对象的<code>derived</code>成分没被销毁。</p>

<p>无端地将所有classes的析构函数声明为<code>virtual</code>，就像从未声明它们为<code>virtual</code>一样，都是错误的，带来对象体积的增加。只有当class内含有至少一个<code>virtual</code>函数才为它声明<code>virtual</code>析构函数。</p>

<p>为你希望它成为抽象的那个class(polymorphic base classes)声明一个<code>pure virtual</code>析构函数。</p>

<pre><code>class AWOV {
public:
	virtual  ~AWOV() = 0;
};
AWOV::~AWOV() {}  //pure virtual 析构函数的定义 
</code></pre>

<p>然而必须为这个<code>pure virtual</code>函数提供一份定义，根据析构函数的运作方式，编译器会在AWOV的<code>derived classes</code>的析构函数中创建一个对~AWOV的调用动作，所以必须为这个函数提供一份定义。否则，连接器会发出抱怨。</p>

<h3 id="item-08-prevent-exceptions-from-leaving-destructors">Item 08: Prevent exceptions from leaving destructors</h3>

<ul>
  <li>析构函数绝对不要突出异常。如果一个被析构函数调用的函数可能抛出异常，析构函数应该捕捉任何异常，然后吞下它们（不传播）或结束程序。</li>
  <li>如果客户需要对某个操作函数运行期间抛出的异常作出反应，那么class应该提供一个普通函数（而非在析构函数中）执行该操作。</li>
</ul>

<h3 id="item-09-never-call-virtual-functions-during-construction-or-destruction">Item 09: Never call virtual functions during construction or destruction</h3>

<p><strong>在base class构造期间，virtual函数不是virtual函数</strong>。因为derived class对象还未构造好，所以base class构造期间virtual函数绝不会下降到derived classes阶层。在derived class对象的base class构造期间，对象类型是base class而不是derived class。</p>

<p>在构造期间，可以借由“令derived classes将必要的构造信息向上传递至base class构造函数”替换之。</p>

<p><strong>同样的道理也适用于析构函数</strong>。一旦derived class析构函数开始执行，对象内的derived class成员变量变成未定义值，所以C++是它们仿佛不再存在。进入base class析构函数后对象就称为一个base class 对象，而C++的任何部分包括virtual函数、<code>dynamic_cast</code>等等也就这么看它。</p>

<p>所以，在构造和析构席间不要调用virtual函数，因为这类调用从不降至derived class（比起当前执行构造函数和析构函数的那层）。</p>

<h3 id="item-10-have-assignment-operators-return-a-reference-to-this">Item 10: Have assignment operators return a reference to *this</h3>

<pre><code>Widget&amp; operator=(const widget &amp;rhs) {
	...
	return *this;
}
</code></pre>

<h3 id="item-11-handle-assignment-to-self-in-operator">Item 11: Handle assignment to self in operator=</h3>

<p>容易掉进“在停止使用资源之前意外释放了它”的陷阱。</p>

<p>让<code>operator=</code>具备“异常安全性”往往自动获得“自我复制安全”的汇报。</p>

<pre><code>Widget&amp; operator=(const widget &amp;rhs) {
	Bitmap * pOrig = pb;
	pb = new Bitmap(*rhs.pb);
	delete pOrig;
	return *this;
}
</code></pre>

<p>还可以使用<code>copy and swap</code>技术。或利用一下事实：(1)某class的<code>copy assignment</code>操作符可能被声明<code>by value</code>的方式；(2)以<code>by value</code>的方式传递东西会造成一份副本。</p>

<h3 id="item-12-copy-all-parts-of-an-object">Item 12: Copy all parts of an object</h3>

<ul>
  <li>编写一个copying函数确保(1)复制所有local成员变量，(2)调用所有base classes内的适当的copy函数。</li>
  <li>不要尝试以某个copying函数实现另一个copying函数。应该讲共同机能放进第三个函数中，并有两个copying函数共同调用。</li>
</ul>

<h2 id="section">资源管理</h2>

<h3 id="item-13-use-objects-to-manage-resources">Item 13: Use objects to manage resources.</h3>

<ul>
  <li>获得资源后立即放进资源对象内。<code>RAII</code>–Resource Acquisition Is initialization</li>
  <li>管理对象运用析构函数确保资源被释放。</li>
  <li>auto_ptr通过copy构造函数或copy assignment操作符复制它们，它们会变成null，而复制所得到的指针将取得资源的唯一拥有权。</li>
  <li>动态分配得到的<code>array</code>身上使用auto_ptr或tr1::shared_ptr是个馊主意。两者再析构函数内做delete而不是delete[]动作。</li>
</ul>

<h3 id="item-14-think-carefully-about-copying-behavior-in-resource-managing-classes">Item 14: Think carefully about copying behavior in resource-managing classes</h3>

<p>当一个RAII对象被复制，考虑两种可能性：</p>

<ul>
  <li>禁止复制</li>
  <li>对底层资源采用<code>引用计数法</code>， 
    <ul>
      <li><code>shared_ptr</code>的缺省行为是“当引用次数为0时删除其所指之物”，允许制定特定的删除器(<code>deleter</code>)</li>
    </ul>
  </li>
  <li>复制底部资源</li>
  <li>转移底部资源的拥有权</li>
</ul>

<h3 id="item-15-provide-access-to-raw-resources-in-resource-managing-classes">Item 15: Provide access to raw resources in resource-managing classes</h3>

<p>智能指针重载了指针取值操作符(operator-&gt; 和 operator*)，它们允许隐式转换至底部原始指针。</p>

<p>隐式转换举例：</p>

<pre><code>class Font {
public:
	...
	operator FontHandle() const //隐式转换函数
	{ return f; }
	...
}
</code></pre>

<ul>
  <li>API往往要求访问原始资源，所以每个RAII class应该提供一个取得原始资源的方法。</li>
  <li>对原始资源的访问可能经由显示转换或隐式转换。一般而言显示转换比较安全，但隐私转换对客户比较方便。</li>
</ul>

<h3 id="item-16-use-the-same-form-in-corresponding-uses-of-new-and-delete">Item 16: Use the same form in corresponding uses of new and delete</h3>

<p>new对应delete，new[] 对应delete[]</p>

<p>对于typedef,必须要在程序中说明清楚</p>

<pre><code>typedef std::string AddressLines[4];
std::string * pal = new AddressLines;
delete [] pal; //delete pal 导致行为未有定义 因此，最好尽量不要对数组形式做typedef动作。
</code></pre>

<h3 id="item-17-store-newed-objects-in-smart-pointers-in-standalone-statements">Item 17: Store newed objects in smart pointers in standalone statements.</h3>

<p>假设有个函数解释处理程序的优先权，另一个函数用来在某动态分配所得的Widget上进行某些带有优先权的处理：</p>

<pre><code>int priority();
void processWidget(std::tr1::shared_ptr&lt;Widget&gt; pw, int priority);
</code></pre>

<p>如果这样调用</p>

<pre><code>processWidget(std::tr1::shared_ptr&lt;Widget&gt;(new Widget), priority()); 编译器创建代码，做以下三件事：
</code></pre>

<ul>
  <li>调用priority</li>
  <li>执行new Widget</li>
  <li>调用tr1::shared_ptr构造函数。</li>
</ul>

<p>只能保证new Widget在shared_ptr构造函数之前被调用。如果priority在两者中间被调用，而且导致异常。那么new Widget返回的指针将会遗失。</p>

<h2 id="section-1">设计与声明</h2>

<h3 id="item-18-make-interfaces-easy-to-use-correctly-and-hard-to-use-incorrectly">Item 18: Make interfaces easy to use correctly and hard to use incorrectly</h3>

<ul>
  <li>好的接口很容易被正确使用，不容易被误用。你应该在你的所有接口中努力达成这些性质。</li>
  <li>“促进正确使用”的办法包括借口的一致性，以及与内置类型的行为兼容。任何接口如果要求客户必须记得做某些事情，就是有着“不正确使用”的倾向，因为客户可能会忘记做那件事。</li>
  <li>“阻止误用”的办法包括建立新类型、限制类型上的操作，束缚对象值，以及消除客户的资源管理责任。</li>
  <li>tr1::shared_ptr支持定制性删除器(custom deleter)。可以防范<code>cross-DLL problem</code>(在一个DLL中被new创建，却在另一个DLL中被delete销毁)，自动解除互斥锁等等。</li>
</ul>

<h3 id="item-20-prefer-pass-by-reference-to-const-to-pass-by-value">Item 20: Prefer pass-by-reference-to-const to pass-by-value.</h3>

<ul>
  <li>尽量以<code>pass-by-reference-to-const</code>替换<code>pass-by-value</code>。前者通常比较高效，并可以避免切割问题。</li>
  <li>以上规则并不适用于<strong>内置类型，以及STL的迭代器和函数对象</strong>。对它们而言，pass-by-value往往比较适当。</li>
</ul>

<h3 id="item-21-dont-try-to-return-a-reference-when-you-must-return-an-object">Item 21: Don’t try to return a reference when you must return an object</h3>

<p>绝不要返回pointer或reference指向一个local stack对象，或返回reference指向一个heap-allocated对象，或返回pointer或reference指向一个local static对象而有可能同时需要多个这样的对象。</p>

<h3 id="item-22-declare-data-members-private">Item 22: Declare data members private.</h3>

<ul>
  <li>封装的重要性比你最初见到它时还要重要</li>
  <li>切记将成员变量声明为private。这可赋予客户访问数据的一致性、可细微划分访问控制、允诺约束条件获得保证，并提供class作者以充分的实现弹性。</li>
  <li>protected并不比public更具有封装性。</li>
</ul>

<h3 id="item-23-prefer-non-member-non-friend-functions-to-member-functions">Item 23: Prefer non-member non-friend functions to member functions</h3>

<ul>
  <li>提供更大的封装性</li>
  <li>比较自然的做法是让 non-member non-friend函数作为便利函数位于类所在的同一个namespace内。并将同类便利函数声明放在同一头文件中。</li>
  <li>将所有便利函数放在多个头文件内但隶属于同一个命名空间，意味客户可以轻松扩展这一组便利函数。</li>
</ul>

<h3 id="item-24-declare-non-member-functions-when-type-conversions-should-apply-to-all-parameters">Item 24: Declare non-member functions when type conversions should apply to all parameters</h3>

<pre><code>class Rational {
public:
	const Rational operator* (const Rational &amp;rhs) const;
};

Rational oneHalf(1, 2);
result = oneHalf * 2; // oneHalf.operator*(2)，可以执行
result = 2 * oneHalf; // 2.operator*(oneHalf)，错误
</code></pre>

<p>所以让函数称为一个<code>non-member</code>函数</p>

<pre><code>const Rational operator* (const Rational &amp;lhs， const Rational &amp;rhs);	 允许编译器在每一个实参身上执行隐私转换类型。
</code></pre>

<h3 id="item-25-consider-support-for-a-non-throwing-swap">Item 25: Consider support for a non-throwing swap</h3>

<pre><code>namespace std {
	template&lt;&gt; //全特化
	void swap&lt;Widget&gt;( Widget &amp;a, Widget &amp;b) {
		swap(a.pImpl, b.pImpl); //私有变量，编译不通过，需要创建类的成员函数
	} }

class Widget {
public:
	void swap(Widget&amp; other) {
		using std::swap; //声明是有必要的，下个swap调用std版本的
		swap(pImpl, other.pImpl);
</code></pre>

<ul>
  <li>当<code>std::swap</code>对你的类型效率不高时，提供一个<code>swap</code>成员函数，并确定这个函数不抛出异常</li>
  <li>如果你提供一个<code>member swap</code>，也应该提供一个<code>non-member swap</code>用来调用前者。对于classes（而非templates），也请特化<code>std::swap</code></li>
  <li>调用<code>swap</code>时应针对<code>std::swap</code>使用<code>using</code>声明式，然后调用<code>swap</code>并且不带任何“命名空间资格修饰”。</li>
  <li>为“用户定义类型”进行<code>std templates</code>全特化是好的，但千万不要尝试在<code>std</code>内加入某些对<code>std</code>而言是全新的东西</li>
</ul>

<h2 id="section-2">实现</h2>

<h3 id="item-26-postpone-variable-definitions-as-long-as-possible">Item 26: Postpone variable definitions as long as possible</h3>

<p>不止应该延后变量的定义，这道非得使用该变量的前一刻为止，甚至应该尝试延后这份定义知道能够给它初值实参为止。</p>

<h3 id="item-27-minimize-casting">Item 27: Minimize casting</h3>

<ul>
  <li><code>const_cast</code>被用来将对象的常量性转除，也是唯一有此能力的c++ style转型操作符</li>
  <li><code>dynamic_cast</code>主要用来执行“safe downcasting”，可能需要耗费重大运行成本。</li>
  <li><code>reinterpret_cast</code>执行低级转型，实际动作及结果可能取决于编译器，也就表示它不可移植。</li>
  <li><code>static_cast</code>用来强迫隐式转换。例如将non-const转为const对象，将int转为double。</li>
</ul>

<p>单一对象(例如一个类型为Derived的对象)<code>可能拥有一个以上的地址</code>(例如“以Base* 指向它”时的地址和“以Derived* 指向它”时的地址)。这至少意味着你通常应该避免作出“对象在C++中如何布局”的假设。</p>

<ul>
  <li>如果可以，尽量避免转型，特别是在注重效率的代码中避免<code>dynamic_cast</code>。如果有个设计需要转向动作，试着发展无需转型的替代设计。</li>
  <li>如果转型是必要的，试着将它隐藏于某个函数背后。客户随后可以调用该函数，而不需将转型放进他们自己的代码内。</li>
  <li>宁可使用C++ style转型，不要使用旧式转型。前者很容易辨识出来，而且也比较有着分门别类的职掌。</li>
</ul>

<h3 id="item-28-avoid-returning-handles-to-object-internals">Item 28: Avoid returning “handles” to object internals</h3>

<p>避免返回handles(包括references、指针、迭代器)指向对象内部。遵守这个条款可增加封装性，帮助const成员函数的行为像个const，并将发生dangling handles的可能性降至最低。</p>

<p>考虑一个例子：</p>

<pre><code>const Point&amp; Rectangle::upperLeft() const { return pData-&gt;ulhc; }	

class GUIObject{};
const Rectangle boundingBox(const GUIObject &amp;obj);

GUIObject *pgo;
const Point* pUpperLeft = &amp;(boundingBox(*pgo).upperLeft()); //指向一个不存在的对象
</code></pre>

<h3 id="item-29-strive-for-exception-safe-code">Item 29: Strive for exception-safe code.</h3>

<ul>
  <li>异常安全函数即使发生异常也不会泄露资源或允许任何数据结构败坏。这样的函数区分三种可能的保证：基本型、强烈型、不抛异常型。</li>
  <li>强烈保证往往能够以copy-and-swap实现出来，但强烈保证并非对所有函数都可实现或具备现实意义。</li>
  <li>函数提供的异常安全保证通常最高只等于其所调用之各个函数的异常安全保证中的最弱者。</li>
</ul>

<h3 id="item-30-understand-the-ins-and-outs-of-inlining">Item 30: Understand the ins and outs of inlining</h3>

<p><code>inline</code>只是对编译器的一个申请，不是强制命令。这项申请可以隐喻提出，也可以明确提出。隐喻方式是将函数定义于class定义内：</p>

<pre><code>class Person {
public:
	int age() const { return theAge; } //隐喻的inline申请
private:
	int the Age;
};
</code></pre>

<p>这样的函数通常是成员函数，<code>friend</code>函数也可以被定义于class内，这样它们也是被隐喻为<code>inline</code>。</p>

<p><code>inline</code>和<code>template</code>函数通常都被定义于头文件内。</p>

<pre><code>inline void f() {}
void ( * pf )() = f;
f(); //这个调用将被inlined
pf(); //或许不被inlined，因为它通过函数指针达成。
</code></pre>

<ul>
  <li><code>inline</code>函数无法随着程序库升级而升级。调用<code>inline</code>函数的程序都必须重新编译。</li>
  <li>大部分调试器面对<code>inline</code>函数都束手无策。</li>
</ul>

<h3 id="item-31-minimize-compilation-dependencies-between-files">Item 31: Minimize compilation dependencies between files</h3>

<p>以<code>声明的依存性</code>替换<code>定义的依存性</code>：</p>

<ul>
  <li>如果使用<code>object reference</code>或<code>object pointers</code>可以完成任务，就不要使用objects。</li>
  <li>如果能够，尽量以class<code>声明式</code>替换class<code>定义式</code>。 </li>
  <li>为声明式和定义式提供不同的头文件。这种方法无论是否涉及templates都适用。
    <ul>
      <li>
        <iosfwd>内含iostream各组件的声明式，包括<sstream>, <streambuf>, <fstream>和<iostream>



</iostream></fstream></streambuf></sstream></iosfwd>
      </li>
    </ul>
  </li>
</ul>
<p>##继承和面向对象设计</p>

<h3 id="item-32-make-sure-public-inheritance-models-is-a">Item 32: Make sure public inheritance models “is-a”</h3>

<h3 id="item-33-avoid-hiding-inherited-names">Item 33: Avoid hiding inherited names</h3>

<pre><code>class Base {
public:
	virtual void mf1() = 0;
	virtual void mf1(int);
	virtual void mf2();
	void mf3();
	void mf3(double);
};

class Derived: public Base {
public:	
	using Base::mf1;  //让base class内名为mf1和mf3的所有东西
	using Base::mf3;  //在Derived作用域内都可见
	virtual void mf1();
	void mf3();
};	

//或者
class Derived: private Base {
public:
	virtual void mf1() { Base::mf1(); }  //转交函数，暗自称为inline
};
</code></pre>

<ul>
  <li>derived class内的名称会遮掩base classes内的名称。在public继承下从来没有人希望如此。
    <ul>
      <li>上述规则对不同参数类型也适用，而且不论函数式virtual或non-virtual。</li>
    </ul>
  </li>
  <li>为了让被遮掩的名称再见天日，可使用using声明式或转变函数。</li>
</ul>

<h3 id="item-34-differentiate-between-inheritance-of-interface-and-inheritance-of-implementation">Item 34: Differentiate between inheritance of interface and inheritance of implementation</h3>

<ul>
  <li>接口继承和实现继承不同。在public继承之下，derived classes总是继承base class的接口。</li>
  <li>pure virtual函数只具体指定接口继承。pure virtual函数必须在derived classes中重新声明，但它们也可以拥有自己的实现。</li>
  <li>简朴的impure virtual函数具体指定接口继承及缺省实现继承。</li>
  <li>non-virtual函数具体指定接口继承以及强制性实现继承。</li>
</ul>

<h3 id="item-35-consider-alternatives-to-virtual-functions">Item 35: Consider alternatives to virtual functions</h3>

<p>当你为解决问题而寻找某个设计方法时，不妨考虑virtual函数的替代方案。</p>

<ul>
  <li>使用non-virtual interface（NVI）手法，那是Template Method设计模式的一种特殊形式。它以public non-virtual成员函数包裹较低访问性(private或protected)的virtual函数, wrapper。</li>
  <li>将virtual函数替换为函数指针成员变量，这是Strategy设计模式的一种分解表现形式。</li>
  <li>以tr1::function成员变量替换virtual函数，因而允许使用任何可调用物(callable entity)搭配一个兼容于需求的签名式。这也是Strategy设计模式的某种形式。</li>
  <li>将继承体系内的virtual函数替换为另一个继承体系内的virtual函数。这是Strategy设计模式的传统实现手法。</li>
</ul>

<h3 id="item-36-never-redefine-an-inherited-non-virtual-function">Item 36: Never redefine an inherited non-virtual function</h3>

<p>non-virtual是静态绑定，调用的方法是静态类型所拥有的方法，而不是实际类型所拥有的方法。</p>

<h3 id="item-37-never-redefine-a-functions-inherited-default-parameter-value">Item 37: Never redefine a function’s inherited default parameter value</h3>

<p>virtual函数是动态绑定，而缺省参数值确实静态绑定。静态绑定为early binding，动态绑定为late binding。即使子类重新定义了virtual函数的缺省参数，调用还是用了父类的缺省参数。这是为了运行期效率。如果缺省参数值是动态绑定，编译器就必须有某种办法在运行期间为virtual函数决定适当的缺省参数值。</p>

<p>可以使用NVI（non-virtual interface）手法：</p>

<pre><code>class Shape {
public:
	enum ShapeColor { Red, Green, Blue};
	void draw(ShapeColor color = Red) const {
		doDraw(color);
	}
private:
	virtual void doDraw(ShapeColor color) const = 0;//真正的工作在此处
}；
class Rectangle: public Shape {
public:
	...
private:
	virtual void doDraw(ShapeColor color) const; //不须制定缺省参数值
};
</code></pre>

<h3 id="item-39-use-private-inheritance-judiciously">Item 39: Use private inheritance judiciously</h3>

<ul>
  <li>编译器不会自动将一个derived class对象转换为一个base class对象。</li>
  <li>由private base class继承而来的所有成员，在derived class 中都会变成private 属性。</li>
  <li>private继承在软件设计层面没有意义，只有在软件实现层面有意义。</li>
  <li>Private继承意味is-implemented-in-terms of(根据某物实际出)。它通常比复合的级别低。但是当derived class需要访问protected base class的成员，或需要重新定义继承而来的virtual函数时，这么设计是合理的。
和</li>
  <li>复合不同，private继承可以造成empty base最优化。这对致力于对象尺寸最小化的程序库开发者而言，可能很重要。</li>
</ul>

<p>怎样阻止derived classes重新定义virtual函数？</p>

<pre><code>class Widget {
private:
	class WidgetTimer: public Timer {
	public:
		virtual void onTick() const;
	};
	WidgetTimer timer;
};
</code></pre>

<p>私有继承空类并不继承空类的空间</p>

<pre><code>class Empty {}; //sizeof Empty == 1;
class HoldsAnInt: private Empty { int x; }; //sizeof HoldsAnInt == 4;
</code></pre>

<h3 id="item-40-use-multiple-inheritance-judiciously">Item 40: Use multiple inheritance judiciously</h3>

<ul>
  <li>多重继承比单一继承复杂。它可能导致新的歧义性，以及对virtual继承的需要。</li>
  <li>virtual继承会增加大小、速度、</li>
  <li>初始化（及赋值）复杂度等等成本。如果virutal base classes不带任何数据，将是最具使用价值的情况。Java和.Net的Interfaces指的注意，它在许多方面兼容于C++的virtual base classes，而且也不允许含有任何数据。</li>
  <li>多重继承的确有正当用途。其中一个情节涉及public继承某个Interface class和private继承某个协助实现的class的两相结合。</li>
</ul>

<h2 id="section-3">模版与泛型编程</h2>

<h3 id="item-41-understand-implicit-interfaces-and-compile-time-polymorphism">Item 41: Understand implicit interfaces and compile-time polymorphism</h3>

<ul>
  <li>classes和templates都支持接口和多态。</li>
  <li>对classes而言接口是显示的，以数字签名为中心。多态则是通过virtual函数发生于运行期。</li>
  <li>对template参数而言，接口是隐式的，奠基于<strong>有效表达式</strong>。多态则是通过template具现化和函数重载解析发生于编译器。</li>
</ul>

<h3 id="item-42-understand-the-two-meanings-of-typename">Item 42: Understand the two meanings of typename.</h3>

<p>在template声明式中，<code>class</code>和<code>typename</code>不一定相同。</p>

<pre><code>template&lt;typename C&gt;
void print2nd(const C&amp; container) {
	if(container.size() &gt;= 2) {
		C::const_iterator iter(container.begin());
		++iter;
		int value = *iter;
	{
}
</code></pre>

<p><code>iter</code>的类型是<code>C::const_iterator</code>，实际是什么值取决于<code>template</code>参数<code>C</code>。<code>template</code>内出现的名称如果相依于某个<code>template</code>参数，称之为从属名称。如果从属名称在<code>class</code>内呈嵌套状，我们称它为嵌套从属名称。<code>C::const_iterator</code>就是这样的一个名称。而<code>value</code>的类型<code>int</code>并不依赖<code>template</code>参数的名称，称之为非从属名称。<strong>在缺省情况下，嵌套从属名称不是类型</strong>。</p>

<p>改为<code>typename C::const_iterator iter(container.begin());</code>。</p>

<p>一种特列情况为，<code>typename</code>不可以出现在<code>base classes list</code>内的嵌套从属类型名称之前，也不可以在<code>member initialization list</code>中作为<code>base class</code>修饰符。</p>

<pre><code>template&lt;typename T&gt;
class Derived: public Base&lt;T&gt;::Nested {
public:
	explict Derived(int x): Base&lt;T&gt;::Nested(x) {
		typename Base&lt;T&gt;::Nested temp;
	}
};

最后一个例子：
template&lt;typename IterT&gt;
void workWithIterator(IterT iter) {
	typename std::iterator_traits&lt;IterT&gt;::value_type temp(*iter);
}
</code></pre>

<h3 id="item-43-know-how-to-access-names-in-templatized-base-classes">Item 43: Know how to access names in templatized base classes</h3>

<p>当我们从<code>Object Oriented C++</code>进入<code>Template C++</code>，继承就不像以前那般顺利。编译器知道<code>base class templates</code>有可能被特化，而那个特化版本可能不提供和一般性template相同的接口，因而它往往拒绝在<code>templatized base classes</code>内寻找继承而来的名称。</p>

<pre><code>template&lt;typename Company&gt;
class LoggingMsgSender: public MsgSender&lt;Company&gt; {
public:
	void sendClearMsg(const MsgInfo* info) {
		sendClear(info);  //调用base class函数；这段代码无法通过编译
	}
};
</code></pre>

<p>基类<code>MsgSender&lt;Company&gt;</code>的特化版本，可能不提供<code>sendClear()</code>方法。</p>

<p>解决方法：</p>

<ol>
  <li>base class函数调用动作之前加上<code>this-&gt;</code></li>
  <li>在函数前使用using声明式，<code>using MsgSender&lt;Company&gt;::sendClear</code>.</li>
  <li>直接使用<code>MsgSender&lt;Company&gt;：：sendClear(info)</code>。</li>
</ol>

<p>第三种做法有缺陷，如果被调用的是<code>virtual</code>函数，上述的做法会关闭<code>virtual绑定行为</code>。</p>

<h3 id="item-44-factor-parameter-independent-code-out-of-templates">Item 44: Factor parameter-independent code out of templates.</h3>

<ul>
  <li>Templates生成多个classes和多个函数，所以任何template代码都不该与某个造成膨胀的template参数产生相依关系。</li>
  <li>因非类型模版参数而造成的代码膨胀，往往可消除，做法是以函数参数或class成员变量替换template参数。</li>
  <li>因类型参数而造成的代码膨胀，往往可降低，做法是让带有完全相同二进制表述的具现类型共享实现码。</li>
</ul>

<p>template &lt;T*&gt;可以改为<code>tempalte&lt;void*&gt;</code>减少代码膨胀。</p>

<h3 id="item-45-use-member-function-templates-to-accept-all-compatible-types">Item 45: Use member function templates to accept “all compatible types”</h3>

<p>如果以带有<code>base-derived</code>关系的B，D两类型分别具现化某个template，产生出来的两个具现体并不带有<code>base-derived</code>关系。</p>

<pre><code>template&lt;typename T&gt;
class SmartPtr {
public:
	tempalte&lt;typename U&gt; //member template, 为了生成copy构造函数
	SmartPtr(const SmartPtr&lt;U&gt;&amp; other); 
};
</code></pre>

<p>这一类构造函数根据SmartPtr&lt;U&gt;创建一个Smart&lt;T&gt;。未加上<code>explicit</code>是因为原始指针类型之间的转换（例如从derived转化base）是隐式转换。可以在构造模板实现代码中约束行为：</p>

<pre><code>template&lt;typename T&gt;
class SmartPtr {
public:
	tempalte&lt;typename U&gt; //以other的heldPtr初始化this的heldPtr
	SmartPtr(const SmartPtr&lt;U&gt;&amp; other):heldPtr(other.get()) {}
	T * get() const { return heldPtr; }
private:
	T* heldPtr; 
};
</code></pre>

<p>成员函数模板的效用不限于构造函数，它们常扮演的另一个角色是支持赋值操作。</p>

<pre><code>template&lt;typename T&gt;
class shared_ptr {
public:
	template&lt;class Y&gt;
	explicit shared_ptr(Y* p);
	template&lt;class Y&gt;
	shared_ptr(shared_ptr&lt;Y&gt; const&amp; r);
	template&lt;class Y&gt;
	explicit shared_ptr(weak_ptr&lt;Y&gt; const&amp; r);
	template&lt;class Y&gt;
	explicit shared_ptr(auto_ptr&lt;Y&gt; const&amp; r);
	template&lt;class Y&gt;
	shared_ptr&amp; operator=(shared_ptr&lt;Y&gt; const&amp; r);
	template&lt;class Y&gt;
	shared_ptr&amp; operator=(auto_ptr&lt;Y&gt; &amp; r);
};
</code></pre>

<p>上述函数的<code>explict</code>表示从某个shared_ptr类型隐式转换至另一个shared_ptr类型是被允许的，但从某个内置指针或从其他智能指针类型进行隐式转换则不被认可。auto_ptr不声明const是因为复制一个auto_ptr，它其实被改动了。</p>

<p>在class内声明泛化copy构造函数并不会阻止编译器生成它们自己的copy构造函数。</p>

<h3 id="item-46-define-non-member-functions-inside-templates-when-type-conversions-are-desired">Item 46: Define non-member functions inside templates when type conversions are desired.</h3>

<p>将Item24的例子改为模板：</p>

<pre><code>template&lt;typename T&gt;
class Rational {
public:
	Rational(const T&amp; numerator = 0, const T&amp; denominator = 1);
	
	template&lt;typename T&gt;
	const Rational&lt;T&gt; operator* (const Rational&lt;T&gt; &amp;rhs, const Rational&lt;T&gt; &amp;rhs);
};

Rational oneHalf(1, 2);
result = oneHalf * 2; // 无法通过编译，不加模板则可以
</code></pre>

<p>这是因为template实参推导过程中从不将隐式类型转换函数考虑在内。可以改为如下：</p>

<pre><code>friend const Rational operator* (const Rational &amp;rhs, const Rational &amp;rhs); //省略了&lt;T&gt;
</code></pre>

<p>当对象oneHalf被声明为一个Rational<int>, 模板被具现化出来，而作为过程的一部分friend函数（接受Rational<int> 参数）也就自动声明出来，后者作为一个函数而非函数模板，因此编译器可以在调用它时使用隐式转换函数。</int></int></p>

<h2 id="newdelete">定制new和delete</h2>
<p>###Item 49: Understand the behavior of the new-handler.</p>

<p>set_new_handler允许客户指定一个函数，在内存分配无法获得满足时候被调用。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Inside C++ Object]]></title>
    <link href="http://billowkiller.github.io/blog/2014/04/12/Inside-C%2B%2B-Object/"/>
    <updated>2014-04-12T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/04/12/Inside-C++-Object</id>
    <content type="html"><![CDATA[<p>modified from <a href="http://blog.csdn.net/eroswang/article/details/1749609">http://blog.csdn.net/eroswang/article/details/1749609</a></p>

<hr />

<h2 id="ooob">面对对象（OO）和基于对象（OB）</h2>

<p>基于对象的数据类型可以展示封装的非多态形式，但是不支持类型的扩充。一个OB设计可能比一个对等的OO设计速度更快而且空间更紧凑。速度快是因为所有的函数引发操作都在编译时期解析完成，对象建构起来时不需要设置virtual机制；空间紧凑则是因为每一个class object不需要负担传统上为了支持virtual机制而需要的额外符合。不过，OB设计比较没有弹性。 </p>

<h2 id="c">C++对象模型</h2>

<p>在C++中，有两种<strong>class data members：static和nonstatic</strong>，以及三种<strong>class member functions：static、nonstatic和virtual</strong>。</p>

<p>Nonstatic data members被配置于每一个class object之内，static data members则被存放在所有的class object之外。Static和nonstatic function members也被放在所有的class object之外，Virtual functions则以两个步骤支持之：</p>

<ul>
  <li>每一个class产生出一堆指向virtual functions的指针，放在表格之中，这个表格被称为<strong>virtual table（vtbl）</strong>。每一个class所关联的type_info object（用以支持<strong>runtime type identification，RTTI</strong>）也经由virtual table被指出来，通常是放在表格的第一个slot处。</li>
  <li>每一个class object被添加了一个指针，指向相关的virtual table。通常这个指针被称为<strong>vptr</strong>。</li>
</ul>

<!--more-->

<p><img src="http://p.blog.csdn.net/images/p_blog_csdn_net/arthurkingios/1.JPG" alt="" /></p>

<p><strong>重置vptr：</strong></p>

<p>假设Bear继承于ZooAnimal，如下所示：</p>

<pre><code>Bear b;
ZooAnimal za = b;  // 这会引起切割（sliced）
// 调用 ZooAnimal::rotate()
za.rotate();
</code></pre>

<p><strong>为什么rotate所调用的是ZooAnimal实体而不是Bear实体？</strong></p>

<p>ZooAnimal class object以另一个ZooAnimal class object作为初值，或Bear class object以另一个Bear class object作为初值，都可以直接靠bitwise copy semantics完成（剔除pointer member情况）
。</p>

<p>而当一个base class object以其derived class object内容做初始化操作时，其vptr复制操作也必须保证其安全。编译器必须确保如果某个object含有一个或一个以上的vptrs，那些vptrs的内容不会被base class object初始化改变。</p>

<h2 id="constructor">Constructor的建构操作</h2>

<h3 id="default-constructor">Default Constructor的建构操作</h3>

<p>default constructor仅在编译器需要它时，才会被合成出来。
通常来说，由编译器合成出来的default constructor是没啥用的（trivial），但有以下几种例外：</p>

<ol>
  <li>
    <p>带有“Default Constructor”的Member Class Object</p>

    <p>如果一个class没有任何constructor，但它内含一个member object，而后者有default constructor，那么编译器会在constructor真正需要被调用时未此class合成一个“nontrivial”的default constructor。</p>

    <p>为了避免合成出多个default constructor，解决方法是把合成的default constructor、copy constructor、destructor、assignment copy operator都以inline方式完成。一个inline函数有静态链接（static linkage），不会被档案以外者看到。如果函数太复杂，不适合做成inline，就会合成出一个explicit non-inline static实体。</p>
  </li>
  <li>“带有Default Constructor”的Base Class</li>
  <li>“带有一个Virtual Function”的Class
    <ul>
      <li>class声明（或继承）一个virtual function</li>
      <li>class派生自一个继承串链，其中有一个或更多的virtual base classes</li>
    </ul>
  </li>
  <li>
    <p>“带有一个virtual Base Class”的Class</p>

    <p>编译器需要在derived class object中为每一个virtual base classes安插一个指针，使得所有“经由reference或pointer来存取一个virtual base class”的操作可以通过相关指针完成。</p>
  </li>
</ol>

<p><strong>总结：</strong>
被合成出来的constructor只能满足编译器（而非程序）的需要。
没有存在着四种情况而又没有声明任何constructor的classes，它们拥有的是implicit trivial default constructor，实际上并不会被合成出来。</p>

<p>在合成的default constructor中，只有base class subobjects和member class objects会被初始化，所有其它的nonstatic data member，如整数、整数指针，整数数组等都不会被初始化。</p>

<p><strong>一般会对dafult constructor有两个误解：</strong></p>

<ol>
  <li>任何class如果没有定义default constructor，就会被合成出来。</li>
  <li>编译器合成出来的default constructor会明确设定“class内每一个data memeber”的默认值。</li>
</ol>

<h3 id="copy-constructor">Copy Constructor的建构操作</h3>

<p>有三种情况会以一个object的内容作为另一个class object的初值，即<strong>object赋值、object参数传递、object作为函数返回值</strong>。</p>

<p>如果class没有提供一个explicit copy constructor，其内部是以所谓的default memberwise initialization手法完成的，也就是把每一个内建的或派生的data member（例如一个指针或一个数组）的值，从某个object拷贝一份到另一个object身上，不过它并不会拷贝其中的member class object，而是以递归的方式施行memberwise initialization。</p>

<p>copy constructor仅在必要的时候（class不展现bitwise copy semantics）才由编译器产生出来。</p>

<p>比如，某个类含有<code>String&amp; str</code>成员变量，在这种情况下，编译器必须合成出一个copy constructor以便调用member class String object的copy constructor：</p>

<p><strong>一个class不展现出“bitwise copy semantics”的四种情况：</strong></p>

<ol>
  <li>当class内含一个member object而后者的class声明有一个copy constructor时（无论是被明确声明或被合成而得）</li>
  <li>当class继承自一个base class而后者存在有一个copy constructor时</li>
  <li>
    <p>当class声明了一个或多个virtual functions时</p>

    <p>由于编译器要对每个新产生的class object的vptr设置初值，因此，当编译器导入一个vptr到class之中时，该class就不再展现bitwise semantics了。特别地，当一个base class object以其derived class的object内容做初始化操作时，其vptr复制操作必须保证安全，而如果依旧采用bitwise copy的话，base class object的vptr会被设定指向derived class的virtual table，而这将导致灾难。</p>
  </li>
  <li>
    <p>当class派生自一个继承串链，其中有一个或多个virtual base classes时</p>

    <p>当一个class object以其derived classes的某个object作为初值时，为了完成正确的virtual base class pointer/offset的初值设定，编译器必须合成一个copy constructor，安插一些码以设定virtual base class pointer/offset的初值，对每一个member执行必要的memberwise初始化操作，以及执行其他的内存相关操作。</p>
  </li>
</ol>

<h2 id="section">成员的初始化列表</h2>

<p>下列情况中，为了让你的程序能够被顺利编译，你必须使用member initialization list：</p>

<ul>
  <li>当初始化一个reference member时；</li>
  <li>当初始化一个const member时；</li>
  <li>当调用一个base class的constructor，而它拥有一组参数时；</li>
  <li>当调用一个member class的constructor，而它拥有一组参数时。</li>
</ul>

<h2 id="class">class大小</h2>

<p>考虑下面的代码：</p>

<pre><code>#include "iostream"
using namespace std;

class X {};
class Y : public virtual X {};
class Z : public virtual X {};
class A : public Y,public Z {};

int main()
{
    cout&lt;&lt;"sizeof(X): "&lt;&lt;sizeof(X)&lt;&lt;endl;
    cout&lt;&lt;"sizeof(Y): "&lt;&lt;sizeof(Y)&lt;&lt;endl;
    cout&lt;&lt;"sizeof(Z): "&lt;&lt;sizeof(Z)&lt;&lt;endl;
    cout&lt;&lt;"sizeof(A): "&lt;&lt;sizeof(A)&lt;&lt;endl;

    return 0;
}
</code></pre>

<p>得到的结果是什么呢？答案是</p>

<pre><code>sizeof(X): 1
sizeof(Y): 4
sizeof(Z): 4
sizeof(A): 8
</code></pre>

<ul>
  <li>对于一个class X这样的空的class，由于需要使得这个class的两个objects得以在内存中配置独一无二的地址，故编译器会在其中安插进一个char。因而class X的大小为1。</li>
  <li>由于class Y虚拟继承于class X，而在derived class中，会包含指向visual base class subobject的指针（4 bytes），而由于需要区分这个class的不同对象，因而virtual base class X subobject的1 bytes也出现在class Y中（1 bytes），此外由于Alignment的限制，class Y必须填补3bytes（3 bytes），这样一来，class Y的大小为8。<strong>编译器将一个empty virtual base class视为derived class object最开头的一部分，因而省去了其后的1 bytes，自然也不存在后面Alignment的问题，故实际的执行结果为4。</strong></li>
  <li>不管它在class继承体系中出现了多少次，一个virtual base class subobject只会在derived class中存在一份实体。因此，class A的大小有以下几点决定：（1）被大家共享的唯一一个class X实体（1 byte）；（2）Base class Y的大小，减去“因virtual base class X而配置”的大小，结果是4 bytes。Base class Z的算法亦同。（3）classs A的alignment数量。前述总和为9 bytes，需要填补3 bytes，结果是12 bytes。empty virtual base class所做的处理，class X实体的那1 byte将被拿掉，于是额外的3 bytes填补额也不必了，故实际的执行结果为8。</li>
</ul>

<p><strong>不管是自身class的还是继承于virtual或nonvirtual base class的nonstatic data members，其都是直接存放在每个class object之中的。至于static data members，则被放置在程序的一个global data segment中，不会影响个别的class object的大小，并永远只存在一份实体。</strong></p>

<h2 id="data-member">Data Member</h2>

<h3 id="data-member-1">Data Member布局</h3>

<p>同一个access section中的nonstatic data member在class object中的排列顺序和其被声明的顺序一致，而多个access sections中的data members可以自由排列。（虽然当前没有任何编译器会这么做）</p>

<p>编译器还可能会合成一些内部使用的data members（例如vptr，编译器会把它安插在每一个“内含virtual function之class”的object内），以支持整个对象模型。</p>

<h3 id="data-member-2">Data Member的存取</h3>

<p><strong>Static Data Members：</strong></p>

<ul>
  <li>每一个static data member只有一个实体，存放在程序的data segment之中，每次程序取用static member，就会被内部转化为对该唯一的extern实体的直接参考操作。</li>
  <li>若取一个static data member的地址，会得到一个指向其数据类型的指针，而不是一个指向其class member的指针，因为static member并不内含在一个class object之中。</li>
  <li>如果有两个classes，每一个都声明了一个static member freeList，那么编译器会采用name-mangling对每一个static data member编码，以获得一个独一无二的程序识别代码。</li>
</ul>

<p><strong>Nonstatic Data Members：</strong></p>

<pre><code>Point3d origin, *pt = &amp;origin;
origin.x = 0.0;
pt-&gt;x = 0.0;
</code></pre>

<p><strong>这两种存取方式有什么区别吗？</strong></p>

<p>答案是“<strong>当Point3d是一个derived class，而在其继承结构中有一个virtual base class，并且并存取的member（如本例的x）是一个从该virtual base class继承而来的member时，就会有重大的差异</strong>”。这时候我们不能够说pt必然指向哪一种 class type（因此我们也就不知道编译期间这个member真正的offset位置），所以这个存取操作必须延迟到<strong>执行期</strong>，经由一个额外的简洁导引，才能够解决。但如果使用origin，就不会有这些问题，其类型无疑是Point3d class，而即使它继承自virtual base class，members的offset位置也在<strong>编译时期就固定了</strong>。</p>

<h3 id="data-member-3">继承与Data Member</h3>

<p><strong>1. 只要继承不要多态</strong></p>

<pre><code>class Concrete {
private:
int val;
char bit1;
};

class Concrete2 : public Concrete1 {
private:
char bit2;
};

class Concrete3 : public Concrete2 {
private:
char bit3;
};
</code></pre>

<p>现在Concrete3 object的大小为16 bytes，细分如下：（a）Concrete1内含两个members：val和bit1，加起来是5 bytes，再填补3 bytes，故一个Concrete1 object实际用掉8 bytes；（b）需要注意的是，Concrete2的bit2实际上是被放在填补空间之后的，于是一个Concrete2 object的大小变成12 bytes；（c）依次类推，一个Concrete3 object的大小为16 bytes。</p>

<p><strong>2. 加上多态</strong></p>

<p>virtual function带来的额外负担：</p>

<ul>
  <li>导入一个virtual table，用来存放它声明的每一个virtual function的地址；</li>
  <li>在每一个class object中导入一个vptr；</li>
  <li>加强constructor和destructor，使它们能设置和抹消vptr。</li>
</ul>

<p><strong>3. 多重继承</strong></p>

<p>对一个多重继承对象，将其地址指定给“第一个base class的指针”，情况将和单一继承时相同，因为二者都指向相同的起始地址，需付出的成本只有地址的指定操作而已。至于第二个或后继的base class的地址指定操作，则需要将地址修改过，加上（或减去，如果downcast的话）介于中间的base class subobjects的大小。</p>

<p><strong>4. 虚拟继承</strong></p>

<p>class如果内含一个或多个virtual base class subobject，将被分隔为两部分：一个不变局部和一个共享局部。不变局部中的数据，不管后继如何衍化，总是拥有固定的offset，所以这一部分数据可以被直接存取。至于共享局部，所表现的就是virtual base class subobject。这一部分的数据，其位置会因为每次的派生操作而变化，所以它们只可以被间接存取。
间接存取主要有以下三种主流策略：</p>

<ol>
  <li>在每一个derived class object中安插一些指针，每个指针指向一个virtual base class。要存取继承得来的virtual base class members，可以使用相关指针间接完成。由于虚拟继承串链得加长，导致间接存取层次的增加。</li>
  <li>在上一个的基础上，为了解决每一个对象必须针对每一个virtual base class背负一个额外的指针的问题，Micorsoft编译器引入所谓的virtual base class table。每一个class object如果有一个或多个virtual base classes，就会由编译器安插一个指针，指向virtual base class table。这样一来，就可以保证class object有固定的负担，不因为其virtual base classes的数目而有所变化。</li>
  <li>在virtual function table中放置virtual base class的offset。新近的Sun编译器采取这样的索引方法，若为正值，就索引到virtual functions，若为负值，则索引到virtual base class offsets。</li>
</ol>

<p><strong>小结：一般而言，virtual base class最有效的一种运用方式就是：一个抽象的virtual base class，没有任何data members。</strong></p>

<h3 id="data-members">指向Data Members的指针</h3>

<pre><code>class Point3d {
public:
	virtual ~Point3d();
protected:
	static Point3d origin;
	float x, y, z;
} 
</code></pre>

<p>如果你去取class中某个data member的地址时，得到的都是data member在class object中的实际偏移量加1。例如<code>&amp;Point3d::z</code>得到9或13，根据vptr放在对象头还是对象尾确定。为什么要这么做呢？主要是为了区分一个“没有指向任何data member”的指针和一个指向“的第一个data member”的指针。即，区分一下情况：</p>

<pre><code>float Point3d::*p1 = 0;
float Point3d::*p2 = &amp;Point3d::x;
</code></pre>

<p>为了区分<code>p1</code>和<code>p2</code>每一个真正的member offset值都被加上1。因此，无论编译器或使用者都必须记住，在真正使用该值以指出一个member之前，请先减掉1。</p>

<p>另外正确区分<code>&amp; Point3d::z</code>和<code>&amp;origin.z</code>：取一个nonstatic data member的地址将会得到它在class中的offset，取一个绑定于真正class object身上的data member的地址将会得到该member在内存中的真正地址。</p>

<p>在多重继承之下，若要将第二个（或后继）base class的指针和一个与derived class object绑定之member结合起来那么将会因为需要加入offset值而变得相当复杂。</p>

<pre><code>struct Base1 { int val1; };
struct Base2 { int val2; };
struct Derived : Base1, Base2 { ... };

void func1(int Derived::*dmp, Derived *pd)
{
	// 期望第一个参数得到的是一个“指向derived class之member”的指针
	// 如果传来的却是一个“指向base class之member”的指针，会怎样呢
	pd-&gt;*dmp;
}

void func2(Derived *pd)
{
	// bmp将成为1
	int Base2::*bmp = &amp;Base2::val2;
	// bmp == 1
	// 但是在Derived中，val2 == 5
	func1(bmp,pd);
}
</code></pre>

<p>也就是说<code>pd-&gt;*dmp</code>将存取到<code>Base1::val1</code>，为解决这个问题，当bmp被作为func1()的第一个参数时，它的值必须因介入的Base1 class的大小而调整：</p>

<pre><code>// 内部转换，防止bmp == 0
func1(bmp ? bmp + sizeof(Base1) : 0, pd);
</code></pre>

<h2 id="functions">Functions</h2>

<h3 id="nonstatic-member-functions">非静态成员函数（Nonstatic Member Functions）</h3>

<p>C++的设计准则之一就是：nonstatic member function至少必须和一般的nonmember function有相同的效率。因为编译器内部已将“member函数实体”转化为对等的“nonmember函数实体”。下面是magnitude()的一个nonmember定义：</p>

<pre><code>loat Pointer3d::magnitude() const
{
	return sqrt(_x*_x + _y*_y + _z*_z);
}
// 内部转化为
float magnitude_7Point3dFv(const Point3d *this)  //已对函数名称进行“mangling”处理
{
	return sqrt(this-&gt;_x*this-&gt;_x + this-&gt;_y*this-&gt;_y + this-&gt;_z*this-&gt;_z);
}
</code></pre>

<p>现在，对该函数的每一个调用操作也都必须转换：</p>

<pre><code>obj.magnitude();
// 转换为
magnitude_7Point3dFv(&amp;obj);
</code></pre>

<p>mangling手法可在链接时期检查出任何不正确的调用操作，但由于编码时未考虑返回类型，故<strong>如果返回类型声明错误，就无法检查出来</strong>。</p>

<h3 id="virtual-member-functions">虚拟成员函数（Virtual Member Functions）</h3>

<p>一个class只会有一个virtual table，其中内含其对应的class object中所有active virtual functions函数实体的地址，具体包括：</p>

<ol>
  <li>
    <p>这个class所定义的函数实体</p>

    <p>它会改写一个可能存在的base class virtual function函数实体。若base class中不存在相应的函数，则会在derived class的virtual table增加相应的slot。</p>
  </li>
  <li>
    <p>继承自base class的函数实体</p>

    <p>这是在derived class决定不改写virtual function时才会出现的情况。具体来说，base class中的函数实体的地址会被拷贝到derived class的virtual table相对应的slot之中。</p>
  </li>
  <li>
    <p>pure_virtual_called函数实体</p>
  </li>
</ol>

<p>对于那些不支持多态的对象，经由一个class object调用一个virtual function，这种操作应该总是被编译器像对待一般的nonstatic member function一样地加以决议：</p>

<pre><code>// Point3d obj
obj.normalize();
// 不会转化为
(*obj.vptr[1])(&amp;obj);
// 而会被转化未
normalize_7Point3dFv(&amp;obj);
</code></pre>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/virtualtable_zpsc5065cda.png" alt="" /></p>

<h3 id="static-member-functions">静态成员函数（Static Member Functions）</h3>

<p>编译器的开发者针对static member functions，分别从编译层面和语言层面对其进行了支持：</p>

<p><strong>编译层面</strong>：当class设计者希望支持“没有class object存在”的情况时，可把0强制转型为一个class指针，因而提供出一个this指针实体：</p>

<pre><code>// 函数调用的内部转换
object_count((Point3d*)0);
</code></pre>

<p><strong>语言层面</strong>：static member function的最大特点是没有this指针，如果取一个static member function的地址，获得的将是其在内存中的位置，其地址类型并不是一个“指向class member function的指针”，而是一个“nonmember函数指针”：</p>

<pre><code>unsigned int Point3d::object_count() { return _object_count; }
&amp;Point3d::object_count();
// 会得到一个地址，其类型不是
unsigned int (Point3d::*)();
// 而是
unsigned int (*)();
</code></pre>

<ul>
  <li>它不能够直接存取其class的nonstatic members。</li>
  <li>它不能够被声明为const、volatile或virtual。</li>
  <li>它不需要经由class object才被调用。</li>
</ul>

<p>static member function经常被用作回调（callback）函数。</p>

<h3 id="virtual-functions">多重继承下的Virtual Functions</h3>

<p>在多重继承中支持virtual functions，其复杂度围绕在第二个及后继的base classes身上，以及“必须在执行期调整this指针”这一点。</p>

<p><strong>多重继承到来的问题：</strong></p>

<ol>
  <li>
    <p>经由指向“第二或后继之base class”的指针（或reference）来调用derived class virtual function，该调用操作连带的“必要的this指针调整”操作，必须在执行期完成；</p>

    <pre><code> Base2 *pbase2 = new Derived;
 //会被内部转化为：
 Derived *temp = new Derived;
 Base2 *pbase2 = temp ? temp + sizeof(Base1) : 0;
 // 必须调用正确的virtual destructor函数实体
 // pbase2需要调整，以指出完整对象的起始点
 delete pbase2;
</code></pre>

    <p>上述的offset加法却不能够在编译时期直接设定，因为pbase2所指的真正对象只有在执行期才能确定。自此，我们明白了在多重继承下所面临的独特问题：经由指向“第二或后继之base class”的指针（或reference）来调用derived class virtual function，该调用操作所连带的“必要的this指针调整”操作，必须在执行期完成。有两种方法来解决这个问题：</p>

    <ol>
      <li>将virtual table加大，每一个virtual table slot不再只是一个指针，而是一个聚合体，内含可能的offset以及地址。</li>
      <li>利用Thunk技术，允许virtual table slot继续内含一个简单的指针，slot中的地址可以直接指向virtual function，也可以指向一个相关的thunk。于是，对于那些不需要调整this指针的virtual function而言，也就不需要承载效率上的额外负担。</li>
    </ol>
  </li>
  <li>
    <p>由于两种不同的可能：（a）经由derived class（或第一个base class）调用；（b）经由第二个（或其后继）base class调用，同一函数在virtual table中可能需要多笔对应的slot；</p>

    <pre><code> Base1 *pbase1 = new Derived;
 Base2 *pbase2 = new Derived;
	
 delete pbase1;
 delete pbase2;
</code></pre>

    <p>虽然两个delete操作导致相同的Derived destructor，但它们需要两个不同的virtual table slots：</p>

    <p><strong>解决方法：</strong>在多重继承下，一个derived class内含n-1个额外的virtual tables，n表示其上一层base classes的数目。按此手法，Derived将内含以下两个tables：vtbl_Derived和vtbl_Base2_Derived。</p>
  </li>
  <li>
    <p>允许一个virtual function的返回值类型有所变化，可能是base type，可能是publicly derived type，这一点可以通过Derived::clone()函数实体来说明。</p>

    <pre><code> Base2 *pb1 = new Derived;

 // 调用Derived::clone()
 // 返回值必须被调整，以指向Base2 subobject
 Base2 *pb2 = pb1-&gt;clone();
</code></pre>

    <p>当运行pb1-&gt;clone()时，pb1会被调整指向Derived对象的起始地址，于是clone()的Derived版会被调用：它会传回一个指针，指向一个新的Derived对象；该对象的地址在被指定给pb2之前，必须先经过调整，以指向Base2 subobject。</p>
  </li>
</ol>

<p>virtual table多重继承内存布局图：</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/virtualtable_zps7dae0fad.png" alt="多重继承" /></p>

<p>virtual table虚拟继承内存布局图：</p>

<p><img src="http://i1113.photobucket.com/albums/k512/billowkiller/LinkSource/virtualtable_zpsb4d94533.png" alt="" /></p>

<h2 id="section-1">其他</h2>

<h3 id="section-2">纯虚函数</h3>

<p>在设计抽象基类时，需要注意以下几点：</p>

<ol>
  <li>
    <p>不要将destructor声明为pure virtual function；</p>

    <p>如果将destructor声明为pure virtual function，则设计者一定得定义它。因为每一个derived class destructor会被编译器加以扩展，以静态调用得方式调用其“每一个virtual base class”以及“上一层base class”的destructor。</p>
  </li>
  <li>不要将那些函数定义内容并不与类型有关的函数设计为virtual function，因为其几乎不会被后继的derived class改写。</li>
  <li>对于其derived class可能修改某一个data member的函数，不应被声明为const。</li>
</ol>

<h3 id="section-3">对象构造</h3>

<p><strong>必须在构造函数初始化列表初始化的类型</strong>：</p>

<ul>
  <li>没有默认构造函数的类型成员</li>
  <li>const成员（整数型的可以申明时赋值）</li>
  <li>
    <p>引用类型的成员</p>

    <p>class Point {
  public:
      Point(float x = 0.0, float y = 0.0) : _x(x),_y(y) {}
      virtual float z();
  protected:
      float _x,_y;
  };</p>
  </li>
</ul>

<p>不能小看z()这个virtual function给class Point带来的巨大变化。virtual function的引入促使每一个class Point拥有一个vtpr，这样一来，编译器在constructor中添加了对vptr进行初始化的代码，而copy constructor和copy assignment operator也会对vptr进行设定，而不再是原先简单的bitwise操作了。</p>

<p>一般而言，如果你的设计之中有很多函数都需要以传值方式（by value）传回一个local class object，那么提供一个copy constructor就比较合理。</p>

<p><strong>constructor的执行算法通常如下：</strong></p>

<ul>
  <li>在derived class constructor中，所有virtual base classes的constructor会被调用；</li>
  <li>在derived class constructor中，上一层base class的constructor会被调用；</li>
  <li>上述完成之后，对象的vptr(s)被初始化，指向相关的virtual table(s)；</li>
  <li>如果class有member class object，而后者拥有constructor，那么它们会以其声明顺序的相反顺序被调用；</li>
  <li>用户所定义的代码。</li>
</ul>

<h3 id="section-4">析构函数</h3>

<p>如果class没有定义destructor，那么只有在class内含的member object（或是class自己的base class）拥有destructor的情况下，编译器才会自动合成出一个来。
其解构顺序与建构顺序正好相反。</p>

<p>一般而言，我们会把object尽可能放置在使用它的那个程序区段附近，这样做可以节省不必要的对象产生操作和销毁操作。</p>

<h3 id="section-5">全局对象</h3>

<p>全局对象的静态初始化策略包括以下几个步骤：</p>

<ol>
  <li>为每一个需要静态初始化的对象产生一个<code>_sti_...()</code>函数，内含必要的constructor调用操作或inline expansions；</li>
  <li>为每一个需要静态的内存释放操作的对象产生一个<code>_std_...()</code>函数，内含必要的destructor调用操作或inline expansions；</li>
  <li>在main()函数的首尾分别添加一个<code>_main()</code>函数（用以调用可执行文件中的所有<code>_sti()</code>函数）和一个<code>_exit()</code>函数（用以调用可执行文件中的所有<code>_std()</code>函数）。</li>
</ol>

<p><strong>建议根本不要用那些需要静态初始化的全局对象。</strong> </p>

<h3 id="section-6">局部静态对象</h3>

<pre><code>const Matrix&amp; identity() {
	static Matrix mat_identity;
	// ...
	return mat_identity;
}
</code></pre>

<p>此处的local static class object保证了以下语意：</p>

<ul>
  <li><code>mat_identity</code>的constructor必须只能施行一次，虽然上述函数可能会被调用多次；</li>
  <li><code>mat_identity</code>的destructor必须只能施行一次，虽然上述函数可能会被调用多次。</li>
</ul>

<p>编译器的实际做法如下：在第一次调用<code>identity()</code>时把<code>mat_identity</code>构造出来，而在与相应文件关联的静态内存释放函数中将其解构。（局部静态对象的地址在downstream component中将会被转换到程序内用来放置global object的data segment中）</p>

<h3 id="section-7">对象数组</h3>

<p>如何支持以下的语句：<code>complex::complex(double=0.0, double=0.0);</code></p>

<pre><code>complex c_array[10];
//内部转换
vec_new(&amp;c_array,sizeof(complex),10,&amp;complex::complex,0);
</code></pre>

<p>为了解决这个问题，可由编译器产生一个内部的constructor，没有参数，在其函数内调用由程序员提供的constructor，并将default参数值明确地指定过去：</p>

<pre><code>complex::complex() {
	complex(0.0, 0.0);
}
</code></pre>

<h3 id="new--delete">new &amp; delete</h3>

<p>以constructor来配置一个class object：<code>Point3d *origin = new Point3d;</code>
转为</p>

<pre><code>Point3d *origin;
if(origin = _new(sizeof(Point3d))) {
	try {
		origin = Point3d::Point3d(origin);
	}
	catch( ... ) {
		_delete(origin);  // 释放因new而配置的内存
		throw;  // 将原来的exception上传
	}
}
</code></pre>

<p>如果我们配置一个数组，内带10个Point3d objects，我们预期Point和Point3d的constructor被调用各10次，每次作用于数组中的一个元素：</p>

<pre><code>// 危险
Point *ptr = new Point3d[10];
// 只有Point::~Point被调用
delete []ptr;
</code></pre>

<p>由于其触发的<code>vec_delete()</code>是通过迭代走过每一个数组元素，而本例中被传递过去的是Point class object的大小而不是Point3d class object的大小，整个运行过程将会失败。
解决之道在于程序层面，而非语言层面：</p>

<pre><code>for(int ix = 0; ix &lt; 10; ix++)
{
	Point3d *p = &amp;((Point3d*)ptr)[ix];
	delete p;
}
</code></pre>

<p>当然，最好还是<strong>避免以一个base class指针指向一个derived class objects所组成的数组。</strong></p>

<h3 id="template">Template</h3>

<p><strong>member functions只有在member functions被使用的时候，C++ Standard才要求它们被“具现”出来</strong>。这个规则的由来主要有两个原因：</p>

<ol>
  <li>空间和效率的考虑。对于未使用的函数进行“具现”将会花费大量的时间和空间；</li>
  <li>尚未实现的功能。并不是一个template具现出来的所有类型一定能够完整支持一组member functions，因而只需具现真正需要的member functions。</li>
</ol>

<p>举个例子：<code>Point&lt;float&gt; *p = new Point&lt;float&gt;;</code></p>

<p>只有（a）Point template的float实例、（b）new 运算符、（c）default constructor需要被“具现”。</p>

<p><strong>并且所有与类型相关的检验，如果涉及到template参数，都必须延迟到真正的具现操作发生</strong>。</p>

<p>区分以下两种意义：一种是“<strong>scope of the template definition</strong>”，也就是“定义出template”的程序，另一种是“<strong>scope of the template instantiation</strong>”，也就是“具现出template”的程序。</p>

<pre><code>// scope of the template definition
extern double foo(double);

template &lt;class type&gt;
class ScopeRules {
public:
	void invariant() { _member = foo(_val); }
	type type_dependent() { return foo(_member); }
	// ...
private:
	int _val;
	type _member;
};

// scope of the template instantiation
extern int foo(int);

ScopeRules&lt;int&gt; sr0;
</code></pre>

<p>在“scope of the template definition”中，只有一个foo()函数声明位于scope之内；然而在“scope of the template instantiation”中，两个foo()函数声明都位于scope之内。对于以下函数操作：<code>sr0.invariant();</code>，那么，在invariant()中调用的究竟是哪一个foo()函数实体呢？</p>

<p>Template之中，对于一个nonmember name的决议结果是根据这个name的使用是否与“用以具现出该template的参数类型”有关而决定的，如果其使用互不相关，那么就以“scope of the template definition”来决定name，否则就以“scope of the template instantiation”来决定name。</p>

<pre><code>// 因为_val的类型是int，而函数的决议只和函数原型有关，与函数返回值无关
// 被用来具现这个template的真正类型对于_val的类型没有影响
_member = foo(_val);
</code></pre>

<p>故此处的调用操作由“scope of the template definition”来决议。</p>

<p>若是如下的函数调用：<code>sr0.type_dependent();</code>。由于_member的类型与template参数有关，故此处由“scope of the template instantiation”来决议。</p>

<h3 id="section-8">执行期类型识别</h3>

<p><code>dynamic_cast</code>运算符可以在执行期决定真正的类型。如果downcast是安全的（也就是说，一个base type pointer指向一个derived class object），这个运算符会传回被适当转型过的指针；如果downcast不是安全的，这个运算符会传回0。</p>

<pre><code>typedef type *ptype;
typedef fct *pfct;

simplify_conv_op(ptype pt)
{
	if(pfct pf = dynamic_cast&lt;pfct&gt;(pt)) {
	...
	}
	else { ... }
}
</code></pre>

<p>什么是<code>dynamic_cast</code>的真正成本？<code>pfct</code>的一个类型描述器会被编译器产生出来，由<code>pt</code>指向之class object类型描述器必须在执行期通过vptr取得。下面是可能的转换：</p>

<pre><code>// 取得pt的类型描述器
((type_info*)(pt-&gt;vptr[0]))-&gt;_type_description;
</code></pre>

<p>其中，<code>type_info</code>是C++ Standard所定义的类型描述器的class名称，该class中放置着待索求的类型信息。virtual table的第一个slot内含<code>type_info</code> object的地址，此<code>type_info</code> object与pt所指之class type有关。</p>

<p><code>dynamic_cast</code>运算符也适用于reference身上，然而对于一个non-type-safe-cast，其结果不会与施行于指针的情况一样。一个reference不可以像指针那样“把自己设为0便代表了no object”；若将一个reference设为0，会引起一个临时性对象（拥有被参考到的类型）被产生出来，该临时对象的初值为0，这个reference然后被设定为该临时变量的一个别名。</p>

<p>因而，如果reference并不真正是某一种derived class，那么可通过丢出一个<code>bad_cast exception</code>进行处理：</p>

<pre><code>simplify_conv_op(const type &amp;rt)
{
	try {
		fct &amp;rf = dynamic_cast&lt;fct&amp;&gt;(rt);
	}
	catch(bad cast) {
		// ...
	}
}
</code></pre>

<p>当然，你也可以使用typeid运算符来达到同样的目的：</p>

<pre><code>simplify_conv_op(const type &amp;rt)
{
	if(typeid(rt) == typeid(fct))
	{
		fct &amp;rf = dynamic_cast&lt;fct&amp;&gt;(rt);
	}
	else { ... }
}
</code></pre>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ string copy-on-write]]></title>
    <link href="http://billowkiller.github.io/blog/2014/03/12/c%2B%2B-string-copy-on-write/"/>
    <updated>2014-03-12T02:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/03/12/c++-string-copy-on-write</id>
    <content type="html"><![CDATA[<p>不同版本的C++ string实现时不同的，sizeof(string)得出来的结果也不尽相同，其中有种实现采用copy-on-write的方式来共享内存。</p>

<p>引用计数就是string类中写时才拷贝的原理！当第一个类构造时，string的构造函数会根据 传入的参数从堆上分配内存，当有其它类需要这块内存时，这个计数为自动累加，当有类析构时，这个计数会减一，直到最后一个类析构时，此时的RefCnt为1或是0，此时，程序才会真正的Free这块从堆上分配的内存。</p>

<p>string类的内存是在堆上动态分配的，共享内存的各个类指向的是同一个内存区。这块内存区域还包括引用计数，其位于字符串内存区域的上方，通过<code>_Ptr[-1]</code>来访问。这样所有共享这块内存的类都可以访问到引用计数，也就知道这块内存的引用者有多少了。</p>

<p>于是，有了这样一个机制，每当我们为string分配内存时，我们总是要多分配一个空间用来存放这个引用计数的值，只要发生拷贝构造可是赋值时，这个内存的值就会加一。而在内容修改时，string类为查看这个引用计数是否为0，如果不为零，表示有人在共享这块内存，那么自己需要先做一份拷贝，然后把引用计数减去一，再把数据拷贝过来。</p>

<!--more-->
<p>具体做法如下：</p>

<pre><code>//构造函数（分存内存）
string::string(const char* tmp)
{
	_Len = strlen(tmp);
	_Ptr = new char[_Len+1+1];
	strcpy( _Ptr, tmp );
	_Ptr[-1]=0;  // 设置引用计数  
}

//拷贝构造（共享内存）
string::string(const string&amp; str)
{
	if (*this != str){
	this-&gt;_Ptr = str.c_str();   //共享内存
	this-&gt;_Len = str.szie();
	this-&gt;_Ptr[-1] ++;  //引用计数加一
}

//写时才拷贝Copy-On-Write
char&amp; string::operator[](unsigned int idx)
{
	if (idx &gt; _Len || _Ptr == 0 ) {
		static char nullchar = 0;
		return nullchar;
	}

	_Ptr[-1]--;   //引用计数减一
	char* tmp = new char[_Len+1+1];
	strncpy( tmp, _Ptr, _Len+1);
	_Ptr = tmp;
	_Ptr[-1]=0; // 设置新的共享内存的引用计数
	
	return _Ptr[idx];
}


//析构函数的一些处理
~string()
{ 
	_Ptr[_Len+1]--;   //引用计数减一
	// 引用计数为0时，释放内存
	if (_Ptr[_Len+1]==0) {
		delete[] _Ptr;
	}
}
</code></pre>

<p>但这样的方式也会造成一些麻烦。容易造成内存访问异常。
<strong>两个例子：</strong></p>

<h3 id="section">动态库</h3>
<p>动态链接库中有一个函数返回string类：</p>

<pre><code>string GetIPAddress(string hostname)
{
	static string ip;
	……
	return ip;
}
</code></pre>

<p>主程序中动态地载入这个动态链接库，并调用其中的这个函数：</p>

<pre><code>main()
{
	//载入动态链接库中的函数
	void(*pTest)();
	void*pdlHandle = dlopen("libtest.so", RTLD_LAZY);   
	pTest = dlsym(pdlHandle, "GetIPAddress");
	//调用动态链接库中的函数
	string ip = (*pTest)(“host1”);
	……
	//释放动态链接库
	 dlclose(pdlHandle);
	……
	cout &lt;&lt; ip &lt;&lt; endl;
}
</code></pre>

<p>当主程序释放了动态链接库后，那个共享的内存区也随之释放。所以，以后对ip的访问，必然做造成内存地址访问非法，造成程序crash。即使你在以后没有使用到ip这个变量，那么在主程序退出时也会发生内存访问异常，因为程序退出时，ip会析构，在析构时就会发生内存访问异常。</p>

<h3 id="section-1">多线程</h3>

<p>在多线程中，对于多线程来说，引用计数就是一个全局变量。指向同一个buffer的多个string的引用计数有可能变得混乱，从而导致delete异常。尤其是在.h中定义const string A = “XXXX”， 如果多个对象都引用了A，则可能在多线程中出现问题。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[C++ inline]]></title>
    <link href="http://billowkiller.github.io/blog/2014/02/16/c%2B%2B-inline/"/>
    <updated>2014-02-16T09:18:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2014/02/16/c++-inline</id>
    <content type="html"><![CDATA[<p><code>inline</code>定义的函数，比起没有<code>inline</code>的函数来说，没有执行函数调用所带来的负担，因此它是高效率的；比起宏来，它具有<strong>函数的可预期行为和参数类型检验</strong>。</p>

<p><code>inline</code>对于编译器而言，意味着“在编译阶段，将调用动作以被调用函数的本体替换之”。但是它只是一种建议，编译器可以去做，也可以不去做。从逻辑上来说，编译器将函数<code>inline</code>的步骤如下：</p>

<ol>
  <li>将<code>inline</code>函数体复制到<code>inline</code>函数调用点处；</li>
  <li>为所用<code>inline</code>函数中的局部变量分配内存；</li>
  <li>将<code>inline</code>函数的的输入参数和返回值映射到调用方法的局部变量空间中；</li>
  <li>如果<code>inline</code>函数有多个返回点，将其转变为<code>inline</code>函数代码块末尾的分支（使用GOTO）。</li>
</ol>

<p><code>inline</code>函数的缺点有哪些呢？</p>

<ol>
  <li><strong>代码膨胀。</strong>如果<code>inline</code>函数体过大且编译器还让它<code>inline</code>成功，那么你最终的程序会代码膨胀，从而造成设备缓冲命中率低，引起较多的页面错误，读写硬盘的次数增多，这样程序的性能就下降了！建议：<strong><code>inline</code>函数体一般不要超过5行，不包括循环，不包括递归调用。</strong></li>
  <li><strong><code>inline</code>函数内部不要有static变量。</strong><code>inline</code>函数的定义几乎总是放在头文件（.h）里，这允许多个实现文件（.cpp）得以引用。我们知道编译器是分别编译的，所以这个时候，在多个实现文件里就会有多个<code>inline</code>函数的展开，也就是说有个多个static变量，这恐怕不是我们期望的！</li>
  <li><strong><code>inline</code>函数无法随着函数库升级而升级。</strong>如果f是函数库中的一个<code>inline</code>函数，使用它的用户会将f函数实体编译到他们的程序中。一旦函数库实现者改变f，所有用到f的程序都必须重新编译。如果f是non-<code>inline</code>的，用户程序只需重新连接即可。如果函数库采用的是动态连接，那这一升级的f函数可以不知不觉的被程序使用。</li>
  <li><strong>不要获取<code>inline</code>函数的地址。</strong>如果要取得一个<code>inline</code>函数的地址，编译器就必须为此函数产生一个函数实体，无论如何，编译器无法交出一个“不存在函数”的指针。注意，有些编译器可能会使用类的constructors和destructors的函数指针，用以构造和析构一个class对象的数组。另外类的constructors和destructors可能简单，但是其父类的类的constructors和destructors可能是复杂的，所以<strong>类的constructors和destructors往往不是<code>inline</code>函数的最佳选择</strong>！</li>
  <li><strong><code>inline</code>虚函数往往是无效的。</strong>虚函数往往是运行时确定的，而<code>inline</code>是在编译时进行的，所以<code>inline</code>虚函数往往无效。当然如果直接用类的对象来使用虚函数，那么对有的编译器而言，也可起到优化的作用。</li>
  <li><strong><code>inline</code>函数无法调试。</strong>原因请参见上面编译器将函数<code>inline</code>的步骤。所以请在项目后期，<strong>对程序进行profile后，再决定将那些函数<code>inline</code>化。</strong></li>
</ol>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Large site technical architecture]]></title>
    <link href="http://billowkiller.github.io/blog/2013/12/31/large-site-technical-architecture/"/>
    <updated>2013-12-31T18:09:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/12/31/large-site-technical-architecture</id>
    <content type="html"><![CDATA[<p>本文是李智慧的<a href="http://book.douban.com/subject/25723064/">《大型网站技术架构》</a>的读书笔记。</p>

<p>何为架构，要有大局观，大局观就是提前预防掉那些通用的问题：高可用，工程化，伸缩性，扩展性。对应需要的能力：了解分布式的一些东西，了解项目的业务和流程和运维使之工程化，了解负载均衡，能够对业务的分割和代码的分层。 </p>

<p><img src="http://img3.douban.com/lpic/s27040583.jpg" height="250px" /></p>

<p>本书并没有什么特别的东西，且都比较泛，但是都是很实在的东西，而且能很好的组织起来，也不失为互联网架构的一张蓝图。另外本书还处处透露着一些为人处世的人生哲学，这也是我喜欢的。</p>

<!--more-->

<p>下面就先从目录部分总结勾勒一下蓝图，然后再摘抄一些自己喜欢的句子。</p>

<h2 id="section">蓝图部分</h2>

<ul>
  <li><strong>大型网站架构演化发展历程</strong>
    <ul>
      <li>初始阶段的网站架构
        <ul>
          <li>应用程序、数据库、文件等所有资源都在一台服务器上</li>
        </ul>
      </li>
      <li>应用服务和数据服务分离 </li>
      <li>使用缓存改善网站性能</li>
      <li>使用应用服务器集群改善网站的并发处理能力</li>
      <li>数据库读写分离</li>
      <li>使用反向代理和CDN加速网站响应	</li>
      <li>使用分布式文件系统和分布式数据库系统</li>
      <li>使用NoSQL和搜索引擎</li>
      <li>业务拆分</li>
      <li>分布式服务</li>
    </ul>
  </li>
  <li>
    <p><strong>网站架构模式</strong></p>

    <blockquote>
      <p>关于什么是模式，这个来自建筑学的词汇是这样定义的：“每一个模式描述了一个在我们周围不断重复发生的问题及该问题解决方案的核心。这样，你就能一次又一次地使用该方案而不必做重复工作”。模式的关键在于<strong>模式的可重复性</strong>，问题与场景的可重复性带来解决方案的可重复使用。
 - 分层
     - 将系统在横向维度上切分成几个部分，每个部分负责一部分相对比较单一的职责，然后通过上层对下层的依赖和调用组成一个完整的系统	 
 - 分割
     - 如果说分层是将软件在横向方面进行切分，那么分割就是在纵向方面对软件进行切分 
 - 分布式
     - 分层和分割的一个主要目的是为了切分后的模块便于分布式部署，即将不同模块部署在不同的服务器上，通过远程调用协同工作。 
 -  集群
 - 缓存
     - CDN、反向代理、本地缓存、分布式缓存
     - 28原理 
 -  异步
     - 降低软件耦合性<br />
 -  冗余，自动化，安全</p>
    </blockquote>
  </li>
  <li>大型网站核心架构要素
    <ul>
      <li>性能，可用性，伸缩性，扩展性，安全性</li>
    </ul>
  </li>
</ul>

<h3 id="section-1">网站的高性能架构</h3>
<ul>
  <li>网站性能测试
    <ul>
      <li>不同视角下的网站性能</li>
      <li>性能测试指标
        <ul>
          <li>响应时间、并发数、吞吐量、性能计数器（服务器或操作系统的一些数据指标）  </li>
        </ul>
      </li>
      <li>性能测试方法
        <ul>
          <li>性能测试、负载测试、压力测试、稳定性测试 </li>
        </ul>
      </li>
      <li>性能测试报告</li>
      <li>性能优化策略</li>
    </ul>
  </li>
  <li>Web前端性能优化
    <ul>
      <li>浏览器访问优化
        <ul>
          <li>减少http请求（合并请求）、使用浏览器缓存、压缩数据、CSS和JS顺序 </li>
        </ul>
      </li>
      <li>CDN加速 </li>
      <li>反向代理</li>
    </ul>
  </li>
  <li>应用服务器性能优化	
    <ul>
      <li>分布式缓存
        <ul>
          <li><strong>网站性能优化第一定律：优先考虑使用缓存优化性能</strong> </li>
          <li>缓存的本质是一个内存Hash表</li>
          <li>合理使用缓存：数据的读写比在2:1以上；数据不一致与脏读（应用要容忍一定时间的数据不一致）；缓存雪崩；缓存预热；缓存穿透</li>
          <li>架构方式有两种，一种是以<code>JBoss Cache</code>为代表的需要更新同步的分布式缓存，一种是以<code>Memcached</code>为代表的不互相通信的分布式缓存</li>
        </ul>
      </li>
      <li>异步操作
        <ul>
          <li>消息队列具有很好的消峰作用</li>
          <li>业务异步处理时候可能需要业务流程配合</li>
          <li><strong>任何可以晚点做的事情都应该晚点再做</strong> </li>
        </ul>
      </li>
      <li>使用集群</li>
      <li>代码优化
        <ul>
          <li>多线程，线程安全手段：将对象设计为无状态对象；使用局部对象；并发访问使用锁</li>
          <li>资源复用：单例模式和对象池</li>
          <li>数据结构</li>
          <li>垃圾回收 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>存储性能优化
    <ul>
      <li>机械硬盘vs. 固态硬盘</li>
      <li>B+树vs. LSM树</li>
    </ul>

    <p><img src="http://img1.tuicool.com/NbeUnm.jpg" alt="LSM树" />
  - RAID vs. HDFS</p>

    <p><img src="http://www.2cto.com/uploadfile/2013/1016/20131016045031342.jpg" alt="常用的RAID技术原理图" /></p>
  </li>
</ul>

<h3 id="section-2">网站的高可用架构</h3>

<ul>
  <li>高可用的应用	
    <ul>
      <li>通过负载均衡进行无状态服务的失效转移	</li>
      <li>应用服务器集群的Session管理	
        <ul>
          <li>Session复制</li>
          <li>Session绑定</li>
          <li>利用Cookie记录Session</li>
          <li>Session服务器 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>高可用的服务
    <ul>
      <li>分级管理，核心应用和服务优先使用更好的硬件</li>
      <li>超时设置</li>
      <li>异步调用，避免一个服务失败导致整个应用请求失败</li>
      <li>服务降级：拒绝服务和关闭服务</li>
      <li>幂等性设计 	</li>
    </ul>
  </li>
  <li>高可用的数据	
    <ul>
      <li><code>CAP</code>原理
        <ul>
          <li>在设计和部署分布式应用的时候，存在三个核心的系统需求，这个三个需求之间存在一定的特殊关系。三个需求如下：<code>Consistency</code>所有程序都能访问得到相同的数据; <code>Availability</code>任何时候，任何应用程序都可以读写访问; <code>Partition Tolerance</code>系统可以跨网络分区线性伸缩。</li>
          <li><code>CAP</code>理论的核心是：一个分布式系统不可能同时很好的满足一致性，可用性和分区容错性这三个需求，最多只能同时较好的满足两个。</li>
          <li>大型网站设计中，通常选择强化分布式存储系统的可用性(A)和伸缩性(P)，而在某种程度放弃一致性(C)
  <img src="http://hi.csdn.net/attachment/201109/6/0_1315316512jhTH.gif" alt="" /></li>
        </ul>
      </li>
      <li>数据备份
        <ul>
          <li>异步热备：写一份，存储系统异步写其他副本。Master-Slave</li>
          <li>同步热备：多份副本同步写入。传统的企业级关系数据库</li>
        </ul>
      </li>
      <li>失效转移
        <ul>
          <li>失效确认、访问转移、数据恢复 	</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>高可用网站的软件质量保证	
    <ul>
      <li>网站发布	</li>
      <li>自动化测试	</li>
      <li>预发布验证	</li>
      <li>代码控制
        <ul>
          <li>主干开发、分支发布</li>
          <li>分支开发、主干发布 	</li>
        </ul>
      </li>
      <li>自动化发布	</li>
      <li>灰度发布	</li>
    </ul>
  </li>
  <li>网站运行监控	
    <ul>
      <li>监控数据采集
        <ul>
          <li>用户行为日志收集，服务器端和客户端</li>
          <li>服务器性能监控</li>
          <li>运行数据报告，缓冲命中、平均响应延迟时间、每分钟发送邮件数目… </li>
        </ul>
      </li>
      <li>监控管理
        <ul>
          <li>系统报警，失效转移，自动降级 </li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h3 id="section-3">网站的伸缩性架构</h3>

<blockquote>
  <p>所谓<strong>网站的伸缩性</strong>是指不需要改变网站的软硬件设计，仅仅通过改变部署的服务器数量就可以扩大或缩小网站的服务处理能力。</p>
</blockquote>

<ul>
  <li>网站架构的伸缩性设计
    <ul>
      <li>不同功能进行物理分离实现伸缩
        <ul>
          <li>纵向分离（分层后分离）：将业务处理流程上的不同部分分离部署，实现系统伸缩性。</li>
          <li>横向分离（业务分割后分离）：将不同的业务模块分离部署，实现系统伸缩性。 </li>
        </ul>
      </li>
      <li>单一功能通过集群规模实现伸缩
        <ul>
          <li>应用服务器集群伸缩性、数据服务器集群伸缩性 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>应用服务器集群的伸缩性设计
    <ul>
      <li>HTTP重定向负载均衡</li>
      <li>DNS域名解析负载均衡	</li>
      <li>反向代理负载均衡</li>
      <li>IP负载均衡	</li>
      <li>数据链路层负载均衡
        <ul>
          <li>虚拟IP、LVS </li>
        </ul>
      </li>
      <li>负载均衡算法
        <ul>
          <li>轮询、加权轮询、随机、最少连接、源地址散列 </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>分布式缓存集群的伸缩性设计
    <ul>
      <li>Memcached分布式缓存集群的访问模型
  <img src="http://blog.chinaunix.net/attachment/201211/20/27767798_1353432372hzgp.png" alt="" /> 
  Memcached依赖于libevent，网络模型是典型的reactor模式，主线程通过自己的<code>event_base</code>绑定端口监听网络中的连接。每个worker线程的初始任务就是轮询管道上的<code>notify_receive_fd</code>的读事件，如果有连接，主线程往相应的worker线程的管道的输入端<code>notify_send_fd</code>写入关键字‘c’，代表着网络上有新的连接要派发给worker线程，这样worker进程直接accept就能得到连接的fd了，同时把这个fd的读事件放到每个worker进程的<code>event_base</code>中，如图，每个worker的进程同时监听<code>notify_receive_fd</code>和外部连接的fd上的事件。每个worker都应该为连接上的fd分配一个conn结构体，这个结构体记录了这个连接全部的信息，如连接的fd，读写buf，操作的item，当前connection的状态等等。</li>
      <li>Memcached分布式缓存集群的伸缩性挑战
        <ul>
          <li>数据库的负载能力是以有缓存的前提而设计的，当大部分被缓存的数据因为服务器扩容而不能正确读取时，这些数据访问的压力就落到数据库身上，超过数据库负载能力，造成数据库宕机。</li>
        </ul>
      </li>
      <li>分布式缓存的一致性Hash算法</li>
    </ul>
  </li>
  <li>数据存储服务器集群的伸缩性设计
    <ul>
      <li>关系数据库集群的伸缩性设计</li>
      <li>NoSQL数据库的伸缩性设计</li>
    </ul>
  </li>
</ul>

<h3 id="section-4">网站的可扩展架构</h3>

<ul>
  <li>构建可扩展的网站架构
    <ul>
      <li>扩展性是对功能而言，应用之间较少依赖和耦合，对需求可以敏捷响应。</li>
      <li>伸缩性是以资源的规模换取处理事务的能力，更多表现在服务器数量，事务吞吐能力。</li>
      <li>设计网站可扩展性的核心是<strong>模块化</strong>，并在此基础上，减低模块间的耦合性，提高模块的复用性。	 </li>
    </ul>
  </li>
  <li>利用分布式消息队列降低系统耦合性
    <ul>
      <li>事件驱动架构</li>
      <li>分布式消息队列</li>
    </ul>
  </li>
  <li>利用分布式服务打造可复用的业务平台
    <ul>
      <li>Web Service与企业级分布式服务</li>
      <li>大型网站分布式服务的需求与特点
        <ul>
          <li>负载均衡、失效转移、高效的远程通信、整合异构系统、对应用最少侵入、版本管理、实时监控 </li>
        </ul>
      </li>
      <li>分布式服务框架设计</li>
    </ul>
  </li>
  <li>可扩展的数据结构</li>
  <li>利用开放平台建设网站生态圈</li>
</ul>

<h2 id="section-5">摘抄与处事哲学</h2>

<p>创新的业务发展模式对网站架构逐步提出更高要求，才使得创新的网站架构得以发展成熟。是业务成就了技术，是事业成就了人，而不是相反。所以网站架构师应该对成就自己技术成绩的网站事业心存感恩，并努力提高技术回馈业务，才能在快速发展的胡两位领域保持持续进步。</p>

<p>网站架构的几个设计误区</p>

<ul>
  <li>以为追随大公司的解决方案</li>
  <li>为了技术而技术</li>
  <li>企图用技术解决所有问题</li>
</ul>

<p>前沿技术总是出现在前沿业务领域。近几年，以Google为首的互联网企业领跑IT前沿技术潮流，是因为互联网企业的业务发展远超传统IT企业领域，面了更多挑战，对IT系统提出了更高的要求；新技术的出现又会驱动企业开展新的业务。亚马逊等互联网公司利用自己的技术优势进军企业级市场，以技术驱动业务，开展云计算、SaaS等新兴IT业务，逐步蚕食IBM、HP、Oracle、微软等传统软件巨头的市场。</p>

<p>好的设计绝对不是模仿、不是生搬硬套某个模式，而是在对问题深刻理解之上的创造与创新，即使是‘微创新’，也是让人耳目一新的似曾相识。山寨与创新的最大区别不在于是否抄袭、是否模仿，而在于对问题和需求是否真正理解与把握。</p>

<p>一个具有良好伸缩性架构设计的网站，其设计总是走在业务发展的前面，在业务需要处理更多访问和服务之前，就做好充足准备，当业务需要是时候，只需要购买或租用服务器简单部署实施就可以了，技术团队亦可以高枕无忧。反之，设计和技术走在业务的后面，采购来的机器根本就没有方法加入集群，勉强加了进去，却发现瓶颈不在这里，系统整体处理能力依然上不去。技术团队每天加班，却总是托公司发展的后退。架构师对网站伸缩性的把握，一线之间，天堂与地狱。</p>

<p>高手定律：这个世界只有遇不到的问题，没有解决不了的问题，高手之所以成为高手，是因为他们遇到了常人很难遇到的问题，并解决了。所以百度有很多广告搜索高手，淘宝有很多海量数据高手，腾讯有很多高并发业务的高手。</p>

<p>WikiPedia如果Master数据库宕机，立即将应用切换到Salve数据库，同时关闭数据写服务，意味着词条编辑功能关闭。WidiPedia通过约束业务获得更大的技术方案选择余地，很多时候业务后退一小步，技术就可以前进一大步。这个也是他们能够那么省钱的原因啊。</p>

<p>秒杀从根本上来讲并不是很难，首先是页面的静态化，开始秒杀的按钮通过js来实现，js不缓存，js尽量小。开始秒杀的时候使用可以秒杀的js。秒杀很少能达数据层，因为就那么几个能成功。主要的压力在应用服务器，但是用一个记数服务器，收到请求更新这个数字，大于数字的直接返回秒杀失败。所以大部分都会进入失败的逻辑，整个也很简单。只要业务服务器能抗住这些访问压力就基本ok了，如果业务服务器不够，可以直接在负载均衡那边随机失败一部分。 </p>

<hr />

<p>是事情成就了人，而不是人成就了事。</p>

<p>要想成就自己，就必须首先成就他人。我们工作不只是生成产品，还要成就人，并最终成就我们自己。关注人而不是产品。</p>

<p>学会妥协。很多时候，对架构和技术方案的反对意见，其实意味着架构和技术方案被关注、被试图理解和接受。架构师不应该对意见过于敏感，这时架构师应该做的事坦率地分享自己的设计思路，让别人理解自己的想法并努力理解别人的想法，求同存异。</p>

<p>新员工Tips</p>

<ul>
  <li>刚开始加入的时候不要急于证明自己，要先融入</li>
</ul>

<p>提出问题Tips</p>

<ul>
  <li>把“我的问题”表述成“我们的问题”</li>
  <li>给上司提出封闭式问题，给下属提出开放式问题</li>
  <li>指出问题而不是批评人，所谓直言有讳是指想要表达的意图要直截了当说明白，不要兜圈子，但是在表达方式上要有所避讳，照顾当事人的感受</li>
  <li>用赞同的方式提出问题</li>
</ul>

<p>解决问题Tips</p>

<ul>
  <li>在解决我的问题之前，先解决你的问题</li>
  <li>适当的逃避问题</li>
</ul>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[gcc summary]]></title>
    <link href="http://billowkiller.github.io/blog/2013/12/31/gcc-summary/"/>
    <updated>2013-12-31T18:07:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2013/12/31/gcc-summary</id>
    <content type="html"><![CDATA[<p>本文介绍在Linux平台下应用程序的编译过程，以及编译程序<a href="http://gcc.gnu.org/">GCC</a>在编译应用程序的过程的具体用法，同时详细说明了GCC的常用选项、模式和警告选项。</p>

<p><img src="https://encrypted-tbn2.gstatic.com/images?q=tbn:ANd9GcQkcpI6uyaKSbXltFKcLfpuPyMjC8aw-VZH7x9uUt8bFQMTpsczYg" alt="gcc" /></p>

<!--more-->

<h3 id="compile-process">Compile Process</h3>

<h4 id="four-steps">Four Steps</h4>

<p>对于GUN编译器来说，程序的编译要经历预处理、编译、汇编、连接四个阶段.</p>

<center>![四个阶段](http://new.51cto.com/files/uploadimg/20060926/1714230.jpg)</center>

<p>从功能上分，预处理、编译、汇编是三个不同的阶段，但<code>gcc</code>的实际操作上，它可以把这三个步骤合并为一个步骤来执行。下面我们以C语言为例来谈一下不同阶段的输入和输出情况。</p>

<p>在预处理阶段，输入的是C语言的源文件，通常为<code>*.c</code>。它们通常带有<code>.h</code>之类头文件的包含文件。这个阶段主要处理源文件中的<code>#ifdef</code>、 <code>#include</code>和<code>#define</code>命令。该阶段会生成一个中间文件<code>*.i</code>，但实际工作中通常不用专门生成这种文件，因为基本上用不到；若非要生成这种文件不可，可以利用下面的示例命令：</p>

<pre><code>gcc -E  test.c -o test.i
</code></pre>

<p>在编译阶段，输入的是中间文件<code>*.i</code>，编译后生成汇编语言文件<code>*.s</code> 。这个阶段对应的<code>gcc</code>命令如下所示：</p>

<pre><code>gcc -S test.i -o test.s 
</code></pre>

<p>在汇编阶段，将输入的汇编文件<code>*.s</code>转换成机器语言<code>*.o</code>。这个阶段对应的<code>gcc</code>命令如下所示：</p>

<pre><code>gcc -c test.s -o test.o 
</code></pre>

<p>最后，在连接阶段将输入的机器代码文件<code>*.s</code>（与其它的机器代码文件和库文件）汇集成一个可执行的二进制代码文件。这一步骤，可以利用下面的示例命令完成：</p>

<pre><code>gcc test.o -o test 
</code></pre>

<h4 id="two-modes">Two Modes</h4>

<p>gcc常用的两种模式：编译模式和编译连接模式。下面以一个例子来说明各种模式的使用方法。为简单起见，假设我们全部的源代码都在一个文件<code>test.c</code>中，要想把这个源文件直接编译成可执行程序，可以使用以下命令：</p>

<pre><code>gcc test.c -o test
</code></pre>

<p>这里<code>test.c</code>是源文件，生成的可执行代码存放在一个名为<code>test</code>的文件中（该文件是机器代码并且可执行）。<code>-o</code>是生成可执行文件的输出选项。如果我们只想让源文件生成目标文件（给文件虽然也是机器代码但不可执行），可以使用标记<code>-c</code>，详细命令如下所示：</p>

<pre><code>gcc -c test.c
</code></pre>

<p>默认情况下，生成的目标文件被命名为<code>test.o</code>，但我们也可以为输出文件指定名称，如下所示：</p>

<pre><code>gcc -c test.c -o mytest.o
</code></pre>

<p>上面这条命令将编译后的目标文件命名为<code>mytest.o</code>，而不是默认的<code>test.o</code>。</p>

<p>迄今为止，我们谈论的程序仅涉及到一个源文件；现实中，一个程序的源代码通常包含在多个源文件之中，这该怎么办？没关系，即使这样，用gcc处理起来也并不复杂，见下例：</p>

<pre><code>gcc -o test  first.c second.c third.c
</code></pre>

<p>该命令将同时编译三个源文件，即<code>first.c</code>、<code>second.c</code>和 <code>third.c</code>，然后将它们连接成一个可执行程序，名为<code>test</code>。</p>

<h3 id="compile-option">Compile Option</h3>

<h4 id="debug">Debug</h4>
<p>在<code>gcc</code>编译源代码时指定<code>-g</code>选项可以产生带有调试信息的目标代码,<code>gcc</code>可以为多个不同平台上帝不同调试器提供调试信息,默认<code>gcc</code>产生的调试信息是为<code>gdb</code>使用的,可以使用<code>-gformat</code>指定要生成的调试信息的格式以提供给其他平台的其他调试器使用.</p>

<p>常用的格式有 </p>

<ul>
  <li>-ggdb:生成gdb专 用的调试信息,使用最适合的格式(DWARF 2,stabs等)会有一些gdb专用的扩展,可能造成其他调试器无法运行. </li>
  <li>-gstabs:使用 stabs格式,不包含gdb扩展,stabs常用于BSD系统的DBX调试器. </li>
  <li>-gcoff:产生COFF格式的调试信息,常用于System V下的SDB调试器; </li>
  <li>-gxcoff:产生XCOFF格式的调试信息,用于IBM的RS/6000下的DBX调试器; </li>
  <li>-gdwarf-2:产生DWARF version2 的格式的调试信息,常用于IRIXX6上的DBX调试器.<code>gcc</code>会使用DWARF version3的一些特性. </li>
</ul>

<h4 id="common-option">Common Option</h4>

<p>–help&lt;/br&gt;
–target-help &lt;/br&gt;
显示 <code>gcc</code> 帮助说明。‘target-help’是显示目标机器特定的命令行选项。</p>

<p>–version &lt;/br&gt;
显示 <code>gcc</code> 版本号和版权信息 。</p>

<p>-o outfile &lt;/br&gt;
输出到指定的文件。</p>

<p>-x language &lt;/br&gt;
指明使用的编程语言。允许的语言包括：c c++ assembler none 。 ‘none’意味着恢复默认行为，即根据文件的扩展名猜测源文件的语言。</p>

<p>-v &lt;/br&gt;
打印较多信息，显示编译器调用的程序。</p>

<p>-### &lt;/br&gt;
与 -v 类似，但选项被引号括住，并且不执行命令。</p>

<p><strong>-E</strong>&lt;/br&gt;
仅作预处理，不进行编译、汇编和链接。如上图所示。</p>

<p>-S &lt;/br&gt;
仅编译到汇编语言，不进行汇编和链接。如上图所示。</p>

<p><strong>-c</strong> &lt;/br&gt;
编译、汇编到目标代码，不进行链接。如上图所示。</p>

<p>-pipe &lt;/br&gt;
使用管道代替临时文件。</p>

<p>-combine &lt;/br&gt;
将多个源文件一次性传递给汇编器。</p>

<h4 id="other-option">Other Option</h4>

<p>更多有用的<code>gcc</code>选项：</p>

<p>-l library&lt;/br&gt;
-llibrary &lt;/br&gt;
进行链接时搜索名为library的库。 &lt;/br&gt;
例子： $ <code>gcc</code> test.c -lm -o test</p>

<p>-Idir &lt;/br&gt;
把dir 加入到搜索头文件的路径列表中。 &lt;/br&gt;
例子： $ <code>gcc</code> test.c -I../inc -o test</p>

<p>-Ldir &lt;/br&gt;
把dir 加入到搜索库文件的路径列表中。 &lt;/br&gt;
例子： $ <code>gcc</code> -I/home/foo -L/home/foo -ltest test.c -o test</p>

<p>-Dname &lt;/br&gt;
预定义一个名为name 的宏，值为1。 &lt;/br&gt;
例子： $ <code>gcc</code> -DTEST_CONFIG test.c -o test</p>

<p>-Dname =definition &lt;/br&gt;
预定义名为name ，值为definition 的宏。</p>

<p>-ggdb &lt;/br&gt;
-ggdblevel &lt;/br&gt;
为调试器 gdb 生成调试信息。level 可以为1，2，3，默认值为2。</p>

<p>-g &lt;/br&gt;
-glevel &lt;/br&gt;
生成操作系统本地格式的调试信息。-g 和 -ggdb 并不太相同， -g 会生成 gdb 之外的信息。level 取值同上。</p>

<p>-s &lt;/br&gt;
去除可执行文件中的符号表和重定位信息。用于减小可执行文件的大小。</p>

<p>-M &lt;/br&gt;
告诉预处理器输出一个适合make的规则，用于描述各目标文件的依赖关系。对于每个 源文件，预处理器输出 一个make规则，该规则的目标项(target)是源文件对应的目标文件名，依赖项(dependency)是源文件中<code>#include</code>引用的所有文件。生成的规则可以是单行，但如果太长，就用<code>\</code>-换行符续成多行。规则 显示在标准输出，不产生预处理过的C程序。</p>

<p>-C &lt;/br&gt;
告诉预处理器不要丢弃注释。配合`-E’选项使用。</p>

<p>-P &lt;/br&gt;
告诉预处理器不要产生<code>#line</code>命令。配合<code>-E</code>选项使用。</p>

<p>-static &lt;/br&gt;
在支持动态链接的系统上，阻止连接共享库。该选项在其它系统上无效。</p>

<p>-nostdlib&lt;/br&gt; 
不连接系统标准启动文件和标准库文件，只把指定的文件传递给连接器。</p>

<h4 id="warnings-option">Warnings Option</h4>

<p>-Wall &lt;/br&gt;
会打开一些很有用的警告选项，建议编译时加此选项。</p>

<p>-W &lt;/br&gt;
-Wextra&lt;/br&gt; 
打印一些额外的警告信息。</p>

<p>-w &lt;/br&gt;
禁止显示所有警告信息。</p>

<p>-Wshadow &lt;/br&gt;
当一个局部变量遮盖住了另一个局部变量，或者全局变量时，给出警告。很有用的选项，建议打开。 -Wall 并不会打开此项。</p>

<p>-Wpointer-arith &lt;/br&gt;
对函数指针或者void *类型的指针进行算术操作时给出警告。也很有用。 -Wall 并不会打开此项。</p>

<p>-Wcast-qual &lt;/br&gt;
当强制转化丢掉了类型修饰符时给出警告。 -Wall 并不会打开此项。</p>

<p>-Waggregate-return &lt;/br&gt;
如果定义或调用了返回结构体或联合体的函数，编译器就发出警告。</p>

<p>-Winline &lt;/br&gt;
无论是声明为 inline 或者是指定了-finline-functions 选项，如果某函数不能内联，编译器都将发出警告。如果你的代码含有很多 inline 函数的话，这是很有用的选项。</p>

<p>-Werror &lt;/br&gt;
把警告当作错误。出现任何警告就放弃编译。</p>

<p>-Wunreachable-code&lt;/br&gt; 
如果编译器探测到永远不会执行到的代码，就给出警告。也是比较有用的选项。</p>

<p>-Wcast-align&lt;/br&gt; 
一旦某个指针类型强制转换导致目标所需的地址对齐增加时，编译器就发出警告。</p>

<p>-Wundef&lt;/br&gt;
当一个没有定义的符号出现在 #if 中时，给出警告。</p>

<p>-Wredundant-decls&lt;/br&gt; 
如果在同一个可见域内某定义多次声明，编译器就发出警告，即使这些重复声明有效并且毫无差别。</p>

<h4 id="standard">Standard</h4>

<p>-ansi &lt;/br&gt;
支持符合ANSI标准的C程序。这样就会关闭GNU C中某些不兼容ANSI C的特性。</p>

<p>-std=c89 &lt;/br&gt;
-iso9899:1990 &lt;/br&gt;
指明使用标准 ISO C90 作为标准来编译程序。</p>

<p>-std=c99 &lt;/br&gt;
-std=iso9899:1999 &lt;/br&gt;
指明使用标准 ISO C99 作为标准来编译程序。</p>

<p>-std=c++98 &lt;/br&gt;
指明使用标准 C++98 作为标准来编译程序。</p>

<p>-std=gnu9x &lt;/br&gt;
-std=gnu99 &lt;/br&gt;
使用 ISO C99 再加上 GNU 的一些扩展。</p>

<p>-fno-asm &lt;/br&gt;
不把asm, inline或typeof当作关键字，因此这些词可以用做标识符。用 <strong>asm</strong>， __inline__和__typeof__能够替代它们。 <code>-ansi</code> 隐含声明了<code>-fno-asm</code>。</p>

<p>-fgnu89-inline &lt;/br&gt;
告诉编译器在 C99 模式下看到 inline 函数时使用传统的 GNU 句法。</p>

<h4 id="c-options">C options</h4>

<p>-fsigned-char &lt;/br&gt;
-funsigned-char &lt;/br&gt;
把char定义为有/无符号类型，如同signed char/unsigned char。</p>

<p>-traditional &lt;/br&gt;
尝试支持传统C编译器的某些方面。详见GNU C手册。</p>

<p>-fno-builtin &lt;/br&gt;
-fno-builtin-function &lt;/br&gt;
不接受没有 <em>_builtin</em> 前缀的函数作为内建函数。</p>

<p>-trigraphs &lt;/br&gt;
支持ANSI C的三联符（ trigraphs）。`-ansi’选项隐含声明了此选项。</p>

<p>-fsigned-bitfields &lt;/br&gt;
-funsigned-bitfields &lt;/br&gt;
如果没有明确声明<code>signed</code>或<code>unsigned</code>修饰符，这些选项用来定义有符号位域或无符号位域。缺省情况下，位域是有符号的，因为它们继承的基本整数类型，如<code>int</code>，是有符号数。</p>

<p>-Wstrict-prototypes &lt;/br&gt;
如果函数的声明或定义没有指出参数类型，编译器就发出警告。很有用的警告。</p>

<p>-Wmissing-prototypes &lt;/br&gt;
如果没有预先声明就定义了全局函数，编译器就发出警告。即使函数定义自身提供了函数原形也会产生这个警告。这个选项 的目的是检查没有在头文件中声明的全局函数。</p>

<p>-Wnested-externs &lt;/br&gt;
如果某<code>extern</code>声明出现在函数内部，编译器就发出警告。</p>

<h4 id="c-options-1">C++ options</h4>

<p>-ffor-scope &lt;/br&gt;
从头开始执行程序，也允许进行重定向。</p>

<p>-fno-rtti &lt;/br&gt;
关闭对 dynamic_cast 和 typeid 的支持。如果你不需要这些功能，关闭它会节省一些空间。</p>

<p>-Wctor-dtor-privacy &lt;/br&gt;
当一个类没有用时给出警告。因为构造函数和析构函数会被当作私有的。</p>

<p>-Wnon-virtual-dtor &lt;/br&gt;
当一个类有多态性，而又没有虚析构函数时，发出警告。-Wall会开启这个选项。</p>

<p>-Wreorder &lt;/br&gt;
如果代码中的成员变量的初始化顺序和它们实际执行时初始化顺序不一致，给出警告。</p>

<p>-Wno-deprecated &lt;/br&gt;
使用过时的特性时不要给出警告。</p>

<p>-Woverloaded-virtual &lt;/br&gt;
如果函数的声明隐藏住了基类的虚函数，就给出警告。</p>

<p>Machine Dependent Options (Intel)&lt;/br&gt;</p>

<p>-mtune=cpu-type &lt;/br&gt;
为指定类型的 CPU 生成代码。cpu-type 可以是：i386，i486，i586，pentium，i686，pentium4 等等。</p>

<p>-msse &lt;/br&gt;
-msse2 &lt;/br&gt;
-mmmx &lt;/br&gt;
-mno-sse &lt;/br&gt;
-mno-sse2 &lt;/br&gt;
-mno-mmx &lt;/br&gt;
使用或者不使用MMX，SSE，SSE2指令。</p>

<p>-m32 &lt;/br&gt;
-m64 &lt;/br&gt;
生成32位/64位机器上的代码。</p>

<p>-mpush-args &lt;/br&gt;
-mno-push-args &lt;/br&gt;
（不）使用 push 指令来进行存储参数。默认是使用。</p>

<p>-mregparm=num &lt;/br&gt;
当传递整数参数时，控制所使用寄存器的个数。</p>

<h4 id="optimization-option">Optimization Option</h4>

<p>-O0 &lt;/br&gt;
禁止编译器进行优化。默认为此项。</p>

<p>-O&lt;/br&gt;
-O1&lt;/br&gt;
尝试优化编译时间和可执行文件大小。</p>

<p>-O2 &lt;/br&gt;
更多的优化，会尝试几乎全部的优化功能，但不会进行“空间换时间”的优化方法。</p>

<p>-O3 &lt;/br&gt;
在 -O2 的基础上再打开一些优化选项：-finline-functions， -funswitch-loops 和 -fgcse-after-reload 。</p>

<p>-Os &lt;/br&gt;
对生成文件大小进行优化。它会打开 -O2 开的全部选项，除了会那些增加文件大小的。</p>

<p>-finline-functions &lt;/br&gt;
把所有简单的函数内联进调用者。编译器会探索式地决定哪些函数足够简单，值得做这种内联。</p>

<p>-fstrict-aliasing &lt;/br&gt;
施加最强的别名规则（aliasing rules）。</p>

<p><code>gcc</code>默认提供了5级优化选项的集合: </p>

<ul>
  <li>-O0:无优化(默认)</li>
  <li>-O和-O1:使用能减少目标文件大小以及执行时间并且不会使编译时间明显增加的优化.在编译大型程序的时候会显著增加编译时内存的使用. </li>
  <li>-O2: 包含-O1的优化并增加了不需要在目标文件大小和执行速度上进行折衷的优化.编译器不执行循环展开以及函数内联.此选项将增加编译时间和目标文件的执行性 能. </li>
  <li>-Os:专门优化目标文件大小,执行所有的不增加目标文件大小的-O2优化选项.并且执行专门减小目标文件大小的优化选项. </li>
  <li>-O3: 打开所有-O2的优化选项并且增加 -finline-functions, -funswitch-loops,-fpredictive-commoning, -fgcse-after-reload and -ftree-vectorize优化选项. </li>
</ul>

<pre>
-O1包含的选项-O1通常可以安全的和调试的选项一起使用:
           -fauto-inc-dec -fcprop-registers -fdce -fdefer-pop -fdelayed-branch 
           -fdse -fguess-branch-probability -fif-conversion2 -fif-conversion 
           -finline-small-functions -fipa-pure-const -fipa-reference 
           -fmerge-constants -fsplit-wide-types -ftree-ccp -ftree-ch 
           -ftree-copyrename -ftree-dce -ftree-dominator-opts -ftree-dse 
           -ftree-fre -ftree-sra -ftree-ter -funit-at-a-time 
</pre>

<p>以下所有的优化选项需要在名字前加上-f,如果不需要此选项可以使用-fno-前缀 </p>

<ul>
  <li>defer-pop:延迟到只在必要时从函数参数栈中pop参数; </li>
  <li>thread-jumps:使用跳转线程优化,避免跳转到另一个跳转; </li>
  <li>branch-probabilities:分支优化; </li>
  <li>cprop-registers:使用寄存器之间copy-propagation传值; </li>
  <li>guess-branch-probability:分支预测; </li>
  <li>omit-frame-pointer:可能的情况下不产生栈帧; </li>
</ul>

<pre>
-O2:以下是-O2在-O1基础上增加的优化选项: 
           -falign-functions  -falign-jumps -falign-loops  -falign-labels 
           -fcaller-saves -fcrossjumping -fcse-follow-jumps  -fcse-skip-blocks 
           -fdelete-null-pointer-checks -fexpensive-optimizations -fgcse 
           -fgcse-lm -foptimize-sibling-calls -fpeephole2 -fregmove 
           -freorder-blocks  -freorder-functions -frerun-cse-after-loop 
           -fsched-interblock  -fsched-spec -fschedule-insns 
           -fschedule-insns2 -fstrict-aliasing -fstrict-overflow -ftree-pre 
           -ftree-vrp
</pre>

<p>cpu架构的优化选项,通常是-mcpu(将被取消);-march,-mtune </p>

<h3 id="warning-interpretation">Warning Interpretation</h3>

<ul>
  <li>unused-function:警告声明但是没有定义的static函数; </li>
  <li>unusedlabel:声明但是未使用的标签; </li>
  <li>unused-parameter:警告未使用的函数参数; </li>
  <li>unused-variable:声明但是未使用的本地变量; </li>
  <li>unused-value:计算了但是未使用的值; </li>
  <li>format:printf和scanf这样的函数中的格式字符串的使用不当; </li>
  <li>implicit-int:未指定类型; </li>
  <li>implicit-function:函数在声明前使用; </li>
  <li>charsubscripts:使用char类作为数组下标(因为char可能是有符号数); </li>
  <li>missingbraces:大括号不匹配; </li>
  <li>parentheses: 圆括号不匹配; </li>
  <li>return-type:函数有无返回值以及返回值类型不匹配; </li>
  <li>sequence-point:违反顺序点的代码,比如 a[i] = c[i++]; </li>
  <li>switch:switch语句缺少default或者switch使用枚举变量为索引时缺少某个变量的case; </li>
  <li>strictaliasing=n:使用n设置对指针变量指向的对象类型产生警告的限制程度,默认n=3;只有在-fstrict-aliasing设置的情况下有效; </li>
  <li>unknow-pragmas:使用未知的#pragma指令; </li>
  <li>uninitialized:使用的变量为初始化,只在-O2时有效; </li>
  <li>以下是在-Wall中不会激活的警告选项: </li>
  <li>cast-align:当指针进行类型转换后有内存对齐要求更严格时发出警告; </li>
  <li>signcompare:当使用signed和unsigned类型比较时; </li>
  <li>missing-prototypes:当函数在使用前没有函数原型时; </li>
  <li>packed:packed 是<code>gcc</code>的一个扩展,是使结构体各成员之间不留内存对齐所需的空间 ,有时候会造成内存对齐的问题; </li>
  <li>padded:也是<code>gcc</code>的扩展,使结构体成员之间进行内存对齐的填充,会 造成结构体体积增大. </li>
  <li>unreachable-code:有不会执行的代码时. </li>
  <li>inline:当inline函数不再保持inline时 (比如对inline函数取地址); </li>
  <li>disable-optimization:当不能执行指定的优化时.(需要太多时间或系统资源). </li>
  <li>可以使用 -Werror时所有的警告都变成错误,使出现警告时也停止编译.需要和指定警告的参数一起使用. </li>
</ul>

<h4 id="warning-multi-character-character-constant">1. Warning: multi-character character constant</h4>

<p>Could be suppressed by -Wno-multichar</p>

<p>There’re three kinds of character constants: Normal character constants, Multicharacter constants and Wide-character constants.</p>

<pre><code>char ch = 'a';
int mbch = '1234';
wchar_t wcch = L'ab';
</code></pre>

<p>Mbch is of type int(signed), has 4 meaningful characters.</p>

<p><code>gcc</code> compiler evaluates a multi-character character constant a character at a time, shifting the previous value left by the number of bits per target character, and then or-ing in the bit-pattern of the new character truncated to the width of a target character.</p>

<p>‘ab’ for a target with an 8-bit char would be interpreted as:</p>

<p>(int) ((unsigned char) ‘a’ * 256 + (unsigned char) ‘b’) = 97*256+98</p>

<p>‘1’,x          0x31
‘12’,x        0x3132
‘123’,x      0x313233
‘1234’,x    0x31323334</p>

<p>判断系统是big endian还是little endian的方法：</p>

<pre><code>if (('1234' &gt;&gt; 24) == '1')
{
    //Little endian
}
else if (('4321' &gt;&gt; 24) == '1')
{
    //Big endian
}
</code></pre>

<h4 id="warning-operation-on-xx-may-be-undefined">2. Warning: operation on xx may be undefined</h4>

<p>序列点问题。为什么 a[i] = i++; 不能正常工作？子表达式 i++ 有一个副作用，它会改变 i 的值。由于 i 在同一表达式的其它地方被引用，这会导致无定义的结果，无从判断该引用(左边的 a[i] 中)是旧值还是新值。(尽管 在 K&amp;R 中建议这类表达式的行为不确定，但 C 标准却强烈声明它是无定义的），具体实现取决于编译器。</p>

<h4 id="warning-conversion-to-xxx-from-yyy-may-alter-its-value">3.  Warning: conversion to xxx from yyy may alter its value</h4>

<p><code>gcc</code> promotes unsigned char/uint16_t/uint8_t  to type int for for all arithmetic. Need to apply static_cast&lt;&gt;.</p>

<h4 id="warning-function-might-be-possible-candidate-for-attribute-noreturn">4.  Warning: function might be possible candidate for attribute ‘noreturn’</h4>

<p>打开了 -Wmissing-noreturn。A few standard library functions, such as abort and exit, cannot return. <code>gcc</code> knows this automatically. With noreturn attribute it can then optimize without regard to what would happen if function ever did return. This makes slightly better code. More importantly, it helps avoid spurious warnings of uninitialized variables. The noreturn keyword does not affect the exceptional path. 给函数加上 <strong>attribute</strong>((noreturn)) 即可消除这个warning。</p>

<h4 id="warning-deprecated-conversion-from-string-constant-to-char-">5. Warning: deprecated conversion from string constant to “char *”</h4>

<p>void SomeFunc (char* str)
{
}</p>

<p>int _tmain(int argc, _TCHAR* argv[])
{
    SomeFunc(“Hello!”);
    return 0;
}</p>

<p>SomeFunc() 的输入时char<em>，含义是：给我个字符串，我要修改它。而传给它的字面常量是没办法修改的，将char</em> 改成 const char*，消除这个warning.</p>

<h4 id="warning-implicit-declaration-of-function-mallocfree-incompatible-implicit-declaration-of-built-in-function-mallocfree">6.  Warning: implicit declaration of function ‘malloc’/’free’, incompatible implicit declaration of built-in function ‘malloc’/’free’</h4>

<p>要显示的#include <stdlib.h></stdlib.h></p>

<h4 id="warning-dereferencing-type-punned-pointer-will-break-strict-aliasing-rules">7.  Warning: Dereferencing type-punned pointer will break strict-aliasing rules</h4>

<p>打开了-fstrict-aliasing and -Wstrict-aliasing. Suppress with -fno-strict-aliasing</p>

<p>Strict-aliasing rule: An object of one type is assumed never to reside at the same address as an object of a different type, unless the types are almost the same. 编译器希望不同类型的对象不会指向同一个地址。</p>

<h4 id="warning-inlining-failed-in-call-to-xxx-call-is-unlikely-and-code-size-would-grow">8.  Warning: inlining failed in call to xxx: call is unlikely and code size would grow</h4>

<p>打开了-Winline: Warn if a function can not be inlined and it was declared as inline. Even with this option, the compiler will not warn about failures to inline functions declared in system headers.</p>

<p>相关选项：</p>

<p>-fno-inline: Don’t compile statement functions inline. Might reduce the size of a program unit–which might be at expense of some speed (though it should compile faster). Note that if you are not optimizing, no functions can be expanded inline.</p>

<p>-finline-functions: Interprocedural optimizations occur. However, if you specify -O0, the default is OFF. Enables function inlining for single file compilation.</p>

<h4 id="warning-cannot-optimize-loop-the-loop-counter-may-overflow">9.  Warning: cannot optimize loop, the loop counter may overflow</h4>

<p>打开了-Wunsafe-loop-optimizations: Warn if the loop cannot be optimized because the compiler could not assume anything on the bounds of the loop indices. With -funsafe-loop-optimizations warn if the compiler made such assumptions.</p>

<p>相关选项：</p>

<p>-funsafe-loop-optimizations: Enable unsafe loop optimizations, e.g. assume loop indices never overflow, etc</p>
]]></content>
  </entry>
  
</feed>
