<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Billowkiller's Blog]]></title>
  <link href="http://billowkiller.github.io/atom.xml" rel="self"/>
  <link href="http://billowkiller.github.io/"/>
  <updated>2016-06-01T23:11:37+08:00</updated>
  <id>http://billowkiller.github.io/</id>
  <author>
    <name><![CDATA[wutao]]></name>
    <email><![CDATA[billowkiller@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[MCMC Methods]]></title>
    <link href="http://billowkiller.github.io/blog/2016/06/01/mcmc/"/>
    <updated>2016-06-01T16:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/06/01/mcmc</id>
    <content type="html"><![CDATA[<p>解释下题目中的MCMC，全名是Markov Chain Monte Carlo，这里面有两个词，Markov Chain、Monte Carlo。第一个词是马尔可夫链，可以参考<a href="http://billowkiller.com/blog/2016/05/09/random-process/">http://billowkiller.com/blog/2016/05/09/random-process/</a>。第二个是蒙特卡罗，是一种模拟方法，可以从一个分布中模拟出点来估计我们感兴趣的参数，例如用来估计密度函数的定积分，称为 Monte Carlo Integration。</p>

<!--more-->

<p>譬如现在有个分布 $p(\theta)$，我们想知道一下积分：</p>

<script type="math/tex; mode=display"> I = \int_{\Theta} g(\theta)p(\theta) d\theta </script>

<p>通过从 $p(\theta)$ 中模拟出 $M$ 个值，我们可以估计 $I$，公式如下：</p>

<script type="math/tex; mode=display"> \hat{I}_M = \frac{1}{M} \sum_{i=1}^M g(\theta^{(i)}) </script>

<p>于是统计 $Beta(3,3)$ 的期望可以通过一下代码得到：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">M <span class="o">&lt;-</span> <span class="m">10000</span>
</span><span class="line">beta.sims <span class="o">&lt;-</span> rbeta<span class="p">(</span>M<span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">3</span><span class="p">)</span>
</span><span class="line">sum<span class="p">(</span>beta.sims<span class="p">)</span><span class="o">/</span>M
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>还有一个经典的例子是计算 $\pi$:</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">M <span class="o">&lt;-</span> <span class="m">1000000</span>
</span><span class="line">x <span class="o">&lt;-</span> runif<span class="p">(</span>N<span class="p">,</span> min<span class="o">=</span> <span class="m">-1</span><span class="p">,</span> max<span class="o">=</span> <span class="m">1</span><span class="p">)</span>
</span><span class="line">y <span class="o">&lt;-</span> runif<span class="p">(</span>N<span class="p">,</span> min<span class="o">=</span> <span class="m">-1</span><span class="p">,</span> max<span class="o">=</span> <span class="m">1</span><span class="p">)</span>
</span><span class="line">is.inside <span class="o">&lt;-</span> <span class="p">(</span>x<span class="o">^</span><span class="m">2</span> <span class="o">+</span> y<span class="o">^</span><span class="m">2</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="m">1</span>
</span><span class="line">pi.estimate <span class="o">&lt;-</span> <span class="m">4</span> <span class="o">*</span> sum<span class="p">(</span>is.inside<span class="p">)</span> <span class="o">/</span> M
</span><span class="line">pi.estimate
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>通过大数定律我们其实是可以知道，当 $M \to \infty$，$\hat{I}_M \to I$。</p>

<p>大数定律要求的是独立同分布的随机变量，上述的例子都是从同一分布中得到独立的变量，但是如果我们不能产生独立的变量又该怎么办呢？</p>

<p>例如，我们想要从后验分布 $p(\theta \vert y)$ 中抽样，但是我们不能产生独立的变量，因为我们通常不知道 normalizing constant。我们却可以产生稍微有点依赖的变量，这时可以应用 Markov chain 得到我们感兴趣的值。</p>

<p>一旦马尔可夫链收敛到了平稳分布，这时候对马尔可夫链的抽样就类似于对 $p(\theta \vert y)$ 的抽样。但是还是没有解决抽样不是独立。</p>

<p>这时候我们祭出大神 <code>Ergodic Theorem</code>，可以让马尔可夫链模拟大数定律，定义如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/86848502.jpg" width="600px" /></p>

<p>下面分别解释下 aperiodic, irreducible, positive recurrent。</p>

<p><strong>aperiodic</strong></p>

<p>马尔可夫链的周期性可以用下图表示</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/33403945.jpg" width="400px" /></p>

<p>只要整个链不是重复一个完整的圆圈，则为 aperiodic。</p>

<p><strong>irreducibility</strong></p>

<p>马尔可夫链的不可约表示为可以从任意一个状态到另外一个状态。</p>

<p>以下的链表示的是可约的：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/75995726.jpg" width="400px" /></p>

<p><strong>positive recurrent</strong></p>

<p>positive recurrent表示经过有限次数步骤，可以从任意给定的状态最终返回这个状态。</p>

<p>如果马尔可夫链满足以上这三个条件，则可以忽略抽样之间的依赖关系，进行 Monte Carlo Integration。</p>

<p>知道了上述的知识，我们可以得到 MCMC 的定义：</p>

<blockquote>
  <p>MCMC is a class of methods in which we can <strong>simulate draws</strong> that are <strong>slightly dependent</strong> and are approximately from a (posterior) distribution.</p>
</blockquote>

<p>在贝叶斯统计中，我们通常会使用两种 MCMC 算法：the Gibbs Sampler 和 Metropolis-Hastings algorithm。</p>

<h2 id="gibbs-sampling">Gibbs Sampling</h2>

<p>假设我们想从联合概率分布 $p(\theta<em>1,…\theta_k)$ 中得到抽样，那么我们需要知道的是<strong>每个参数的条件分布</strong> $p(\theta_j \vert \theta</em>{-j},y)$。</p>

<p>从条件概率是如何得到联合概率的呢？具体是根据 <code>The Hammersley-Clifford Theorem</code>。有个例子如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/41685068.jpg" width="600px" /></p>

<p>于是右边就可以得到 $f(y \vert x) f(x) = f(x,y)$。</p>

<p>接下来我们要确认的是如何得到每个参数的条件概率分布，full conditional probability.</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/33580254.jpg" width="600px" /></p>

<p>得到了 full conditional probability 就可以进行 Gibbs Sampling.</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/5179470.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/18003635.jpg" width="600px" /></p>

<p>通过对后验概率的近似抽样我们其实是在模拟马尔可夫链。所以也就可以通过这些抽样得到估计值。</p>

<u>Example:</u>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/34647596.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/6225347.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/68667610.jpg" width="600px" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">gibbs <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>n.sims<span class="p">,</span> beta.start<span class="p">,</span> alpha<span class="p">,</span> gamma<span class="p">,</span> delta<span class="p">,</span>
</span><span class="line">        y<span class="p">,</span> t<span class="p">,</span> burnin<span class="o">=</span><span class="m">0</span><span class="p">,</span> thin<span class="o">=</span><span class="m">1</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">        beta.draws <span class="o">&lt;-</span> c<span class="p">()</span>
</span><span class="line">        lambda.draws <span class="o">&lt;-</span> matrix<span class="p">(</span><span class="kc">NA</span><span class="p">,</span> nrow <span class="o">=</span> n.sims<span class="p">,</span> ncol <span class="o">=</span> length<span class="p">(</span>y<span class="p">))</span>
</span><span class="line">        beta.cur <span class="o">&lt;-</span> beta.start
</span><span class="line">        lambda.update <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>alpha<span class="p">,</span> beta<span class="p">,</span> y<span class="p">,</span> t<span class="p">)</span> <span class="p">{</span>
</span><span class="line">           rgamma<span class="p">(</span>length<span class="p">(</span>y<span class="p">),</span> y <span class="o">+</span> alpha<span class="p">,</span> t <span class="o">+</span> beta<span class="p">)</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">        beta.update <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>alpha<span class="p">,</span> gamma<span class="p">,</span> delta<span class="p">,</span> lambda<span class="p">,</span> y<span class="p">)</span> <span class="p">{</span>
</span><span class="line">           rgamma<span class="p">(</span><span class="m">1</span><span class="p">,</span> length<span class="p">(</span>y<span class="p">)</span> <span class="o">*</span> alpha <span class="o">+</span> gamma<span class="p">,</span> delta <span class="o">+</span> sum<span class="p">(</span>lambda<span class="p">))</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">        <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>n.sims<span class="p">)</span> <span class="p">{</span>
</span><span class="line">            lambda.cur <span class="o">&lt;-</span> lambda.update<span class="p">(</span>alpha <span class="o">=</span> alpha<span class="p">,</span> beta <span class="o">=</span> beta.cur<span class="p">,</span>
</span><span class="line">                y <span class="o">=</span> y<span class="p">,</span> t <span class="o">=</span> t<span class="p">)</span>
</span><span class="line">            beta.cur <span class="o">&lt;-</span> beta.update<span class="p">(</span>alpha <span class="o">=</span> alpha<span class="p">,</span> gamma <span class="o">=</span> gamma<span class="p">,</span>
</span><span class="line">                delta <span class="o">=</span> delta<span class="p">,</span> lambda <span class="o">=</span> lambda.cur<span class="p">,</span> y <span class="o">=</span> y<span class="p">)</span>
</span><span class="line">            <span class="kr">if</span> <span class="p">(</span>i <span class="o">&gt;</span> burnin <span class="o">&amp;</span> <span class="p">(</span>i <span class="o">-</span> burnin<span class="p">)</span><span class="o">%%</span>thin <span class="o">==</span> <span class="m">0</span><span class="p">)</span> <span class="p">{</span>
</span><span class="line">                lambda.draws<span class="p">[(</span>i <span class="o">-</span> burnin<span class="p">)</span><span class="o">/</span>thin<span class="p">,</span> <span class="p">]</span> <span class="o">&lt;-</span> lambda.cur
</span><span class="line">                beta.draws<span class="p">[(</span>i <span class="o">-</span> burnin<span class="p">)</span><span class="o">/</span>thin<span class="p">]</span> <span class="o">&lt;-</span> beta.cur
</span><span class="line">            <span class="p">}</span>
</span><span class="line">        <span class="p">}</span>
</span><span class="line">        <span class="kr">return</span><span class="p">(</span>list<span class="p">(</span>lambda.draws <span class="o">=</span> lambda.draws<span class="p">,</span> beta.draws <span class="o">=</span> beta.draws<span class="p">))</span>
</span><span class="line"><span class="p">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>下面实验得到上述例子的参数估计</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">y <span class="o">&lt;-</span> c<span class="p">(</span><span class="m">5</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">14</span><span class="p">,</span> <span class="m">3</span><span class="p">,</span> <span class="m">19</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">4</span><span class="p">,</span> <span class="m">22</span><span class="p">)</span>
</span><span class="line">t <span class="o">&lt;-</span> c<span class="p">(</span><span class="m">94</span><span class="p">,</span> <span class="m">16</span><span class="p">,</span> <span class="m">63</span><span class="p">,</span> <span class="m">126</span><span class="p">,</span> <span class="m">5</span><span class="p">,</span> <span class="m">31</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">1</span><span class="p">,</span> <span class="m">2</span><span class="p">,</span> <span class="m">10</span><span class="p">)</span>
</span><span class="line">posterior <span class="o">&lt;-</span> gibbs<span class="p">(</span>n.sims <span class="o">=</span> <span class="m">10000</span><span class="p">,</span> beta.start <span class="o">=</span> <span class="m">1</span><span class="p">,</span> alpha <span class="o">=</span> <span class="m">1.8</span><span class="p">,</span> gamma <span class="o">=</span> <span class="m">0.01</span><span class="p">,</span> delta <span class="o">=</span> <span class="m">1</span><span class="p">,</span> y <span class="o">=</span> y<span class="p">,</span> t <span class="o">=</span> t<span class="p">)</span>
</span><span class="line"><span class="c1"># 大数定律</span>
</span><span class="line">colMeans<span class="p">(</span>posterior<span class="o">$</span>lambda.draws<span class="p">)</span>
</span><span class="line">mean<span class="p">(</span>posterior<span class="o">$</span>beta.draws<span class="p">)</span>
</span><span class="line">apply<span class="p">(</span>posterior<span class="o">$</span>lambda.draws<span class="p">,</span> <span class="m">2</span><span class="p">,</span> sd<span class="p">)</span>
</span><span class="line">sd<span class="p">(</span>posterior<span class="o">$</span>beta.draws<span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h2 id="metropolis-hastings-algorithm">Metropolis-Hastings Algorithm</h2>

<p>Metropolis-Hastings 算法适用于这种情况：</p>

<ul>
  <li>后验概率并不像任何我们知晓的分布（没有共轭分布）</li>
  <li>参数的条件概率并不像任何我们知晓的分布（没法用Gibbs sampling）</li>
  <li>后验概率拥有三个以上的参数（grid approximations 不可解）</li>
</ul>

<p>具体的算法有以下步骤：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/92275724.jpg" width="600px" /> </p>

<p>细分下每个步骤：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/86212406.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/28170626.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/32187111.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/28671748.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/28650748.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/73904716.jpg" width="600px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/8969349.jpg" width="600px" /></p>

<u>Example:</u>

<p>使用随机游走Metropolis算法从Gamma(1.7, 4.4)分布抽样，jumping distribution是一个标准差为2的正太分布。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
</pre></td><td class="code"><pre><code class="r"><span class="line">mh.gamma <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>n.sims<span class="p">,</span> start<span class="p">,</span> burnin<span class="p">,</span> cand.sd<span class="p">,</span> shape<span class="p">,</span> rate<span class="p">)</span> <span class="p">{</span>
</span><span class="line">    theta.cur <span class="o">&lt;-</span> start
</span><span class="line">    draws <span class="o">&lt;-</span> c<span class="p">()</span>
</span><span class="line">    theta.update <span class="o">&lt;-</span> <span class="kr">function</span><span class="p">(</span>theta.cur<span class="p">,</span> shape<span class="p">,</span> rate<span class="p">)</span> <span class="p">{</span>
</span><span class="line">        theta.can <span class="o">&lt;-</span> rnorm<span class="p">(</span><span class="m">1</span><span class="p">,</span> mean <span class="o">=</span> theta.cur<span class="p">,</span> sd <span class="o">=</span> cand.sd<span class="p">)</span>
</span><span class="line">        accept.prob <span class="o">&lt;-</span> dgamma<span class="p">(</span>theta.can<span class="p">,</span> shape <span class="o">=</span> shape<span class="p">,</span> rate <span class="o">=</span> rate<span class="p">)</span> <span class="o">/</span>
</span><span class="line">            dgamma<span class="p">(</span>theta.cur<span class="p">,</span> shape <span class="o">=</span> shape<span class="p">,</span> rate <span class="o">=</span> rate<span class="p">)</span>
</span><span class="line">        <span class="kr">if</span> <span class="p">(</span>runif<span class="p">(</span><span class="m">1</span><span class="p">)</span> <span class="o">&lt;=</span> accept.prob<span class="p">)</span> theta.can <span class="kr">else</span> theta.cur
</span><span class="line">    <span class="p">}</span>
</span><span class="line">    <span class="kr">for</span> <span class="p">(</span>i <span class="kr">in</span> <span class="m">1</span><span class="o">:</span>n.sims<span class="p">)</span> <span class="p">{</span>
</span><span class="line">        draws<span class="p">[</span>i<span class="p">]</span> <span class="o">&lt;-</span> theta.cur <span class="o">&lt;-</span> theta.update<span class="p">(</span>theta.cur<span class="p">,</span> shape <span class="o">=</span> shape<span class="p">,</span> rate <span class="o">=</span> rate<span class="p">)</span>
</span><span class="line">    <span class="p">}</span>
</span><span class="line">    <span class="kr">return</span><span class="p">(</span>draws<span class="p">[(</span>burnin <span class="o">+</span> <span class="m">1</span><span class="p">)</span><span class="o">:</span>n.sims<span class="p">])</span>
</span><span class="line"><span class="p">}</span>
</span><span class="line">mh.draws <span class="o">&lt;-</span> mh.gamma<span class="p">(</span><span class="m">10000</span><span class="p">,</span> start <span class="o">=</span> <span class="m">1</span><span class="p">,</span> burnin <span class="o">=</span> <span class="m">1000</span><span class="p">,</span> cand.sd <span class="o">=</span> <span class="m">2</span><span class="p">,</span> shape <span class="o">=</span> <span class="m">1.7</span><span class="p">,</span> rate <span class="o">=</span> <span class="m">4.4</span><span class="p">)</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Random Process]]></title>
    <link href="http://billowkiller.github.io/blog/2016/05/09/random-process/"/>
    <updated>2016-05-09T16:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/05/09/random-process</id>
    <content type="html"><![CDATA[<p>本文用来记录一些随机过程。随机过程是处理包含时间以及数据序列的概率模型。可用于一下数据序列的建模：</p>

<ul>
  <li>每天的股票价格数据序列</li>
  <li>交通网络中的每个点的交通负荷数据序列</li>
  <li>雷达对飞机的定位数据序列</li>
</ul>

<p>序列中的每个数据都视为一个随机变量，所以随机序列就是一串有限或无限的随机变量序列，但是更加强调：</p>

<ul>
  <li>过程中产生的数据序列之间的<strong>相关</strong>关系。比如股票的未来价格与历史价格关系。</li>
  <li>对整个过程中<strong>长期均值</strong>感兴趣。比如有多大比例的时间机器出于闲置。</li>
  <li>需要刻画某些<strong>边界事件</strong>的似然或频率。在给定时间内，线路同时出于忙碌的概率，计算机网络中缓冲器数据溢出的频率。</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-4-16/62147816.jpg" width="500px" /></p>

<p>下面讨论几个随机过程。</p>

<!--more-->

<h2 id="section">伯努利过程和泊松过程</h2>

<p>这两个过程重点研究的是<strong>相邻到达时间是互相独立的随机变量</strong>的模型。区别在于：</p>

<ul>
  <li>伯努利（Bernoulli）过程考虑到达时间是<code>离散</code>的情形，相邻时间服从<code>几何分布</code>。</li>
  <li>泊松（Poisson）过程考虑到达时间是<code>连续</code>的情形，相邻时间服从<code>指数分布</code>。</li>
</ul>

<h3 id="section-1">伯努利过程</h3>

<p>通常将伯努利过程视为独立投币序列，正面朝上的概率是 $p,\ 0&lt;p&lt;1$。这里把硬币朝上视为“到达”，连续投币产生伯努利过程。下面给出伯努利过程相关的随机变量和性质：</p>

<ul>
  <li>服从参数为 $n$ 和 $p$ 的二项分布。这是 $n$ 次相继独立的实验成功的总次数 $S$ 的分布，有</li>
</ul>

<script type="math/tex; mode=display"> P_S(k) =  \binom{k}{n} p^k (1-p)^{n-k},\ k = 0,1,..n </script>

<script type="math/tex; mode=display">E(S) = np,\ var(S)=np(1-p)</script>

<ul>
  <li>服从参数为 $p$ 的集合分布。这是相互独立重复的伯努利试验首次成功时刻T的分布，有</li>
</ul>

<script type="math/tex; mode=display"> P_T(t) = p(1-p)^{t-1},\ t=1,2,...</script>

<script type="math/tex; mode=display"> E(T) = \frac{1}{p},\ var(T) = \frac{1-p}{p^2}</script>

<p>伯努利过程有<strong>独立性</strong>和<strong>无记忆性</strong>。假设我们观测过程 $n$ 步，但是还没有成功。那么余下的 $T-n$ 有什么结论呢？</p>

<script type="math/tex; mode=display"> P(T-n=t \vert T>n) = (1-p)^{t-1}p = P(T=t),\ t=1,2,...</script>

<p>可以看到未来试验次数仍然是相同的集合分布。</p>

<p>当 $n$ 充分大，而 $p$ 很小，均值 $np$ 始终。数学上，我们可以让 $n$ 增大，但是同时缩小 $p$，这样可以保值 $np$ 是一个固定值 $\lambda$，从极值意义上看，二项分布的分布列可以简化为泊松分布。</p>

<h3 id="section-2">泊松分布</h3>

<p>跟伯努利过程相比，泊松过程是连续时间轴上的到达时间。</p>

<p>伯努利过程无法刻画相同时间段内，发生两次或者多次到达事件，虽然可以通过将时间段选的非常小，但是无法选择一个准确的小时间段。这时候考虑时间段长度趋近于零的情况，即连续时间模型。</p>

<p>泊松过程相关的随机变量和性质：</p>

<ul>
  <li>服从参数为 $\lambda \tau$ 的<strong>泊松分布</strong>。这是泊松过程的强度为 $\lambda$，在时间长度为 $\tau$ 的区间内到达的总次数 $N_\tau$ 的分布，有</li>
</ul>

<script type="math/tex; mode=display"> P_{N_\tau}(k) = P(k,\tau) = e^{-\lambda \tau} \frac{(\lambda \tau)^k}{k!},\ k=0,1,...</script>

<script type="math/tex; mode=display"> E(N_\tau) = \lambda \tau,\ var(N_\tau) = \lambda \tau</script>

<ul>
  <li>服从参数为 $\lambda$ 的<strong>指数分布</strong>，这是首次达到的时间 $T$ 的分布，有</li>
</ul>

<script type="math/tex; mode=display">f_T(t) = \lambda e^{-\lambda t},\ t \ge 0,\ E(T)=\frac{1}{\lambda},\ var(T)=\frac{1}{\lambda^2}</script>

<p>上式可以将一个固定长度为 $\tau$ 的时间区间分成一个个小区间，将小区间看成伯努利过程来近似。</p>

<h3 id="section-3">马尔可夫链</h3>

<p>马尔可夫链的定义是一种随机过程，它描述了一种状态序列，其每个状态值取决于前面的状态。用以下公式表示马尔可夫性质：</p>

<script type="math/tex; mode=display">p(\theta^{(t+1)} \vert \theta^{(1)},\theta^{(2)},..\theta^{(t)}) = p(\theta^{(t+1)} \vert \theta^{(t)}) </script>

<p>状态之间的转换通过 transition kernel，这是一个 $k \times k$ 矩阵，$k$ 表示状态数。一个 $3 \times 3$ 的转换矩阵 $P$ 如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-6-1/92862152.jpg" alt="" /></p>

<p>马尔可夫链有一个平稳分布，stationary distribution $\pi$，定义为：$\pi = \pi P$。无论起始状态是什么样，马尔可夫链通常会收敛到 $\pi$ 上。</p>

<p>通常会根据所选的起始状态，有这不同的收敛时间。在利用马尔可夫链进行抽样时，在收敛之前的一段时间，比如前 $n-1$ 次迭代，各个状态的边际分布还不能认为是稳定分布，所以在进行估计的时候，应该把前面的这$n-1$ 个迭代值去掉。这个过程称为 <code>burn-in</code>。这样会使我们的抽样更加接近平稳分布，减少对起始位置的依赖。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Funny Facts about Rating]]></title>
    <link href="http://billowkiller.github.io/blog/2016/04/09/rating/"/>
    <updated>2016-04-09T16:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/04/09/rating</id>
    <content type="html"><![CDATA[<p>本文分析Wilson score confidence interval，它在Reddit评论评分中的应用，另外分析了Hacker News、Reddit的评分算法。先来看下错误的评分。</p>

<p>Case 1: 网站的内容排名，得分高的排前面，得分低的排后面。如何计算得分。</p>

<p><strong>Solution 1:  Score = (Positive ratings) - (Negative ratings)</strong></p>

<u>未考虑内容的受欢迎程度。</u>

<!--more-->

<blockquote>
  <p>Suppose one item has 600 positive ratings and 400 negative ratings: 60% positive. Suppose item two has 5,500 positive ratings and 4,500 negative ratings: 55% positive. This algorithm puts item two above item one.</p>
</blockquote>

<p><strong>Solution 2: Score = Average rating = (Positive ratings) / (Total ratings)</strong></p>

<u>数据较多的时候比较适合，但是数据量少的时候会有比较大的Bias。</u>

<blockquote>
  <p>Average rating works fine if you always have a ton of ratings, but suppose item 1 has 2 positive ratings and 0 negative ratings. Suppose item 2 has 100 positive ratings and 1 negative rating. This algorithm puts item two below item one.</p>
</blockquote>

<p><strong>Correct Solution: Score = Lower bound of <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Wilson_score_interval">Wilson score confidence interval</a> for a Bernoulli parameter</strong></p>

<u>We need to balance the proportion of positive ratings with the uncertainty of a small number of observations. </u>

<p><img src="http://www.evanmiller.org/images/rating-equation.png" alt="" /></p>

<p>Here $\hat{p}$ is the observed fraction of positive ratings, $z_{\alpha/2}$ is the $(1-\alpha/2)$ quantile of the standard normal distribution, and $n$ is the total number of ratings. </p>

<p>上式适合于二元评分机制，并不适用于例如5-star评分。</p>

<p>Wilson score confidence interval除了排序问题，还可以应用在如下地方：</p>

<ul>
  <li>Detect spam/abuse: What percentage of people who see this item will mark it as spam?</li>
  <li>Create a “best of” list: What percentage of people who see this item will mark it as “best of”?</li>
  <li>Create a “Most emailed” list: What percentage of people who see this page will click “Email”?</li>
</ul>

<h3 id="hacker-news-ranking-algorithm">Hacker News ranking algorithm</h3>

<p>Hacker News由Lisp的一种方言Arc实现，代码现在是开源的。它实现的内容得分公式为：</p>

<script type="math/tex; mode=display">Score = \frac{P-1}{(T+2)^G}</script>

<ul>
  <li>P = points of an item (and -1 is to negate submitters vote)</li>
  <li>T = time since submission (in hours)</li>
  <li>G = Gravity, defaults to 1.8</li>
</ul>

<p>Gravity和Time对内容得分有很大影响：</p>

<ul>
  <li>T增加导致得分降低，这是新闻老化的效果</li>
  <li>当Gravity增加的时候，上述降低会来的更快</li>
</ul>

<p>查看Time和Gravity的影响，在<a href="http://www.wolframalpha.com">Wolfram Alpha</a>的输入框中输入：</p>

<pre><code>plot(
    (30 - 1) / (t + 2)^1.8, 
    (60 - 1) / (t + 2)^1.8,
    (200 - 1) / (t + 2)^1.8
) where t=0..24
</code></pre>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-5-26/75012257.jpg" alt="" /></p>

<pre><code>plot(
    (p - 1) / (t + 2)^1.8, 
    (p - 1) / (t + 2)^0.5,
    (p - 1) / (t + 2)^2.0
) where t=0..24, p=10
</code></pre>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-5-26/43469961.jpg" alt="" /></p>

<h3 id="reddit-ranking-algorithm">Reddit ranking algorithm</h3>

<p>在Hacker News中新闻和评论都是采用同样的评分算法，而在Reddit中，它们采用不同的算法。</p>

<p>Reddit 同样是开源的，并且使用Python实现，为了加速计算，评分算法使用 Pyrex 实现。先来看下新闻的评分算法，hot algorithm：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-5-26/36257254.jpg" alt="" /></p>

<ul>
  <li>同样，submission time对评分的影响很大，人们总是喜欢新鲜的事情</li>
  <li>和Hacker News不同，新闻评分并不会随着时间流逝而降低，虽然它会比较新的新闻得分低。</li>
</ul>

<p>对于同样的votes，但是submission time不同的新闻，它们的得分可以参考：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-5-26/83965192.jpg" alt="" /></p>

<p>公式中的logarithm表示，最开始的votes拥有比较大的权重：开始的10 upvotes和接下的100 upvotes具有相同的权重，接下是 1000 upvotes。这就是upvotes的平滑效果。</p>

<p>比较有意思的是Reddit中的downvotes，它认为具有比较多upvotes和downvotes的新闻代表争议，它们的得分应该会比只有upvotes的新闻得分低。看看downvotes的影响：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-5-26/95155391.jpg" alt="" /></p>

<p>下面看下Reddit的评论的评分算法：</p>

<p>Reddit认为hot algorithm并不适用于comment，原因如下：</p>

<ul>
  <li>In a comment system you want to rank the best comments highest regardless of their submission time</li>
</ul>

<p>Reddit用到我们上面提到过的Wilson score interval，由这个interval得到the confidence sort，解释如下：</p>

<ul>
  <li>The confidence sort treats the vote count as a statistical sampling of a hypothetical full vote by everyone</li>
  <li>The confidence sort gives a comment a provisional ranking that it is 85% sure it will get to</li>
  <li>The more votes, the closer the 85% confidence score gets to the actual score</li>
  <li>Wilson’s interval has good properties for a small number of trials and/or an extreme probability</li>
</ul>

<blockquote>
  <p>If a comment has one upvote and zero downvotes, it has a 100% upvote rate, but since there’s not very much data, the system will keep it near the bottom. But if it has 10 upvotes and only 1 downvote, the system might have enough confidence to place it above something with 40 upvotes and 20 downvotes — figuring that by the time it’s also gotten 40 upvotes, it’s almost certain it will have fewer than 20 downvotes. And the best part is that if it’s wrong (which it is 15% of the time), it will quickly get more data, since the comment with less data is near the top.</p>
</blockquote>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-5-26/41802353.jpg" alt="" /></p>

<h3 id="references">REFERENCES</h3>

<p><a href="http://www.evanmiller.org/how-not-to-sort-by-average-rating.html">How Not To Sort By Average Rating</a></p>

<p><a href="https://medium.com/hacking-and-gonzo/how-hacker-news-ranking-algorithm-works-1d9b0cf2c08d#.utg0mohjf">How Hacker News ranking algorithm works</a></p>

<p><a href="https://medium.com/hacking-and-gonzo/how-reddit-ranking-algorithms-work-ef111e33d0d9#.ub7osc36n">How Reddit ranking algorithms work</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Recommender System in a Nutshell]]></title>
    <link href="http://billowkiller.github.io/blog/2016/04/09/recsys-introduction/"/>
    <updated>2016-04-09T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/04/09/recsys-introduction</id>
    <content type="html"><![CDATA[<p>推荐系统（Recommender System An Introduction）读书笔记。</p>

<!--more-->

<h2 id="section">基于内容的推荐系统</h2>

<p>基于内容的推荐：基于两类信息，<code>物品特征的描述</code>和描述用户兴趣的<code>用户记录</code>（比如喜爱的物品特点）。</p>

<p>一般工作原理是评估用户还没有看到的物品与当前用户过去喜欢的物品的相似度。那么如何表示物品的内容以及相似度？</p>

<p>描述物品目录最简单的方法就是维护每个物品特征的详细列表，<strong>属性集、特征集或物品记录</strong>。另外可以使用<code>关键词列表</code>表示文档内容，好处是能够从文档内容本身自动生成列表。</p>

<p>为了防止<code>通用词</code>和<code>长文档</code>带来的推荐结果偏置，一般会使用TF-IDF计算关键词的权重。给出下列公式：</p>

<script type="math/tex; mode=display"> TF(i, j) = \frac{freq(i,j)}{maxOthers(i,j)},\ IDF(i) = log\frac{N}{n(i)} </script>

<script type="math/tex; mode=display"> TF-IDF(i, j) = TF(i,j) \cdot IDF(i) </script>

<p>$TF(i,j)$ 表示文档 $j$ 中关键词 $i$ 的<code>归一化词频值</code>，$freq(i,j)$ 表示 $i$ 在 $j$ 中出现的绝对频率； $maxOthers(i,j)$ 表示 $j$ 中其他关键词的最大词频。 $N$ 为所有可推荐文档数量，$n(i)$ 为关键词 $i$ 出现过文档的数量。</p>

<p>归一化是针对长文档，IDF 是针对通用词</p>

<p>从文本中抽取关键词并赋予权值的做法局限性为</p>

<ul>
  <li>向量通常大而稀疏，通过以下几种技术改进：
    <ul>
      <li>停用词和词干还原</li>
      <li>特征选择，仅用信息量最大的一些词来减少文档描述规模，期望删除噪声。</li>
      <li>选用短语</li>
    </ul>
  </li>
  <li>没有考虑到文档上下文</li>
</ul>

<p>User-CF为“推荐相似用户喜欢的物品”，基于内容的推荐可以描述成“推荐与用户过去喜欢的物品相似的物品”。通常的基于内容相似度检索技术为：</p>

<ul>
  <li>KNN
    <ul>
      <li>用余弦相似度评估两个文档的向量是否相似；</li>
      <li>可以考虑用户的短期兴趣和长期兴趣，适合于个性化的新闻推荐；</li>
      <li>易于实现，能够快速适应新近变化，只需要相对少的评分数据；</li>
      <li>预测精确度较低。</li>
    </ul>
  </li>
  <li>相关项反馈——Rocchio方法</li>
</ul>

<p>另外可以将基于内容的推荐看成分类问题。</p>

<p>典型的是朴素贝叶斯方法，基本上有两种对文档及其特征建模的方法：<strong>多项式模型和伯努利模型</strong>，二者都忽略词的<code>位序</code>问题。多元伯努利模型中，文档被处理成一个二进制向量，描述某个词是否包含在文档中；多项式模型中，考虑词出现在文档中的次数，分类结果会比莫努力模型好些。</p>

<p>在多项式模型中，词 $v_i$ 出现在 $c$ 类文档的条件概率为：</p>

<table>
  <tbody>
    <tr>
      <td>$$ P(v_i</td>
      <td>C=c) = \frac{CountTerms(v_i, docs(c))+1}{AllTerms(docs(c))+\vert V \vert}$$</td>
    </tr>
  </tbody>
</table>

<p>上式采用<code>拉普拉斯平滑</code>以防止条件概率为 0，$\vert V \vert$ 为所有文档中不同词的数量。</p>

<p>朴素贝叶斯分类器能够达到很高的精确度，并且其组成部分能够在获得新数据时很容易更新，且学习时间复杂度随样本数量线性增加。</p>

<p>上文提到过<code>特征选择</code>问题，原始的大而稀疏向量会导致性能和内存需求问题，并且容易导致过拟合。典型的可以采用 $\chi^2$ 检验或 Fisher 判别指标。</p>

<p>$\chi^2$ 检验是检测两个时间是否不相干的标准统计方法。在特征选择中，根据训练数据分析某种分类结果是否与某个具体词的出现有联系。基于$\chi^2$ 检验来选择特征，首先按词的$\chi^2$ 值大小降序排列；其次需要确定用于分类器的理想特征数目。</p>

<p>基于内容的推荐系统有许多局限：</p>

<ul>
  <li><strong>浅层内容分析</strong>。</li>
  <li>推荐结果缺乏新颖性，倾向于给出相同的推荐。</li>
  <li>冷启动问题，需要来自用户的初始评分集合。</li>
</ul>

<h2 id="section-1">协同过滤</h2>

<p>协同过滤推荐方法的主要思想：利用已有用户群过去的行为或意见预测当前用户最可能喜欢那些东西或对那些东西感兴趣。纯粹的协同方法输入只有用户-物品评分矩阵，输出可以为：</p>

<ol>
  <li>当前用户对物品的评分</li>
  <li>TopN推荐物品列表</li>
</ol>

<h3 id="section-2">基于用户的最近邻推荐</h3>

<p>这是一种早期方法，对当前用户没有见过的物品 $p$，利用近邻对物品的评价计算预测值。潜在的假设为：</p>

<ol>
  <li>如果用户过去有相似的偏好，未来也会有相似的偏好</li>
  <li>用户偏好不会随着时间而改变</li>
</ol>

<p>确定相似用户集，通常用的方法是Pearson相关系数。给定评分矩阵R，$\bar{r}_a$ 代表用户a的平均评分，用户a和用户b的相似度 $sim(a,b)$ 表示</p>

<script type="math/tex; mode=display"> sim(a,b) = \frac{\sum_{p \in P}(r_{a,p}-\bar{r}_a)(r_{b,p}-\bar{r}_b)}{\sqrt{\sum_{p \in P}(r_{a,p}-\bar{r}_a)^2}\sqrt{\sum_{p \in P}(r_{b,p}-\bar{r}_b)^2}}</script>

<p>Pearson方法考虑到用户评分标准并不相同的事实，可以发现评分值之间存在的线性相关性。但是对于广受大众欢迎的物品相似度会更高，可以类似TF-IDF，引入反用户频率(IUF)计算。用户a对物品p的预测值如下：</p>

<script type="math/tex; mode=display">pred(a,p) = \bar{r}_a + \frac{\sum_{b \in N}sim(a,b)(r_{b,p}-\bar{r}_b)}{\sum_{b \in N}sim(a,b)}</script>

<p>预测的时候可以降低近邻规模减少计算复杂度，可以将用户相似度定义一个具体的最小阈值，或者将规模大小限制为一个固定值，只考虑K个最近邻。阈值会影响可预测物品的覆盖率，但是K值不会影响，它却会带来bias-variance tradeoff。</p>

<p>对于基于用户的推荐系统，Pearson相关系数比其他方法更胜一筹，但是对于基于物品的推荐技术，余弦相似度会比Pearson相关度量表现更好。</p>

<p>基于物品的算法主要思想是利用物品相似度，而不是用户相似度。</p>

<p>在基于物品的推荐中，通常使用改进版的余弦相似度，在原有的基础上减去评分的平均值，得到的结果类似于Pearson方法，取值在-1到+1之间，公式如下：</p>

<script type="math/tex; mode=display"> sim(a,b) = \frac{\sum_{u \in U}(r_{u,a}-\bar{r}_u)(r_{u,b}-\bar{r}_u)}{\sqrt{\sum_{u \in U}(r_{u,a}-\bar{r}_u)^2}\sqrt{\sum_{u \in U}(r_{u,b}-\bar{r}_u)^2}}</script>

<p>预测公式为加权评分综合：</p>

<script type="math/tex; mode=display">pred(u,p) = \frac{\sum_{i \in ratedItems(u)}sim(i,p) \cdot r_{u,i}}{\sum_{i \in ratedItems(u)}sim(i,p)}</script>

<p>基于物品的推荐可以离线构建一个物品相似度矩阵加速线上预测。在线上，通过确定与p最相似的物品，并计算u对这些领巾物品评分的加权综合得到u对p的预测评分。</p>

<p>原则上这种方法对基于用户的推荐也适用，但是实际情况中，两个用户评分重叠情况非常少见，这就意味着一些其他的评分值可能影响到用户间的相似度。</p>

<p>在协同过滤中，会遇到数据稀疏和冷启动问题。这种挑战就是用相对较少的有效评分得到准确的预测。直接做法就是利用用户的附加信息，比如性别、年龄等帮助分类用户信息，这就涉及到利用矩阵的外部信息，也就是混合系统。</p>

<p>另外处理这些问题的方法还包括，基于图的方法，主要思想是利用假定用户品味的传递性，并由此增强额外信息矩阵；缺省投票；利用相似用户给出相似物品的评分。</p>

<p>冷启动是稀疏问题的一个特例，问题包括：如何处理新用户；如何处理为评分或购买的新物品。这两个问题都是通过混合方法解决，可以在推荐之前要求用户给出最低限度数量的评分。</p>

<p>上述的协同推荐技术是Memory-based CF Algorithm。另外一种是Model-based。包括</p>

<ul>
  <li>矩阵因子分解</li>
  <li>关联规则挖掘</li>
  <li>基于概率分析的推荐方法（预测问题看成分类问题）</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kafka Introduction]]></title>
    <link href="http://billowkiller.github.io/blog/2016/04/06/kafka/"/>
    <updated>2016-04-06T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/04/06/kafka</id>
    <content type="html"><![CDATA[<p>Kafka最早是由LinkedIn开发的一个分布式发布-订阅消息系统，现在已经是Apache的一个开源项目。它具有以下的一些特点：</p>

<ul>
  <li>作为分布式系统，很容易 scale out</li>
  <li>消息以时间复杂度为O(1)的方式持久化到磁盘，支持离线消费和实时消费</li>
  <li>发布和订阅都支持高吞吐量，单机支持每秒100K条以上消息的传输</li>
  <li>支持多个订阅端，并且可以在异常情况下自动对这些消费者进行负载均衡</li>
</ul>

<p>消息系统的好处包括：</p>

<ul>
  <li>解耦生产者和消费者</li>
  <li>持久化直到消息已经被完全处理</li>
  <li>扩展性</li>
  <li>灵活性 &amp; 峰值处理能力</li>
  <li>可恢复性，系统的一部分组件失效时，不会影响到整个系统。</li>
  <li>顺序保证</li>
  <li>缓冲，有助于控制和优化数据流经过系统的速度。</li>
  <li>异步通信</li>
</ul>

<!--more-->

<h2 id="section">名词解释</h2>

<ul>
  <li>
    <p>Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker</p>
  </li>
  <li>
    <p>Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）</p>
  </li>
  <li>
    <p>Partition：Parition是物理上的概念，每个Topic包含一个或多个Partition.</p>
  </li>
  <li>
    <p>Producer：负责发布消息到Kafka broker</p>
  </li>
  <li>
    <p>Consumer：消息消费者，向Kafka broker读取消息的客户端。</p>
  </li>
  <li>
    <p>Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。</p>
  </li>
</ul>

<h2 id="section-1">架构图</h2>

<p><img src="http://cdn.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-1/zh/resources/0310020.png" width="500px" /></p>

<p>如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。</p>

<p><img src="http://cdn.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-1/zh/resources/0310025.png" width="500px" /></p>

<p>上图示意消费者和生产者的工作方式。同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。</p>

<p><img src="http://sookocheff.com/img/kafka/kafka-in-a-nutshell/log-anatomy.png" width="500px" /></p>

<p>Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。每条消息都被append到某个Partition中，具体存储到哪一个Partition是根据Partition机制。如果Partition机制比较合理，不同的消息可以并行写入不同broker的不同Partition里，能极大的提高了吞吐率。另因为磁盘限制，Kafka提供两种策略删除旧数据：一是基于时间，二是基于Partition文件大小。</p>

<h3 id="kafka-delivery-guarantee">Kafka delivery guarantee</h3>

<p>Producer向broker发送消息时，默认情况下一条消息从Producer到broker是确保了 <code>At least once</code>，但如果设置Producer为异步发送则实现 <code>At most once</code>。<code>Exactly once</code>还未实现（生成一种消息主键，幂等重试）。</p>

<p>Consumer在从broker读取消息后，可以选择<code>autocommit</code>或<code>手动commit</code>。区别在于一个是读完消息先commit再处理消息，一个是读完消息先处理再commit。前者实现 <code>At most once</code>，后者实现 <code>At least once</code>，但如果消息的处理有幂等性，则可以理解为<code>Exactly once</code>。如果要做到严格<code>Exactly once</code>，则让offset和操作输入存在同一个地方，保证数据的输出和offset的更新要么都完成，要么都不完成，参考Spark Kafka的DirectAPI的实现。</p>

<h2 id="high-available">High Available</h2>

<p>Kafka的HA包括Data Replication和Leader Election两方面。</p>

<h3 id="data-replication">Data Replication</h3>

<p><img src="http://cdn4.infoqstatic.com/statics_s2_20160405-0343u1/resource/articles/kafka-analysis-part-2/zh/resources/0416000.png" width="500px" /></p>

<p>为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。Kafka分配Replica的算法如下：</p>

<ol>
  <li>将所有Broker（假设共n个Broker）和待分配的Partition排序</li>
  <li>将第i个Partition分配到第（i mod n）个Broker上</li>
  <li>将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上</li>
</ol>

<p>Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR(in-sync replica)中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW(high watermark)并且向Producer发送ACK。HW会从leader持续发送到follower并被保存到每个broker的磁盘中。</p>

<p>对于Producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks来设置。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。</p>

<p>Consumer读消息也是从Leader读取，只有被commit过的消息（offset低于HW的消息）才会暴露给Consumer。</p>

<h3 id="leader-election">Leader Election</h3>

<p>Kafka在ZooKeeper中动态维护了一个ISR（in-sync replicas），这个ISR里的所有Replica都跟上了leader，只有ISR里的成员才有被选为Leader的可能。在这种模式下，对于f+1个Replica，一个Partition能在保证不丢失已经commit的消息的前提下容忍f个Replica的失败。对比Majority Vote则需要2f+1个Replica。</p>

<p>Kafka中，如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除，包括两种情况：长时间未向leader发送fetch request，消息lag超过阈值。
为了防止ISR里面的慢节点，Producer选择是否被commit阻塞。</p>

<p>选举时候，Kafka会在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。这种方式改善每个follower都使用zk watch的方法进行选举的问题：</p>

<ul>
  <li>brain split</li>
  <li>herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整</li>
  <li>ZooKeeper负载过重 </li>
</ul>

<h2 id="kafka-">Kafka 网络模型</h2>

<p>Kafka使用的网络模型是典型的reactor模式，一个acceptor处理新来的连接请求，分配给N个processor处理，每个processor都有selector从socket中读取数据，生成request对象放到requestChannel中。requestChannel包含一个requestQueue和一个responseQueues，requestQueue是一个blocking queue，它的大小为<code>queued.max.requests</code>；responseQueues 包含N个blocking queue，对应每个processor。Kafka会有M个Handler threads用于处理responseQueues中的request，并且生成response放到对应的response队列中，处理过程如下：KafkaRequestHandler循环从RequestChannel中取Request并交给kafka.server.KafkaApis处理具体的业务逻辑。。</p>

<p>这里面涉及的数目在配置文件中都有体现，上述的每个acceptor包括processor在Kafka中称为NIO socket server，数量在<code>listeners</code>中定义，例如<code>PLAINTEXT://myhost:9092, SSL://:9091 </code>。N 取值 <code>background.threads</code>，M 取值 <code>num.io.threads</code>。</p>

<p>在 NIO socket server 中会给每个processor的responseQueue都注册一个ResponseListener，一旦有Response产生就会通知对应的processor发送Response到客户端。</p>

<h2 id="kafka-clients-operations">Kafka Clients’ Operations</h2>

<p>这一章节介绍一个Kafka client对于Kafka Resources可能的操作类型。</p>

<p>Operation包括以下几种：Read, Write, Create, Delete, Alter, Describe, ClusterAction。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-4-12/80246194.jpg" width="450px" /></p>

<p><a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-4+-+Command+line+and+centralized+administrative+operations">KIP-4</a></p>

<h3 id="createdelete">Create/Delete</h3>

<p>Create/Delete就是创建和删除Topics。</p>

<p>具体过程如下：</p>

<ol>
  <li>broker发送<code>TopicMetadataRequest</code>到controller。</li>
  <li>Controller在ZooKeeper的/brokers/topics节点上注册Watch，一旦某个Topic被创建或删除，则Controller会通过Watch得到新创建/删除的Topic的Partition/Replica分配。</li>
  <li>对于删除Topic操作，Topic工具会将该Topic名字存于/admin/delete_topics。若delete.topic.enable为true，则Controller注册在/admin/delete_topics上的Watch被fire，Controller通过回调向对应的Broker发送StopReplicaRequest，若为false则Controller不会在/admin/delete_topics上注册Watch，也就不会对该事件作出反应。</li>
  <li>对于创建Topic操作，Controller从/brokers/ids读取当前所有可用的Broker列表，对于set_p中的每一个Partition：
    <ul>
      <li>从分配给该Partition的所有Replica（称为AR）中任选一个可用的Broker作为新的Leader，并将AR设置为新的ISR（因为该Topic是新创建的，所以AR中所有的Replica都没有数据，可认为它们都是同步的，也即都在ISR中，任意一个Replica都可作为Leader）</li>
      <li>将新的Leader和ISR写入/brokers/topics/[topic]/partitions/[partition]</li>
    </ul>
  </li>
  <li>直接通过RPC向相关的Broker发送LeaderAndISRRequest。</li>
</ol>

<p>创建Topic顺序图如下所示。</p>

<p><img src="http://cdn4.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-3/zh/resources/0606003.png" width="500px" /></p>

<p>有两点说明：</p>

<ul>
  <li>对于<code>auto.create.topics.enable=false</code>的Kafka，如果对未存在的topic进行produce，则会导致producer <code>org.apache.kafka.common.errors.TimeoutException</code>错误。</li>
  <li>除了使用broker进行创建Topic，还可以通过Kafka的AdminUtils直接指定zk、topic、partitions，replicationFactor，把相关信息写入zk来创建Topic。</li>
</ul>

<h3 id="alterdescribe">Alter/Describe</h3>

<p>alter/describe 是对配置修改或查看的操作，包括Topic和Client两个部分。改变方法也是通过Kafka的AdminUtils和ConfigCommand，指定zk、topic或要修改的properties。</p>

<h3 id="clusteraction">ClusterAction</h3>

<p>包括LeaderAndIsrRequest，StopReplicaRequest，UpdateMetadataRequest，ControlledShutdownRequest</p>

<h3 id="read">Read</h3>

<p>consumer 订阅Topic数据。consumer根据consumer group的分配算法如下</p>

<pre><code>rebalance process for consumer C_i in group G
For each topic T that C_i subscribes to {
 remove partitions owned by C_i from the ownership registry
 read the broker and the consumer registries from Zookeeper
 compute P_T = partitions available in all brokers under topic T
 compute C_T = all consumers in G that subscribe to topic T
 sort P_T and C_T
 let j be the index position of C_i in C_T and let N = |P_T|/|C_T|
 assign partitions from j*N to (j+1)*N - 1 in P_T to consumer C_i
 for each assigned partition p {
 set the owner of p to C_i in the ownership registry
 let O_p = the offset of partition p stored in the offset registry
 invoke a thread to pull data in partition p from offset O_p
 }
}
</code></pre>

<p>当订阅topic的时候，kafka会注册一个<code>ConsumerRebalanceListener</code>，当发生以下任何一个事件的时候，会引发上述的rebalance算法：</p>

<ul>
  <li>Number of partitions change for any of the subscribed list of topics</li>
  <li>Topic is created or deleted</li>
  <li>An existing member of the consumer group dies</li>
  <li>A new member is added to an existing consumer group via the join API</li>
</ul>

<p>Kafka的Consumer API可以透明地处理上述情况，另外还包括server的fail，partition的聚合。</p>

<p>读取数据发生在<code>poll</code>函数中，每次调用时，consumer都会使用上次消费的offset作为这次的起始offset，并且顺序的读取记录。当然上次消费的offset也可以由<code>seek</code>函数直接指定。</p>

<p>读取数据在Kafka内部是一个FetchRequest，处理的过程为
* authorize
* FetchResponse
* recordAndMaybeThrottle(quota控制)</p>

<h3 id="write">Write</h3>

<p>producer 发布数据的动作。produce的api接口可以选择同步或异步，默认情况下<code>send</code>接口是异步的，它将数据放到缓冲区后就立即返回，等到数据到达一定带下后再发送出去，节约IO开销。可以直接在send()后调用get()，这样可以达到同步的效果。另外一个重要的参数是acks，用来设置produce 请求完成的标准，也就是数据要写到几个broker中才算是完成。</p>

<p>发布数据在Kafka内部是一个ProducerRequest，处理过程为：</p>

<ul>
  <li>authorize</li>
  <li>produceResponse</li>
  <li>recordAndMaybeThrottle(quota控制)</li>
</ul>

<h3 id="partition-and-key">Partition and Key</h3>

<p>这里说下partition和key的关系。注意到，在kafka的api中会有一个key的概念，而实际上kafka只是一个消息的订阅和发布系统，和key应该扯不上一点关系，那么这个key有什么用呢，不用key会有什么影响。</p>

<p>看下没有指定key或者key为null的时候kafka是怎么处理的。首先kafka会随机选择一个partition，然后在一个默认的时间（10min）内所有的数据都会写到这个partition内。这会造成数据不均衡的分布在各个partition中。这时可以通过减少metadata refresh interval 缩短这个默认时间来减轻数据不均衡的现象。</p>

<p>不过更实际的还是指定一个key，因为kafka默认的是使用hashing-based partitioner，可能还会造成数据不均衡。这时候就需要使用自定义的partition，并指定<code>partitioner.class</code>。</p>

<h2 id="authorize">Authorize</h2>

<h3 id="authorizer">Authorizer接口</h3>

<p>Kafka带有Authorizer接口，这个是所有实现授权的插件都必须要实现的接口。启动的时候会读<code>authorizer.class</code>配置，<code>authorizer.class</code>就是实现授权的具体类。</p>

<p>Kafka的授权逻辑是<code>Principal P is [Allowed/Denied] Operation O From Host H On Resource R</code>，P是用户，O是上文提到的各种Operation，Host就是client地址，R是Kafka资源，包括cluster、topic、consumer-group。</p>

<p>Kafka本身自带一个<code>SimpleAclAuthorizer</code>，用它来实现一些简单资源的访问，例如</p>

<blockquote>
  <p>Principals User:Bob and User:Alice are allowed to perform Operation Read and Write on Topic Test-Topic from IP 198.51.100.0 and IP 198.51.100.1</p>
</blockquote>

<h3 id="ranger">Ranger</h3>

<p>Ranger的Kafka plugin也是实现了Authorizer接口。Ranger的实现机制简单的介绍下，Ranger整体分为Admin和Plugin：</p>

<ol>
  <li>Ranger Plugin运行在服务进程内，在Kafka中，Ranger plugin代码就运行在broker内。</li>
  <li>Policy通过Ranger Admin存储在database中，plugin轮询地向admin请求最新的policy；policy存储在本地的一个文件中。</li>
  <li>在service请求到来的时候，ranger plugin中的policy engine会evaluate request，判断是否合法。</li>
</ol>

<p>Ranger的policy engine分为role based和tag based，kafka中使用的是tag based，evaluae的流程图如下：</p>

<p><img src="https://cwiki.apache.org/confluence/download/attachments/61322361/Ranger-Policy-Evaluation-Flow-with-Tags.png?version=2&amp;modificationDate=1444869949000&amp;api=v2" width="600px" /></p>

<p>Ranger Kafka 目前支持的功能还是比较少的，如下图：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-4-12/11458053.jpg" width="600px" /></p>

<p>这些功能在Kafka自带的<code>SimpleAclAuthorizer</code>都是可以实现的。</p>

<h2 id="saslkerberos-and-ssl-implementation">Sasl/Kerberos and SSL implementation</h2>

<p>sasl 是broker的认证机制，ssl是数据传输的加密和认证机制。从协议的角度来说，kafka支持以下四种：</p>

<ul>
  <li>
    <p>PLAINTEXT (non-authenticated, non-encrypted)</p>

    <p>This channel will provide exact behavior for communication channels as previous releases</p>
  </li>
  <li>
    <p>SSL</p>

    <p>SSL  implementation. Authenticated principal in the session will be from the certificate presented or the peer host. </p>
  </li>
  <li>
    <p>SASL+PLAINTEXT</p>

    <p>SASL authentication will be used over plaintext channel. Once the sasl authentication established between client and server . Session will have client’s principal as authenticated user. There won’t be any wire encryption in this case as all the channel communication will be over plain text .</p>
  </li>
  <li>
    <p>SASL+SSL</p>

    <p>SSL will be established initially and  SASL authentication will be done over SSL. Once SASL authentication is established users principal will be used as authenticated user .  This option is useful if users want to use SASL authentication ( for example kerberos ) with wire encryption.</p>
  </li>
</ul>

<p>实现SSL需要做如下配置：</p>

<ol>
  <li>Generate SSL key and certificate for each Kafka broker
    <ul>
      <li>Ensure that common name (CN) matches exactly with the fully qualified domain name (FQDN) of the server. The client compares the CN with the DNS domain name to ensure that it is indeed connecting to the desired server, not the malicious one.</li>
    </ul>
  </li>
  <li>Creating your own CA</li>
  <li>Signing the certificate</li>
  <li>Configuring Kafka Brokers</li>
  <li>Configuring Kafka Clients
    <ul>
      <li>需要将生成的<code>kafka.client.truststore.jks</code>拷贝到client</li>
      <li>如果进行双向认证则还需要生成和配置<code>kafka.client.keystore.jks</code></li>
    </ul>
  </li>
</ol>

<p>实现SASL需要：</p>

<ol>
  <li>Kerberos
    <ul>
      <li>客户端需要安装 kerberos client</li>
    </ul>
  </li>
  <li>Create Kerberos Principals
    <ul>
      <li>需要对应的用户principal</li>
    </ul>
  </li>
  <li>Make sure all hosts can be reachable using hostnames</li>
</ol>

<p>具体过程参考<a href="http://kafka.apache.org/documentation.html#security">http://kafka.apache.org/documentation.html#security</a></p>

<p><strong>zookeeper安全性</strong></p>

<ol>
  <li>不开通ibgw（端口），bcc无法直接访问</li>
  <li>zookeeper限制ip段，</li>
  <li>增加zookeeper authentication</li>
</ol>

<p>对每个resource都应该能够实现管理和控制。</p>

<h2 id="references">REFERENCES:</h2>

<p><a href="https://cwiki.apache.org/confluence/display/RANGER/Kafka+Plugin">https://cwiki.apache.org/confluence/display/RANGER/Kafka+Plugin</a></p>

<p><a href="https://kafka.apache.org/090/configuration.html">https://kafka.apache.org/090/configuration.html</a></p>

<p><a href="https://kafka.apache.org/090/ops.html">https://kafka.apache.org/090/ops.html</a></p>

<p><a href="https://kafka.apache.org/090/security.html">https://kafka.apache.org/090/security.html</a></p>

<p><a href="http://kafka.apache.org/documentation.html">http://kafka.apache.org/documentation.html</a></p>

<p><a href="http://people.csail.mit.edu/matei/courses/2015/6.S897/readings/kafka.pdf">Kafka: A distributed messaging system for log processing</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Table Join Semantics]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/19/table-join/"/>
    <updated>2016-03-19T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/19/table-join</id>
    <content type="html"><![CDATA[<p>这篇文章主要是记录下各种不同 <code>join</code> 的语义。</p>

<p>在最高层面上，<code>join</code> 分为三种：</p>

<ul>
  <li>INNER</li>
  <li>OUTER</li>
  <li>CROSS</li>
</ul>

<!--more-->

<hr />

<ol>
  <li>
    <p><code>INNER JOIN</code> - fetches data if present in both the tables.</p>
  </li>
  <li>
    <p><code>OUTER JOIN</code> are of 3 types:</p>

    <ul>
      <li><code>LEFT OUTER JOIN</code> - fetches data if present in the left table.</li>
      <li><code>RIGHT OUTER JOIN</code> - fetches data if present in the right table.</li>
      <li><code>FULL OUTER JOIN</code> - fetches data if present in either of the two tables.</li>
    </ul>
  </li>
  <li>
    <p><code>CROSS JOIN</code>, as the name suggests, does [n X m] that joins everything to everything. Similar to scenario where we simply lists the tables for joining (in the FROM clause of the SELECT statement), using commas to separate them.</p>
  </li>
</ol>

<p>重点关注前两种，因为在语法中它们包含 <code>join</code> 这个关键词。语法如下：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
</pre></td><td class="code"><pre><code class=""><span class="line">&lt;join_type&gt; ::= 
</span><span class="line">    [ { INNER | { { LEFT | RIGHT | FULL } [ OUTER ] } } [ &lt;join_hint&gt; ] ]
</span><span class="line">    JOIN</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><code>OUTER</code>是一个可选词，有没有对于语义并没有什么区别。解释下上面的语法，可以看到以下的用法是等价的：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
</pre></td><td class="code"><pre><code class=""><span class="line">A LEFT JOIN B            A LEFT OUTER JOIN B
</span><span class="line">A RIGHT JOIN B           A RIGHT OUTER JOIN B
</span><span class="line">A FULL JOIN B            A FULL OUTER JOIN B
</span><span class="line">A INNER JOIN B           A JOIN B</span></code></pre></td></tr></table></div></figure></notextile></div>

<p><img src="http://i.stack.imgur.com/qje6o.png" width="500px" /></p>

<p>结果可以看到是这样的：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class=""><span class="line">Table A | Table B     Table A | Table B      Table A | Table B      Table A | Table B
</span><span class="line">   1    |   5            1    |   1             1    |   1             1    |   1
</span><span class="line">   2    |   1            2    |   2             2    |   2             2    |   2
</span><span class="line">   3    |   6            3    |  null           3    |  null           -    |   -
</span><span class="line">   4    |   2            4    |  null           4    |  null           -    |   -
</span><span class="line">                        null  |   5             -    |   -            null  |   5
</span><span class="line">                        null  |   6             -    |   -            null  |   6
</span><span class="line">
</span><span class="line">                      OUTER JOIN (FULL)     LEFT OUTER (partial)   RIGHT OUTER (partial)</span></code></pre></td></tr></table></div></figure></notextile></div>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hidden Markov Model]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/19/hmm/"/>
    <updated>2016-03-19T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/19/hmm</id>
    <content type="html"><![CDATA[<p>隐马尔可夫模型（Hidden Markov Model，HMM）是统计模型，它用来描述一个含有隐含未知参数的马尔可夫过程（Markov process）。HMM 被用来对有序的序列数据建模，例如句子中的单词，基因中的基本序列，所以常被应用在语音识别、信息提取、基因测序、股票预测等领域。</p>

<p>在 HMM 中，马尔可夫过程是一类随机过程，原始模型是马尔可夫链。它包含一个状态的有限集，状态的变化只依赖于上一个时间点，而与再之前的时间无任何关系，且状态的轮换是有一定的概率发生。所以可以把马尔可夫过程当成是一个有限状态自动机的概率变种。PageRank 其实也是一种马尔可夫过程。</p>

<p>但是在 HMM 中，状态是未知的，这就是 hidden 的由来，我们只能看到观察值，也就是由状态产生的结果。下图是一个 HMM 的例子。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/24496294.jpg" width="300px" /></p>

<!--more-->

<h2 id="hmm-">1. HMM 模型</h2>

<p>HMM 包含三种假设：</p>

<ul>
  <li>The Markov assumption：现在的状态只依赖于上一个时刻的状态。</li>
  <li>The stationarity assumption：状态的转换概率并不依赖于转换发送的时刻。</li>
  <li>The output independence assumption：观察值生成事件是独立的。</li>
</ul>

<p>HMM 模型由三元组 $&lt;S, O, \theta&gt;$ 组成。$S$ 是有限状态，产生一个观察值 $o, o \in O$。另外 $\theta$ 是另外一个三元组 $&lt;A, B, \pi&gt;$，$A$ 是一个 $\vert S \vert \times \vert S \vert$ 的隐含状态转移概率矩阵，$A_q (r)$ 就表示从状态 $q$ 到 $r$ 的概率；$B$ 是一个 $\vert S \vert \times \vert O \vert$ 的观测状态转移概率矩阵，$B_q(o)$ 表示由状态 $q$ 生成 观察值 $o$ 的概率；$\pi$ 是一个 $\vert S \vert$ 的向量，$\pi_q$ 表示 HMM 开始于状态 $q$ 的概率。</p>

<p>在大部分应用中，稀疏矩阵就够用了，现在我们规定 $A_q(r) \ge 0, B_q(o) \ge 0, \pi_q \ge 0$，并且有</p>

<p><script type="math/tex"> \underset{r \in S}{\Sigma} A_q(r)=1\ \forall q, \underset{o \in O}{\Sigma} B_q(o)=1\ \forall q, \underset{q \in S}{\Sigma} \pi_q=1</script>。</p>

<p>一个观察序列的生成如下：</p>

<ol>
  <li>$t=1$，从 $\pi$ 的分布中选择一个初始状态 $q$</li>
  <li>观察值 $o \in O$ 从 $B_q$ 的分布中生成</li>
  <li>新的状态 $r$ 根据上一个状态的分布 $A_q$ 得到</li>
  <li>重复上述过程直到生成的观察值达到指定长度</li>
</ol>

<p>下图表示一个 part-of speech tagging 的例子，即给单词标记词的词义属性 (determiner, adjective, noun, and verb)。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/24593933.jpg" width="500px" /></p>

<h2 id="hmm--1">2. HMM 的三个问题</h2>

<p>有以下几个关于 HMM 的基础问题。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/12179682.jpg" width="520px" /></p>

<h3 id="the-forward-algorithm">2.1 The Forward Algorithm</h3>

<p>现在我们解答第一个问题，观察值 $x$ 的概率也就是关于 $x$ 和所有可能的词性 $y$ 组合的联合概率之和。$y$ 的个数是关于 $x$ 长度的指数级别，所以这种方法并不现实。那么有什么其他方法？</p>

<p>现在提出另外一个相关的问题，在时间 $t$ 的状态为 $q$，那么我们观察到的序列为 $&lt;x_1, x_2…x_t&gt;$ 的概率为多大？假设这个概率是 $\alpha_t(q)$，可以看到 $\alpha_t(q)$ 是一个 $\vert x \vert \times \vert S \vert$ 的矩阵，称为 trellis，容易知道 $\alpha_1(q) = \pi_q \cdot B_q(x_1)$。根据时刻 $t$ 的 trellis，我们可以很容易地得到 $t+1$ 时刻的 trellis。</p>

<script type="math/tex; mode=display"> \alpha_{t+1}(r) = B_r(x_{t+1}) \cdot \underset{q \in S}{\Sigma} \alpha_t(q) \cdot A_q(r) </script>

<p>所以，最后我们可以在多项式时间内得到时刻 $\vert x \vert$ 的观察值概率：</p>

<script type="math/tex; mode=display"> Pr(x; \theta) = \underset{q \in S}{\Sigma} \alpha_{\vert x \vert}(q)</script>

<p>上面例子的示例为：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/14971721.jpg" width="300px" /></p>

<h3 id="the-viterbi-algorithm">2.2 The Viterbi Algorithm</h3>

<p>现在回答第二个问题，也就是求最有可能产生观察值的状态序列。</p>

<p>从 Forward Algorithm 得到启发，我们可以定义 Viterbi Probability $\gamma_t(q)$，表示在时刻 $t$ 产生观察值并且最后的状态为 $q$ 的状态序列的概率。因为最后要重新构造状态序列，所以我们另外定义 backpointer, $bp_t(q)$，表示在时刻 $t-1$ 的状态。可以得到以下公式：</p>

<script type="math/tex; mode=display"> \gamma_1(q) = \pi_q \cdot B_q(x_1),\ bp_1(q) = -1</script>

<script type="math/tex; mode=display"> \gamma_t(q) = \underset{q \in S}{max}\ \gamma_{t-1}(q) \cdot A_q(r) \cdot B_r(x_t)</script>

<script type="math/tex; mode=display"> bp_t(r) = \underset{q \in S}{argmax}\ \gamma_{t-1}(q) \cdot A_q(r) \cdot B_r(x_t)</script>

<p>最后为了得到最有可能的状态序列 $y^*$，我们选择时刻 $\vert x \vert$ 概率最高的 viterbi probability。整个序列可以根据 backpointer 递归求出来：</p>

<script type="math/tex; mode=display"> y_{\vert x \vert}^* = \underset{q \in S}{argmax}\ \gamma_{\vert x \vert}(q),\ y_{t-1}^* = bp_t(y_t)</script>

<h3 id="parameter-estimation-for-hmms">2.3 Parameter Estimation for HMMs</h3>

<p>现在来看问题3，已知 $S,O$，要求最有可能生成观察序列的参数 $\pi^*$。观察值是由未知的状态序列产生的，这时可以通过 EM 算法最优化观察值的 marginal likelihood 得到参数估计。</p>

<p>假设未知的状态是已知的，那么参数的最大似然估计可以根据测试集的得到：在所有测试集中从状态 $q$ 转移到状态 $r$ 的比例，$T(q \to r)$；状态 $q$ 生成观察值 $o$ 的次数 $O(q \uparrow o)$；起始状态 $q$ 的次数 $I(q)$。下面给出 fully observable case 的参数最大似然估计，$N(q)$ 表示马尔可夫过程进入状态 $q$ 的次数：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/64200477.jpg" width="500px" /></p>

<p>那么又怎样才能在未知状态序列的情况下做参数估计呢？ 可以看到在 fully observable case ，每个马尔可夫过程中的状态转换记为 1，这样就可以统计参数的最大似然估计。但是未知状态序列的情况下，我们可以想象每个状态转换的发生都是有一定概率，这个概率其实就是 “posterior probability of the transition, given the model and an observation sequence”。根据这个概率，可以计算特定状态转换的期望次数。于是我们得到如下的公式：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/47910145.jpg" width="500px" /> </p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/15960296.jpg" width="400px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/46548481.jpg" width="400px" /></p>

<p>因为马尔可夫过程的独立假设，我们其实包含的是 $2 \vert S \vert +1$ 个独立的优化问题：求解 $\pi$ 是一个；$\vert S \vert$ 个解决 $A_q(\cdot)$；$\vert S \vert$ 个解决 $B_q(\cdot)$。</p>

<p>解释下上面的后验概率。这个后验概率其实就是关于 $\theta$ 的先验概率加上观察值这个 evidence 形成的，包含有状态转移的后验概率和观察值生成的后验概率。这两个概率又都可以由 forward probabilities $\alpha_t(\cdot)$ 和 backward probabilities $\beta_t(\cdot)$ 得到。</p>

<ul>
  <li>forward probabilities：在时刻 $t$ 到达某个状态时生成观察值序列 $&lt;x_1, x_2….x_t&gt;$ 的概率</li>
  <li>backward probabilities：在时刻 $t$ 到达某个状态后生成观察值序列 $&lt;x_{t+1}, x_{t+2}….x_{\vert x \vert}&gt;$ 的概率</li>
</ul>

<p>这时候两个后验概率就可以写成</p>

<script type="math/tex; mode=display">Pr(y_i = q \vert x;\theta) = \alpha_i(q) \cdot \beta_i(q)</script>

<script type="math/tex; mode=display">Pr(y_i=q, y_{i+1}=r \vert x;\theta) = \alpha_i(q) \cdot A_q(r) \cdot B_r(x_{i+1}) \cdot \beta_{i+1}(q)</script>

<p><strong>The backward algorithm.</strong> 类似于forward 和 Viterbi algorithms， backward algorithm 也可以用动态规划算法计算，在时刻 $\vert x \vert$ 初始公式为 $\beta_{\vert x \vert}(q) = 1$，递归如下：</p>

<script type="math/tex; mode=display">\beta_t(q) = \underset{r \in S}{\Sigma} \beta_{t+1}(r) \cdot A_q(r) \cdot B_r(x_{t+1}) </script>

<p><strong>重新总结下。</strong>在 EM 迭代中，我们想要根据 $M=&lt;S,O,\theta^{(i)}&gt;$ 得到 $\theta^{(i+1)}$。每个训练实例都可以独立计算，根据上述的算法计算 forward 和 backward probabilities，这些后验概率就用来计算状态转换、观察值生成和初始状态的期望次数。各个训练实例中的期望值之和也就是 E-step。M-step 就是进行 normalizing，计算 $\pi_q,A_q(r),B_q(o)$。HMM 的 EM 参数估计中有几点需要注意：</p>

<ul>
  <li>HMM 的似然函数是非凸的，EM 只能找到局部最优值，所以算法依赖于初始值。</li>
  <li>如果一个参数在 EM 过程中变为 0，那么接下来就会一直为 0.</li>
  <li>计算过程容易造成 arithmetic underflow，可以用概率对数化进行解决。</li>
</ul>

<h2 id="hmm-in-mr">3. HMM in MR</h2>

<p>HMM 的参数估计很有效地在 MR 中进行并行化：</p>

<ul>
  <li>计算量比较大的为 forward 和 backward 算法，而每个训练实例都可以单独计算，所以理论上可以为每个实例都分配一个 mapper</li>
  <li>M-step 其实就是 $2 \vert S \vert +1$ 个优化问题，因此可以用相应个数的 reducer 进行计算。</li>
</ul>

<p>对应的算法如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/53556849.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-19/60561193.jpg" width="500px" /></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Practice in Recommend System]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/16/rs-note/"/>
    <updated>2016-03-16T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/16/rs-note</id>
    <content type="html"><![CDATA[<p>本文作为推荐系统实践笔记。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/11336234.jpg" width="350px" /></p>

<p>推荐系统是为了解决信息过载问题，一般说来这个问题还可以用搜索引擎解决，但是搜索引擎需要需要用户主动提供准确的关键词来寻找信息；推荐系统不需要用户提供明确的需求,而是通过分析用户的历史行为给用户的兴趣建模,从而主动给用户推荐能够满足他们兴趣和需求的信息。</p>

<p>总的来说，<strong>搜索引擎满足了用户有明确目的时的主动查找需求,而推荐系统能够在用户没有明确目的的时候帮助他们发现感兴趣的新内容</strong>。</p>

<!--more-->

<p>推荐系统可以更好地发掘物品的长尾，推荐系统通过发掘用户的行为，找到用户的个性化需求，从而将长尾商品准确地推荐给需要它的用户，帮助用户发现那些他们感兴趣但很难发现的商品。个性化推荐系统应用包括：</p>

<ul>
  <li>电子商务</li>
  <li>电影和视频网站</li>
  <li>个性化音乐网站电台</li>
  <li>社交网络</li>
  <li>个性化阅读</li>
  <li>基于位置的服务</li>
  <li>个性化邮件</li>
  <li>个性化广告</li>
</ul>

<p>一般来说,一个新的推荐算法最终上线，需要完成3个实验：</p>

<ul>
  <li>首先，需要通过离线实验证明它在很多离线指标上优于现有的算法。</li>
  <li>然后，需要通过用户调查确定它的用户满意度不低于现有算法。</li>
  <li>最后，通过在线的AB测试确定它在我们关系的指标上由于现有的算法。</li>
</ul>

<p>指标包括以下：</p>

<ol>
  <li>
    <p>用户满意度，反馈按钮，点击率，用户停留时间，转化率</p>
  </li>
  <li>
    <p>预测准确度，可以通过离线实验计算</p>

    <ul>
      <li>
        <p>评分预测的预测准确度一般通过均方根误差(RMSE)和平均绝对误差(MAE)计算。</p>

        <script type="math/tex; mode=display"> RMSE = \frac{\sqrt{\sum_{u,i \in T}(r_{ui}-\hat{r}_{ui})^2}}{\vert T \vert}，MAE = \frac{\sum_{u,i \in T} \vert r_{ui}-\hat{r}_{ui} \vert}{\vert T \vert} </script>

        <ul>
          <li>用户u和物品i，$r_{ui}$ 是用户u对物品i的实际评分，$\hat{r}_{ui}$ 是推荐算法给出的预测评分</li>
          <li>RMSE加大了对预测不准的用户物品评分的惩罚，因而对系统的评测更加苛刻；如果评分系统是基于整数建立的，那么对预测结果取整会降低MAE的误差。</li>
        </ul>
      </li>
      <li>
        <p>TopN推荐的预测准确率一般通过准确率(precision)/召回率(recall)度量</p>

        <script type="math/tex; mode=display"> Recall = \frac{\sum_{u \in U} \vert R(u) \cap T(u) \vert }{\sum_{u \in U} \vert  T(u) \vert}，Precision = \frac{\sum_{u \in U} \vert R(u) \cap T(u) \vert }{\sum_{u \in U} \vert  R(u) \vert} </script>

        <ul>
          <li>$R(u)$ 是根据用户在训练集上的行为给用户作出的推荐列表，而 $T(u)$ 是用户在测试集上的行为列表。</li>
          <li>
            <u>召回率描述有多少比例的用户—物品评分记录包含在最终的推荐列表中,而准确率描述最终的推荐列表中有多少比例是发生过的用户—物品评分记录</u>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>覆盖率</p>

    <ul>
      <li>描述一个推荐系统对物品长尾的发掘能力。表示推荐系统能够推荐出来的物品占总物品集合的比例。</li>
      <li>系统的用户集合为 $U$，推荐系统给每个用户推荐一个长度为N的物品列表 $R(u)$。</li>
      <li>物品在推荐列表中出现次数的分布描述推荐系统挖掘长尾的能力，可以用信息熵和基尼系数定义覆盖率。分配不均匀，基尼系数大，表示覆盖率低。</li>
    </ul>
  </li>
  <li>
    <p>多样性</p>

    <ul>
      <li>为了满足用户广泛的兴趣，推荐列表需要能够覆盖用户不同的兴趣领域，即推荐结果需要具有多样性，描述推荐列表物品两两之间的不相似性。</li>
    </ul>
  </li>
  <li>
    <p>新颖性</p>
  </li>
  <li>
    <p>惊喜度</p>
  </li>
  <li>
    <p>信任度</p>

    <ul>
      <li>需要增加推荐系统的透明度</li>
      <li>虑用户的社交网络信息,利用用户的好友信息给用户做推荐,并且用好友进行推荐解释</li>
    </ul>
  </li>
  <li>
    <p>实时性</p>

    <ul>
      <li>实时地更新推荐列表来满足用户新的行为变化</li>
      <li>能够将新加入系统的物品推荐给用户</li>
    </ul>
  </li>
  <li>
    <p>健壮性</p>
  </li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-14/24652935.jpg" width="500px" /></p>

<h2 id="section">一 利用用户行为数据</h2>

<p>存储的日志种类：</p>

<ul>
  <li>raw log：网站在运行过程中都产生大量原始日志</li>
  <li>session log：原始日志按照用户行为汇总成会话日志，其中每个会话表示一次用户行为和对应的服务</li>
  <li>impression log：展示日志，session log的一种，在搜索引擎和搜索广告系统中,服务会为每次查询生成一个展示日志，记录了查询和返回结。</li>
  <li>click log：点击了某个结果,这个点击信息会被服务器截获并存储在点击日志</li>
</ul>

<p>一个并行程序会周期性地归并展示日志和点击日志,得到的会话日志中每个消息是一个用户提交的查询、得到的结果以及点击。会话日志通常存储在分布式数据仓库中,如支持离线分析的Hadoop Hive和支持在线分析的Google Dremel。</p>

<p>用户行为在个性化推荐系统中一般分两种</p>

<ul>
  <li>显性反馈行为(explicit feedback)</li>
  <li>隐性反馈 行为(implicit feedback)</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-14/78274688.jpg" width="500px" /></p>

<p>仅仅基于用户行为数据设计的推荐算法一般称为<strong>协同过滤算法</strong>，包括但不限于：</p>

<ul>
  <li>基于邻域的方法(neighborhood-based)
    <ul>
      <li>基于用户的协同过滤算法</li>
      <li>基于物品的协同过滤算法</li>
    </ul>
  </li>
  <li>隐语义模型 (latent factor model)</li>
  <li>基于图的随机游走算法(random walk on graph)</li>
</ul>

<h3 id="section-1">1.1 基于用户的协同过滤算法</h3>

<p>基于用户的协同过滤算法主要包括两个步骤。</p>

<ol>
  <li>找到和目标用户兴趣相似的用户集合。</li>
  <li>找到这个集合中的用户喜欢的,且目标用户没有听说过的物品推荐给目标用户.</li>
</ol>

<p>步骤1的关键就是计算两个用户的兴趣相似度。这里，协同过滤算法主要利用行为的相似度计算兴趣的相似度。给定用户u和用户v，$N(u)$ 表示用户u曾经有过正反馈的物品集合，$N(v)$ 为用户v曾经有过正反馈的物品集合。</p>

<p>可以通过如下的Jaccard公式简单地计算u和v的兴趣相似度:</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\vert N(u) \cup N(v) \vert} </script>

<p>或者通过余弦相似度计算:</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\vert N(u) \cap N(v) \vert}{\sqrt{\vert N(u) \vert  \vert N(v) \vert}} </script>

<p>事实上,很多用户相互之间并没有对同样的物品产生过行为,即很多时候 $\vert N(u) \cap N(v) \vert = 0$。我们可以首先计算出$\vert N(u) \cap N(v) \vert \neq 0$ 的用户对 $(u,v)$，然后再对这种情况除以分母。</p>

<p>为此,可以首先建立物品到用户的倒排表,对于每个物品都保存对该物品产生过行为的用户列表。令稀疏矩阵 $C[u][v] = \vert N(u) \cap N(v) \vert$。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/4819139.jpg" width="300px" /></p>

<p>得到用户之间的兴趣相似度后,UserCF算法会给用户推荐和他兴趣最相似的K个用户喜欢的物品。如下的公式度量了UserCF算法中用户u对物品i的感兴趣程度:</p>

<script type="math/tex; mode=display"> p(u,i) = \sum_{v \in S(u,K) \cap N(i)} w_{uv} r_{vi} </script>

<p>其中, $S(u, K)$ 包含和用户u兴趣最接近的K个用户, $N(i)$ 是对物品i有过行为的用户集合, $w_{uv}$ 是用户u和用户v的兴趣相似度, $r_{vi}$ 代表用户v对物品i的兴趣。</p>

<p>可以使用改进的余弦相似度公式来提高UserCF的推荐性能：</p>

<script type="math/tex; mode=display"> w_{uv} = \frac{\sum_{i \in  N(u) \cap N(v)}\frac{1}{log(1+N(i))}}{\sqrt{\vert N(u) \vert  \vert N(v) \vert}} </script>

<p>该公式惩罚了用户u和用户v共同兴趣列表中热门物品对他们相似度的影响。</p>

<h3 id="section-2">1.2 基于物品的协同过滤算法</h3>

<p>基于物品的协同过滤算法(简称ItemCF)给用户推荐那些和他们之前喜欢的物品相似的物品。ItemCF算法并不利用物品的内容属性计算物品之间的相似度,它主要通过分析用户的行为记录计算物品之间的相似度。该算法认为,物品A和物品B具有很大的相似度是因为喜欢物品A的用户大都也喜欢物品B。</p>

<p>基于物品的协同过滤算法主要分为两步。</p>

<ol>
  <li>计算物品之间的相似度。</li>
  <li>根据物品的相似度和用户的历史行为给用户生成推荐列表。</li>
</ol>

<p>可以用下面的公式定义物品的相似度, $\vert N(i) \vert$ 是喜欢物品i的用户数:</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\vert N(i) \cap N(j) \vert}{\sqrt{\vert N(i) \vert \vert N(j) \vert}} </script>

<p>上述公式惩罚了物品j的权重,因此减轻了热门物品会和很多物品相似的可能性。和UserCF算法类似,用ItemCF算法计算物品相似度时也可以首先建立用户—物品倒排表,然后对于每个用户,将他物品列表中的物品两两在共现矩阵C中加1。</p>

<p>如果j非常热门,那么上面公式的分子 就会越来越接近 $N(i)$。尽管上面的公式分母已经考虑到了j的流行度,但在实际应用中,热门的j仍然会获得比较大的相似度。可以采用下面的公式加大惩罚：</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\vert N(i) \cap N(j) \vert}{\vert N(i) \vert^{1-\alpha} \vert N(j) \vert ^{\alpha}} </script>

<p>其中 $\alpha \in [0.5 ,1]$。通过提高$\alpha$, 就可以惩罚热门的j。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/51979298.jpg" width="400px" /></p>

<p>在得到物品之间的相似度后,ItemCF通过如下公式计算用户u对一个物品j的兴趣:</p>

<script type="math/tex; mode=display"> p(u,j) = \sum_{i \in S(j,K) \cap N(u)} w_{ji} r_{ui} </script>

<p>这里 $N(u)$ 是用户喜欢的物品的集合, $S(j,K)$ 是和物品j最相似的K个物品的集合, $w_{ji}$ 是物品j和i的相似度, $r_{ui}$是用户u对物品i的兴趣。该公式的含义是，和用户历史上感兴趣的物品越相似的物品，越有可能在用户的推荐列表中获得比较高的排名。</p>

<p>类似UserCF中的惩罚公式，ItemCF中认为不活跃的用户的贡献程度要比活跃用户更大，所以应该加上Inverse User Frequence修正物品相似度的计算公式：</p>

<script type="math/tex; mode=display"> w_{ij} = \frac{\sum_{u \in  N(i) \cap N(j)}\frac{1}{log(1+N(u))}}{\sqrt{\vert N(i) \vert  \vert N(j) \vert}} </script>

<p>另外如果将ItemCF的相似度矩阵按最大值归一化,可以提高推荐的准确率。如果已经得到了物品相似度矩阵 $w$, 那么可以用如下公式得到归一化之后的相似度 矩阵 $w’$：</p>

<script type="math/tex; mode=display"> w'_{ij} = \frac{w_{ij}}{max_j w_{ij}} </script>

<p>归一化的好处不仅仅在于增加推荐的准确度,它还可以提高推荐的覆盖率和多样性。一般来说,热门的类其类内物品相似度一般比较大。如果不进行归一化,就会推荐 比较热门的类里面的物品,而这些物品也是比较热门的。因此,推荐的覆盖率就比较低。相反, 如果进行相似度的归一化,则可以提高推荐系统的覆盖率。</p>

<h3 id="usercfitemcf">1.3 UserCF和ItemCF的综合比较</h3>

<p>UserCF给用户推荐那些和他有共同兴趣爱好的用户喜欢的物品,而ItemCF给用户推荐那些和他之前喜欢的物品类似的物品。从这个算法的原理可以看到,UserCF的推荐结果着重于反映和用户兴趣相似的小群体的热点,而ItemCF的推荐结果着重于维系用户的历史兴趣。</p>

<p>UserCF适合用于新闻推荐</p>

<ul>
  <li>可以给用户推荐有相似爱好的其他用户看的新闻，这样在抓住热点和时效性的同时，保证了一定程度的个性化。</li>
  <li>技术角度考量，物品的更新速度远远快于新用户的加入速度。</li>
</ul>

<p>ItemCF适合于图书、电子商务和电影网站等的推荐：</p>

<ul>
  <li>在这些网站中，用户的兴趣是比较固定和持久的</li>
  <li>用户不需要流行物品，而是通过自己熟悉领域的知识自己判断物品的质量</li>
  <li>从技术上考虑，用户数目往往非常庞大，物品的数目则是比较少的</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/2625074.jpg" width="700px" /></p>

<h3 id="section-3">1.4 隐语义模型</h3>

<p>除了使用UserCF、ItemCF外，还可以对书和物品的兴趣进行分类做推荐。要解决自动地找到那些类,然后进行个性化推荐，可以使用隐含语义分析技术(latent variable analysis)，采取基于用户行为统计的自动聚类。</p>

<p>隐含语义分析技术从诞生到今天产生了很多著名的模型和方法,其中和该技术相关且耳熟能详的名词有pLSA、LDA、隐含类别模型(latent class model)、隐含主题模型(latent topic model)、 矩阵分解(matrix factorization)。</p>

<h3 id="section-4">1.5 基于图的模型</h3>

<p>如果 将个性化推荐算法放到二分图模型上,那么给用户u推荐物品的任务就可以转化为度量用户顶点 $v_u$ 和与 $v_u$ 没有边直接相连的物品节点在图上的相关性,相关性越高的物品在推荐列表中的权重就越高。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/23922601.jpg" width="400px" /></p>

<p>相关性高的一对顶点一般具有如下特征:</p>

<ul>
  <li>两个顶点之间有很多路径相连</li>
  <li>连接两个顶点之间的路径长度都比较短;</li>
  <li>连接两个顶点之间的路径不会经过出度比较大的顶点。</li>
</ul>

<p>基于这三个要素，可以使用一种基于随机游走的PersonRank算法：</p>

<p>假设要给用户u进行个性化推荐，可以从用户u对应的节点 $v_u$ 开始在用户物品二分图上进行随机游走。游走到任何一个节点时，首先按照概率 $\alpha$ 决定是继续游走，还是停止这次游走并从 $v_u$ 节点开始重新游走。如果决定继续游走，那么就从当前节点指向的节点中按照均匀分布随机选择一个节点作为游走下次经过的节点。这样，经过很多次随机游走后，每个物品节点被访问到的概率会收敛到一个数。最终的推荐列表中物品的权重就是物品节点的访问概率。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/56306116.jpg" width="500px" /></p>

<h2 id="section-5">二 推荐系统冷启动问题</h2>

<p>冷启动问题(cold start)主要分3类。</p>

<ul>
  <li><strong>用户冷启动</strong>  用户冷启动主要解决如何给新用户做个性化推荐的问题。当新用户到来时，我们没有他的行为数据，所以也无法根据他的历史行为预测其兴趣，从而无法借此给他做个性化推荐 </li>
  <li><strong>物品冷启动</strong>  物品冷启动主要解决如何将新的物品推荐给可能对它感兴趣的用户这一问题。 </li>
  <li><strong>系统冷启动</strong>  系统冷启动主要解决如何在一个新开发的网站上设计个性化推荐系统,从而在网站刚发布时就让用户体验到个性化推荐服务这一问题。</li>
</ul>

<p>对于这3种不同的冷启动问题,有不同的解决方案。一般来说,可以参考如下解决方案</p>

<ul>
  <li><strong>提供非个性化的推荐</strong>   非个性化推荐的最简单例子就是热门排行榜,我们可以给用户推荐热门排行榜,然后等到用户数据收集到一定的时候,再切换为个性化推荐。</li>
  <li>利用用户注册时提供的年龄、性别等数据做粗粒度的个性化推荐。</li>
  <li>利用用户的社交网络获取好友信息，然后给用户推荐好友喜欢的物品。</li>
  <li>要求用户登录时对一些物品进行反馈，收集用户对这些物*品的兴趣信息，然后给用户推荐那些和这些物品相似的物品。</li>
  <li>对于新加入的物品,可以利用内容信息，将它们推荐给喜欢过和它们相似的物品的用户。</li>
  <li>在系统冷启动时，可以引入专家的知识，通过一定的高效方式迅速建立起物品的相关度表。</li>
</ul>

<p>可以用一个决策树解决启动用户兴趣的物品问题：</p>

<p>首先,给定一群用户用这群用户对物品评分的方差度量这群用户兴趣的一 致程度。如果方差很大,说明这一群用户的兴趣不太一致,反之则说明这群用户的兴趣比较一致。</p>

<script type="math/tex; mode=display">D(i) = \sigma_{u \in N^+(i)} + \sigma_{u \in N^-(i)} + \sigma_{u \in N^*(i)}</script>

<p>其中，$N^+(i)$ 是喜欢物品i的用户集合，$N^-(i)$ 是不喜欢物品i的用户集合，$N^*(i)$ 是没有对物品
i评分的用户集合。</p>

<p>接着会从所有用户中找到具有最高区分度的物品i，然后将用户分成3 类。接着在每类用户中再找到最具区分度的物品，如此迭代到叶子节点。</p>

<h3 id="section-6">2.1 利用物品的内容信息</h3>

<p>UserCF算法对物品冷启动问题并不非常敏感。因为，UserCF在给用户进行推荐时，首先找到和用户兴趣相似的一群用户，然后给用户推荐这一群用户喜欢的物品。那么需要解决的是第一个用户从哪儿发现新的物品。可以考虑利用物品的 内容信息,将新物品先投放给曾经喜欢过和它内容相似的其他物品的用户。</p>

<p>对于ItemCF算法来说,物品冷启动就是一个严重的问题。新物品的加入需要更新物品相似度表，但这个操作非常耗时。为此,我们只能利用物品的内容信息计算物品相关表，并且频繁地更新相关表(比如半小时计算一次)。</p>

<p>物品的内容可以通过向量空间模型表示，该模型会将物品表示成一个关键词向量。每个关键词都有权重，可以用TF-IDF表示。得到向量后，就可以用余弦相似度等计算物品的相似度。这里同样可以建立关键词—物品的倒排表加速文档集合相似度的计算过程。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-15/58154911.jpg" width="400px" /></p>

<p>另外，如果两篇文章的关键词虽然不同，但关键词所属的话题是相同的时，可以使用话题模型，代表算法是LDA。</p>

<blockquote>
  <p>任何模型都有一个假设，LDA作为一种生成模型，对一篇文档产生的过程进行了建模。话题模型的基本思想是，一个人在写一篇文档的时候，会首先想这篇文章要讨论哪些话题，然后思考这些话题应该用什么词描述，从而最终用词写成一篇文章。因此，文章和词之间是通过话题联系的。</p>
</blockquote>

<h2 id="section-7">三 利用用户标签数据</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/51079519.jpg" width="500px" /></p>

<p>上图中的第三种方式是通过一些特征(feature)联系用户和物品，给用户推荐那些具有用户喜欢的特征的物品。特征有不同的表现方式</p>

<ul>
  <li>物品的属性集合</li>
  <li>隐语义向量(latent factor vector)</li>
  <li>物品的标签，包括作者或者专家给物品打标签;另一种是UGC标签</li>
</ul>

<p>UGC的标签系统是一种表示用户兴趣和物品语义的重要方式。当一个用户对一个物品打上一个标签，这个标签一方面描述了用户的兴趣，另一方面则表示了物品的 语义，从而将用户和物品联系了起来。</p>

<p>一个简单的算法如下：</p>

<ul>
  <li>统计每个用户最常用的标签。</li>
  <li>对于每个标签，统计被打过这个标签次数最多的物品。</li>
  <li>对于一个用户，首先找到他常用的标签，然后找到具有这些标签的最热门物品推荐给这个用户。</li>
</ul>

<p>用户u对物品i的兴趣公式为：$p(u,i)=\sum_b n_{u,b} n_{b,i}$</p>

<p>$B(u)$ 是用户u打过的标签集合, $B(i)$ 是物品i被打过的标签集合, $n_{u,b}$ 是用户u打过标签b的次数, $n_{b,i}$是物品i被打过标签b的次数。</p>

<p>可以进行如下改进：</p>

<ul>
  <li>TF-IDF： 上式给热门标签和物品过大的权重,从而不能反应用户个性化的兴趣。改进公式如下，$n_b^{(u)}$ 记录了标签b被多少个不同的用户使用过，$n_i^{(u)}$记录了物品i被多少个不同的用户打过标签：</li>
</ul>

<script type="math/tex; mode=display"> p(u,i)=\underset{b}{sum} \frac{n_{u,b}}{log(1+n_b^{(u)})} \frac{n_{b,i}}{log(1+n_i^{(u)})}</script>

<ul>
  <li>
    <p>数据稀疏性：通过标签扩展解决，方法包括话题模型，基于邻域的方法（从数据中统计出标签的相似度）</p>
  </li>
  <li>
    <p>标签清理：只保留正向推荐的标签词；另外可以将标签作为推荐解释。</p>
  </li>
</ul>

<h2 id="section-8">四 利用上下文信息</h2>

<p>用户所处的上下文(context)包括用户访问推荐系统的时间、地点、心情等。时间信息对于用户兴趣的影响表现在以下几个方面：</p>

<ul>
  <li>用户兴趣是变化的</li>
  <li>物品是有生命周期和时效性
    <ul>
      <li>物品平均在线天数</li>
      <li>相隔T天系统物品流行度向量的平均相似度</li>
    </ul>
  </li>
  <li>季节效应</li>
</ul>

<p>实现推荐系统的实时性除了对用户行为的存取有实时性要求，还要求推荐算法本身具有实时性，推荐算法实时性意味着：</p>

<ul>
  <li>要求在每个用户访问推荐系统时，都根据用户这个时间点前的行为实时计推荐列表。</li>
  <li>需要平衡考虑用户的近期行为和长期行为。</li>
</ul>

<p>推荐系统每天推荐结果的变化程度被定义为推荐系统的时间多样性。首先，需要保证推荐系统能够在用户有了新的行为后及时调整推荐结果，使推荐结果满足用户最近的兴趣；其次，需要保证推荐系统在用户没有新的行为时也能够经常变化一下结果，具有一定的时间多样性。</p>

<p>如果用户没有行为，可以：</p>

<ul>
  <li>在生成推荐结果时加入一定的随机性。</li>
  <li>记录用户每天看到的推荐结果，对之前的推荐结果进行降权。</li>
  <li>每天给用户使用不同的推荐算法。</li>
</ul>

<h3 id="section-9">4.1 时间上下文推荐算法</h3>

<ol>
  <li>
    <p>最近最热门</p>

    <p>给定时间T, 物品i最近的流行度 $n_i(T)$ 可以定义为</p>

    <script type="math/tex; mode=display">% &lt;![CDATA[
n_i(T)=\underset{(u,i,t) \in Train, t<T}{\Sigma} \frac{1}{1+\alpha (T-t)} %]]&gt;</script>
  </li>
  <li>
    <p>时间上下文相关的ItemCF算法</p>

    <ul>
      <li>用户在相隔很短的时间内喜欢的物品具有更高相似度</li>
      <li>用户近期行为相比用户很久之前的行为,更能体现用户现在的兴趣。</li>
    </ul>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/45373851.jpg" width="600px" /></p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/9416103.jpg" width="350px" /></p>

    <p>其中, $t_0$ 是当前时间。</p>
  </li>
  <li>
    <p>时间上下文相关的UserCF算法</p>
    <ul>
      <li>类似于ItemCF算法，在权重和预测部分增加时间衰减因子</li>
      <li>对于用户u和用户v共同喜欢的物品i增加了一个时间衰减因子。</li>
      <li>考虑和用户u兴趣相似用户的最近兴趣</li>
    </ul>
  </li>
</ol>

<h2 id="section-10">五 利用社交网络数据</h2>

<p>社会化推荐之所以受到很多网站的重视，是缘于如下优点：</p>

<ul>
  <li>好友推荐可以增加推荐的信任度</li>
  <li>社交网络可以解决冷启动问题</li>
</ul>

<ol>
  <li>
    <p>基于邻域的社会化推荐算法</p>

    <p>也就是给用户推荐好友喜欢的物品集合。$p_{ui} = \underset{v \in out(u)}{\Sigma} w_{uv} r_{vi}$</p>

    <p>其中 $out(u)$ 是用户u的好友集合，如果用户v喜欢物品i，则 $r_{vi}=1$，否则 $r_{vi}=0$。$w_{uv}$ 由两部分相似度构成，一部分是用户u和用户v的熟悉程度，另一部分是用户u和用户v的兴趣相似度。</p>

    <script type="math/tex; mode=display"> familiarity(u,v) = \frac{\vert out(u) \cap out(v) \vert}{\vert out(u) \cup out(v) \vert}</script>

    <script type="math/tex; mode=display"> similiarity(u,v) = \frac{\vert N(u) \cap N(v) \vert}{\vert N(u) \cup N(v) \vert}</script>

    <p>其中 $N(u)$ 是用户u喜欢的物品集合。</p>
  </li>
  <li>
    <p>基于图的社会化推荐算法</p>

    <p>在社交网站中存在两种关系，一种是用户对物品的兴趣关系，一种是用户之间的社交网络关系。需要将这两种关系建立到图模型中。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/68899610.jpg" width="300px" /></p>

    <p>该图上有用户顶点（圆圈）和物品顶点（方块）两种顶点。在定义完图中的顶点和边后,需要定义边的权重。其中用户和用户之间边的权重可以定义为用户之间相似度的 $\alpha$ 倍（包括熟悉程度和兴趣相似度）,而用户和物品之间的权重可以定义为用户对物品喜欢程度的 $\beta$ 倍。$\alpha,\beta$ 根据应用的需求确定。</p>
  </li>
</ol>

<p>大型网站中用户数目、历史行为记录非常庞大，所以不太可能将用户的所有行为都缓存在内存中，只能在数据库前做一个热数据的缓存。如果我们需要比较实时的数据，这个缓存中的数据就要比较频繁地更新，因而避免不了数据库的查询。数据库查询一般是很慢的，所以在实际做推荐时获取用户历史行为数据比较困难。</p>

<p>可以从几个方面改进基于邻域的社会化推荐算法,让它能够具有比较快的响应时间:</p>

<ul>
  <li>只拿出和用户相似度最高的N个好友；只返回用户最近1个月的行为。</li>
  <li>重新设计数据库
    <ul>
      <li>首先，为每个用户维护一个消息队列，用于存储他的推荐列表;</li>
      <li>当一个用户喜欢一个物品时，就将(物品ID、用户ID和时间)这条记录写入关注该用户的推荐列表消息队列中;</li>
      <li>当用户访问推荐系统时，读出他的推荐列表消息队列，对于这个消息队列中的每个物品，重新计算该物品的权重。</li>
    </ul>
  </li>
</ul>

<u>对比于协同过滤推荐，社会化推荐的优势不在于增加预测准确度，而是在于通过用户的好友增加用户对推荐结果的信任度，从而让用户单击那些很冷门的推荐 结果。</u>

<p>信息流推荐可以参考Facebook的EdgeRank算法。</p>

<p>另外好友推荐算法在社交网络上被称为链接预测(link prediction)，可以基于以下方法做推荐：</p>

<ul>
  <li>基于内容的匹配</li>
  <li>基于共同兴趣的好友推荐</li>
  <li>基于社交网络图的好友推荐</li>
</ul>

<h2 id="section-11">六 推荐系统实例</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/94386004.jpg" width="400px" /></p>

<p>从实时存取的角度上看，购买、收藏、评论、评分、分享等行为都是需要实时存取的，因为只要用户有了这些行为，界面上就需要体现出来，比如用户购买了商品后，用户的个人购买列表中就应立即显示用户购买的商品。而有些行为，比如浏览网页的行为和搜索行为并不需要实时存取。</p>

<p>数据能否实时存取在推荐系统中非常重要，因为推荐系统的实时性主要依赖于能否实时拿到用户的新行为。只有快速拿到大量用户的新行为，推荐系统才能够实时地适应用户当前的需求，给用户进行实时推荐。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/79737632.jpg" width="600px" /></p>

<p>推荐系统由多个推荐引擎组成，每个推荐引擎负责一类特征和一种任务，而推荐系统的任务只是将推荐引擎的结果按照一定权重或者优先级合并、排序然后返回。多个推荐引擎还可以：</p>

<ul>
  <li>可以方便地增加/删除引擎,控制不同引擎对推荐结果的影响。</li>
  <li>可以实现推荐引擎级别的用户反馈。</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/32415777.jpg" width="500px" /></p>

<p>如上图所示推荐引擎架构主要包括3部分：</p>

<ul>
  <li>该部分负责从数据库或者缓存中拿到用户行为数据，通过分析不同行为，生成当前用户的特征向量。不过如果是使用非行为特征，就不需要使用行为提取和分析模块了。该模块的输出是用户特征向量。</li>
  <li>该部分负责将用户的特征向量通过特征-物品相关矩阵转化为初始推荐物品列表。</li>
  <li>该部分负责对初始的推荐列表进行过滤、排名等处理，从而生成最终的推荐结果。</li>
</ul>

<p>具体对不同部分解释下。</p>

<ol>
  <li>
    <p><strong>用户特征向量</strong>包括两种：</p>

    <ul>
      <li>用户的注册信息中可以提取出来的,主要包括用户 的人口统计学特征。</li>
      <li>
        <p>从用户的行为中计算出来的，需要考虑：</p>

        <ul>
          <li>用户行为的种类（按行为的成本划分）</li>
          <li>用户行为产生的时间，近期行为比较重要</li>
          <li>用户行为的次数</li>
          <li>物品的热门程度</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>
    <p>特征—物品相关推荐</p>

    <p>在得到用户的特征向量后,我们可以根据离线的相关表得到初始的物品推荐列表。在线使用的特征物品相关表一般都不止一张，推荐引擎可以在配置文件中配置很多相关表以及它们的权重。</p>

    <p>特征—物品相关推荐模块还可以接受一个候选物品集合。候选物品集合的目的是保证推荐结果只包含候选物品集合中的物品。</p>
  </li>
  <li>
    <p>过滤模块</p>

    <ul>
      <li>用户已经产生过行为物品</li>
      <li>候选物品以外的物品</li>
      <li>某些质量很差的物品</li>
    </ul>
  </li>
  <li>
    <p>排名模块</p>

    <ul>
      <li>新颖性排名，对推荐结果中热门的物品进行降权。</li>
      <li>多样性，推荐结果分类；控制不同推荐结果的推荐理由出现的次数。</li>
      <li>时间多样性</li>
      <li>用户反馈，通过分析用户之前和推荐结果的交互日志，预测用户会对什么样的推荐结果比较感兴趣。
        <ul>
          <li>CTR预测</li>
        </ul>
      </li>
    </ul>
  </li>
</ol>

<h2 id="section-12">七 评分预测问题</h2>

<p>前面主要介绍TopN推荐，因为它非常接近于满足实际系统的需求。评分预测问题却是推荐系统研究的核心。</p>

<ol>
  <li>
    <p>基于邻域的方法</p>

    <p>基于用户的邻域算法和基于物品的邻域算法都可以应用到评分预测中。基于用户的邻域算法：</p>

    <script type="math/tex; mode=display">\hat{r}_{ui} = \overline{r}_u + \frac{\sum_{v \in S(u,K) \cap N(i)} w_{uv}(r_{vi} -\overline{r}_v)}{\sum_{v \in S(u,K) \cap N(i)} \vert w_{uv} \vert}</script>

    <p>这里, $S(u, K)$ 是和用户u兴趣最相似的K个用户的集合, $N(i)$ 是对物品i评过分的用户集合, $r_{vi}$ 是用户v对物品i的评分, $\overline{r}_v$ 是用户v对他评过分的所有物品评分的平均值。$w_{uv}$ 是相似度，有以下几种：</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/86649362.jpg" width="420px" /></p>

    <p>基于物品的领域算法类似。</p>
  </li>
  <li>
    <p>隐语义模型与矩阵分解模型</p>

    <p>传统的SVD分解有一下几个缺点：</p>

    <ul>
      <li>该方法首先需要用一个简单的方法补全稀疏评分矩阵。</li>
      <li>该方法依赖的SVD分解方法的计算复杂度很高</li>
    </ul>

    <p>基于此，Simon Funk提出的基于新的矩阵分解方法Latent Factor Model (LFM)。</p>

    <p>将评分矩阵R分解为两个低维矩阵相乘 $\hat{R} = P^TQ$，其中 $P_{f \times m}$ 和 $Q_{f \times n}$ 是两个降维后的矩阵。那么，对于用户u对物品i的评分的预测值 $\hat{R}(u,i)=\hat{r}_{ui}$，可以表示为 $\hat{r}_{ui} = \sum_f p_{uf} q_{if}$。</p>

    <p>Simon Funk的思想很简单:可以直接通过训练集中的观察值利用最小化RMSE学习P、Q矩阵。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/90816576.jpg" width="620px" /></p>

    <p>要最小化上面的损失函数，可以利用随机梯度下降法。</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/9179243.jpg" width="620px" /></p>
  </li>
  <li>
    <p>加入偏置项后的LFM</p>

    <p>LFM预测公式通过隐类将用户和物品联系在了一起。但是，实际情况下，一个评分系统有些固有属性和用户物品无关，而用户也有些属性和物品无关，物品也有些属性和用户无关。所以提出加入偏置项后的LFM：</p>

    <script type="math/tex; mode=display">\hat{r}_{ui} = \mu + b_u + b_i + p_u^T \cdot q_i</script>

    <p>$\mu$ 是训练集中所有记录的评分的全局平均数。$b_u$ 是用户偏置(user bias)项，表示了用户的评分习惯中和物品没有关系的因素。$b_i$ 是物品偏置(item bias)项，表示了物品接受的评分中和用户没有什么关系的因素。</p>

    <p>$b_u,b_i$ 通过机器学习训练出来的。同样可以求导，然后用梯度下降法求解这两个参数。</p>
  </li>
  <li>
    <p>考虑邻域影响的LFM</p>

    <p>前面的LFM模型中并没有显式地考虑用户的历史行为对用户评分预测的影响。新的算法成为SVD++。可以将ItemCF的预测算法改成如下方式:</p>

    <p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-16/88102444.jpg" width="620px" /></p>
  </li>
</ol>

<p>另外还可以增加时间因素进行考虑。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Apriori and FP-Growth]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/06/apriori/"/>
    <updated>2016-03-06T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/06/apriori</id>
    <content type="html"><![CDATA[<p>如果说监督学习的形式化表达是 $Pr(Y \vert X)$, 找到最佳的参数最小化每个 $x$ 的epxected error： $argmin_{\theta}\ E_{Y \vert X} L(Y, \theta)$。那么非监督学习的形式化表达就是 $Pr(X)$，目标是在没有 $Y$ 引导的情况下，推测出 $Pr(X)$ 的潜在属性。本文要提到的apriori算法也是一种非监督学习算法，wiki的定义为</p>

<blockquote>
  <p>The Apriori Algorithm is an influential algorithm for mining frequent itemsets for boolean association rules.</p>
</blockquote>

<p>著名的啤酒和尿布例子就是指这个算法。它是属于关联分析中的一种，也就是从大规模数据集中寻找物品间的隐含关系。</p>

<!--more-->

<p>在apriori的定义中出现两个词，frequent itemsets 和 association rules，也就是频繁项集和关联规则，这里解释下频繁项集是经常出现在一块的物品的集合，关联规暗示两种物品之间可能存在很强的关系。下面给个简单的例子：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/5038926.jpg" width="300px" /></p>

<p>集合{葡萄酒，尿布, 豆奶} 就是频繁项集的一个例子，尿布➞葡萄酒 则是关联规则，意味着如果有人买了尿布，那么他很可能也会买葡萄酒。</p>

<h2 id="definition">Definition</h2>

<p>频繁是如何定义的呢？有许多的概念可以表示，主要有</p>

<ul>
  <li><strong>Support</strong>，这个表示数据集包含该项集的记录比例， $S(A) = T(A) / total\ transactions$</li>
  <li><strong>Confidence</strong>，$C(A \to B) = T(A \to B) / T(A)$</li>
  <li><strong>Lift</strong>, $L(A \to B) = C(A \to B)/ T(B)$</li>
</ul>

<p>如果有，Computer ➞ antivirus_software , 其中 support=2%, confidence=60%。
表示的意思是所有的商品交易中有2%的顾客同时买了电脑和杀毒软件，并且购买电脑的顾客中有60%也购买了杀毒软件。</p>

<p>下面我们给出关联规则形式化的定义：</p>

<p>假设 $I = \lbrace i_1, i_2…i_n \rbrace $ 表示items，$i_n$ 是binary attribute，表示商品买或不买。$T = \lbrace t_1, t_2…t_n \rbrace $ 是交易的集合，成为 database。每个交易都有唯一的标示，并且为 $I$ 的一个子集。规则就是 $X \to Y,\ where\ X,Y \subseteq I, X \cap Y = \varnothing$，这里 $X$ 称为 antecedent， $Y$ 称为 consequent.</p>

<h2 id="apriori-algorithm">Apriori Algorithm</h2>

<p>关联规则的生成过程可以分为两步：</p>

<ol>
  <li>首先根据最小support在database中找出所有的频繁项集</li>
  <li>根据所得的频繁项集和最小confidence约束生成规则</li>
</ol>

<p>在database中找到所有的频繁项集是比较困难的，因为需要找到所有可能的 $2^n-1$ 项集（排除空集）。虽然项集的个数是根据 $I$ 的大小呈指数增长，但是可以通过support的downward-closure特性进行有效的搜索。downward-closure表示对于一个频繁项，它的子集也必须是频繁的；对于一个非频繁的集合，它的超集必定也是非频繁的。下面给出伪代码：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/1439703.jpg" width="600px" /></p>

<p>迭代过程可以看成两个步骤：</p>

<ul>
  <li>Join Step: $C_k$ is generated by joining $L_{k-1}$ width itself</li>
  <li>Prune Step: Any (k-1)-itemset that is not frequent cnanot be a subset of a frequent k-itemset</li>
</ul>

<p>下面给出一个示例可以参考：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/4948435.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/92538392.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/62108557.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/26861819.jpg" width="500px" /></p>

<p>这里解释下3-itemset的生成，对于 $\lbrace I1,I2,I3 \rbrace$ 这儿例子，因为是属于L2的笛卡尔积，所以在L2中需要包含有 $\lbrace I1,I2 \rbrace, \lbrace I2, I3 \rbrace, \lbrace I1, I3 \rbrace$。所有不满足的都不能构成 $C_3$。</p>

<p>对于下一步 Generating 4-itemset Frequent Pattern，我们得到是一个空集，所以被剪枝了。最后一步是根据频繁项集生成关联规则。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/33075969.jpg" width="500px" /></p>

<p>对于大的数据量来说，生成频繁项集比较耗时，可以采用下面的方法提高效率。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-6/23943688.jpg" width="500px" /></p>

<h2 id="fp-growth">FP-Growth</h2>

<p>Apriori通过不断的构造候选集、筛选候选集挖掘出频繁项集，需要多次扫描原始数据，当原始数据较大时，磁盘I/O次数太多，效率比较低下。FP-Growth算法则只需扫描原始数据两遍，通过FP-tree数据结构对原始数据进行压缩，效率较高。</p>

<p>搜索引擎中的提示词项就可以用FP-Growth得到，通过输入项找到它的频繁项集。</p>

<p>FP-Growth算法主要分为两个步骤：FP-tree构建、递归挖掘FP-tree。FP-tree构建通过两次数据扫描，将原始数据中的事务压缩到一个FP-tree树，该FP-tree类似于前缀树，相同前缀的路径可以共用，从而达到压缩数据，减少数据库扫描的目的。接着通过FP-tree找出每个item的条件模式基、条件FP-tree，递归的挖掘条件FP-tree得到所有的频繁项集。递归挖掘FP-tree利用分治的思想将任务分解为更小的任务，并且可以避免频繁项集Candidate的生成。</p>

<p>还是以上面的数据库为示例，我们看下产生频繁项集的过程。剩下的挖掘关联规则则和Apriori一样。</p>

<ul>
  <li>
    <p>第一次扫描和Apriori一样，得到1-itemsets和它们的support counts。频繁集是按照support的带下倒序排列。结果为 $L = \lbrace I2:7,I1:6,I3:6,I4:2,I5:2 \rbrace$。</p>
  </li>
  <li>
    <p>第二次扫描的时候构建FP-tree。</p>

    <ul>
      <li>对每个transaction，过滤不频繁集合，剩下的频繁项集按 $L$ 顺序排序</li>
      <li>把每个transaction的1-itemsets插入到FP-tree中，相同前缀的路径可以共用</li>
      <li>同时增加一个header table，把FP-tree中相同item连接起来，也是降序排序</li>
    </ul>
  </li>
</ul>

<p>结果如图所示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/45883923.jpg" width="500px" /></p>

<p>接下来进行频繁项的挖掘。</p>

<p>步骤为：</p>

<ol>
  <li>从header table的最下面的item开始，构造每个item的条件模式基（conditional pattern base）
    <ul>
      <li>顺着header table中item的链表，找出所有包含该item的前缀路径，这些前缀路径就是该item的条件模式基（CPB）</li>
      <li>所有这些CPB的频繁度（计数）为该路径上item的频繁度（计数）</li>
    </ul>
  </li>
  <li>构造条件FP-tree（conditional FP-tree）
    <ul>
      <li>累加每个CPB上的item的频繁度（计数），过滤低于阈值的item，构建FP-tree</li>
    </ul>
  </li>
  <li>FP-Growh：递归的挖掘每个条件FP-tree，累加后缀频繁项集，直到找到FP-tree为空或者FP-tree只有一条路径（只有一条路径情况下，所有路径上item的组合都是频繁项集）</li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/57749816.jpg" width="500px" /></p>

<p>接着上面的例子：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/37306135.jpg" width="500px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-7/29869117.jpg" width="500px" /></p>

<p>FP-Growth算法计算频繁项集的效率要高于Apriori，原因有以下几点：</p>

<ul>
  <li>无需Candidate的生成和检查</li>
  <li>使用压缩的数据结构</li>
  <li>减少重复的数据库扫描，事实上只需要两次</li>
  <li>基本的操作就是计数和构建FP-Tree</li>
</ul>

<h2 id="reference">Reference</h2>

<p><a href="http://120.52.72.49/software.ucv.ro/c3pr90ntcsf0/~cmihaescu/ro/teaching/AIR/docs/Lab8-Apriori.pdf">http://120.52.72.49/software.ucv.ro/c3pr90ntcsf0/~cmihaescu/ro/teaching/AIR/docs/Lab8-Apriori.pdf</a>
<a href="http://120.52.72.51/www3.cs.stonybrook.edu/c3pr90ntcsf0/~cse634/lecture_notes/07apriori.pdf">http://120.52.72.51/www3.cs.stonybrook.edu/c3pr90ntcsf0/~cse634/lecture_notes/07apriori.pdf</a></p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Expectation Maximization]]></title>
    <link href="http://billowkiller.github.io/blog/2016/03/05/em/"/>
    <updated>2016-03-05T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/03/05/em</id>
    <content type="html"><![CDATA[<p>Expectation Maximization, EM算法在参数估计里面有极大的用处，它用于含有隐变量的概率模型参数的极大似然估计，或极大后验概率（MAP）估计。隐变量的概率模型参数的极大似然估计可以理解为，使用的方法还是的极大似然估计，但是要处理隐变量。极大后验概率是一种Beyesian Inference，其实就是把极大似然估计中的参数赋予权值，这个权值是预先定义好的先验概率。可以来看下下表中Frequentist-Bayesian对峙的部分，来感受下EM算法的应用范围：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/88568881.jpg" width="500px" /></p>

<!--more-->

<p>下面我们先从一个Two-Component Gaussian Mixture Model为例，介绍EM算法。</p>

<h2 id="two-component-gaussian-mixture-model">Two-Component Gaussian Mixture Model</h2>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/45836233.jpg" width="600px" /></p>

<p>上图是一个mixture example，左边是我们观察到数据的直方图，右边红线是最大似然拟合的高斯密度函数，绿色的点是用来做两个模型的分类用。</p>

<p>这里其实我们得到的是一些数据点，对于这些点的分布完全一无所知。先做出如下假设，这是两个高斯模型混合后的sample data。</p>

<script type="math/tex; mode=display"> Y_1 \sim N(\mu_1, \theta_1^2) </script>

<script type="math/tex; mode=display"> Y_2 \sim N(\mu_2, \theta_2^2) </script>

<script type="math/tex; mode=display"> Y = (1 - \Delta)\cdot Y_1 + \Delta \cdot Y_2,\  \Delta \in \{0,1\}, Pr(\Delta =1) = \pi</script>

<p>那么需要我们估计的参数就为 $(\pi, \theta_1, \theta_2) = (\pi, \mu_1, \sigma_1, \mu_2, \sigma_2)$，一共五个参数。使用似然估计，我们可以得到如下过程：</p>

<script type="math/tex; mode=display"> g_Y(y) = (1-\pi)\phi_{\theta_1}(y) + \pi \phi_{\theta_2}(y) </script>

<script type="math/tex; mode=display">log\ likelihood \to l(\theta; Z) = \sum_{i=1}^N log[(1-\pi)\phi_{\theta_1}(y_i) + \pi \phi_{\theta_2}(y_i)] </script>

<p>最大化 $l(\theta; Z)$ 无疑是困难的，因为对数中含有加号。如果我们知道隐变量 $\Delta$ 的取值，那么参数估计就会变得容易，$\phi$ 的估计也就是 $\Delta_i=1$ 的比例，另外 $\theta_1,\theta_2$ 也就变成 $\Delta_i=0，\Delta_i=1$ 的似然估计。</p>

<p>所以问题的关键是 $\Delta$ 的取值，解决问题的思路是采用迭代的方式，每次都用 $\Delta_i$ 的估计值替换：</p>

<script type="math/tex; mode=display">\gamma_i(\theta) = E(\Delta_i \vert \theta,Z) = Pr(\Delta_i=1 \vert \theta,Z)</script>

<p>如此 $\theta_1,\theta_2$ 自然也就可以由最大似然估计求出。在下一次过程中，$\gamma_i(\theta)$ 又可以由上一步估计的 $\theta_1,\theta_2$ 求出。所以我们首先需要给出参数的初始值，就可以由上述过程得到结果。算法入下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/24344888.jpg" width="550px" /></p>

<p>这里需要注意的是，如果我们在某个点取 $\hat{\mu}_1 = y_i, \hat{\sigma}_1=0$ 那么我们可以去到最大的似然值，无限大，但这并不是有用的解。所以我们其实是求解 <u>a good local maximum of the likelihood</u>，因此我们可以设多个初值，最后选择似然值最大的解。</p>

<h2 id="em-in-general">EM in General</h2>

<p>EM算法被用于data augmentation，关于data augmentation的解释如下：</p>

<blockquote>
  <p>maximization of the likelihodd is difficult, but made easier by enlarging the sample with latent data</p>
</blockquote>

<p>上面的例子中我们设的latent data为 $\Delta$，是出于我们对模型的假设；其他的latent data还可以为丢失的观察值。接下来我们介绍EM的通用形式，先给出算法：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/67870944.jpg" width="550px" /></p>

<p>上面的算法中，$Z$ 为观察值，log likelihood是 $l(\theta, Z)$。latent or missing data 为 $Z^m$， 完整的数据为 $T=(Z, Z^m$)，对比于上面的例子 $(Z, Z^m) = (y, \Delta)$。</p>

<ul>
  <li>E step就是完全数据 $T$ 的对数似然函数 $l_0(\theta’; T)$ 关于在给定观察数据 $Z$ 和当前参数 $\theta^{(j)}$ 下对未观察数据 $Z^m$ 的条件概率分布 $Pr(Z^m \vert Z, \theta^{(j)})$ 的期望，得到的是 $Z^m$ 的估计。</li>
  <li>M step就是通过似然估计方法，求未观察数据 $Z^m$ 的条件概率分布的期望的最大值，得到参数 $\theta$ 的重新估计 $\theta’$，在下一个E中变为 $\theta^{(j+1)}$。</li>
</ul>

<p>上面叙述了EM的算法，那么为什么EM算法能有效，也就是近似实现对观测数据的极大似然估计呢？我们看到</p>

<script type="math/tex; mode=display"> Pr(Z^m \vert Z, \theta') = \frac{Pr(Z^m,Z  \vert \theta')}{Pr(Z \vert  \theta')} </script>

<script type="math/tex; mode=display"> \to Pr(Z \vert  \theta') = \frac{Pr(T  \vert  \theta')}{ Pr(Z^m \vert Z, \theta')} </script>

<script type="math/tex; mode=display"> \to l(\theta'; Z) = l_0(\theta'; T) - l_1(\theta'; Z^m \vert Z) </script>

<p>对由 $\theta$ 控制的分布 $T \vert Z$ 数据求期望可以得到：</p>

<script type="math/tex; mode=display"> l(\theta'; Z) = E[l_0(\theta'; T) \vert Z,\theta] - E[l_1(\theta'; Z^m \vert Z) \vert Z,\theta] = Q(\theta', \theta) - R(\theta', \theta) </script>

<p>在 $M\ step$ 中，EM算法求出可以使 $Q(\theta’, \theta)$ 最大化的 $\theta’$，而不是真正的目标函数 $l(\theta’; Z)$。为什么最大化 $Q(\theta’, \theta)$ 最终可以最大化 $l(\theta’; Z)$呢？</p>

<p>可以看到 $R(\theta^*, \theta)$ 是由 $\theta^*$ 决定的条件分布的log-likelihood的期望，这个分布和由 $\theta$ 决定的条件分布是相同的。因此由 Jensen’s inequality 可以得到，$R(\theta’, \theta) \le R(\theta, \theta)$。具体的推导可以参考《统计学习方法》。所以如果 $\theta’$ 最大化 $Q(\theta’, \theta)$ 则</p>

<script type="math/tex; mode=display"> l(\theta'; Z) - l(\theta; Z) = [Q(\theta', \theta) - Q(\theta, \theta)] - [R(\theta', \theta) - R(\theta, \theta)] \ge 0 </script>

<p>所以说EM迭代中，$l(\theta’; Z)$ 一直都会在增大。</p>

<blockquote>
  <p>Jensen’s inequality, $E[\phi(X)] \ge \phi[E(X)]$, for Random variable $X$ and convex function $\phi(x)$</p>
</blockquote>

<p>也就是说在 $M step$ 中完全的最大化是没有必要的，我们只需要找到一个 $\theta^{(j+1)}$ 使得 $Q(\theta^{(j+1)}, \theta^{(j)}) - Q(\theta^{(j)}, \theta^{(j)})$。所以我们得到的EM收敛条件也就是 </p>

<script type="math/tex; mode=display">% &lt;![CDATA[
 \theta^{(j+1)} - \theta^{(j)} < \epsilon\ or\ Q(\theta^{(j+1)}, \theta^{(j)}) - Q(\theta^{(j)}, \theta^{(j)}) < \epsilon  %]]&gt;</script>

<h2 id="em-as-max-max-procedure">EM as max-max Procedure</h2>

<p>EM算法还可以看成是F 函数的极大极大算法， F函数定义如下</p>

<script type="math/tex; mode=display"> F(\theta',  \tilde{P}) = E_{\tilde{P}}[l_0(\theta'; T)] - E_{\tilde{P}}[log \tilde{P}(Z^m)] </script>

<p>$\tilde{P}(Z^m)$也就是隐变量 $Z^m$ 的分布, $- E_{\tilde{P}}[log \tilde{P}(Z^m)]$ 也就是 $\tilde{P}(Z^m)$ 的熵。于是EM算法可以由下图表示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-5/44573110.jpg" width="500px" /></p>

<p>也就是，设 $\theta^{(i)}$ 为第 $i$ 次迭代参数 $\theta$ 的估计，$\tilde{P}^{(i)}$ 为第 $i$ 次迭代参数 $\tilde{P}$ 的估计。在第 $i+1$ 次迭代的两步为：</p>

<ul>
  <li>对固定的 $\theta^{(i)}$，求 $\tilde{P}^{(i+1)}$ 使得 $F(\theta^{(i)},  \tilde{P})$ 极大化</li>
  <li>对固定的 $\tilde{P}^{(i+1)}$，求 $\theta^{(i+1)}$ 使得 $F(\theta,  \tilde{P}^{(i+1)})$ 极大化</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Kernel Logistic Regression versus SVM]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/29/klr-svr/"/>
    <updated>2016-02-29T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/29/klr-svr</id>
    <content type="html"><![CDATA[<p>Logistic Regression和SVM都是分类方法，它们定义线性决策边界（linear decision boundaries）作为划分的依据。但二者在motivation方便完全不同，区别如下</p>

<ul>
  <li>LR初衷是为了让linear regression能够输出二元分类，估计一个实例属于某一类的概率；线性决策边界也只是回归函数的结果，在回归函数中使用阈值作为分类的标准，一般是0.5。决策边界在SVM中来的更为重要，整个模型的目标就是为了获得最优的决策边界。</li>
  <li>每个训练样本都对LR的过程有一定的影响，但SVM只依赖于在决策边界附近的某些点。</li>
  <li>LR适应于低维空间，并且由于使用最大似然估计，所以对噪声不敏感；SVM更适应于高维空间</li>
  <li>没有正规化的LR无法保证获得最好的分离超平面，只能获得margin附近的较高的置信度; SVM则能获得最优的分离超平面。</li>
</ul>

<p>那么二者会有什么联系呢，SVM的kernel function又是如何应用到LR模型的呢？</p>

<!--more-->

<h2 id="loss-function">Loss Function</h2>

<p>我们先来看下Loss Function，它是用来衡量学习函数与数据拟合的程度的。回顾对于机器学习来说有一下几个过程：</p>

<ol>
  <li>假设空间：函数的参数形式，包括lr，svm等</li>
  <li>拟合的衡量：Loss function，likelihood</li>
  <li>bias和variance的trade-off：regularization，bayesian estimator (MAP)</li>
  <li>在假设空间中寻找好的假设：optimization. convex - global. non-convex - multiple starts</li>
  <li>假设的验证：测试数据的预测，cross validation</li>
</ol>

<p>在线性学习方法中，通常我们是要找到一个假设 $y=f(\theta^T x)$，选决定f的参数形式，再通过最大化似然函数或者最小化损失函数找到对应的 $\theta$，常见的几个Loss Function：</p>

<p>For classfication $correct \to y \cdot f &gt; 0;\ incorrect \to y \cdot f &lt; 0$</p>

<ol>
  <li>0/1 loss： $min_\theta \sum_i L_{0/1}(\theta^T x)$. 定义 $L_{0/1}(\theta^T x)=1\ if\ y \cdot f &lt; 0$，其他情况等于0，非凸函数，难以优化。</li>
  <li>Hinge loss: $min_\theta \sum_i H(\theta^T x)$。接近 0/1 损失函数，定义 $H(\theta^T x) = max (0,1-y \cdot f)$</li>
  <li>Logistic loss: $min_\theta \sum_i log(1 + exp(-y \cdot \theta^T x))$. </li>
</ol>

<p>关于3，在逻辑回归中我们最大化似然函数其实就是最小化Logistic loss：</p>

<script type="math/tex; mode=display">\sum_i log \frac{1}{1+exp(-y^{(i)}\cdot \theta^T x^{(i)})} = \sum_i -log (1+exp(-y^{(i)}\cdot \theta^T x^{(i)}))</script>

<script type="math/tex; mode=display">\to min_\theta \sum_i log(1 + exp(-y \cdot \theta^T x))</script>

<p>For regression:</p>

<ol>
  <li>Square loss: $min_\theta \sum_i | y^{(i)} - \theta^T x^{(i)} |^2$</li>
</ol>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-22/70940842.jpg" width="400px" /></p>

<p>如上图所示，SVM使用Hinge Loss；Binomial Deviance就是Logistic Loss，因为output是binomial的；Exponential Loss 可以在Gradient Boost中应用到。</p>

<h2 id="connection-between-svm-and-logistic-regression">Connection between SVM and Logistic Regression</h2>

<p>回顾下soft-margin SVM的原始问题：</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi}{min} \frac{1}{2}w^T w  + C\sum_{n=1}\xi_n</script>

<script type="math/tex; mode=display">s.t.\ y_i(w^T z_n + b) \ge 1-\xi_n,\ \xi_n \ge 0\ for\ all\ n</script>

<p>这里的 $\xi_n$ 实际上就是违反 margin 的距离，称为 margin violation。如果 $(x_n, y_n)$ 不违反 margin，那么 $\xi_n=0$，否则为 $\xi_n=1-y_n(w^T z_n + b)$，从这里我们看到实际上 $\xi_n = max(1-y_n(w^T z_n + b), 0)$，所以原来问题可以写成：</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi}{min} \frac{1}{2}w^T w  + C\sum_{n=1}max(1-y_n(w^T z_n + b), 0)</script>

<p>上式写成 $min\ \frac{1}{2} w^Tw + C \sum \hat{err}$ 就比较熟悉了，这个就是L2 regularization: $min\ \lambda w^Tw + C \sum err$ 嘛。对应关系如下：</p>

<ul>
  <li>soft-margin $\to special\ \hat{err}$</li>
  <li>large margin $\to$ fewer hyperplanes $\to$ L2 regularization for small $w$</li>
  <li>larger C or C $\to$ smaller $\lambda\ to$ less regularization</li>
</ul>

<p>对比于SVM的原始问题，我们发现新的形式并不是凸二次规划问题；不能利用kernel trick；并且max函数不能微分，所以难以解决。那么为什么要变化成这种形式呢？如果设置 linear score: $s=w^T z_n + b$。我们观察下它的损失函数 $\hat{err}_{svm}(s,y) = max(1-ys, 0)$，另外再看下logistic loss: $err_{ll}(ys) = log(1 + exp(-ys))$.</p>

<p>可以对比下上图的损失函数曲线，二者比较接近，并且都是 0/1 损失函数的上限。所以可以把 SVM 当成 L2-regularized logistic regression。以下是几个二分类线性模型的对比：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/76344341.jpg" width="600px" /></p>

<h2 id="kernel-logistic-regression">Kernel Logistic Regression</h2>

<p>现在我们知道 SVM 和 Logistic Regression存在联系，那么是否可以综合二者的有点呢：</p>

<ul>
  <li>SVM flavor: 利用kernel function 得到 $w_{svm}，b_{svm}$ 得到超平面 </li>
  <li>LR flavor: 通过 scalling(A) 和 shifting(B) 匹配最大似然函数的方法细粒度地调优超平面
    <ul>
      <li>often $A &gt; 0$ if $w_{svm}$ reasonably good</li>
      <li>often $B \approx 0$ if $b_{svm}$ reasonably good</li>
    </ul>
  </li>
</ul>

<p>所以新的LR问题可以看成 two-level learning 问题：LR on SVM-transformed data</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/6560678.jpg" width="450px" /></p>

<p>于是我们得到Probabilistic SVM for Soft Binary Classification 的算法，因为 LR 是根据概率分类的，过程如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/75482355.jpg" width="450px" /></p>

<ul>
  <li>这个 Soft Binary Classifier 得到 bounary 与 SVM 的不同，因为有平移 B。</li>
  <li>只需要解两个变量，可以使用GD或者SGD等。</li>
  <li>Kernel SVM 相当于在 $Z$ 空间中进行 LR</li>
</ul>

<p>Kernel SVM 中有 $w_{svm}^T \phi(x) + b_{svm} = \sum_{SV} \alpha_n y_n K(x_n, x) + b_{svm}$，则最后 Probabilistic SVM 的结果为</p>

<script type="math/tex; mode=display"> g(x) = \theta(\sum_{SV} A\alpha_n y_n K(x_n, x) + Ab_{svm} + B)</script>

<p>但这个方法其实并不是在 $Z$ 空间里的最好的解，只是通过两次 scaling 和 shifting 接近最好的解，那么如何得到最好的解呢。这就是我们要介绍的Kernel Logistic Regression。</p>

<p>先来介绍下 Representer Theorem，它的定义如下：</p>

<blockquote>
  <p>the solution of regularization and interpolation problems with Hillbertian penalties can be expressed as a linear combination of the data.</p>
</blockquote>

<p>也就是最优的 $w_* = \sum_{n=1}^N \beta_n z_n$，我们可以把原来在 Hillbertian Space
 的计算放到低维空间中进行。</p>

<script type="math/tex; mode=display"> w_*z = \sum_{n=1}^N \beta_n z_n^Tz = \sum_{n=1}^N \beta_n K(x_n, x)</script>

<p>证明Representer Theorem如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/22880811.jpg" width="500px" /></p>

<p>这其实就表明所有的 L2-regularized linear model 都可以被 kernalized。把损失函数替换成 logistic loss，我们就得到 Kernel Logistic Regression 的优化函数。</p>

<script type="math/tex; mode=display"> \underset{w}{min}\ \frac{\lambda}{N}w^Tw + \frac{1}{N} \sum_{n=1}^N log(1+ exp(-y_n w^T z_n)) </script>

<p>利用 Representer Theorem，将原来对 $w$ 的求解转化为对 $\beta$ 求解：</p>

<script type="math/tex; mode=display"> \underset{\beta}{min}\ \frac{\lambda}{N} \sum_{n=1}^N \sum_{m=1}^N \beta_n \beta_m K(x_n, x_m) +  \frac{1}{N} \sum_{n=1}^N log(1+ exp(-y_n \sum_{m=1}^N \beta_m K(x_m, x_n)))</script>

<p>可以用 GD/SGD 等做最优化求解，<strong>解出来的 $\beta$ 并不同于 SVM 的 $\alpha$，基本上是非零的</strong>。综合上述，总结得到 KLR 其实就是</p>

<blockquote>
  <p>use representer theorem for kernel trick on L2-regularized logistic regression</p>
</blockquote>

<p>对 KLR 还有另外另外的解释</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/45320882.jpg" width="450px" /></p>

<h2 id="support-vector-regression">Support Vector Regression</h2>

<p>最后说下SVR，上面提到 regression 的损失函数 squared error $err(y, w^Tz) = (y- w^Tz)^2$，替换下KLR的损失函数我们可以得到</p>

<script type="math/tex; mode=display"> \underset{w}{min}\ \frac{\lambda}{N}w^Tw + \frac{1}{N} \sum_{n=1}^N (y- w^Tz)^2 </script>

<p>这个就是 <strong>kernel ridge regression</strong>，也可以通过解 $\beta$ 得到答案</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/56123028.jpg" width="500px" /></p>

<p>对 $\beta$ 求导得到</p>

<script type="math/tex; mode=display">\nabla E_{aug}(\beta) = \frac{2}{N}(\lambda K^TI\beta + K^TK\beta - K^Ty) = \frac{2}{N}K^T((\lambda I + K)\beta - y)</script>

<script type="math/tex; mode=display">\nabla E_{aug}(\beta) =0 \to \beta=(\lambda I + K)^{-1}y</script>

<p>因为 Merer’s condition，所以 $K$ 是半正定矩阵，继而上式有解。但是稠密矩阵求反需要 $O(N^3)$ 时间复杂度。可以对比下 linear ridge regression:</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/7052157.jpg" width="450px" /></p>

<p>根据前面所述的SVM和LR之间的关系，我们这里可以吧 kernel ridge regression 看成 least-squares SVM(LLSVM)。它有什么特点呢：</p>

<ul>
  <li>对比soft-margin SVM，有这相似的boundary，但是更多的支持向量。导致预测慢，因为 $\beta$ 比较稠密</li>
</ul>

<p>现在想让 $\beta$ 变得和 soft-margin SVM 的 $\alpha$ 一样稀疏。可以看到 tube regression 的特点，使用 $\epsilon$-insensitive error：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-29/74768649.jpg" width="450px" /></p>

<p>整理下是 L2-regularized tube regression</p>

<script type="math/tex; mode=display"> \underset{w}{min}\ \frac{\lambda}{N}w^Tw + \frac{1}{N} \sum_{n=1}^N\ max(0, \vert w^Tz_n - y \vert - \epsilon)</script>

<p>这个函数没有限制条件，但是max难以微分，并且不能很明显的看出有 sparse $\beta$。发现这个表达式和最开始 soft-SVM 的表示有点像，那么我们可以反向的把它模拟成 standard SVM 形式:</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi^ \vee, \xi ^ \land}{min}\ \frac{1}{2} w^Tw + C \sum_{n=1}^N (\xi_n^ \vee + \xi_n ^ \land)</script>

<script type="math/tex; mode=display">s.t.\ -\epsilon-\xi_n^ \vee \le y_n - w^Tz_n-b \le \epsilon-\xi_n^ \land,\ \xi_n^ \vee \ge 0,\ \xi_n^ \land \ge 0</script>

<p>这就构成 SVR 的原始问题: minimize regularizer + (upper tube violations $\xi_n^ \land$ and lower violations $\xi_n^ \vee$)。这里参数 $C$ 就是 trade-off of regularization and tube violation. 现在要求 SVR 的对偶问题。</p>

<ul>
  <li>Lagrange multiplier $\alpha_n^ \vee\ for\ -\epsilon-\xi_n^ \vee \le y_n - w^Tz_n-b$</li>
  <li>Lagrange multiplier $\alpha_n^ \land\ for\ y_n - w^Tz_n-b \le \epsilon-\xi_n^ \land$</li>
</ul>

<p>一些KTT条件如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-1/97895297.jpg" width="450px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-1/34361452.jpg" width="500px" /></p>

<p>在 tube 中我们可以得到 </p>

<p>$\vert w^Tz_n + b- y_n \vert &lt; \epsilon$</p>

<p>$\to \xi_n^ \vee=0,\ \xi_n^ \land=0$</p>

<p>$\to (\epsilon + \xi_n^ \land - y_n + w^Tz_n +b) \neq 0,\ (\epsilon + \xi_n^ \vee + y_n - w^Tz_n -b) \neq 0$</p>

<p>$\to \alpha_n^ \vee =0,\ \alpha_n^ \land=0$</p>

<p>$\to \beta_n=0$</p>

<p>对于support vector来说，$\beta_n \neq 0$，是在tube上或者tube外的。综上可以得到sparse $\beta$。</p>

<u>总结得到的Linear/Kernel Model如下图：</u>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-1/58915472.jpg" width="450px" /></p>

<ul>
  <li>first row: less used due to worse performance</li>
  <li>second row: popular in <strong>LIBLINEAR</strong></li>
  <li>third row: less used due to dense $\beta$</li>
  <li>fourth row: popular in <strong>LIBSVM</strong></li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Support Vector Machine]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/27/svm/"/>
    <updated>2016-02-27T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/27/svm</id>
    <content type="html"><![CDATA[<p>支持向量机(support vector machine, SVM)是一种二类分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，其学习策略便是间隔最大化，可以形式化为凸二次规划问题的求解，也等价于正则化的合页损失函数的最小化问题。SVM还包括kernel trick，使得它可以成为实质上的非线性分类器。下面就介绍Perceptron到三种类型的SVM模型。</p>

<p><img src="http://research.microsoft.com/en-us/um/people/manik/projects/trade-off/figs/svm2.PNG" width="400px" /></p>

<!--more-->

<h2 id="perceptron">Perceptron</h2>

<p>SVM可以说是Perceptron的一种进化。什么是Perceptron，Wiki的解释如下：</p>

<blockquote>
  <p>the perceptron is an algorithm for supervised learning of binary classifiers</p>
</blockquote>

<p>实则是一个二元线性分类器，通过一个线性的预测函数将观察点分成两类，这个预测函数就是特征空间中的一个分离超平面。对应于方程 $wx+b=0$, $w$ 为法向量或者权值，$b$ 是截距或偏置。</p>

<p>能够将数据集的正实例点和负实例点完全正确地划分到超平面的两侧，即对所有 $y_i＝+1$ 的实例 $i$，有 $wx_i+b&gt;0$，对所有 $y_i＝-1$ 的实例 $i$，有 $wx_i+b&lt;0$，则称数据集为线性可分数据集（linearly separable data set）;否则，称数据集线性不可分。</p>

<p>对于误分类点有 $y_i(wx_i+b) &lt; 0$, 设误分类点集 $M$, 采用0/1损失函数, 则得到感知机的损失函数如下：</p>

<script type="math/tex; mode=display"> L(w, b) = -\sum_{x_i \in M} y_i(w x_i + b) </script>

<p>要使损失函数最小，可以采用随机梯度下降法。任意选取一个超平面 $w_0, b_0$，然后用梯度下降法不断地最小化目标函数，每次选取一个误分类点使其梯度下降。每次迭代如下，随机选取一个误分类点 $(x_i, y_i)$, 对 $(w, b)$ 更新, $\eta$ 为步长：</p>

<script type="math/tex; mode=display"> w \gets w + \eta y_ix_i </script>

<script type="math/tex; mode=display"> b \gets b + \eta y_i </script>

<u>下面我们来证明下经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。</u>

<p>存在超平面 $y_i(\hat{w}_{opt} \cdot \hat{x}_i) = w_{opt} \cdot x_i + b_{opt} = 0$，使 $|\hat{w}_{opt}| = 1$，那么可以对于任意的点 $i$，$y_i(\hat{w}_{opt} \cdot \hat{x}_i) &gt; 0$，所有存在 $\gamma$，使得</p>

<script type="math/tex; mode=display">y_i(\hat{w}_{opt} \cdot \hat{x}_i) = w_{opt} \cdot x_i + b_{opt} \ge \gamma</script>

<p>感知机算法从 $\hat{w}_0 = 0$ 开始，如果实例被误分类，则更新权重。设 $\hat{w}_{k-1}$ 是第 $k$ 个误分类点之前扩充的权值向量，则第 $k$ 个误分类点满足$y_i(\hat{w}_{k-1} \cdot \hat{x}_i) \le 0$，$\hat{w}$ 更新后有</p>

<script type="math/tex; mode=display"> \hat{w}_{k} = \hat{w}_{k-1} + \eta y_i \hat{x}_i </script>

<p>可以得到</p>

<script type="math/tex; mode=display"> \hat{w}_{k} \cdot \hat{w}_{opt} = \hat{w}_{k-1} \cdot \hat{w}_{opt} + \eta y_i \hat{w}_{opt} \cdot \hat{x}_i \ge \hat{w}_{k-1} \cdot \hat{w}_{opt} + \eta \gamma </script>

<script type="math/tex; mode=display">\to \hat{w}_{k} \cdot \hat{w}_{opt} \ge k \eta \gamma</script>

<p>另外假设 $R = max(|\hat{x}_i|)$，有</p>

<script type="math/tex; mode=display"> \|\hat{w}_{k}\|^2 = \|\hat{w}_{k-1}\|^2 + 2\eta y_i \hat{w}_{k-1} \cdot \hat{x}_i + \eta^2 \|\hat{x}_i\|^2 \le \|\hat{w}_{k-1}\|^2 + \eta^2 \|\hat{x}_i\|^2 \le \|\hat{w}_{k-1}\|^2 \eta^2 R^2 </script>

<script type="math/tex; mode=display">\to \|\hat{w}_{k}\|^2  \le k \eta^2 R^2 </script>

<p>我们可以得到 </p>

<script type="math/tex; mode=display">k\eta\gamma \le \hat{w}_{k} \cdot \hat{w}_{opt} \le \|\hat{w}_{k}\| \|\hat{w}_{opt}\| \le \sqrt{k}\eta R</script>

<p>于是 $k \le (R / \gamma)^2$，表示误分类次数 $k$ 是有上界的，也就是经过有限次搜索可以找到将训练数据完全正确分开的分离超平面。</p>

<h3 id="pocket">pocket</h3>

<p>这里想另外介绍一种算法，Pocket算法。当训练集线性不可分时，感知机学习算法不收敛，迭代结果会发生震荡。 Pocket算法也就是用来权衡分离超平面和误分类点的。</p>

<p>从直觉上，我们知道如果当前超平面犯错越少越好，Pocket本质上就是在改错的时候多做一步，判断当前改正犯的错是否比之前更小，也就是贪心选择。</p>

<p>方法如图所示：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/79944104.jpg" width="500px" /></p>

<h2 id="linear-support-vector-machine">Linear Support Vector Machine</h2>

<p>Perceptron的问题是什么？它存在许多种解，只要是能够分割观察点的超平面全是它的解，既依赖于初值的选择，也依赖于迭代过程中误分类点的选择。这样的算法带来了不稳定性。为了得到唯一的超平面，需要增加一些约束条件。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/18916886.jpg" width="400px" /></p>

<p>我们认为点距离超平面越远，则越能够容忍噪声，并且对于overfitting的安全边界更大，也就是置信度越大。所以希望能够找到一个距离观察点最远的超平面作为我们的解，这个距离称为Margin，这样的超平面是唯一的。</p>

<p>点到平面的距离为沿着法向量方向的距离，所以有</p>

<script type="math/tex; mode=display"> distance(x, b, w) = \frac{1}{\|w\|} \vert w^Tx + b \vert </script>

<p>顺便提下，上式对法向量进行规范化，使得法向量为单位法向量，这个距离称<strong>几何间隔</strong>，否则是<strong>函数间隔</strong>。接下来，我们想要优化的目标可以写作：</p>

<script type="math/tex; mode=display"> \underset{b,w}{max} \frac{1}{\|w\|} </script>

<script type="math/tex; mode=display">s.t.\ every\ y_n(w^T x_n + b) > 0, \underset{n=1,2..N}{min} y_n(w^T x_n + b) = 1</script>

<p>这里我们有对distance进行缩放，除以 $w^Tx + b$。进一步对问题优化我们得到：</p>

<script type="math/tex; mode=display"> \underset{b,w}{max} \frac{1}{2}w^T w </script>

<script type="math/tex; mode=display">s.t.\ y_n(w^T x_n + b) \ge 1\ for\ all\ n</script>

<p>这样的一个问题其实就是<strong>凸二次规划问题</strong>。可以看下凸二次规划的解法：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/59800326.jpg" width="500px" /></p>

<p>使用任意一款可以解决二次规划的语言包就可以套用上图解决我们的目标问题。这个时候解出来的 $b，w$ 称之为hard-margin，因为没有任何一个点违反我们的限制条件。后面我们会看到一个soft-margin，这个就类似于pocket之于perceptron，可以解决线性不可分的数据集。</p>

<p>对于少量的数据集可以用凸二次规划直接求解，但是数据量一旦增多，求解的速度就成问题。我们可以用拉格朗日乘子法求解原始问题的对偶问题，得到最优解。定义的拉格朗日函数为：</p>

<script type="math/tex; mode=display"> L(b, w, \alpha) = \frac{1}{2}w^Tw + \sum_{n=1}^N \alpha_n(1-y_n(w^T z_n +b)) </script>

<p>这里的 $z_n = \phi(x_n)$ 是为了表示可以对 $x_n$ 做非线性的转换，也就是下一章中提到的kernel function，这里可以直接理解为 $z_n=x_n$。可以这么理解上式：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/6390373.jpg" width="450px" /></p>

<p>根据拉格朗日对偶性，原始问题的对偶问题是极大极小问题，下面我们需要证明：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/47082134.jpg" width="400px" /></p>

<p>假设对于任意的 $\alpha’$，所有的 $\alpha_n’ \ge 0$, 那么</p>

<script type="math/tex; mode=display"> \underset{b,w}{min}(\underset{\alpha_n \ge 0}{max}\ L(b, w, \alpha)) \ge \underset{b,w}{min}\ L(b, w,\alpha’)</script>

<p>因为 $max \ge any$。则对于右式的最优解 $\alpha’$ 有 $best \in any$</p>

<script type="math/tex; mode=display"> \underset{b,w}{min}(\underset{\alpha_n \ge 0}{max}\ L(b, w, \alpha)) \ge \underset{\alpha_n' \ge 0}{max}\underset{b,w}{min}\ L(b, w,\alpha’)</script>

<p>对于大于等于符号来说，这是一个weak duality。如果等号成立则是strong duality，也就是对偶问题和原始问题的最优值相等。需要满足一些限制条件，那就是<a href="https://en.wikipedia.org/wiki/Karush%E2%80%93Kuhn%E2%80%93Tucker_conditions">KKT条件</a>。</p>

<p>求解对偶问题，首先求 （1）$\underset{b,w}{min}\ L(w, b, \alpha)$ </p>

<script type="math/tex; mode=display"> \nabla_w L(w, b, \alpha) = w - \sum_{i=1}^N \alpha_i y_i z_i = 0 \to w=\sum_{i=1}^N \alpha_i y_i z_i</script>

<script type="math/tex; mode=display">\nabla_b L(w, b, \alpha) = \sum_{i=1}^N \alpha_i y_i = 0 \to \sum_{i=1}^N \alpha_i y_i=0</script>

<p>带入原公式得到</p>

<script type="math/tex; mode=display"> L(w, b, \alpha)= -\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_j y_i y_j (z_i \cdot z_j) + \sum_{i=1}^N \alpha_i </script>

<p>接下来求解 （2） $\underset{b,w}{min}\ L(w, b, \alpha)$ 对 $\alpha$ 的极大值，极大值可以变为极小值</p>

<script type="math/tex; mode=display"> \underset{\alpha}{min}\ \frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \alpha_i\alpha_j y_i y_j (z_i \cdot z_j) - \sum_{i=1}^N \alpha_i</script>

<script type="math/tex; mode=display"> s.t.\ \sum_{i=1}^N \alpha_i y_i=0,\ \alpha_i \ge 0</script>

<p>求解（2）可以用到<a href="http://www.cnblogs.com/biyeymyhjob/archive/2012/07/17/2591592.html">SMO</a>（序列最小最优化）算法。现在回过头来看 $\alpha$ 的最优解，我们发现至少会有一个 $\alpha_j &gt; 0$，因为根据KKT条件有complementary slackness：</p>

<script type="math/tex; mode=display"> \alpha_i(y_i(w \cdot z_i +b)-1) = 0,\ i=1,2,...N</script>

<p>如果 $\alpha=0$ 则会导致 $w=0$，对于$\alpha_j &gt; 0$，我们看到会有 $y_j(w \cdot z_j +b)-1=0$。如此，可以定义分离超平面为</p>

<script type="math/tex; mode=display"> \sum_{i=1}^N \alpha_i y_i (z \cdot z_i) + b = 0 </script>

<script type="math/tex; mode=display"> b = y_i - \sum_{i=1}^N \alpha_i y_i (z_i \cdot z_j)</script>

<p>上面的推导表明，这些点 $(z_j, y_j)$ 也就是站在分离超平面的margin上的点，所以说SVM只依赖于边界上的点，它们被称为support vectors，支持向量，这也是SVM的由来。</p>

<h2 id="kernel-support-machine">Kernel Support Machine</h2>

<p>在上文中，我们已经了解到了SVM处理线性可分的情况，而对于非线性的情况，SVM 的处理方法是选择一个核函数 $K(⋅,⋅)$，<u>通过将数据映射到高维空间，来解决在原始空间中线性不可分的问题</u>。</p>

<p><img src="http://my.csdn.net/uploads/201206/02/1338612063_1634.JPG" width="400px" /></p>

<p>例如，对于上面的数据集中两类数据，分别分布为两个圆圈的形状，这样的数据本身就是线性不可分的。理想的分界应该是一个二次曲面，可以写成：</p>

<script type="math/tex; mode=display">a_1X_1 + a_2X_1^2 + a_3X_2 + a_4X_2^2 + a_5X_1X_2 + a_6 = 0</script>

<p>上式其实就是一个五维的空间。一般地对于二次多项式的转换形式，我们有</p>

<script type="math/tex; mode=display"> \phi_2(x) = (1, x_1, x_2....x_d, x_1^2, x_1x_2,...x_1x_d,x_2x_1, x_2^2...x_d^2) </script>

<p>在这个 $O(d^2)$ 高维空间做计算无疑非常困难。幸运的是从上一章推导出的分离超平面中，我们可以看到<strong>分类决策其实只依赖输入和训练样本输入的内积</strong>，也就是说，我们可以直接计算 </p>

<script type="math/tex; mode=display"> \phi_2(x)^T \phi_2(x') = 1 + \sum_{i=1}^dx_ix_i' +  \sum_{i=1}^d\sum_{j=1}^d x_ix_j'x_ix_j' = 1 + x^Tx' + (x^Tx')^2</script>

<p>这里我们直接计算高维转换后的内积，有什么好处呢？注意到计算可以在原来的低维空间$O(d)$中发生，不需要再高维空间中计算。这样，称呼<strong>计算两个向量在隐式映射过后的空间中的内积的函数叫做核函数</strong>。可以对原有空间进行一些线性变换，得到</p>

<script type="math/tex; mode=display"> \phi_2(x) = (1, \sqrt{2\gamma}x_1,....\gamma x_d^2) \to K_2(x, x')=1 + 2\gamma x^Tx' + \gamma^2 (x^Tx')^2 </script>

<p>推广之后，我们得到一般的多项式Kernel：</p>

<script type="math/tex; mode=display">K_n(x, x')= (\xi + \gamma x^Tx')^n,\ \xi>0,\gamma>0</script>

<p>对于不同的 $\xi,\gamma$ SVM是不同的，它们的支持向量也是不同的，因为对于SVM来说变化Kernel就意味着重新定义margin。下面是二次多项式Kernel的一些例子：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/72039507.jpg" width="450px" /></p>

<p>其他常用的核函数还包括高斯核，它可以把原来的低维空间扩展到无线大的高维空间中，它的一般公式为 $K(x,x’)=exp(-\gamma |x-x’|^2),\gamma&gt;0$。高斯核函数也被称为 Radial Basis Function(RBF) kernel。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/61331101.jpg" width="500px" /></p>

<p>满足核函数的充要条件是Mercer’s condition，包括：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/48999470.jpg" width="450px" /></p>

<h2 id="soft-margin-support-vector-machine">Soft-Margin Support Vector Machine</h2>

<p>下面我们来讨论下 Soft-Margin SVM。Soft-Margin可以支持数据集线性不可分的情况，允许一些误分类点的存在，在目标优化函数上会对这些误分类点增加处罚：</p>

<script type="math/tex; mode=display"> \underset{b,w,\xi}{min} \frac{1}{2}w^T w  + C\sum_{n=1}\xi_n</script>

<script type="math/tex; mode=display">s.t.\ y_i(w^T z_n + b) \ge 1-\xi_n,\ \xi_n \ge 0\ for\ all\ n</script>

<p>对于参数 $C$ 而言，它是大margin和误分类点的trade-off，大 $C$ 表示少误分类点，小 $C$ 表示大margin。同样计算拉格朗日对偶问题：</p>

<script type="math/tex; mode=display">L(b, w, \xi, \alpha, \beta) = \frac{1}{2}w^Tw + C\sum_{n=1}\xi_n + \sum_{n=1}^N \alpha_n(1-\xi_n-y_n(w^T z_n +b)) + \sum_{n=1}^N \beta_n (-\xi_n)</script>

<script type="math/tex; mode=display">want\ \underset{\alpha \ge 0, \beta \ge 0}{max}(\underset{b,w,\xi}{min}\ L(b, w, \xi, \alpha, \beta))</script>

<p>和hard-margin一样的计算后可以得到</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/23447671.jpg" width="350px" /></p>

<p>对于soft-margin的complementary slackness有</p>

<script type="math/tex; mode=display"> \alpha_n(1- \xi_n - y_n(w^T z_n +b)) = 0,\ (C-\alpha_n)\xi_n=0</script>

<p>存在以下三种情况：</p>

<ul>
  <li>$\alpha_n=0$: $\xi_n=0$, 在边界之外正确分类的点.</li>
  <li>$0&lt;\alpha_n&lt;C$: $\xi_n=0$，支持向量落在边界上。也正是通过这种情况计算截距 $b$.</li>
  <li>$\alpha_n=C$：这种情况比较复杂，可以有下图表示，支持向量的位置由$\xi_n$决定。$0&lt;\xi_n&lt;1$则分类正确，在间隔边界和分离超平面之间；$\xi_n=1$则在分离超平面上；$\xi_n&gt;1$则位于超平面误分类的一侧.</li>
</ul>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/76271972.jpg" width="300px" /></p>

<h2 id="hinge-loss-function">Hinge Loss Function</h2>

<p>最后我们说明下SVM可以用合页损失函数表示，就是最小化以下目标函数：</p>

<script type="math/tex; mode=display"> \sum_{i=1}^N[1-y_i(w \cdot x_i + b)]_+ + \lambda\|w\|^2 </script>

<p>下标“+”表示，对 $[z]_+ = z,\ z&gt;0; [z]_+ = 0,\ z \le 0$</p>

<p>可以看到 $1-y_i(w \cdot x_i + b)$ 可以写成</p>

<script type="math/tex; mode=display"> y_i(w \cdot x_i + b) \ge 1-\xi_i,\ \xi_i \ge 0, \ i=1,2,...N </script>

<p>也就是soft-margin SVM的限制条件，那么取 $\lambda= 1/2C$ 则有</p>

<script type="math/tex; mode=display"> \underset{b,w}{min} \frac{1}{C}(\frac{1}{2}\|w\|^2 + C\sum_{n=1}\xi_n)</script>

<p>也就是soft-margin SVM的目标优化函数。合页损失函数的形状如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-27/97100573.jpg" width="400px" /></p>

<p>虚线显示的是感知机的损失函数 $[y_i(w \cdot x_i+b)]_+$。这时，当样本点 $(x_i，y_i)$ 被正确分类时，损失是0，否则损失是 $-y_i(w \cdot x_i+b)$。相比之下，合页损失函数不仅要分类正确，而且置信度足够高时损失才是0。也就是说，合页损失函数对学习有更高的要求。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[PCA and SVD]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/26/pca-svd/"/>
    <updated>2016-02-26T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/26/pca-svd</id>
    <content type="html"><![CDATA[<p>PCA即为（Principal Components Analysis）主成分分析，SVD是（Singular value decomposition）奇异值分解。从字面上的理解就可以看出这两个并不是在同一语义层面的东西。之所以把这两个放在一块，一是为了文章的完整性，二是为了说明二者在数据转换（基转换）上的共性。</p>

<!--more-->

<h2 id="principal-components-analysis">Principal Components Analysis</h2>

<p>由于采样的受限，我们的观察值并不能最有效的反应出事物的特征，因此我们希望大而全的收集能收集到的所有数据。但是这里面存在两个问题：噪声和冗余。因此在描述事物的时候，我们希望能够排除这些多余的甚至是错误的数据，得到最简洁，最省力的数据。</p>

<p>那么什么是最简洁，最省力的数据呢？把我们的观察值想象成一个向量空间，排除噪声和冗余后，那么这个空间上的点应该可以用一系列的正交单位向量缩放后的向量和表示。这个就是PCA的目的。</p>

<p>在上面的描述中，有一些很重要的假设：</p>

<ul>
  <li>原有的基是通过线性转化转化为现有空间的基，否则就是Kernel PCA</li>
  <li>现有空间的基是正交的</li>
  <li>每个维度数据的均值和方差是充分统计的。</li>
  <li>数据中方差能够表示数据的重要程度。</li>
</ul>

<p>第一点比较容易理解，其实是做了一些限制，限制潜在最优基的数目并且相信数据集存在线性的连续性，即我们可以用线性的方式内推出独立的数据点。第二点就比较直接，直觉上是合理的并且可以用线性代数的矩阵分解解决。</p>

<p>第三点比较复杂，充分统计的意思是可以用均值和方差完整的描述数据的概率分布。如果方差为0，只用方差完整的描述概率分布的只有高斯分布。也就是说维度上的数据服从高斯分布，如果不服从呢，这就涉及到ICA算法（Independent Component Analysis）。根据中心极限定理，PCA还是比较robust的一种解决方案。</p>

<p>第四点来自信号处理，认为信号具有较大的方差，噪声有较小的方差，信噪比(Signal-to-noise ratio, SNR)就是信号与噪声的方差比，越大越好。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-24/39988407.jpg" width="600px" /></p>

<p>噪声可以用<em>SNR</em>量化表示，那么冗余呢？冗余可以用协方差表示。如果向量 $a$、向量 $b$ 的协方差为0，则代表 $a$ 和 $b$ 完全没有关系，协方差越大则关联的程度越高。<u>这里对所有的数据集都是*mean deviaton form*，即均值为0。</u>则我们可以得到向量 $a$ 和向量 $b$ 的协方差 $\delta_{ab}^2 = \frac{1}{n-1}ab^T$，之所以除以 $n-1$ 是为了得到无偏估计，因为样本中的最后一个值可以通过均值推到出来。</p>

<p>假设原有的输入是一个 $m \times n$ 的矩阵，m是特征维度，n是样本数量，那么它的协方差矩阵为 $S_x = \frac{1}{n-1}XX^T$. $S_x$ 是 $m \times m$ 的矩阵，<strong>表示特征之间的关联程度</strong>。$S_x$ 量化了原有任意两个维度数据之间的关系。那么既然如此，我们希望 $S_x$ 是什么样的？答案就是非对角元素全为0，表示任意维度之间的数据没有冗余，这个过程叫对角化（Diagonalize）得到的协方差矩阵我们成为 $S_y$。</p>

<p>有很多种方法可以实现对角化，PCA选择特征值分解的方法。现在问题定义如下，找到一个正交矩阵 $P$，$Y=PX$, 使得 $S_y = \frac{1}{n-1}YY^T$ 是对角化的矩阵。这时，$P$ 的每排就是 $X$ 的 principal components。这也是PCA名字的由来，$Y$ 是经过矩阵 $P$ 线性转换后的矩阵。$S_y$ 用 $P$ 表示：</p>

<script type="math/tex; mode=display"> S_y = \frac{1}{n-1}YY^T = \frac{1}{n-1}PXX^TP^T = \frac{1}{n-1}PAP^T </script>

<p>这里 $A=XX^T$ 是一个 $m \times m$  的对称矩阵。对称矩阵可以由特征向量构成的正交矩阵表示 $A=EDE^T$，$D$ 是对角矩阵，$E$ 的列向量为 $A$ 的特征向量。如果 $P=E^T$，即 $P$ 的行向量为 $A$ 的特征向量，则有</p>

<script type="math/tex; mode=display">S_y = \frac{1}{n-1}PAP^T = \frac{1}{n-1}(PP^T)D(PP^T) = \frac{1}{n-1}D</script>

<p>可以看到 $P$ 对角化 $S_y$，这就是PCA要求的。下面我们总结下</p>

<ul>
  <li>$X$ 的<strong>主成分</strong>也就是 $XX^T$ 的特征向量，或者 $P$ 的行向量。</li>
  <li>$S_y$ 的第 $i$ 个对角值（特征值）也就是 $X$ 在 $p_i$方向上的方差。</li>
</ul>

<p>所以PCA的计算很简单，就两个步骤</p>

<ol>
  <li>计算dataset的<em>mean deviaton form</em></li>
  <li>计算$XX^T$的特征分解。</li>
</ol>

<p>PCA可以选择最大的几个特征值降维，也可以防止overfitting，但是经过线性变换后拟合的函数就不好理解了。</p>

<h2 id="singular-value-decomposition">Singular value decomposition</h2>

<p>SVD是另外一种基变换的更通用的方法，二者在使用上通常可以互相的替换。SVD和上文中提到的特征值分解都是一种矩阵的对角化分解方法。</p>

<p>假设 $X$ 是任意 $m \times n$ 矩阵，$XX^T$ 是秩为 $r$ 的对称矩阵，我们定义</p>

<ul>
  <li>$(v_1, v_2,…v_r)$ 是 $XX^T$ 的 $n \times 1$ 的特征向量，特征值为 $(\lambda_1, \lambda_2,…\lambda_r)$, $(XX^T)v_i = \lambda_i v_i$。</li>
  <li>$\sigma_i = \sqrt{(n-1) \lambda_i}$ 为正实数，也被成为奇异值。</li>
  <li>$(u_1, u_2,…u_r)$ 是 $m \times 1$ 的正交向量集，$u_i = \frac{1}{\sigma_i}Xv_i$</li>
</ul>

<p>重新组织下第三个定义，有 $Xv_i=\sigma_iu_i$, $U = (u_1, u_2,…u_r)，V = (v_1, v_2,…v_r)$ 都是定义在 $r$ 维空间的正交基。用任意的 $(m-r), (n-r)$ 正交向量补充到 $U, V$ 中，得到 $m$ 和 $n$ 维的 $U、V$，我们有下面用一个矩阵乘法：$XV=U \Sigma$, 其中</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-24/86503163.jpg" width="200px" /></p>

<p>因为 $V$ 是正交的，所以上式又可以写成</p>

<script type="math/tex; mode=display"> X=U \Sigma V^T </script>

<p>这个就是奇异值分解，表示任意的矩阵都可以表示一个正交矩阵，一个对角矩阵和另一个正交矩阵的乘积，或者说是旋转、拉伸和另外一个旋转。其中，$U_{m \times m}$ 是左奇异向量矩阵，$V_{n \times n}$ 是右奇异向量矩阵。</p>

<p>关于奇异值分解的问题最常用的算法分为两大类，QR分解和Jacobi选择，这里就不细说。</p>

<h3 id="pcasvd">PCA和SVD的关系</h3>

<p>通常来说，PCA要求计算协方差矩阵的特征值和特征向量，因为协方差矩阵是对称的，因此是可对角化的，特征向量也是正交的。对于SVD，我们有</p>

<script type="math/tex; mode=display">XX^T=(U\Sigma V)(U\Sigma V)^T = U \Sigma^2 U^T</script>

<p>复习下介绍PCA时我们的到的公式：</p>

<script type="math/tex; mode=display">XX^T = (n-1)P^TS_yP</script>

<p>这时二者的关系就很清晰了，$P、U$ 都是正交矩阵：</p>

<ul>
  <li>
    <p>$XX^T$ 的特征值 $\lambda=\frac{\sigma^2}{n-1}$</p>
  </li>
  <li>
    <p>$\frac{1}{\sqrt{n-1}}X$ 经过SVD分解后的 $U$ 的列向量也正是PCA中的主成分。</p>
  </li>
</ul>

<p>所以我们在PCA的最后一步中可以用SVD或者特征分解。但是SVD在数值上的精确程度会高于特征分解，因为计算 $XX^T$ 可能会带来一些精度的损失。</p>

<h3 id="svd">SVD的说明</h3>

<p>可以对SVD进行一些有趣的变换:</p>

<script type="math/tex; mode=display"> U^TX = \Sigma V^T </script>

<script type="math/tex; mode=display"> U^TX = Z </script>

<p>定义 $Z=\Sigma V^T$ 可以看到 $U^T$ 是改变了 $X$ 的基，使其变成 $Z$, 这里是改变了 $X$ 的列向量。同理对于 $V$ 来说，$V^TX^T = U^T \Sigma$ 这是改变 $X$ 的行向量。而 $\Sigma$ 则表示对某些维度的缩放，之所以说某些维度是 $\Sigma$ 中有为0的奇异值，非0奇异值的个数也就是矩阵的秩的大小。</p>

<p>$\Sigma$中奇异值的大小和特征值有关系，表示特征的重要程度，因此我们可以令奇异值较小的数0，这样重新计算 $X$ 的时候也就进行降噪和去冗余。</p>

<p>总的来说，无论是特征分解还是奇异值分解，都是为了让人们对矩阵（或者线性变换）的作用有一个直观的认识。通过特征分解和奇异值分解我们可以更加明白这些矩阵信息背后的真实含义，简化我们对矩阵的认识。</p>

<p>关于更多对SVD物理意义的说明可以参考<a href="http://www.ams.org/samplings/feature-column/fcarc-svd">http://www.ams.org/samplings/feature-column/fcarc-svd</a>.</p>

<h2 id="limits-and-extensions-of-pca">Limits And Extensions of PCA</h2>

<p>可以看到PCA是无参数分析的，所以只需要做出上文提到的假设，无需对参数进行训练和选择就可以得到结果。但是也正是上述假设所限，如果一个人正好知道数据的一些先验知识，那么他也无法通过这些先验知识得到更好的分析结果，这个时候如果能够将这些先验知识融入有参数的算法中会得到更好的结果。</p>

<p>如果这个先验知识表示需要做些数据的非线性转化（kernel transformation），那么这样的参数算法就是<code>kernel PCA</code>。</p>

<p>有时候需要作出如下假设，主成分不必正交，特征数据的分布也不是高斯分布。那么可以用<code>Idependent Component Analysis</code>解决，它和PCA有同意的目的，降噪和去冗余。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Ensemble Methods]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/18/ensemble/"/>
    <updated>2016-02-18T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/18/ensemble</id>
    <content type="html"><![CDATA[<p>Ensemble<code>|ɒnˈsɒmbl|</code> Methods 称为集成方法，它还有其他类似的名字，meta-algorithm、aggregation model，这些都代表这同一个意思，就是不同弱分类器的组合成一个强分类器。这里的弱分类器要比随机猜测的结果好，错误率小于50%；弱分类器可以是决策树、逻辑回归、朴素贝叶斯等算法。Ensemble的形式有很多种：</p>

<ul>
  <li>不同算法的集成;</li>
  <li>同一算法在不同设置下的集成;</li>
  <li>数据集不同部分分配给不同分类器之后的集成。</li>
</ul>

<p>那么这多个弱分类器又是如何组合的呢，下面给出一个big picture，后面的文章也是对其的阐述。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-18/38802537.jpg" width="450px" /></p>

<!--more-->

<p>弱分类的组合可以是linear或者stacking的，linear又可以是uniform或者non-uniform.
stacking或者stacked generalization的大意是non-linear combining. 通常stacking的组合算法有LR，GBM, KNN, NN, RF 和 ET，可以参考<a href="http://mlwave.com/kaggle-ensembling-guide/">http://mlwave.com/kaggle-ensembling-guide/</a>. 作者Wolpert是这样形容的：</p>

<blockquote>
  <p>stacked generalization is a means of non-linearly combining generalizers to make a new generalizer, to try to optimally integrate what each of the original generalizers has to say about the learning set. The more each generalizer has to say (which isn’t duplicated in what the other generalizer’s have to say), the better the resultant stacked generalization. </p>
</blockquote>

<p>那么为什么要把这些分类器进行组合呢？组合之后是否能获得更好的效果？可以看下下面的例子。</p>

<p>假设我们有10个samples的测试集，正确的结果是<code>1111111111</code>。现在有三个分类器，它们只有70%的正确率，那么三个分类器进行majority vote，可以得到如下的正确率：</p>

<script type="math/tex; mode=display">0.7 * 0.7 * 0.7 + \binom{3}{2}0.7 * 0.7 * 0.3 = 0.784</script>

<p>也就是由原来的70%提升到了78%。正确率会随着分类器的增加而增加。5个分类器的正确率大约为83%。这个在统计学上就是“Wisdom of Crowds”。但是这个结果提高的前提在于sample的diversity，也就是减少sample之间的correlation。例如：</p>

<pre><code>1111111100 = 80% accuracy
1111111100 = 80% accuracy
1011111100 = 70% accuracy
</code></pre>

<p>在这个例子中得到<code>1111111100</code>还是只有80%的正确率，而</p>

<pre><code>1111111100 = 80% accuracy
0111011101 = 70% accuracy
1000101111 = 60% accuracy
</code></pre>

<p>经过Ensemle就可以得到<code>1111111101</code>，90%的正确率。</p>

<p>那么如何证明多个组合会比单个的结果好呢，可以用Uniform Linear的组合进行下面的理论描述。</p>

<script type="math/tex; mode=display"> Let\ G(x) = \frac{1}{T}\sum_{t=1}^T g_t(x)</script>

<script type="math/tex; mode=display">   avg((g_t(x) - f(x))^2) = avg(g_t^2 - 2g_tf + f^2)</script>

<script type="math/tex; mode=display">   =avg(g_t^2) - G^2 + (G-f)^2</script>

<script type="math/tex; mode=display">   =avg((g_t-G)^2) + (G-f)^2</script>

<script type="math/tex; mode=display"> avg(E(g_t)) = avg((g_t-G)^2) + E(G) \ge E(G) </script>

<p>更一般的，有如下的预测模型$\hat{F}(x)^T = [\hat{f}_1(x), \hat{f}_2(x)…\hat{f}_M(x)]$, 用最小二乘法寻找线性最小值</p>

<script type="math/tex; mode=display"> \hat{w} = argmin_w E[Y - \sum_{m=1}^M w_m\hat{f}_m(x)]^2 </script>

<script type="math/tex; mode=display"> \hat{w} = E[\hat{F}(x)\hat{F}(x)^T]^{-1}E[\hat{F}(x)Y] </script>

<script type="math/tex; mode=display"> E[Y - \sum_{m=1}^M w_m\hat{f}_m(x)]^2 \le E[Y-\hat{f}_m(x)]^2 \forall m</script>

<h2 id="bagging">Bagging</h2>

<p>Bagging或者bootstrap aggregation是上文提到的Uniform Linear aggregation。其中用到bootstrapping，这是是一种resample的方法，定义如下</p>

<blockquote>
  <p>re-sample N examples from original sample <strong>uniformly with replacement</strong> – can also use arbitrary N’ instead of original N</p>
</blockquote>

<p>有training set $Z$, 对每个bootstrap sample $Z^{*b}, b=1,2…B$，bagging定义如下：</p>

<script type="math/tex; mode=display"> \hat{f}_{bag}(x) = \frac{1}{B} \sum_{b=1}^B \hat{f}^{*b}(x) </script>

<h2 id="adaboost">AdaBoost</h2>

<p>AdaBoost或者Adaptive Boosting中只要弱分类器的正确率优于随机选择，那么通过AdaBoost就会得到非常好的结果。它是一种Boosting方法，所谓Boosting就是改变训练数据的概率分布（权值分布）针对不同的训练数据分布调用弱学习算法学习一系列弱分类器。对应于上面的non-uniform linear model。</p>

<p>AdaBoost强调对错误分类的反复学习，但是最后对错误率较高的分类器赋予低权重。每轮学习中都会重新对分类器赋予不同的权重，这是为了得到更多关于数据的不同假设。如何得到更多的不同假设呢？</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-19/91708853.jpg" width="300px" /></p>

<p>那么我们希望在$t+1$迭代学习的时候，$t$轮的结果尽可能的随机，即有错误率</p>

<script type="math/tex; mode=display"> \epsilon_t = \frac{\sum_{n=1}^N u_n^{(t+1)}I(y_n \ne g_t(x_n))}{\sum_{n=1}^N u_n^{(t+1)}} = \frac{1}{2} </script>

<p>于是可以 multiply incorrect $\propto (1 - \epsilon_t)$; multiply correct $\propto \epsilon_t$</p>

<p>定义scalling factor $\blacklozenge_t = \sqrt{\frac{1 - \epsilon_t}{\epsilon_t}}$</p>

<script type="math/tex; mode=display"> incorrect \gets incorrect \cdot \blacklozenge_t \\ correct \gets correct \div \blacklozenge_t </script>

<p>最后对scalling factor取自然对数作为权值 $\alpha_t$ 将弱分类器线性组合在一块，取自然对数的逻辑如下：</p>

<script type="math/tex; mode=display"> \epsilon_t = 1/2 => \blacklozenge_t = 1 => \alpha_t = 0 \\
\epsilon_t = 0 => \blacklozenge_t = \infty => \alpha_t = \infty </script>

<p>最后伪代码为</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/40495628.jpg" width="450px" /></p>

<p>比较常见的弱分类器是Decision Stump，和AdaBoost组成<code>AdaBoost-Stump</code>，具有efficient feature selection and efficiency的特点。</p>

<h2 id="random-forest">Random Forest</h2>

<p>Bagging是通过平均带有噪声但是近似无偏的模型来减少variance，而对于足够深的Decision Tree来说，它的bias可以非常少，但是variance非常高。所以自然的想将二者结合，综合他们的优点。Bagged Tree并不能减少bias，但是可以有效的减少variance。这个Boosting正好相反，Boosting通过自适应的变化树的样子来减少bias。Random Forest就是Bagging + Decision Tree(C&amp;RT)。EST给出RF的本质：</p>

<blockquote>
  <p>The idea in random forests is to improve the variance reduction of bagging by reducing the correlation between the trees, without increasing the variance too much.</p>
</blockquote>

<p>我们了解到增加hypothesis diversity可以提高最终结果的表现，那么Random Forest就将这种Random性发挥到极致，得到多样的hypothesis。为了增加随机性，可以做了以下的措施：</p>

<ul>
  <li>re-sample new feature subspace for each b(x) in C&amp;RT, 记得bagging进行data randomness for diversity, 那么在RF中是feature randomness for diversity</li>
  <li>random low-dimensional projections for each b(x) in C&amp;RT, 这就是对feature进行投影，进行feature combination，在特征空间中随机选择若干特征组投影到若干个方向上。</li>
</ul>

<p>伪代码如下（只用了第一个Randomness）：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/2671550.jpg" width="500px" /></p>

<p>RF还有的特点是训练的时候可以自带<strong>Model Selection和Feature Selection</strong>。那么RF是如何做到的？</p>

<h3 id="model-selection">Model Selection</h3>
<p>在RF中使用bagging时，每个bootstrap sample都会有一定的概率没有选择原来sample中的一些数据，这些数据就是out-of-bag (OOB) Samples. 在一个RF中，某个Decision Tree训练没有用到数据 $(x_n, y_n)$的概率为：$(1 - \frac{1}{N}) ^ N$，当N无限大的时候，接近 $\frac{1}{e}$.</p>

<p>可以用OOB来validate G, $E_{oob}G = \frac{1}{N} \sum_{n=1}^N err(y_n, G_n^-(x_n))$, $G_n^-$ 表示 $x_n$在OOB中的Decision Tree。这样可以用 $E_{oob}$ 对bagging/RF进行self-validation。</p>

<p>这有什么用呢，当然是进行模型选择了，可以使用 $E_{oob}$ 进行RF的参数选择，例如feature subspace。下图表示使用Validation中进行的模型选择，可以看到RF中少了re-training的步骤。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/30059076.jpg" width="250px" /></p>

<h3 id="feature-selection">Feature Selection</h3>

<p>在模型训练的时候通常希望能够去掉多余的、无关的特征，这样能够得到的好处有：</p>

<ul>
  <li><strong>efficiency</strong>: simpler hypothesis and shorter prediction time</li>
  <li><strong>generalization</strong>: feature noise removed</li>
  <li><strong>interpretability</strong></li>
</ul>

<p>通常可以通过特征的重要性来进行特征的选择，对于线性模型来说就是 $w_i$ 的绝对值，也就是特征对于最终结果的影响程度。那么在非线性的RF模型中呢？</p>

<p>所用的方法就是random test，例如特征 $i$ 被选择，那么在特征 $i$ 的数据集中加入随机变量重新训练则会降低模型正确率，而对于不重要的特征，怎么改变数据集当然对模型没有什么影响。</p>

<p>RF中使用的random test就是一种常用的统计学工具permutation test，也就是将特征 $i$ 的数据做重新排列。数据表达也就是：</p>

<script type="math/tex; mode=display"> importance(i) = performance(\mathcal{D}) - performance(\mathcal{D}^{(p)}) </script>

<script type="math/tex; mode=display"> \mathcal{D}^{(p)}\ is\ \mathcal{D}\ with\ \{x_{n,i}\}\ replaced\ by\ permuted\ \{x_{n,i}\}_{n=1}^N </script>

<p>$performance(\mathcal{D}^{(p)})$需要重新训练和评估，那么有什么办法可以避免呢？我们可以重新定义 $importance(i) = E_{oob}(G^-) - E_{oob}^{(p)}(G^-)$，表达式后项就是一个permuted OOB value。</p>

<p>具体过程如下，当 $b$ 个树生成的时候，记录OOB评估的 $G^-$ 的正确率，然后OOB sample中的特征 $i$ 数据重新随机排列后再次评估的 $G^-$ 的正确率，二者相减得到特征 $i$的重要性。</p>

<p>RF的缺点是，如果随机过程表现的不稳定，则需要很多的Decision Tree来支持。所以需要重新检查 $G$ 的稳定性来确保有足够多的树。</p>

<h2 id="gradient-boosted-decision-tree">Gradient Boosted Decision Tree</h2>

<p>回忆下假设AdaBoost的分类器输出是binary的，则权值迭代可以转化为</p>

<script type="math/tex; mode=display"> u_n^{t+1} = \begin{cases}{u_n^t \cdot \blacklozenge_t\ if\ incorrect}\\{u_n^t \div \blacklozenge_t\ if\ correct}\end{cases} = u_n^t \cdot \blacklozenge_t^{-y_ng_t(x_n)} = u_n^t \cdot exp(-y_n\alpha_tg_t(x_n))</script>

<script type="math/tex; mode=display"> u_n^{(T+1)} = u_n^{(1)} \cdot \prod_{t=1}^Texp(-y_n\alpha_tg_t(x_n)) = \frac{1}{N} \cdot exp(-y_n\sum_{t=1}^T\alpha_tg_t(x_n)) </script>

<p>在AdaBoost中 $G(x) = sign(\sum_{t=1}^T\alpha_tg_t(x_n))$ 括号中的表达式也被成为voting score。现在我们想要 $y_n(voting\ score)$ 为正且越大越好，也就是让 $u_n^{(T+1)}$ 越小越好。</p>

<p>所以AdaBoost的过程也就是让 $\sum_{n=1}^N u_n^{(t)}$ 减小，也就是最小化</p>

<script type="math/tex; mode=display"> \sum_{n=1}^Nu_n^{(T+1)} =  \frac{1}{N} \cdot exp(-y_n\sum_{t=1}^T\alpha_tg_t(x_n)) </script>

<p>注意到上式是一个损失函数，Exponential Loss Function，之所以用指数损失函数是为了后续的计算方便，可以对比下不同的损失函数。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-22/70940842.jpg" width="400x" /></p>

<p>注意到在gradient descent中第 $t$ 次迭代有：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/31496263.jpg" width="400px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/14307315.jpg" width="400px" /></p>

<p>所以找到一个好的 $h(function\ direction)$ 函数也就是最小化 $\sum_{n=1}^Nu_n^{(t)}(-y_nh(x_n))$。对于二元分类，$y_n, h(x_n) \in {-1, +1}$，有</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/93309458.jpg" width="400px" /></p>

<p>也就是每次迭代都需要最小化其中的hypothesis $E_{in}^{u^{(t)}}(h)$，那么谁最小化 $E_{in}^{u^{(t)}}(h)$呢，当然是AdaBoost中的reweighted sample所对应的 $g_t$ 了。</p>

<p>所以现在需要优化 $\eta_t$ 得到梯度下降方向最佳步长，原来的 $\hat{E}_{ADA}$ 变为 $(\sum_{n=1}^N u_n^{(t)}) \cdot ((1-\epsilon_t)exp(-\eta) + \epsilon_t exp(+\eta))$。微分后容易得到 $\eta_t=ln\sqrt{\frac{1-\epsilon_t}{\epsilon_t}} = \alpha_t$。这和我们上面得到的scaling Factor是一致的。</p>

<p>所以AdaBoost是steepest descent with approximate functional gradient. 我们总结下，AdaBoost的数学表达式：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/16682553.jpg" width="400px" /></p>

<p>Gradient Boost就是把二元分类的假设推广到任意的假设并且损失函数也可以任意的。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/85486720.jpg" width="400px" /></p>

<p>当选择平方损失函数时，有如下的可以看到</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/61222916.jpg" width="460px" /></p>

<p>现在需要对 $h$ 加一些限制，否则 $h(x_n) = -\infty \cdot (s_n - y_n)$</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/34172769.jpg" width="400px" /></p>

<p>最优 $g_t = h$ 就是 $(x_n, y_n-s_n)$ 上的最小二乘回归函数，$y_n - s_n$就是残差。于是原来的Gradient Boost表达式变成：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/37566404.jpg" width="400px" /></p>

<p>最小化 $\eta$ 就是 $(g_t\ transformed\ input,\ residual)$ 上的单变量线性回归。所以GradientBoost for regression 的 $\alpha_t = optimal\ \eta\ by\ g_t\ transformed\ linear\ regression$.</p>

<p>Gradient Boosted Decision Tree也就是使用回归算法为Decision Tree。伪代码如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-20/38067174.jpg" width="500px" /></p>

<p>总结下Ensemble Methods的有点：</p>

<ul>
  <li>cure underfitting, 通过feature transform加强$G(x)$的Bias。</li>
  <li>cure overfitting, 通过多样化假设的合并达到regularization的目的，减少$G(x)$的variance。</li>
</ul>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Logistic Regression and Linear Discriminant Analysis]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/17/lr-and-lda/"/>
    <updated>2016-02-17T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/17/lr-and-lda</id>
    <content type="html"><![CDATA[<p>在回归方法中，我们找一个超平面作为类与类之间的decision boundary。回归方法为每个分类建立一个判别函数 $\sigma_k (x)$, 对任意的 $x$，选出得到最大值的判别函数最为归属类。对于后验概率模型 $Pr(G = k|X = x)$ 也是使用同样的方法。对于$\sigma_k (x) 和 Pr(G = k|X = x)$ 来说，只要它们是线性的，那么得到的decision boundary也是线性的。</p>

<p>虽然无法直接使得 $\sigma_k (x) 和 Pr(G = k|X = x)$ 是线性的，但是如果有一个单调的转化函数能够使得是线性的，那么我们也可以得到一个超平面分割数据点。</p>

<p>Logistic Regression 和 Linear Discriminant Analysis就是基于这样的需求构造的模型。</p>

<!--more-->

<h2 id="logistic-regression">Logistic Regression</h2>

<p>逻辑回归的模型也是源于通过 $x$ 的线性函数建立 $K$ 个类的后验概率模型，同时保证它们在[0,1]之间以及和为1。</p>

<script type="math/tex; mode=display"> log {Pr(G = 1 \vert X = x) \over Pr(G = K \vert X = x)} = \beta_{10} + \beta_1^Tx </script>

<script type="math/tex; mode=display"> log {Pr(G = 2 \vert X = x) \over Pr(G = K \vert X = x)} = \beta_{20} + \beta_2^Tx </script>

<script type="math/tex; mode=display"> log {Pr(G = K-1 \vert X = x) \over Pr(G = K \vert X = x)} = \beta_{(K-1)0} + \beta_{K-1}^Tx </script>

<p>这个转换函数称为 logit transformation, 概率称为 log-odds。得到</p>

<script type="math/tex; mode=display"> Pr(G = k \vert X = x) = {exp(\beta_{k0} + \beta_k^Tx) \over {1 + \sum_{l=1}^{K-1} exp(\beta_{l0} + \beta_l^Tx) }} </script>

<script type="math/tex; mode=display"> Pr(G = K \vert X = x) = {1 \over {1 + \sum_{l=1}^{K-1} exp(\beta_{l0} + \beta_l^Tx) }} </script>

<p>当 $K=2$ 的时候，输出设为0/1, 输出结果就是一个伯努利过程。可以使用maximum likelihood来对模型进行参数估计。</p>

<p>假设 $y_i = 1\ when\ g_i = 1,\ y_i = 0\ when\ g_i = 2$, 那么不妨设 $p(x_i; \beta) = Pr(G = 1|X = x) = {\beta^Tx \over {1 + exp(\beta^Tx)}}$，这时的 $p(x_i; \beta) = {1 \over {1 + exp(-\beta^Tx)}}$, 也成为<code>sigmoid function</code>。</p>

<p>log-likelihood得到结果为</p>

<script type="math/tex; mode=display"> \ell(\beta) = \sum {y_i log p(x_i; \beta) + (1 - y_i)log(1-p(x_i, \beta))} 
        = \sum {y_i\beta^Tx_i - log(1 + exp(\beta^Tx_i))}, </script>

<script type="math/tex; mode=display">其中\beta = \{\beta_{10}, \beta_1\}, x_i$ 的第一个元素为截距1.</script>

<script type="math/tex; mode=display"> 求导后得到\frac{\partial \ell (\beta)}{\partial \beta} = \sum_{i=1}^N {x_i(y_i - p(x_i; \beta))} = 0 </script>

<p>此时，可以使用梯度下降法或者牛顿法求解 $\beta$。下面使用牛顿法求解。</p>

<p>$$ \frac{\partial^2 \ell (\beta)}{\partial \beta \partial \beta^T} = 
    - \sum_{i=1}^N  {x_i x_i^T p(x_i; \beta)(1 - p(x_i; \beta))} $$
于是牛顿迭代即为
<script type="math/tex"> \beta^{new} = \beta^{old} - (\frac{\partial^2 \ell (\beta)}{\partial \beta \partial \beta^T})^{-1} \frac{\partial \ell (\beta)}{\partial \beta}, 其中所有的倒数都是在\beta^{old}的时候计算的 </script></p>

<p>下面说明这个问题就是加权最小二乘问题，可以变换得到
<script type="math/tex">\frac{\partial \ell (\beta)}{\partial \beta} = X^T(Y-P),\ \frac{\partial^2 \ell (\beta)}{\partial \beta \partial \beta^T} = -X^TWX </script>
其中 $Y$ 是 $y_i$的向量，$X$ 为 $N * (p+1)$ 的矩阵，$W$ 是一个 $N*N$ 的对角矩阵，元素为 $p(x_i; \beta^{old})(1 - p(x_i; \beta^{old}))$</p>

<p>可以得到 <script type="math/tex">\beta^{new} = (X^TWX)^{-1}X^TWz,\ z = X\beta^{old} + W^{-1}(Y-P)</script>, 这个表达式得到的就是weighted least squares step. $z$ 称为 response，或者说是 <em>adjusted response</em>。每个迭代$p$都会变，所以$W 和 z$也都会变，可以用<em>iteratively reweighted least squares</em>或者IRLS算法来计算，每个迭代就是解决一个weighted least squares问题：</p>

<script type="math/tex; mode=display">\beta^{new} \gets arg min_\beta (z - X\beta)^TW(z - X\beta)</script>

<p><em>注：weighted linear least squares</em></p>

<script type="math/tex; mode=display"> arg min_\beta \sum_{i=1}^m w_i \|y_i - \sum_{j=1}^n x_{ij}\beta_j\|^2 = arg min_\beta \vert W^{1 \over 2}(Y - X\beta) \vert ^2 </script>

<script type="math/tex; mode=display"> \hat{\beta} = (X^TWX)^{-1}X^TWY </script>

<h2 id="linear-discriminant-analysis">Linear Discriminant Analysis</h2>

<p>接下来我们给出另外一个模型，它的后验概率的logit也同样是一个线性模型。</p>

<p>假设 $f_k(x)$ 是类 $G=k$ 的输入的条件密度函数，$\pi_k$ 是类 $k$ 的先验概率，有 $\sum_{k=1}^K \pi_k = 1$。那么依据贝叶斯公式得到</p>

<script type="math/tex; mode=display"> Pr(G=k \vert X=x) = \frac{f_k(x) \pi_k}{\sum_{i=1}^K f_i(x) \pi_i} </script>

<p>假设每个类服从multivariate Guassian分布， 那么</p>

<script type="math/tex; mode=display">f_k(x) = \frac{e^{-1/2(x-\mu_k)^T\Sigma_k^{-1}(x-\mu_k)}}{(2\pi)^{p/2} \vert \Sigma_k \vert ^{1/2}}</script>

<p>当每个类都有一个相同的协方差矩阵 $\Sigma$ 的时候，我们有以下推导</p>

<script type="math/tex; mode=display"> log {Pr(G = k \vert X = x) \over Pr(G = \ell \vert X = x)} = log{\pi_k \over \pi_\ell} - \frac{1}{2}(\mu_k + \mu_\ell)^T\Sigma^{-1}(\mu_k - \mu_\ell) + x^T\Sigma^{-1}(\mu_k - \mu_\ell) </script>

<p>注意到这个式子也就是 $\alpha_{k0} + \alpha_k^Tx$，也就是和logistic regression一样的模型。</p>

<p>并且这个式子可以推出线性判别函数为 </p>

<script type="math/tex; mode=display"> \delta_k(x) = x^T\Sigma^{-1}\mu_k - \frac{1}{2}\mu_k^T\Sigma^{-1}\mu_k + log\pi_k</script>

<script type="math/tex; mode=display"> G(x) = argmax_k \delta_k(x) </script>

<p>实际上，高斯分布的参数可以从训练集中估计：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-16/18265816.jpg" width="400px" /></p>

<p>可以看出来LDA做了一下的假设：</p>

<ul>
  <li>类的分布是高斯函数</li>
  <li>每个类都有一个共同的协方差矩阵</li>
</ul>

<p>看起来LDA和logistic regression模型是一样的，它们的区别是对线性参数估计的方法不同。
$X$ 和 $G$ 的联合概率如下</p>

<script type="math/tex; mode=display"> Pr(X, G=k) = Pr(X)Pr(G=k \vert X) </script>

<p>对于LDA和logistic regression，公式的后半部分都是一样的。LR模型也是忽略了前半部分的边际概率，直接对条件概率进行最大似然估计。但是LDA的参数估计是基于整个联合概率分布的</p>

<p><script type="math/tex"> Pr(X, G=k) = \phi(X; \mu_k, \Sigma)\pi_k, \phi是高斯密度函数 </script>
<script type="math/tex"> Pr(X) = \sum_{k=1}^K\phi(X; \mu_k, \Sigma)\pi_k</script></p>

<p>这个边际概率有什么用呢，总的来说是提供参数估计的更多信息，减少参数估计的方差。但是在LDA中，由于outliers会对协方差矩阵做出一定贡献，所以LDA对outliers会比较敏感。如果我们忽略这些假设，而Input确实是高斯分布的，那么根据Efrom的论文，会有”in the worst case ignoring this marginal part of the likelihood constitutes a loss of efficiency of about 30% asymptotically in the error rate”.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Gradient Descent and Newton Method]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/15/gradient-descent-and-newton-method/"/>
    <updated>2016-02-15T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/15/gradient-descent-and-newton-method</id>
    <content type="html"><![CDATA[<p>梯度下降和牛顿法都是最优化算法，二者都是求解无约束优化问题的方法，通过递归地逼近最优值来达到求解值。区别在于梯度下降是一阶收敛，而牛顿法是二阶收敛的，所以牛顿法通常会更快，因为牛顿法是用一个二次曲面去拟合当前所处位置的局部曲面，而梯度下降法是用一个平面去拟合当前的局部曲面。wiki上有张图形象地说明了这个问题：</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/da/Newton_optimization_vs_grad_descent.svg" width="200px" /></p>

<p>下面给出两种方法的具体推导。</p>

<!--more-->

<h2 id="gradient-descent">Gradient Descent</h2>

<p>假设 $f(x)$ 是 $R^n$ 上具有一阶连续偏导数的函数，要求解无约束最优化问题 $min f(x)$.</p>

<p>由于 $f(x)$ 具有一阶连续偏导数，$k$ 次迭代后在 $x^{(k)}$ 附近进行一阶泰勒展开：</p>

<script type="math/tex; mode=display"> f(x) = f(x^{(k)}) + \nabla f(x^{(k)})^T (x - x^{(k)}) </script>

<p>第 $k+1$ 次迭代值 $x^{(k+1)} \gets x^{(k)} - \lambda \nabla f(x^{(k)})$, 其中 $-\nabla f(x^{(k)})$是负梯度方向，$\lambda$是步长。</p>

<p>在上述公式中，$\lambda$ 的每次迭代都可以由一维搜索得到结果，这时的梯度搜索方法叫<code>Exact line search</code>。它形成的搜索路径很有意思，相邻的搜索路径是正交的，形状是 zig-zagging，如图：</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/db/Gradient_ascent_%28contour%29.png" width="300px" /></p>

<p>很容易证明：
<script type="math/tex"> \varphi(\lambda) = f(x^{(k)}) + \lambda d^{(k)}, d^{(k)} = -\nabla f(x^{(k)}) </script>
为求出从 $x^{(k)}$ 出发沿着负梯度方向的极小值，令
<script type="math/tex"> \varphi'(\lambda) = \nabla f(x^{(k)} + \lambda d^{(k)})^T d^{(k)} = 0</script>
<script type="math/tex">-\nabla f(x^{(k+1)})^T -\nabla f(x^{(k)}) = 0 </script></p>

<p>上述表明 $d^{(k)}$ 与 $d^{(k+1)}$ 正交，搜索路径是锯齿形状的，当接近极小值点的时候，每次迭代移动的步长很小，这样影响了收敛速度。</p>

<p>大多数的梯度搜索方法代用<code>inexact line search</code>，这种方法使用更加的普遍，它不要求每次迭代得到准确的步长值，而是采用估计值。有种搜索方法叫<code>backtracking line search</code>，它依赖两个常量：$\alpha, \beta$, </p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-15/4737593.jpg" width="600px" /></p>

<h2 id="newton-method">Newton Method</h2>

<p>牛顿法用迭代点的梯度和二阶导数对目标函数进行二次逼近，把二次函数的极小点作为新的迭代点，不断重复此过程，直到找到最优点。</p>

<p>假设 $f(x)$ 是 $R^n$ 上具有二阶连续偏导数的函数，要求解无约束最优化问题 $min f(x)$.</p>

<p>由于 $f(x)$ 具有二阶连续偏导数，$k$ 次迭代后在 $x^{(k)}$ 附近进行二阶泰勒展开：</p>

<script type="math/tex; mode=display"> f(x) = f(x^{(k)}) + \nabla f(x^{(k)})^T (x - x^{(k)}) + 1/2 (x - x^{(k)})^T \nabla^2 f(x^{(k)}) (x - x^{(k)})</script>

<p>其中 $\nabla^2 f(x^{(k)})$ 是 $f(x)$ 在 $x^{(k)}$ 处的Hesse矩阵，为了求极值，对二阶泰勒公式求导，得到</p>

<script type="math/tex; mode=display"> \nabla f(x) = \nabla f(x^{(k)}) + \nabla^2 f(x^{(k)})(x - x^{(k)}) = 0 </script>

<script type="math/tex; mode=display"> x^{(k+1)} \gets x^{(k)} - \nabla^2 f(x^{(k)})^{-1} \nabla f(x^{(k)}) </script>

<p>其中我们假设Hesse矩阵是可逆的，并且对于正定的Hesse矩阵，我们可以确定是迭代方向是下降的，因为 $-\nabla f(x)^T \nabla^2 f(x)^{-1} \nabla f(x) &lt; 0$, $-\nabla^2 f(x)^{-1} \nabla f(x)$就被称为 <em>Newton step</em>. 算法如下：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-15/19107554.jpg" width="600px" /></p>

<h3 id="quasi-newton-methods">Quasi-Newton Methods</h3>

<p>Quasi-Newton即拟牛顿法，这是一种“模拟“的牛顿法，它模拟牛顿法中的搜索方向的生成方式。那么为什么要模拟呢？</p>

<p>在牛顿法中，有如下的缺点：</p>

<ul>
  <li>可能出现Hesse矩阵奇异的情形，因此不能确定后继点；</li>
  <li>即使矩阵非奇异，也未必正定，因而牛顿方向不一定是下降方向</li>
  <li>需要计算Hesse矩阵的逆矩阵，计算比较复杂。</li>
</ul>

<p>我们可以使用另外一个n阶矩阵 $G_k$ 来代替，并且需要确保 $G_k$ 的正定。</p>

<p>在牛顿法中，我们令 $\nabla f(x)$ 中 $x$ 为 $x^{(k+1)}$，得到
<script type="math/tex"> g_{k+1} - g_k = H_k (x^{(k+1)} - x^{k}), 其中 g_k = \nabla f(x^{(k)}), H_k = \nabla^2 f(x^{(k)})</script></p>

<p>记 $y_k = g_{k+1} - g_k, \delta_k = x^{(k+1)} - x^{k}$, 则有
<script type="math/tex">y_k = H_k \delta_k 或者 H_k^{-1} y_k = \delta_k </script></p>

<p>拟牛顿法将 $G_k$ 作为 $H_k^{-1}$ 的近似，要求矩阵 $G_k$ 同样满足，每次迭代都是正定，并且 $G_{k+1} y_k = \delta_k$ . 按照拟牛顿条件，每次迭代中可以选择更新矩阵 $G_{k+1} = G_k + \nabla G_k$ . 由此延伸出来三种算法</p>

<ol>
  <li>DFP算法使用 $G_k$ 逼近Hesse矩阵的逆矩阵。</li>
  <li>BFGS算法使用 $B_k$ 逼近Hesse矩阵。</li>
  <li>Broyden类算法。</li>
</ol>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Some Pre-Concepts in Machine Learning]]></title>
    <link href="http://billowkiller.github.io/blog/2016/02/13/concepts-ml/"/>
    <updated>2016-02-13T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/02/13/concepts-ml</id>
    <content type="html"><![CDATA[<p>几个容易模糊的机器学习前置概念。做下记录，包括classifier, Hypothesis, Model等。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-2-21/78335003.jpg" width="400px" /></p>

<!--more-->

<p>Essentially, the terms “classifier” and “model” are synonymous in certain contexts; however, sometimes people refer to “classifier” as the learning algorithm that learns the model from the training data. To makes things more tractable, let’s define some of the key terminology:</p>

<ul>
  <li>
    <p><code>Training sample</code>: A training sample is a data point x in an available training set that we use for tackling a predictive modeling task. For example, if we are interested in classifying emails, one email in our dataset would be one training sample. Sometimes, people also use the synonymous terms training instance ortraining example.</p>
  </li>
  <li>
    <p><code>Target function</code>: In predictive modeling, we are typically interested in modeling a particular process; we want to learn or approximate a particular function that, for example, let’s us distinguish spam from non-spam email. The target function f(x) = y is the true function f that we want to model.</p>
  </li>
  <li>
    <p><code>Hypothesis</code>: A hypothesis is a certain function that we believe (or hope) is similar to the true function, the target function that we want to model. In context of email spam classification, it would be the rule we came up with that allows us to separate spam from non-spam emails.</p>
  </li>
  <li>
    <p><code>Model</code>: In machine learning field, the terms hypothesis and model are often used interchangeably. In other sciences, they can have different meanings, i.e., the hypothesis would be the “educated guess” by the scientist, and the model would be the manifestation of this guess that can be used to test the hypothesis.</p>
  </li>
  <li>
    <p><code>Learning algorithm</code>: Again, our goal is to find or approximate the target function, and the learning algorithm is a set of instructions that tries to model the target function using our training dataset. A learning algorithm comes with ahypothesis space, the set of possible hypotheses it can come up with in order to model the unknown target function by formulating the final hypothesis</p>
  </li>
  <li>
    <p><code>Classifier</code>: A classifier is a special case of a hypothesis (nowadays, often learned by a machine learning algorithm). A classifier is a hypothesis or discrete-valued function that is used to assign (categorical) class labels to particular data points. In the email classification example, this classifier could be a hypothesis for labeling emails as spam or non-spam. However, a hypothesis must not necessarily be synonymous to a classifier. In a different application, ourhypothesis could be a function for mapping study time and educational backgrounds of students to their future SAT scores.</p>
  </li>
</ul>

<p>So, we can say that a <code>classifier</code> is a special case of a <code>hypothesis</code> or <code>model</code>: a classifier is a function that assigns a class label to a data point.</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Extract-Transform-Load Application Scenarios]]></title>
    <link href="http://billowkiller.github.io/blog/2016/01/13/etl/"/>
    <updated>2016-01-13T14:00:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2016/01/13/etl</id>
    <content type="html"><![CDATA[<h1 id="etl">实时流ETL应用场景</h1>

<p>现有的企业级数据量在不断增大，用户也在寻求大数据解决方案来处理这些日益增长的数据。那么什么是大数据处理的架构呢。Cloudera总结的很好，大数据架构是建立在一系列开发可靠、可扩张、完整的自动化data pipeline上，下面的一张图给了很好的解释：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-1-25/11725472.jpg" width="500px" /></p>

<!--more-->

<p>data pipeline目的在于获取数据并能够发掘其中的价值。数据工程师决定数据从何处来，如何进入数据处理层，以及如何处理，如何存储和进一步展示。当然还需要包括必不可少的集群设计、系统调优等。上图中后端的分析工具通常为BI展示或其他分析工具，中间的处理通常由Spark、Hadoop进行，前端的数据获取包括批量和实时的两种。</p>

<p>在BMR中，我们已经为您处理了底层的集群设计、系统调优，打通数据交互层等工作，您只需要专注于如何在业务上挖掘数据潜在的价值即可。</p>

<h2 id="section">应用场景举例</h2>

<p>百度的IDMapping接入层每天的PV达到上亿，每天产生的日志量达到100GB，日志中的信息包括用户的访问IP、访问时间、响应时间、用户请求、应答内容等。IDMapping由10台nginx服务器构成、分别部署在不同的服务器上。其中的日志格式如下：</p>

<p>数据格式如下：</p>

<pre><code>$remote_addr - [$time_local] "$request" $status $body_bytes_sent "$http_referer"  $http_cookie" $remote_user "$http_user_agent" $request_time  $host $msec
</code></pre>

<p>下面是一条具体日志：</p>

<pre><code>10.81.78.220 - [04/Oct/2015:21:31:22 +0800] "GET /u2bmp.html?dm=37no6.com/003&amp;ac=1510042131161237772&amp;v=y88j6-1.0&amp;rnd=1510042131161237772&amp;ext_y88j6_tid=003&amp;ext_y88j6_uid=1510042131161237772 HTTP/1.1" 200 54 "-" "-" 9CA13069CB4D7B836DC0B8F8FD06F8AF "ImgoTV-iphone/4.5.3.150815 CFNetwork/672.1.13 Darwin/14.0.0" 0.004 test.com.org 1443965482.737
</code></pre>

<p>负责人希望能够通过这些日志信息实时地获取服务的PV、UV等统计信息以及访问用户IP的所在地信息等，并且希望可以查询任意时间的用户访问信息，以此满足日常运营的需求，后续还可能添加告警和日运营报表等功能。</p>

<h2 id="section-1">解决方案</h2>

<p>在BMR中我们集成了Flume、Kafka、Spark、Hbase组件，可以很好的满足应用场景中IDMapping负责人的集群需求。我们设计了如下的大数据处理的pipeline。</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-1-26/97268179.jpg" width="750px" /></p>

<p>每台机器上的日志数据通过flume实时地推送到Kafka集群中，在spark集群中订阅这些日志数据，经过ETL处理后存储到Hbase中。前端展示系统可以通过Hbase的Restful接口实时的获取数据。同时，可以提交新的spark streaming application修改原有的数据处理模型，也可以在后端也可以对数据进一步加工：通过集群内部的mahout、spark mllib或对接其他的BI系统，例如Palo、Saiku。</p>

<p>以下是前端获取数据后的展示效果图：</p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-1-24/88317070.jpg" width="350px" /></p>

<p><img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-3-23/77070404.jpg" width="400px" /></p>

<p>接下来通过三步骤对这个解决方案在BMR中的实现进行详细的阐述。</p>

<h3 id="step-1-">Step 1 创建集群</h3>

<p>创建包括Spark和Streaming组件的集群。在生产环境中建议分别创建Kafka和Spark集群。可以参考<a href="https://bce.baidu.com/doc/BMR/GettingStarted.html#.E5.88.9B.E5.BB.BA.E9.9B.86.E7.BE.A4">文档</a>。</p>

<h3 id="step-2-">Step 2 数据准备</h3>

<p>数据获取表示如何将nginx产生的日志通过flume导入到BMR集群中。我们执行下面的命令：</p>

<pre><code>wget http://bmr.bj.bcebos.com/tools/flume/flume-1.6.0.tar.gz
vim $FLUME_HOME/conf/flume-conf.properties
$FLUME_HOME/bin/flume-ng agent --conf conf --conf-file $FLUME_HOME/conf/flume-conf.properties --name agent
</code></pre>

<p>以上的命令分别表示获取flume、编辑配置文件、运行flume agent。其中配置文件参考<a href="http://wiki.baidu.com/pages/viewpage.action?pageId=158727265">http://wiki.baidu.com/pages/viewpage.action?pageId=158727265</a>，将<code>agent.sources.s.command</code>改为<code>tail $NGINX_HOME/logs/access.log</code>。</p>

<h3 id="step-3-">Step 3 数据处理</h3>
<p>建立新的spark集群，当然在测试阶段您也可以直接使用kafka集群中的spark进行处理，在实际应用中推荐使用新的spark集群。</p>

<ol>
  <li>下载spark streaming代码，进行编译，将编译结果<code>bmr-spark-kafka-samples-1.0-SNAPSHOT-jar-with-dependencies.jar</code>放到bos中。</li>
  <li>
    <p>从console页面进去到对应集群的作业列表页面，然后点击“添加作业”，如果使用系统提供的输入数据和jar包，可以按照如下方式填写参数：</p>

    <blockquote>
      <p>作业类型：Spark</p>
    </blockquote>

    <blockquote>
      <p>名称：FKSTest</p>
    </blockquote>

    <blockquote>
      <p>bos输入地址： bos://${PATH}/bmr-spark-kafka-samples-1.0-SNAPSHOT-jar-with-dependencies.jar</p>
    </blockquote>

    <blockquote>
      <p>失败后操作：继续</p>
    </blockquote>

    <blockquote>
      <p>Spark-submit: –class com.baidubce.bmr.sample.DirectFKSTest</p>
    </blockquote>

    <blockquote>
      <p>应用程序参数：ng1889b62-master-instance-f5lvbago topic</p>
    </blockquote>

    <p>其中应用程序参数分别代表集群master的hostname和kafka topic。 </p>
  </li>
  <li>
    <p>您可以通过集群页面的<code>Resource Manager Web UI</code>查看spark UI查看作业运行的状态。（进入页面所需要的用户名密码会通过短信形式发送到您手机上）
 <img src="http://7xqfqs.com1.z0.glb.clouddn.com/16-1-25/49196148.jpg" alt="" /></p>
  </li>
  <li>
    <p>查看hbase中的数据：</p>

    <pre><code> hbase(main):001:0&gt; list
 hbase(main):002:0&gt; scan 'PVUV', {COLUMN=&gt;['statistics:PV:toInt', 'statistics:UV:toInt']}
</code></pre>
  </li>
</ol>

<h2 id="spark-streaming">关于Spark Streaming中实时流的说明建议</h2>

<p>在Spark Streaming中有两种API用于处理与kafka之间的交互。</p>

<ul>
  <li>一种是spark1.2.0引进的<code>KafkaUtils.createStream</code>，这种方式可以将kafka或其他流式输入先写入磁盘再分片处理，防止重启driver造成数据丢失。换句话说，可以保证At least Once语义，前提是开启<code>Write Ahead Logs</code>，方法如下
    <ul>
      <li>在代码中通过<code>streamingContext.checkpoint</code>配置checkpoint目录</li>
      <li>配置<code>spark.streaming.receiver.writeAheadLog.enable</code>为<code>true</code></li>
    </ul>
  </li>
  <li>另外一种则是spark1.3.0引进的Direct API。这种方式保证的是<code>Exactly Once</code>语义，解决上种方式中<code>consumer offset</code>和数据Logs存储不一致性造成的数据重复计算。这种方式通过将<code>offset</code>存入
checkpoints中，来保证接收数据的一致性。</li>
</ul>

<p>使用<code>KafkaUtils.createStream</code>需要有一下两种考虑：</p>

<ul>
  <li>提高streaming的吞吐量，我们通常会使用多个consumer来并行的获取数据，每个consumer分配到一个executor的单核上，最后将所有得到的Stream进行<code>Union</code>操作。
如果不进行<code>Union</code>则会导致<code>Transformation</code>数量增多<code>#consumer</code>倍。</li>
  <li>另外也要考虑RDD中partition的数量，减少partition数量有助于减少task个数以及调度时间。partition的数量是由batchInterval和spark.streaming.blockInterval共同决定的，根据spark官方指导，通常partition数目
为cores的2到3倍比较合适，所以可以调整适当的参数控制partition的个数。</li>
</ul>

<p>而在DirectAPI中会自动定期的根据kafka的topic+partition查询最新的offset，定义需要处理的offset范围。所以不需要考虑创建多少receivers，也不需要考虑partition的数量。在API中每个kafka partition都是自动地并行读取，并且对应每个RDD partition，从而简化Streaming处理的并行模式。</p>

<p>但是DirectAPI并不会在zookeeper中更新offset，所以基于zookeeper的kafka监控工具无法查看日志处理的进度。但您也可以查询checkpoint，将offset写入zookeeper中。</p>

<p>这两种使用方式在Sample中都有详细的例子可以参考，分别是<code>com.baidubce.bmr.sample.FKSTest</code>和<code>com.baidubce.bmr.sample.DirectFKSTest</code>。</p>

<h2 id="section-2">总结</h2>

<p>虽然针对不同的目标和业务案例使用流式处理的方式也不同，但其主要场景包括：</p>

<ul>
  <li>流ETL——将数据推入存储系统之前对其进行清洗和聚合。</li>
  <li>触发器——实时检测异常行为并触发相关的处理逻辑。</li>
  <li>数据浓缩——将实时数据与静态数据浓缩成更为精炼的数据以用于实时分析。</li>
  <li>复杂会话和持续学习——将与实时会话相关的事件组合起来进行分析。</li>
</ul>

<p>在上述例子中我们介绍了BMR中流ETL的场景。
在BMR中，我们提供了Hadoop生态圈中的全栈组件包括Hadoop、Spark、Hbase、Hive、Pig、Kafka、Mahout等，
您可以根据自己的业务场景灵活地选择不同的组件。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop Tunning]]></title>
    <link href="http://billowkiller.github.io/blog/2015/12/01/hadoop-tunning/"/>
    <updated>2015-12-01T09:50:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2015/12/01/hadoop-tunning</id>
    <content type="html"><![CDATA[<p>Hadoop的调优涉及到整个MapReduce的各个过程，并且要对每个参数的意义和Counter信息有一定的了解。也就是说，根据Counter的信息推测哪些MapReduce阶段可能存在性能瓶颈，并且根据这个瓶颈理解对应的Hadoop 框架中的处理逻辑，进而可以调整相关参数的大小或程序的行为。</p>

<p>从大面上来看，MapReduce的瓶颈可能存在以下图中的各个部分。</p>

<p><img src="http://ww2.sinaimg.cn/large/74311666jw1eyjx8zpfz2j20rq0cegna.jpg" width="500px" /></p>

<!--more-->

<p>在开始调优之旅前，先来个开胃小菜。进行调优的过程中，我们首先要知道整个job的运行情况。</p>

<p>Hadoop 2中的JobHistory是能够提供作业运行时各个参数指标的展示工具，可以通过这个UI界面查看所有的Counter。另一方面如果不方便通过界面的方式查看，则可以利用Hadoop自带的命令行工具查看，方法是<code>hadoop job -history &lt;history file&gt;</code>, 这个history file的位置通常是在mapreduce.jobhistory.done-dir目录下，可以用如下方式查找<code>hadoop fs -lsr &lt;done-dir&gt; | grep job_1398974791337_0037</code>。</p>

<h2 id="map-optimizations">Map Optimizations</h2>

<p>在Map端的优化通常会涉及到输入的数据和它的处理过程，以及你的应用程序代码。Mapper需要读取作业的输入，输入文件的不同也会影响到作业运行的效率，例如文件是否是splittable，数据的本地性和input split的数量等等。</p>

<h3 id="data-locality">Data Locality</h3>

<p>在分布式计算中有条著名的准则<strong>Pushing compute to the data</strong>，map的task应该尽可能的被安排在数据存放的节点上。可以用Counter来判断作业是否符合这条准则:</p>

<ul>
  <li>HDFS_BYTES_READ：这个值应当不大于input file的block size</li>
  <li>DATA_LOCAL_MAPS：这个值应当为1</li>
  <li>RACK_LOCAL_MAPS：这个值应当为0</li>
</ul>

<p>以下几种情况可能会发生non-local read:</p>

<ul>
  <li>不能分割的大文件，这样mapper就必须从不同的节点中读取blocks。</li>
  <li>文件格式支持split，但是用的input format不对。典型的情况是LZOP格式，需要先建立索引后再进行读取。</li>
  <li>Yarn的调度器不能在某个节点上产生map container，通常是由于集群under load。</li>
</ul>

<p>解决方法是：</p>

<ul>
  <li>尽量保持unsplittable文件的大小接近一个block的大小。</li>
  <li>设置yarn的<code>scheduler.capacity.node-locality-delay</code>，引入跳过的调度次数，来增加map task分配到数据节点上的概率。</li>
  <li>使用Twitter提供的LZO Input Format来处理lzop数据，或者使用bzip2格式的文件。</li>
</ul>

<h3 id="map-number-overwhelm">Map Number Overwhelm</h3>

<p>当输入有很多的input split的时候，每个input split都需要一个mapper来执行，而每个mapper都是一个单独的进程。这样会给调度器和集群带来极大的压力。原因通常有两个：</p>

<ul>
  <li>input data由很多的小文件组成，Hadoop会为每个小文件生成一个mapper，最终时间会大量消耗在启动进程上。</li>
  <li>每个文件并不是很小（和block size相当），但总体的数据量很大，横跨上千个HDFS的blocks。这样每个block也会分配给单独的mapper。</li>
</ul>

<p>如果是第一种情况，可以先聚合这个小文件，或者使用类似avro的文件格式来存储。或者直接用<code>CombineFileInputFormat</code>来处理以上这两种情况，它可以在一个mapper里处理多个HDFS block的数据。<code>CombineFileInputFormat</code>会首先检查input files的所有blocks，简历每个block到data nodes的映射关系，接着将同一个节点上的blocks聚合到一个input split中以保持data locality。它有三个配置项来调整：</p>

<ul>
  <li>mapreduce.input.fileinputformat.split.minsize.per.node</li>
  <li>mapreduce.input.fileinputformat.split.minsize.per.rac</li>
  <li>mapreduce.input.fileinputformat.split.maxsize</li>
</ul>

<p>以上的默认配置会造成每个节点上尽量形成一个最大的input split，影响作业的并行性，可以用以上几个配置来调整。<code>CombineFileInputFormat</code>还包括两个具体的类：</p>

<ul>
  <li><code>CombineTextInputFormat</code></li>
  <li><code>CombineSequenceFileInputFormata</code></li>
</ul>

<h3 id="input-split-computation">Input Split Computation</h3>

<p>如果提交作业的client是在集群局域网之外，那么input split的计算可能带来高成本。</p>

<p>当输入的数据源是HDFS时，client需要做如下事情，包括file listing, file status retrieving，input files数量比较多的时候，整个过程带来数据传输的延迟是比较可观的。</p>

<p>可以通过设置<code>yarn.app.mapreduce.am.compute-splits-in-cluster</code>将input split的计算交给AppMaster处理，这是在集群内部进行的。</p>

<h2 id="shuffle-optimizations">Shuffle Optimizations</h2>

<h3 id="using-the-combiner">Using the Combiner</h3>

<p>combiner可以有效的减少mapper和reducer之间通信的数据量。</p>

<h3 id="using-binary-comparators">Using Binary Comparators</h3>

<p>MapReduce在做sorting或者merging的时候，使用<code>RawComparator</code>比较map output key。内置的<code>Writable</code> classes（<code>Text</code>、<code>IntWritable</code>）有byte-level的比较器，无需将二进制的数据重新组装成实际的对象，所以能够快速进行序列化对象的比较。</p>

<p>用户可以在自己构造的<code>Writable</code>对象里面实现<code>WritableComparable</code>接口，这处理起来会比较容易，但是另一方面要注意MapReduce中map output data是以byte的形式存储的，这会导致在shuffle和sort的阶段需要从byte到object的转化才可以完成对象的比较。</p>

<p>可以看到在Hadoop的内置<code>Writable</code>对象不仅实现了<code>WritableComparable</code>接口，还自定义继承自<code>WritableComparator</code>的比较器。<code>WritableComparator</code>有什么作用呢，可以看下它的一些方法申明。</p>

<pre><code>public class WritableComparator implements RawComparator {
    public int compare(byte[] b1, int s1, int l1,
                       byte[] b2, int s2, int l2); 
}
</code></pre>

<p>可以看到这是byte-level的Comparator，<code>Writable</code>对象正是覆盖了这里面的compare方法。在内置的<code>Writable</code>对象中都实现了<code>WritableComparator</code>，所以无需担心内置对象的效率。但是自己所构造的对象也可以实现<code>WritableComparator</code>方法来提高效率。</p>

<p>例如一个拥有firstName和lastName的Person对象：</p>

<pre><code>private String firstName;
private String lastName;

@Override
public void write(DataOutput out) throws IOException {
    out.writeUTF(lastName);
    out.writeUTF(firstName);
}
</code></pre>

<p><img src="http://i5.tietuku.com/e5eba32886b5773d.png" width="600px" /></p>

<pre><code>public int compare(byte[] b1, int s1, int l1, byte[] b2, int s2,
                     int l2) {
    int lastNameResult = compare(b1, s1, b2, s2);
    if (lastNameResult != 0) {
        return lastNameResult;
    }
    int b1l1 = readUnsignedShort(b1, s1);
    int b2l1 = readUnsignedShort(b2, s2);
    return compare(b1, s1 + b1l1 + 2, b2, s2 + b2l1 + 2);
}

public static int compare(byte[] b1, int s1, byte[] b2, int s2) {
    int b1l1 = readUnsignedShort(b1, s1);
    int b2l1 = readUnsignedShort(b2, s2);
    return compareBytes(b1, s1 + 2, b1l1, b2, s2 + 2, b2l1);
}

public static int readUnsignedShort(byte[] b, int offset) {
    int ch1 = b[offset];
    int ch2 = b[offset + 1];
    return (ch1 &lt;&lt; 8) + (ch2);
}
</code></pre>

<h3 id="tunning-the-shuffle-internals">Tunning the shuffle internals</h3>

<p>在mapper中，output record首先被存储在一个内存buffer中，当这个buffer增长到一定大小的时候，数据被spill到磁盘中的一个文件。整个过程持续到mapper完成所有的output record生成。过程如下：</p>

<p><img src="http://i5.tietuku.com/952140624345e77f.png" width="500px" /></p>

<p>在整个阶段中，I/O相关的splling和merging是最耗时的，所以理想状况应该是所有的output数据都可以装入buffer中，这样只有一个文件被spill到磁盘。这对所有的作业来说自然是不大可能，但是如果mapper可以通过filter或者project的方法减少input data，那么可以好好调整下<code>mapreduce.task.io.sort.mb</code>的大小，因为这个数据直接关系buffer的大小。可以通过检查下面的Counters来调整map端的shuffle：</p>

<ul>
  <li>MAP_OUTPUT_BYTES  用这个数据来估计是否可以调整<code>mapreduce.task.io.sort.mb</code>来装入map的output record</li>
  <li>SPILLED_RECORDS/MAP_OUTPUT_RECORDS  这两个数据的理想情况是一致的，表示只有一个spill发生。</li>
  <li>FILE_BYTES_READ/FILE_BYTES_WRITTEN  比较这两个数据和MAP_OUTPUT_BYTES可以理解在splling和merging阶段发生的读写副作用</li>
</ul>

<p>在reduce方面，map的output通过每个节点上运行的shuffle service进程被发送到对应的reducer。在reducer中，map output是被写入到一个内存buffer中，在数据接收的过程中buffer中的数据被排好序，并在到达一定数据量的时候写入磁盘。同时有一个后台进程负责不断merge这个小的spllied file到merged files中，当所有的fetcher获取了所有的outputs，会有一个最终的merging发生，这时候数据也就从merged files到reducer了。也就是如下图的这个过程：</p>

<p><img src="http://i5.tietuku.com/d11419d045f44d9a.png" width="500px" /></p>

<p>通map端的调优一样，reduce端也是尽量将数据存入内存中，减少splling和merging发生的次数，但是这个过程并不如map端一样明显，因为数据是在边接收边merging的。默认情况下，无论数据是否可以装入内存中，splling总会发生，所以可以调整<code>mapreduce.reduce.merge.memtomem.enabled</code>为true启动memory-to-memory的merge。map端的Counter同样适用于reduce。</p>

<p>以下的参数可以用来调整Hadoop的shuffle行为：</p>

<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Default</th>
      <th>Map or Reduce</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>mapreduce.task.io.sort.mb</td>
      <td>100 (MB)</td>
      <td>Map</td>
      <td>The total amount of buffer memory in megabytes to use when buffering map outputs. This should be approximately 70% of the map task’s heap size.</td>
    </tr>
    <tr>
      <td>mapreduce.map.sort.spill.percent</td>
      <td>0.8</td>
      <td>Map</td>
      <td>Note that collection will not block if this threshold is exceeded while a spill is already in progress, so spills may be larger than this threshold when it is set to less than 0.5.</td>
    </tr>
    <tr>
      <td>mapreduce.task.io.sort.factor</td>
      <td>10</td>
      <td>Map and Reduce</td>
      <td>The number of streams to merge at once while sorting files. This determines the number of open file handles. Larger clusters with 1,000 or more nodes can bump this up to 100.</td>
    </tr>
    <tr>
      <td>mapreduce.reduce.shuffle.parallelcopies</td>
      <td>5</td>
      <td>Reduce</td>
      <td>The default number of parallel transfers run on the reduce side during the copy (shuffle) phase. Larger clusters with 1,000 or more nodes can bump this up to 20.</td>
    </tr>
    <tr>
      <td>mapreduce.reduce.shuffle.input.buffer.percent</td>
      <td>0.7</td>
      <td>Reduce</td>
      <td>The percentage of memory to be allocated from the maximum heap size to store map outputs during the shuffle.</td>
    </tr>
    <tr>
      <td>mapreduce.reduce.shuffle.merge.percent</td>
      <td>0.66</td>
      <td>Reduce</td>
      <td>The usage threshold at which an in-memory merge will be initiated, expressed as a percentage of the total memory allocated to storing in-memory map outputs, as defined by mapreduce.reduce.shuffle.input.buffer.percent.</td>
    </tr>
    <tr>
      <td>mapreduce.reduce.merge.memtomem.enabled</td>
      <td>false</td>
      <td>Reduce</td>
      <td>If all the map outputs for each reducer can be stored in memory, then set this property to true.</td>
    </tr>
  </tbody>
</table>

<p>Shuffle的原则是使用filter和project减少数据量，使用combiner以及压缩map的output，尽可能的减少mapper和reducer质检传递的数据，减低IO带来的开销。这样之后再利用上述提到的参数来调整Shuffle的过程。</p>

<h2 id="recuder-optimizations">Recuder Optimizations</h2>

<h3 id="the-number-of-reducers">The Number of Reducers</h3>

<p>大多数情况下map端的并行度是由框架根据input files和input format来自动决定的，但在Reduce端，reducer的数量是由用户自行决定的。太少的reducers意味着没能充分利用集群的资源，太多的reducer则会让调度器疲于奔命，如果没有太多的资源供所有reducer运行则会拖累reducer的执行效率。在一些使用场景中，不能避免的需要使用少量的reducer来运行作业，例如数据写入DB系统中。另外一些场景中需要确认数据是否会发生倾斜，以及如何partition的，数据量是否会让reducer发生OOM的情况。</p>

<h2 id="general-tunning-tips">General tunning tips</h2>

<ul>
  <li>压缩</li>
  <li>使用类似于Avro或Parquet的数据格式存储数据，带来的好处是空间利用率，序列化和反序列化更加有效。
    <ul>
      <li>在Hadoop中，text并不是一个有效的数据格式，空间利用率低，解析成本高，特别是用到正则的时候。</li>
      <li>尽可能考虑使用二进制的文件存储格式。</li>
    </ul>
  </li>
</ul>

<h2 id="tunning-tools">Tunning tools</h2>

<h3 id="stack-dumps">stack dumps</h3>

<p>ssh到task运行的机器上，执行下面的命令：</p>

<pre><code>ps aux | grep container_1393242034820_0001_01_000002
kill -s SIGQUIT 554284
kill -s SIGQUIT 554284
kill -s SIGQUIT 554284
</code></pre>

<p><code>SIGQUIT</code>信号的发送应该要间隔几秒，当JVM收到这个信号的时候会执行stack dump，这样可以了解到程序在这段时间内的运行情况。最后可以在task 的output file中查看dump出来的栈信息。</p>

<h3 id="profiling-map-and-reduce-task">Profiling Map and Reduce Task</h3>

<p>可以使用HPROF结合一些Mapreduce job method来进行Profiling。HPROF是JVM内置的java profiling工具，Hadoop内置了对HPROF的支持。可以在driver中加入如下的代码：</p>

<pre><code>job.setProfileEnabled(true);
job.setProfileParams(
    "-agentlib:hprof=depth=8,cpu=samples,heap=sites,force=n," +
        "thread=y,verbose=n,file=%s");
job.setProfileTaskRange(true, "0,1,5-10");
job.setProfileTaskRange(false, "");
</code></pre>

<p>在<code>setProfileParams</code>方法中设置的参数会在每个container中建立一个名为profile.out的文件，这个文件可以很容易被解析。可以通过ssh到目标机器查看或者通过JobHistory UI界面查看。</p>

<p>profile.out包括一些stack traces，还包括内存和CPU时间的信息。以下是一个profile.out文件：</p>

<p><img src="http://i5.tietuku.com/ba1dcbebf426b1a8.png" width="600px" /></p>

<p>可以看出来第一个问题是在<code>String.split</code>这个方法的使用上，它采用正则表达式来分割字符串，这个是相当耗时的一个举措，可以用Apache Commons Lang library的<code>StringUtils.split</code>来替换。另外一个是发生在Text的构造上，可以只构造一个Text实例，采用<code>set</code>方法进行设置，这样会更加有效率。</p>

<p>需要注意，使用HPROF会给程序的执行带来额外的负担，需要持续的收集profiling的信息，所以在正常的运行过程中不应该加上。</p>

]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Hadoop Secondary Sorting]]></title>
    <link href="http://billowkiller.github.io/blog/2015/11/22/hadoop-secondary-sorting/"/>
    <updated>2015-11-22T17:27:00+08:00</updated>
    <id>http://billowkiller.github.io/blog/2015/11/22/hadoop-secondary-sorting</id>
    <content type="html"><![CDATA[<p>Hadoop MapReduce的神奇之处发生在mapper和reducer之间，将所有相同key的map输出记录聚集在一块，使得用户可以方便的处理聚合在一起的数据。Hadoop内部使用了partition、sort和merge（shuffle的一部分），在每个reducer中流式地得到排序后的key和value集合。在MapReduce Sorting中有个特别的部分是secondary sort，也就是对value进行排序。</p>

<!--more-->

<p>Secondary sort在两种情况下特别有用：</p>

<ul>
  <li>需要某一部分的数据比其他数据更快的到达reducer。</li>
  <li>希望job的输出按照两个key进行排序。</li>
</ul>

<p>实现Secondary sort需要对MapReduce中的数据流和处理有一定的了解，下图展示了对reducer中出现的数据有影响的三个部分。</p>

<p><img src="http://i5.tietuku.com/7ad3ad872415c4b6.png" width="600px" /></p>

<p><code>partitioner</code>决定哪个reducer接收该mapper数据记录；<code>sorting RawComparator</code>用于在各自的分片中排序输出的结果，map和reduce阶段都有它，其中map阶段的sorting是对reduce阶段sorting的一个优化，让reducer的sorting更高效；最后，<code>grouping RawComparator</code>用于决定reducer处理排序后记录的边界，发生在reducer从本地磁盘读取数据的时候，也就是说，你可以用这个方法决定数据记录是如何聚集起来调用一个reduce方法的。MapReduce默认把这个三个方法作用于map方法输出的key上。</p>

<p>要实现Secondary sorting，我们需要重写partitioner、sort comparator和grouping comparator。</p>

<p>下面，通过对人名的排序来说明如何使用Secondary sorting。使用primary sort排序last name，secondary sort排序first name。</p>

<p>我们需要构建一个由map方法输出的Composite key，这个key由两部分组成：</p>

<ul>
  <li>Natural Key</li>
  <li>Secondary Key</li>
</ul>

<p><img src="http://i5.tietuku.com/25eedf0319e92775.png" width="430px" /></p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">Person</span> <span class="kd">implements</span> <span class="n">WritableComparable</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">  <span class="kd">private</span> <span class="n">String</span> <span class="n">firstName</span><span class="o">;</span>
</span><span class="line">  <span class="kd">private</span> <span class="n">String</span> <span class="n">lastName</span><span class="o">;</span>
</span><span class="line">
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">readFields</span><span class="o">(</span><span class="n">DataInput</span> <span class="n">in</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">    <span class="k">this</span><span class="o">.</span><span class="na">firstName</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">readUTF</span><span class="o">();</span>
</span><span class="line">    <span class="k">this</span><span class="o">.</span><span class="na">lastName</span> <span class="o">=</span> <span class="n">in</span><span class="o">.</span><span class="na">readUTF</span><span class="o">();</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line">
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">write</span><span class="o">(</span><span class="n">DataOutput</span> <span class="n">out</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span> <span class="o">{</span>
</span><span class="line">    <span class="n">out</span><span class="o">.</span><span class="na">writeUTF</span><span class="o">(</span><span class="n">firstName</span><span class="o">);</span>
</span><span class="line">    <span class="n">out</span><span class="o">.</span><span class="na">writeUTF</span><span class="o">(</span><span class="n">lastName</span><span class="o">);</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line"><span class="o">...</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>下图说明hadoop框架配置中用于设置partitioning、sorting和grouping类的名字和方法。</p>

<p><img src="http://i5.tietuku.com/520e7242cd6ecc43.png" width="530px" /></p>

<h3 id="partitioner">Partitioner</h3>

<p>默认的partitioner使用对key进行hash后取reducer个数的模。但是默认的partitioner使用整个key，会导致相同的natural key发往不同的reducer。所以需要实现自己的partitioner。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">PersonNamePartitioner</span> <span class="kd">extends</span>
</span><span class="line">    <span class="n">Partitioner</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">getPartition</span><span class="o">(</span><span class="n">Person</span> <span class="n">key</span><span class="o">,</span> <span class="n">Text</span> <span class="n">value</span><span class="o">,</span> <span class="kt">int</span> <span class="n">numPartitions</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">    <span class="k">return</span> <span class="n">Math</span><span class="o">.</span><span class="na">abs</span><span class="o">(</span><span class="n">key</span><span class="o">.</span><span class="na">getLastName</span><span class="o">().</span><span class="na">hashCode</span><span class="o">()</span> <span class="o">*</span> <span class="mi">127</span><span class="o">)</span> <span class="o">%</span>
</span><span class="line">        <span class="n">numPartitions</span><span class="o">;</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="sorting">Sorting</h3>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">PersonComparator</span> <span class="kd">extends</span> <span class="n">WritableComparator</span> <span class="o">{</span>
</span><span class="line">  <span class="kd">protected</span> <span class="nf">PersonComparator</span><span class="o">()</span> <span class="o">{</span>
</span><span class="line">    <span class="kd">super</span><span class="o">(</span><span class="n">Person</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="kc">true</span><span class="o">);</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line">
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">compare</span><span class="o">(</span><span class="n">WritableComparable</span> <span class="n">w1</span><span class="o">,</span> <span class="n">WritableComparable</span> <span class="n">w2</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">    <span class="n">Person</span> <span class="n">p1</span> <span class="o">=</span> <span class="o">(</span><span class="n">Person</span><span class="o">)</span> <span class="n">w1</span><span class="o">;</span>
</span><span class="line">    <span class="n">Person</span> <span class="n">p2</span> <span class="o">=</span> <span class="o">(</span><span class="n">Person</span><span class="o">)</span> <span class="n">w2</span><span class="o">;</span>
</span><span class="line">
</span><span class="line">
</span><span class="line">    <span class="kt">int</span> <span class="n">cmp</span> <span class="o">=</span> <span class="n">p1</span><span class="o">.</span><span class="na">getLastName</span><span class="o">().</span><span class="na">compareTo</span><span class="o">(</span><span class="n">p2</span><span class="o">.</span><span class="na">getLastName</span><span class="o">());</span>
</span><span class="line">    <span class="k">if</span> <span class="o">(</span><span class="n">cmp</span> <span class="o">!=</span> <span class="mi">0</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">      <span class="k">return</span> <span class="n">cmp</span><span class="o">;</span>
</span><span class="line">    <span class="o">}</span>
</span><span class="line">
</span><span class="line">    <span class="k">return</span> <span class="n">p1</span><span class="o">.</span><span class="na">getFirstName</span><span class="o">().</span><span class="na">compareTo</span><span class="o">(</span><span class="n">p2</span><span class="o">.</span><span class="na">getFirstName</span><span class="o">());</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="grouping">grouping</h3>

<p>grouping阶段所有的数据记录已经是secondary sort了，grouping comparator需要将相同的last name聚合在一起。</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">PersonNameComparator</span> <span class="kd">extends</span> <span class="n">WritableComparator</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">  <span class="kd">protected</span> <span class="nf">PersonNameComparator</span><span class="o">()</span> <span class="o">{</span>
</span><span class="line">    <span class="kd">super</span><span class="o">(</span><span class="n">Person</span><span class="o">.</span><span class="na">class</span><span class="o">,</span> <span class="kc">true</span><span class="o">);</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line">
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">public</span> <span class="kt">int</span> <span class="nf">compare</span><span class="o">(</span><span class="n">WritableComparable</span> <span class="n">o1</span><span class="o">,</span> <span class="n">WritableComparable</span> <span class="n">o2</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">    <span class="n">Person</span> <span class="n">p1</span> <span class="o">=</span> <span class="o">(</span><span class="n">Person</span><span class="o">)</span> <span class="n">o1</span><span class="o">;</span>
</span><span class="line">    <span class="n">Person</span> <span class="n">p2</span> <span class="o">=</span> <span class="o">(</span><span class="n">Person</span><span class="o">)</span> <span class="n">o2</span><span class="o">;</span>
</span><span class="line">
</span><span class="line">    <span class="k">return</span> <span class="n">p1</span><span class="o">.</span><span class="na">getLastName</span><span class="o">().</span><span class="na">compareTo</span><span class="o">(</span><span class="n">p2</span><span class="o">.</span><span class="na">getLastName</span><span class="o">());</span>
</span><span class="line">
</span><span class="line">  <span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<h3 id="mapreduce">MapReduce</h3>

<p>最后在driver中，需要设置上文提到的三个类：</p>

<div class="bogus-wrapper"><notextile><figure class="code"><figcaption><span></span></figcaption><div class="highlight"><table><tr><td class="gutter"><pre class="line-numbers"><span class="line-number">1</span>
<span class="line-number">2</span>
<span class="line-number">3</span>
<span class="line-number">4</span>
<span class="line-number">5</span>
<span class="line-number">6</span>
<span class="line-number">7</span>
<span class="line-number">8</span>
<span class="line-number">9</span>
<span class="line-number">10</span>
<span class="line-number">11</span>
<span class="line-number">12</span>
<span class="line-number">13</span>
<span class="line-number">14</span>
<span class="line-number">15</span>
<span class="line-number">16</span>
<span class="line-number">17</span>
<span class="line-number">18</span>
<span class="line-number">19</span>
<span class="line-number">20</span>
<span class="line-number">21</span>
<span class="line-number">22</span>
<span class="line-number">23</span>
<span class="line-number">24</span>
<span class="line-number">25</span>
<span class="line-number">26</span>
<span class="line-number">27</span>
<span class="line-number">28</span>
</pre></td><td class="code"><pre><code class="java"><span class="line"><span class="n">job</span><span class="o">.</span><span class="na">setPartitionerClass</span><span class="o">(</span><span class="n">PersonNamePartitioner</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line"><span class="n">job</span><span class="o">.</span><span class="na">setSortComparatorClass</span><span class="o">(</span><span class="n">PersonComparator</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line"><span class="n">job</span><span class="o">.</span><span class="na">setGroupingComparatorClass</span><span class="o">(</span><span class="n">PersonNameComparator</span><span class="o">.</span><span class="na">class</span><span class="o">);</span>
</span><span class="line">
</span><span class="line"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Map</span> <span class="kd">extends</span> <span class="n">Mapper</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Person</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class="line">  <span class="kd">private</span> <span class="n">Person</span> <span class="n">outputKey</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Person</span><span class="o">();</span>
</span><span class="line">
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">protected</span> <span class="kt">void</span> <span class="nf">map</span><span class="o">(</span><span class="n">Text</span> <span class="n">lastName</span><span class="o">,</span> <span class="n">Text</span> <span class="n">firstName</span><span class="o">,</span> <span class="n">Context</span> <span class="n">context</span><span class="o">)</span>
</span><span class="line">      <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
</span><span class="line">    <span class="n">outputKey</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">lastName</span><span class="o">.</span><span class="na">toString</span><span class="o">(),</span> <span class="n">firstName</span><span class="o">.</span><span class="na">toString</span><span class="o">());</span>
</span><span class="line">    <span class="n">context</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">outputKey</span><span class="o">,</span> <span class="n">firstName</span><span class="o">);</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span><span class="line">
</span><span class="line"><span class="kd">public</span> <span class="kd">static</span> <span class="kd">class</span> <span class="nc">Reduce</span> <span class="kd">extends</span> <span class="n">Reducer</span><span class="o">&lt;</span><span class="n">Person</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">,</span> <span class="n">Text</span><span class="o">&gt;</span> <span class="o">{</span>
</span><span class="line">
</span><span class="line">  <span class="n">Text</span> <span class="n">lastName</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Text</span><span class="o">();</span>
</span><span class="line">  <span class="nd">@Override</span>
</span><span class="line">  <span class="kd">public</span> <span class="kt">void</span> <span class="nf">reduce</span><span class="o">(</span><span class="n">Person</span> <span class="n">key</span><span class="o">,</span> <span class="n">Iterable</span><span class="o">&lt;</span><span class="n">Text</span><span class="o">&gt;</span> <span class="n">values</span><span class="o">,</span>
</span><span class="line">                     <span class="n">Context</span> <span class="n">context</span><span class="o">)</span>
</span><span class="line">      <span class="kd">throws</span> <span class="n">IOException</span><span class="o">,</span> <span class="n">InterruptedException</span> <span class="o">{</span>
</span><span class="line">    <span class="n">lastName</span><span class="o">.</span><span class="na">set</span><span class="o">(</span><span class="n">key</span><span class="o">.</span><span class="na">getLastName</span><span class="o">());</span>
</span><span class="line">    <span class="k">for</span> <span class="o">(</span><span class="n">Text</span> <span class="n">firstName</span> <span class="o">:</span> <span class="n">values</span><span class="o">)</span> <span class="o">{</span>
</span><span class="line">      <span class="n">context</span><span class="o">.</span><span class="na">write</span><span class="o">(</span><span class="n">lastName</span><span class="o">,</span> <span class="n">firstName</span><span class="o">);</span>
</span><span class="line">    <span class="o">}</span>
</span><span class="line">  <span class="o">}</span>
</span><span class="line"><span class="o">}</span>
</span></code></pre></td></tr></table></div></figure></notextile></div>

<p>Secondary sort涉及到的自定义的partitioner、sorter和grouper，还是比较复杂的。可以考虑<a href="http://htuple.org">htuple</a>对简单类型进行secondary sort。</p>

]]></content>
  </entry>
  
</feed>
