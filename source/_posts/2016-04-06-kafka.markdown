---
layout: post
title: "Kafka Introduction"
date: 2016-04-06 14:00
comments: true
category: "Big Data"
tags: [kafka, intro, unfinished]
---

Kafka最早是由LinkedIn开发的一个分布式发布-订阅消息系统，现在已经是Apache的一个开源项目。它具有以下的一些特点：

* 作为分布式系统，很容易 scale out
* 消息以时间复杂度为O(1)的方式持久化到磁盘，支持离线消费和实时消费
* 发布和订阅都支持高吞吐量，单机支持每秒100K条以上消息的传输
* 支持多个订阅端，并且可以在异常情况下自动对这些消费者进行负载均衡

![](http://kafka.apache.org/images/kafka_logo.png)

<!--more-->

消息系统的好处包括：

* 解耦生产者和消费者
* 持久化直到消息已经被完全处理
* 扩展性
* 灵活性 & 峰值处理能力
* 可恢复性，系统的一部分组件失效时，不会影响到整个系统。
* 顺序保证
* 缓冲，有助于控制和优化数据流经过系统的速度。
* 异步通信

## 名词解释

* Broker：Kafka集群包含一个或多个服务器，这种服务器被称为broker

* Topic：每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处）

* Partition：Parition是物理上的概念，每个Topic包含一个或多个Partition.

* Producer：负责发布消息到Kafka broker

* Consumer：消息消费者，向Kafka broker读取消息的客户端。

* Consumer Group：每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group）。

## 架构图

![](http://cdn.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-1/zh/resources/0310020.png)

如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。

![](http://cdn.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-1/zh/resources/0310025.png)

上图示意消费者和生产者的工作方式。同一Topic的一条消息只能被同一个Consumer Group内的一个Consumer消费，但多个Consumer Group可同时消费这一消息。实现一个Topic消息的广播（发给所有的Consumer）和单播（发给某一个Consumer）的手段。一个Topic可以对应多个Consumer Group。

![](http://sookocheff.com/img/kafka/kafka-in-a-nutshell/log-anatomy.png)

Topic在逻辑上可以被认为是一个queue，每条消费都必须指定它的Topic。为了使得Kafka的吞吐率可以线性提高，物理上把Topic分成一个或多个Partition，每个Partition在物理上对应一个文件夹，该文件夹下存储这个Partition的所有消息和索引文件。每条消息都被append到某个Partition中，具体存储到哪一个Partition是根据Partition机制。如果Partition机制比较合理，不同的消息可以并行写入不同broker的不同Partition里，能极大的提高了吞吐率。另因为磁盘限制，Kafka提供两种策略删除旧数据：一是基于时间，二是基于Partition文件大小。

### Kafka delivery guarantee

Producer向broker发送消息时，默认情况下一条消息从Producer到broker是确保了 `At least once`，但如果设置Producer为异步发送则实现 `At most once`。`Exactly once`还未实现（生成一种消息主键，幂等重试）。

Consumer在从broker读取消息后，可以选择`autocommit`或`手动commit`。区别在于一个是读完消息先commit再处理消息，一个是读完消息先处理再commit。前者实现 `At most once`，后者实现 `At least once`，但如果消息的处理有幂等性，则可以理解为`Exactly once`。如果要做到严格`Exactly once`，则让offset和操作输入存在同一个地方，保证数据的输出和offset的更新要么都完成，要么都不完成，参考Spark Kafka的DirectAPI的实现。

## High Available

Kafka的HA包括Data Replication和Leader Election两方面。

### Data Replication

![](http://cdn4.infoqstatic.com/statics_s2_20160405-0343u1/resource/articles/kafka-analysis-part-2/zh/resources/0416000.png)

为了更好的做负载均衡，Kafka尽量将所有的Partition均匀分配到整个集群上。一个典型的部署方式是一个Topic的Partition数量大于Broker的数量。同时为了提高Kafka的容错能力，也需要将同一个Partition的Replica尽量分散到不同的机器。Kafka分配Replica的算法如下：

1. 将所有Broker（假设共n个Broker）和待分配的Partition排序
2. 将第i个Partition分配到第（i mod n）个Broker上
3. 将第i个Partition的第j个Replica分配到第（(i + j) mode n）个Broker上

Producer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader pull数据。这种方式上，Follower存储的数据顺序与Leader保持一致。Follower在收到该消息并写入其Log后，向Leader发送ACK。一旦Leader收到了ISR(in-sync replica)中的所有Replica的ACK，该消息就被认为已经commit了，Leader将增加HW(high watermark)并且向Producer发送ACK。HW会从leader持续发送到follower并被保存到每个broker的磁盘中。

对于Producer而言，它可以选择是否等待消息commit，这可以通过request.required.acks来设置。这种机制确保了只要ISR有一个或以上的Follower，一条被commit的消息就不会丢失。

Consumer读消息也是从Leader读取，只有被commit过的消息（offset低于HW的消息）才会暴露给Consumer。

### Leader Election

Kafka在ZooKeeper中动态维护了一个ISR（in-sync replicas），这个ISR里的所有Replica都跟上了leader，只有ISR里的成员才有被选为Leader的可能。在这种模式下，对于f+1个Replica，一个Partition能在保证不丢失已经commit的消息的前提下容忍f个Replica的失败。对比Majority Vote则需要2f+1个Replica。

Kafka中，如果一个Follower宕机，或者落后太多，Leader将把它从ISR中移除，包括两种情况：长时间未向leader发送fetch request，消息lag超过阈值。
为了防止ISR里面的慢节点，Producer选择是否被commit阻塞。

选举时候，Kafka会在所有broker中选出一个controller，所有Partition的Leader选举都由controller决定。controller会将Leader的改变直接通过RPC的方式通知需为为此作为响应的Broker。同时controller也负责增删Topic以及Replica的重新分配。这种方式改善每个follower都使用zk watch的方法进行选举的问题：

* brain split
* herd effect 如果宕机的那个Broker上的Partition比较多，会造成多个Watch被触发，造成集群内大量的调整
* ZooKeeper负载过重 


## Kafka Clients' Operations

这一章节介绍一个Kafka client对于Kafka Resources可能的操作类型。

Operation包括以下几种：Read, Write, Create, Delete, Alter, Describe, ClusterAction。

### Create/Delete 

Create/Delete就是创建和删除Topics。

具体过程如下：

1. broker发送`TopicMetadataRequest`到controller。
1. Controller在ZooKeeper的/brokers/topics节点上注册Watch，一旦某个Topic被创建或删除，则Controller会通过Watch得到新创建/删除的Topic的Partition/Replica分配。
2. 对于删除Topic操作，Topic工具会将该Topic名字存于/admin/delete_topics。若delete.topic.enable为true，则Controller注册在/admin/delete_topics上的Watch被fire，Controller通过回调向对应的Broker发送StopReplicaRequest，若为false则Controller不会在/admin/delete_topics上注册Watch，也就不会对该事件作出反应。
3. 对于创建Topic操作，Controller从/brokers/ids读取当前所有可用的Broker列表，对于set_p中的每一个Partition：
    * 从分配给该Partition的所有Replica（称为AR）中任选一个可用的Broker作为新的Leader，并将AR设置为新的ISR（因为该Topic是新创建的，所以AR中所有的Replica都没有数据，可认为它们都是同步的，也即都在ISR中，任意一个Replica都可作为Leader）
    * 将新的Leader和ISR写入/brokers/topics/[topic]/partitions/[partition]
4. 直接通过RPC向相关的Broker发送LeaderAndISRRequest。

创建Topic顺序图如下所示。

![](http://cdn4.infoqstatic.com/statics_s1_20160405-0343u1/resource/articles/kafka-analysis-part-3/zh/resources/0606003.png)

有两点说明：

* 对于`auto.create.topics.enable=false`的Kafka，如果对未存在的topic进行produce，则会导致producer `org.apache.kafka.common.errors.TimeoutException`错误。
* 除了使用broker进行创建Topic，还可以通过Kafka的AdminUtils直接指定zk、topic、partitions，replicationFactor，把相关信息写入zk来创建Topic。

### Alter/Describe 

alter/describe 是对配置修改或查看的操作，包括Topic和Client两个部分。改变方法也是通过Kafka的AdminUtils和ConfigCommand，指定zk、topic或要修改的properties。

### ClusterAction

### Read


### Write

## Ranger



