---
layout: post
title: "Design Patterns for MapReduce Algorithms"
date: 2015-07-26 17:23
comments: true
category: Big Data
tags: [mapreduce]
---

参考《MapReduce设计模式》，做个总结。

## 概要模式

### 数值概要

**问题描述：**求一堆数据的一个高层次展示，平均值，中位数，最大，最小，标准差这类的特征值。
	
假设θ是我们想要执行的聚合方法，要计算的值是列表values（v1, v2, v3,…, vn)），要想求出聚合值λ， 令：λ=θ(v1, v2, v3, …, vn) 。
	
**解决方案：**
	
* 使用combiner

	如果函数θ满足结合律和交换律，那么就可以使用combiner来减少中间数据的传输量。
	
	为了得到最终要的那个统计值，是否一定要把所有的数据都传递给reduce，是不是可以先小范围的做些汇总。比如求最大值。 得出每一part的最大值后，再比较得出最大值。那么任意打乱顺序（交换律），任意将数据组成part（结合律），都不会影响最终结果

	再比如算中位数，那么可能就无法使用combiner优化了。中位数不满足交换律和结合律。比如θ函数表示求中位数，那么显然 （1,1,1,1,1,2,2,3,3）这组数据不同的组合结果不同：
	
		θ( θ(1,1,1), θ(1,2,2), θ(1,3,3) ) = 2
		θ( θ(1,1,1), θ(1,1,2), θ(2,3,3) ) = 1
		
* 定制partition

	数据倾斜严重的会造成reduce处理的数据量差异很大。建议采样分析或者根据之前的经验重新实现partition。
	
	该策略也适用于其他任何mapreduce程序，线上也时常能碰到partition分桶严重不均的情况，曾经发现一个任务其余reduce都是在秒级跑完，而其中一个reduce跑了10几个小时，查看该任务的partition分布，发现这个reduce处理的量比其他的多好几个数量级。
	
* 内存优化版的中位数和标准差程序

	前面提到，求中位数的函数不满足交换律和结合律。 因此无法简单的使用combiner。因此就设计了一种新的存储方式。
	
	 (1,1,1,1,2,2,3,4,5,5,5)这样的数据集合可以存储为：(1→4, 2→2, 3→1, 4→1, 5→3)
	 
	 实际情况下，这种优化在数据重复率高的情况下，收益明显。另外，考虑到reduce端需要排序，而combiner内排序无意义，因此重新实现下combiner用hashmap来存储上面的数据结构。（reduce端用SortedMapWritable）
	 
## 过滤模式

### 过滤

**问题描述：**针对每一条记录，基于某个条件作出判断，决定这条记录是应该保留还是放弃。

**解决方案：**

* 可以不使用reduce
	
	如果只是为了过滤，那么可以不加reduce。结果会输出多个part-m-文件。
	
	但是，如果保留下的数据量很小，就会造成大量小文件。如果是永久存储的，为了节省inode以及后续处理这些文件时不至于浪费大量map去处理。那么可以考虑用一定数量的reduce收集结果。
	
* 布隆过滤

	利用布隆过滤器来替代字典，每条记录查询布隆过滤器来决定去留。
	
	其优点是省内存。缺点或者说特点是：只能判断no或者maybe，但是不能判断yes。(有一定概率的fase-positive)
	
	而对于线上实际，可以采用分层的架构，在布隆过滤器下游再加一个精确的过滤来处理。如果需求仅仅是要判断不存在或可以容忍fase-positive，那就可以直接使用。
	
	布隆过滤器训练的结果如果不是经常变更，那么可以保存下来每次复用。然后将该结果作为分布式cache分发到各个map端。
	
### Top10

**问题描述：**求一个大数据集合的的top 10的数据。

**解决方案：**

* key设置为null，每个map数据拼接到一行。

	mapper遍历数据拿到top 10之后，将这10个数据拼接，组成一个value, 然后设置key为null。这样，key都是null，节省了shuffle排序的开销。 
	
**性能分析：**

* 由于reduce只能有一个，因此这个单点在数据不断增长的情况下迟早会成为瓶颈。
* 对于 Top K的模型，K值很大时，reduce会更快的达到瓶颈。
* 可以多跑几轮map的逻辑。比如reduce设置多个，每个也是产出top 10，然后再起一轮mapreduce。
* ChainMapper/ChainReducer
* 使用全排序，运行成本要看具体情况

###去重

**解决方案：**

		map(key,record):
		emit record,null
		reduce(key,records):
		emit key

这种去重方法是无法保持数据原来的顺序的

##连接模式

### reduce端连接
就是在reduce端执行各种连接操作，map会将所有数据传给reduce。该操作耗带宽，io等资源。

但是，这种方式的可伸缩性强，数据集大的情况下，通过增加reduce个数就可以处理。甚至，在所有的数据集都非常大的情况下，这种方式可能是唯一的选择。

在map端使用布隆过滤器来减少传递给reduce的量.

<img src="http://img.my.csdn.net/uploads/201301/09/1357709896_1263.jpg" width="500px"/>

### Replicated Join

复制join是一种特殊的join，用于一个大数据和许多小数据集map端执行的情况。能够消除reduce阶段的shuffle。

如果其中一个数据集很小，可以全部放入内存，那么只要将这个文件作为分布式cache分发即可。因此，这种情况值适用于内连接和大数据集在左边的左外连接。

<img src="http://img.my.csdn.net/uploads/201301/10/1357790552_4334.jpg" width="300px"/>

### Composite Join

复合join是一种特殊的join操作用来执行map端的很多大数据集的join。该模式对数据有一定的要求。就是需要连接的两份数据已经按照相同的标尺切分好了，并且是排好序的.

<img src="http://img.my.csdn.net/uploads/201301/10/1357790574_9671.jpg" width="350px"/>

### 笛卡尔积

数据集中的每条记录都与另个数据集的每条记录两两匹配。这是一个非常重型的操作。假设两个数据集都是1万条数据，那么将匹配1亿次。随着数据量的增长，算法复杂度指数级增长。

<img src="http://img.my.csdn.net/uploads/201301/10/1357790607_3097.jpg" width="500px"/>



