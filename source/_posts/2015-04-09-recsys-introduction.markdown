---
layout: post
title: "Recommender System in a Nutshell"
date: 2015-04-10 14:00
comments: true
category: "Machine Learning"
tags: [ml, intro, unfinished]
---

推荐系统（Recommender System An Introduction）读书笔记。

<!--more-->

## 基于内容的推荐系统

基于内容的推荐：基于两类信息，`物品特征的描述`和描述用户兴趣的`用户记录`（比如喜爱的物品特点）。

一般工作原理是评估用户还没有看到的物品与当前用户过去喜欢的物品的相似度。那么如何表示物品的内容以及相似度？

描述物品目录最简单的方法就是维护每个物品特征的详细列表，**属性集、特征集或物品记录**。另外可以使用`关键词列表`表示文档内容，好处是能够从文档内容本身自动生成列表。

为了防止`通用词`和`长文档`带来的推荐结果偏置，一般会使用TF-IDF计算关键词的权重。给出下列公式：

$$ TF(i, j) = \frac{freq(i,j)}{maxOthers(i,j)},\ IDF(i) = log\frac{N}{n(i)} $$

$$ TF-IDF(i, j) = TF(i,j) \cdot IDF(i) $$

$TF(i,j)$ 表示文档 $j$ 中关键词 $i$ 的`归一化词频值`，$freq(i,j)$ 表示 $i$ 在 $j$ 中出现的绝对频率； $maxOthers(i,j)$ 表示 $j$ 中其他关键词的最大词频。 $N$ 为所有可推荐文档数量，$n(i)$ 为关键词 $i$ 出现过文档的数量。

归一化是针对长文档，IDF 是针对通用词

从文本中抽取关键词并赋予权值的做法局限性为

* 向量通常大而稀疏，通过以下几种技术改进：
    * 停用词和词干还原
    * 特征选择，仅用信息量最大的一些词来减少文档描述规模，期望删除噪声。
    * 选用短语

* 没有考虑到文档上下文

User-CF为“推荐相似用户喜欢的物品”，基于内容的推荐可以描述成“推荐与用户过去喜欢的物品相似的物品”。通常的基于内容相似度检索技术为：

* KNN
    * 用余弦相似度评估两个文档的向量是否相似；
    * 可以考虑用户的短期兴趣和长期兴趣，适合于个性化的新闻推荐；
    * 易于实现，能够快速适应新近变化，只需要相对少的评分数据；
    * 预测精确度较低。
* 相关项反馈——Rocchio方法

另外可以将基于内容的推荐看成分类问题。

典型的是朴素贝叶斯方法，基本上有两种对文档及其特征建模的方法：**多项式模型和伯努利模型**，二者都忽略词的`位序`问题。多元伯努利模型中，文档被处理成一个二进制向量，描述某个词是否包含在文档中；多项式模型中，考虑词出现在文档中的次数，分类结果会比莫努力模型好些。

在多项式模型中，词 $v_i$ 出现在 $c$ 类文档的条件概率为：

$$ P(v_i | C=c) = \frac{CountTerms(v_i, docs(c))+1}{AllTerms(docs(c))+\vert V \vert}$$

上式采用`拉普拉斯平滑`以防止条件概率为 0，$\vert V \vert$ 为所有文档中不同词的数量。

朴素贝叶斯分类器能够达到很高的精确度，并且其组成部分能够在获得新数据时很容易更新，且学习时间复杂度随样本数量线性增加。

上文提到过`特征选择`问题，原始的大而稀疏向量会导致性能和内存需求问题，并且容易导致过拟合。典型的可以采用 $\chi^2$ 检验或 Fisher 判别指标。

$\chi^2$ 检验是检测两个时间是否不相干的标准统计方法。在特征选择中，根据训练数据分析某种分类结果是否与某个具体词的出现有联系。基于$\chi^2$ 检验来选择特征，首先按词的$\chi^2$ 值大小降序排列；其次需要确定用于分类器的理想特征数目。

基于内容的推荐系统有许多局限：

* **浅层内容分析**。
* 推荐结果缺乏新颖性，倾向于给出相同的推荐。
* 冷启动问题，需要来自用户的初始评分集合。

## 协同过滤

协同过滤推荐方法的主要思想：利用已有用户群过去的行为或意见预测当前用户最可能喜欢那些东西或对那些东西感兴趣。纯粹的协同方法输入只有用户-物品评分矩阵，输出可以为：

1. 当前用户对物品的评分
2. TopN推荐物品列表

### 基于用户的最近邻推荐

这是一种早期方法，对当前用户没有见过的物品 $p$，利用近邻对物品的评价计算预测值。潜在的假设为：

1. 如果用户过去有相似的偏好，未来也会有相似的偏好
2. 用户偏好不会随着时间而改变

确定相似用户集，通常用的方法是Pearson相关系数。给定评分矩阵R，$\bar{r}_a$ 代表用户a的平均评分，用户a和用户b的相似度 $sim(a,b)$ 表示

$$ sim(a,b) = \frac{\sum_{p \in P}(r_{a,p}-\bar{r}_a)(r_{b,p}-\bar{r}_b)}{\sqrt{\sum_{p \in P}(r_{a,p}-\bar{r}_a)^2}\sqrt{\sum_{p \in P}(r_{b,p}-\bar{r}_b)^2}}$$

Pearson方法考虑到用户评分标准并不相同的事实，可以发现评分值之间存在的线性相关性。但是对于广受大众欢迎的物品相似度会更高，可以类似TF-IDF，引入反用户频率(IUF)计算。用户a对物品p的预测值如下：

$$pred(a,p) = \bar{r}_a + \frac{\sum_{b \in N}sim(a,b)(r_{b,p}-\bar{r}_b)}{\sum_{b \in N}sim(a,b)}$$

预测的时候可以降低近邻规模减少计算复杂度，可以将用户相似度定义一个具体的最小阈值，或者将规模大小限制为一个固定值，只考虑K个最近邻。阈值会影响可预测物品的覆盖率，但是K值不会影响，它却会带来bias-variance tradeoff。

对于基于用户的推荐系统，Pearson相关系数比其他方法更胜一筹，但是对于基于物品的推荐技术，余弦相似度会比Pearson相关度量表现更好。

基于物品的算法主要思想是利用物品相似度，而不是用户相似度。

在基于物品的推荐中，通常使用改进版的余弦相似度，在原有的基础上减去评分的平均值，得到的结果类似于Pearson方法，取值在-1到+1之间，公式如下：

$$ sim(a,b) = \frac{\sum_{u \in U}(r_{u,a}-\bar{r}_u)(r_{u,b}-\bar{r}_u)}{\sqrt{\sum_{u \in U}(r_{u,a}-\bar{r}_u)^2}\sqrt{\sum_{u \in U}(r_{u,b}-\bar{r}_u)^2}}$$

预测公式为加权评分综合：

$$pred(u,p) = \frac{\sum_{i \in ratedItems(u)}sim(i,p) \cdot r_{u,i}}{\sum_{i \in ratedItems(u)}sim(i,p)}$$

基于物品的推荐可以离线构建一个物品相似度矩阵加速线上预测。在线上，通过确定与p最相似的物品，并计算u对这些领巾物品评分的加权综合得到u对p的预测评分。

原则上这种方法对基于用户的推荐也适用，但是实际情况中，两个用户评分重叠情况非常少见，这就意味着一些其他的评分值可能影响到用户间的相似度。

在协同过滤中，会遇到数据稀疏和冷启动问题。这种挑战就是用相对较少的有效评分得到准确的预测。直接做法就是利用用户的附加信息，比如性别、年龄等帮助分类用户信息，这就涉及到利用矩阵的外部信息，也就是混合系统。

另外处理这些问题的方法还包括，基于图的方法，主要思想是利用假定用户品味的传递性，并由此增强额外信息矩阵；缺省投票；利用相似用户给出相似物品的评分。

冷启动是稀疏问题的一个特例，问题包括：如何处理新用户；如何处理为评分或购买的新物品。这两个问题都是通过混合方法解决，可以在推荐之前要求用户给出最低限度数量的评分。

上述的协同推荐技术是Memory-based CF Algorithm。另外一种是Model-based。包括

* 矩阵因子分解
* 关联规则挖掘
* 基于概率分析的推荐方法（预测问题看成分类问题）



